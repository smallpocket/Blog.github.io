<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zookeeper：目录]]></title>
    <url>%2F2019%2F08%2F20%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FZookeeper%EF%BC%9A%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[简介 中间件，提供协调服务。 作用于分布式系统，发挥其优势，可以为大数据服务。 支持Java，提供Java和C语言的客户端API。 Zookeeper的特性 一致性：数据一致性(非强一致性)，数据按照顺序分批入库。 原子性：事务要么成功，要么失败，不会局部化。 单一视图：客户端连接集群中的任一zk节点，数据都是一致的。 可靠性：每次对zk的操作状态都会保存在服务端。 实时性：客户端可以读取到zk服务端的最新数据。 Zookeeper作用 master节点选举：主节点挂了后，从节点就会接手工作，并且保证这个节点是唯一的，即首脑模式，从而保证我们的集群是高可用的。 统一配置文件管理：即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他所有服务器，此操作在云计算中运用很多（如修改了redis统一配置）。 发布与订阅，类似消息队列，dubbo发布者将数据存在znode中，订阅者会读取这个数据。 提供分布式锁，分布式环境中不同进程间争夺资源，类似于多线程中的锁。 集群管理，集群中保证数据的强一致性。 会将主节点的数据同步到子节点中。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构：中间件]]></title>
    <url>%2F2019%2F08%2F19%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[中间件中间件为软件应用提供了OS所提供的服务之外的服务，中间件不是OS的一部分，不是DBMS，也不是软件应用的一部分，而是能够让软件开发者方便地处理通信、输入和输出，能够专注于他们自己应用的部分。 三个领域的中间件： 远程调用和对象访问中间件：主要解决分布式环境下应用的互相访问问题，这也是支撑我们介绍应用服务化的基础。 消息中间件：解决应用之间的消息传递、解耦、异步的问题。 数据访问中间件：主要解决应用访问数据库的共性问题的组件。 分布式系统的Java中间件 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式：分布式事务]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[分布式事务提出问题基础概述 分布式事务就是将多个节点的事务看成一个整体处理。 分布式事务由事务参与者、资源服务器、事务管理器等组成。 事务参与者：例如下订单、扣除库存、支付的机器。 资源服务器：控制我们在用的订单状态、库存数量等。 事务管理器：帮助协调等功能。如果一个事务参与者挂掉了，由它进行通知其他两个。 应用实现两段式事务(2PC)与三段式事务(3PC)实际上很少有在用，都是在用变形 2PC： 预备 如果都就绪了，但是其中一个事务提交了之后立即宕机了，即对事务处理器而言是不知道事务是否处理成功了。 3PC： 在准备提交与已经提交中间加入了一个预备提交的阶段。 基于XA的分布式事务本质上也是一种两段式提交，MySQL、Oracle等基本都支持该XA事务。 基于消息的最终一致性方案常见场景： 扫码下单后，支付成功了，钱已经到了支付宝。此时要下单，然而下单失败了。 先下单，然后sleep，已经准备提交了。然后告诉订单去修改状态。如果订单状态修改成功了，则支付成功；否则支付失败。 好处：强一致性方案，不会出现资源浪费，要么成功要么失败。 缺陷：会对时间有一定影响。 消息中间件：rabbitMQ、rocketMQ(支持一些增强功能)等。 单机系统下的事务： 分布式系统下： 发送预备消息： TCC编程式补偿式事务Try-Confirm-Cancel。最优？ 启动事务：业务系统执行任务。 Try：尝试进行事务操作，根据返回结果，确定是否Confirm。 提交或回滚事务：如果Try的结果是有一个服务执行失败，则执行Cancel接口。 对于APP与业务系统，不需要关心接口的实现。并且通过Cancel进行补偿事务的错误。 对比 基于消息的事务是强一致性事务，存在资源浪费。 解决支付宝等支付问题，是非常有效的解决方案。即解决无法补偿的任务。 线程需要等待，如果很多基于消息的事务，则会很慢。 TCC事务是柔性事务。在try阶段要对资源做预留，在Confirm与Cancel阶段释放资源。 TCC事务时效性比基于消息的事务更好。 分布式事务的前世今生分布式事务框架全局事务服务(Global Transaction Service)：GTS。 蚂蚁金服分布式事务（Distributed Transaction-eXtended）：DTX，解决金融相关的强事务。 开源TCC框架（TCC-transaction） 开源TCC框架（ByteTCC） TCC-transaction参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo：实战]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FDubbo%EF%BC%9A%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Dubbo：Study]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FDubbo%EF%BC%9AStudy%2F</url>
    <content type="text"><![CDATA[Dubbo特性 启动检查： 服务启动过程中验证服务提供者的可用性。 验证过程出现问题，则阻止Spring容器的初始化。 服务启动检查可以尽早发现服务问题。但是如果A-&gt;B，B-&gt;A，则一定要关闭了，否则都启动不了了。 多协议支持，是服务间的通信协议，Protocol： 最常见的是dubbo，并支持RMI、Hessian、HTTP、Redis、Memcached等多种协议。 dubbo的长连接减少了握手时间，速度较快，并且NIO。 Dubbo负载均衡策略 Random LoadBalance。缺省值 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance。 轮循，生产环境用的比较多，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。即存在雪崩现象。 LeastActive LoadBalance 最少活跃调用数，生产环境用的比较多，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot;value=&quot;0,1&quot; /&gt; 缺省用160份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt; 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux：常用命令]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2FLinux%EF%BC%9A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux常用命令tab键会对Linux命令进行补全。两下tab会以该命令开头的所有命令打印出。 命令基本格式命令提示符 [root@localhost ~]# root：当前登录用户。 localhost：主机名。 ~：当前所在目录。 用户登录的家目录。root用户在/root。 普通用户在/home/user1/。 #（$）：超级（普通）用户的提示符。 命令格式命令 [选项] [参数] 注意： 个别命令使用不遵循此格式。 当有多个选项时，可以写在一起。 简化选项与完整选项。 -a在一些目录当中等于–all。 基本命令pwd命令显示当前所在目录：print working directory。 ls查询目录中的内容。ls [选项] [文件或目录] 选项： -a： 显示所有文件，包括隐藏文件。 -l： 显示详细属性。 第一列代表权限。默认为10位 -rw-r–r–。 第一位：文件类型（- 文件 d 目录 I 软链接文件，即快捷方式）。 2-4件：文件的所有者，u。r：读，w：写，x：执行。 5-7位：文件的所属组，g。相同用户相同权限的人放到一组。 8-10位：其他人，o，不能使用。 1-rwxr-xr-x 1 root root 347472 Jun 29 2017 xfs_copy 1 代表引用该文件的次数。 347472是字节。 Jun 29 2017代表最后修改的时间。 -d： 查看目录属性。 -h： 人性化显示文件大小。 -i： 显示inode。 文件处理命令目录处理命令 mkdir建立目录建立目录：mkdir -p [目录名]。 -p 递归创建。 英文名 make directory。 cd切换目录切换目录：cd [目录]change directory： cd ~ 回到家目录。 cd - 进入上次所在目录。 cd .. 进入上级目录。 cd . 进入当前目录。 相对路径进行查找 cd ../usr/local。 绝对路径：要从根目录进行制定，cd /etc/。 rmdir删除空白目录只能删除空白目录：remove empty directory。 rm 删除文件删除文件或目录：rm [选项] [文件或目录]：remove。 -r：删除目录。 -f：强制执行 false。 cp 复制命令cp [选项] [原文件或目录] [目标目录]：复制命令copy。 -r： 复制目录。 -p： 连带文件属性复制。 -d： 若源文件是链接文件，则复制链接属性。 -a： 相当于-pdr。 mv 移动mv [源文件或目录] [目标目录]。剪切或改名命令：move 文件处理命令 链接命令lnln 文件搜索命令findgrep文件权限命令chgrp 更改文件属组1chgrp [-R] 属组名 文件名 -R：递归更改文件属组，就是在更改某个目录文件的属组s时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。 chown 更改文件属主，也可以同时更改文件属组12chown [–R] 属主名 文件名chown [-R] 属主名：属组名 文件名 修改install.log的拥有者改为bin这个账号： 1chown bin install.log chomd 更改文件9个属性一种是数字，一种是符号。符号与分数的对应：r-4，w-2，x-1。 chmod 777 .bashrc或 chmod u = rwx , g = rx,o = r .bashrc 帮助命令压缩命令关机命令其他常用命令参考]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：InnoDB-锁与事务]]></title>
    <url>%2F2019%2F08%2F14%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9AInnoDB-%E9%94%81%E4%B8%8E%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[锁讨论InnoDB如何实现事务的隔离性的。 最大程度地利用数据库的并发访问 确保每个用户能以一致的方式读取和修改数据 将介绍InnoDB存储引擎对表中的数据的锁定，同时分析InnoDB存储引擎会以怎样的粒度锁定数据。 人们认为行级锁的一个神话：人们认为行级锁总会增加开销。实际上，只有当实现本身会增加开销时，行级锁才会增加开销。InnoDB存储引擎不需要锁升级，因为一个锁和多个锁的开销是相同的。 什么是锁锁机制用于管理对共享资源的并发访问。InnoDB存储引擎在行级别上对表数据上锁，页会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。如缓冲池的LRU列表。 InnoDB锁提供： 一致性的非锁定读。 行级锁支持，且行级锁没有额外开销，同时得到并发性和一致性。 MyISAM： 表级锁，不支持行级锁。 lock与latchlock与latch都被称为锁，但具有截然不同的含义 latch称为轻量级锁，要求锁定的时间必须非常短。若持续时间长，则性能会非常差。 其对象为线程，保护内部数据结构，存在于每个数据结构的对象中。 分为mutex互斥量和rwlock读写锁。 保证并发线程操作临界资源的正确性，并没有死锁检测机制。 lock用来锁定的是数据库中的对象，如表、页、行。 其对象为事务，持续整个事务过程。 分为包含行锁、表锁、意向锁。 lock的对象仅在commit或rollback后释放。 存在死锁机制。通过waits-for graph、time out等机制进行死锁检测于处理。 存在于Lock Manager的哈希表中。 InnoDB存储引擎中的锁锁的类型InnoDB存储引擎实现了两种标准的行级锁。 共享锁S LOCK，允许事务读一行数据。 排他锁X LOCK，允许事务删除或更新一行数据。 兼容性： X S X 不兼容 不兼容 S 不兼容 兼容 InnoDB存储引擎支持多粒度锁定，允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，支持一种额外的锁方式：意向锁。 意向锁：将锁定的对象分为多个层次，意味着事务希望在更细粒度上加锁。 如果希望对记录上锁，则分别需要对数据库、表、页上意向锁IX，最后对记录上X锁。 若其中任一个部分导致等待，那么该操作需要等待粗粒度锁的完成 如有事务在表1进行了S锁，则由于需要IX锁不兼容，需要等待 InnoDB存储引擎支持的意向锁是表级别的锁 意向共享锁，事务想获得一张表中某几行的共享锁 意向排他锁，事务想获得一张表中某几行的排他锁 查看当前锁请求的信息show engine innodb status可以查看当前锁请求的信息： select * from table.innodb_locks\G 一致性非锁定读多版本并发控制（Multi-Version Concurrency Control, MVCC）是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用MVCC无法实现。 如果读取的行正在执行DEL或update操作，这时读取操作不会因此去等待行上锁的释放，而是会去读行的一个快照数据。 快照数据是指该行的之前版本的数据。该实现是通过undo段来完成。undo用来在事务中回滚数据。 快照数据本身没有额外的开销，并不需要上锁，因为没有事务需要对历史的数据进行修改。 非锁定读：不需要等待访问的行上X锁的释放。因此非锁定读机制极大地提高了数据库并发性。 是默认的读取方式。 在不同事务隔离级别下读取方式不同。 即使都是使用非锁定的一致性读，对快照数据的定义也各不相同。 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列 MVCC在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：指示创建一个数据行的快照时的系统版本号。 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo日志 MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程 以下实现过程针对可重复读隔离级别。 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。 1. SELECT 多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为T，T所要读取的数据行快照的创建版本号必须小于T的版本号，因为如果大于或者等于T的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T所要读取的数据行快照的删除版本号必须大于T的版本号，因为如果小于等于T的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 2. INSERT 将当前系统版本号作为数据行快照的创建版本号。 3.DELETE 将当前系统版本号作为数据行快照的删除版本号。 4. UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行DELETE后执行INSERT。 快照读与当前读 快照读 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 1select * from table ...;Copy to clipboardErrorCopied 当前读 读取的是最新的数据，需要加锁。以下第一个语句需要加S锁，其它都需要加X锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update;delete; 快照定义 在READ COMMITED和REPEATABLE READ下，采用非锁定的一致性读。但是快照数据的定义不同 已提交读下，总是读取被锁定行最新一份快照数据： 在事务开始后，有其他的事务对该行数据进行了修改并commit，则会出现对一个数据的读取，两次结果不一致。 因为每次会读取最新一份快照。 可重复读下，总是读取事务开始时的行数据版本。 即只要事务开始了，在该次事务当中，对同一个数据的读取，永远不会改变。 MVCC从上图6-4可以看到，快照数据是当前行数据的历史版本，因此可能存在多个版本，即存在不止一个快照数据。由此带来的并发控制称为多版本并发控制（MVCC）。 一致性锁定读在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。 InnoDB存储引擎对于Select语句支持两种一致性锁定读操作，这些操作必须在一个事务当中： select … for update。 对读取的行记录加一个X锁，其他事务不能对已经锁定的行加任何锁。 select … lock in share mode。 对读取的行记录加一个S锁，其他事务可以加S锁。 自增长与锁外键和锁对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎会自动对其加一个索引，因为可以避免表锁。 对于外键值的插入和更新： 首先向父表查询，并使用select … lock in share mode，以防止数据不一致的问题。如果使用一致性非锁定读会产生数据不一致问题。 锁的算法Record Locks锁定一个记录上的索引，而不是记录本身，即不是行数据。Read Committed下采用。 Record locks会锁住索引记录（而不是行数据），如果表没有设置索引，InnoDB会自动在主键上创建隐藏的聚簇索引，因此Record Locks依然可以使用。 Gap Locks间隙锁，锁定一个范围，但不包含记录本身。作用是阻止多个事务将记录插入到同一范围内，会导致Phantom Problem问题的产生。 如果对于辅助索引b，会话A锁定了b=3的记录。 若没有gap Lock锁定(3,6)，则用户可以插入索引b=3的记录。 此时会话A再次查询时，会返回不同的记录。 而使用了gap locks后，例如当一个事务执行以下语句，其它事务就不能在t.c中插入 15。 1SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; locking reads，UPDATE和DELETE时，除了对唯一索引的唯一搜索外都会获取gap锁或next-key锁，即锁住其扫描的范围。 如果表扫描没有用到索引，则会锁住整个表。 READ COMMITTED 123For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE), UPDATE statements, and DELETE statements, InnoDB locks only index records, not the gaps before them, and thus permits the free insertion of new records next to locked records. 只会锁住已有记录，不会加gap锁。 SERIALIZABLE 12This level is like REPEATABLE READ, but InnoDB implicitly converts all plain SELECT statements to SELECT ... LOCK IN SHARE MODE if autocommit is disabled. 和REPEATABLE READ的主要区别在于把普通的SELECT变成SELECT … LOCK IN SHARE MODE，即对普通的select都会获取gap锁或next-key锁。 Next-Key LockNext-Key Lock：Gap Lock+Record Lock，锁定一个范围，并锁定记录本身。 Repeadtable Read采用。 如果查询用到的索引有10，11，13，20，则该索引可能被Next-Key锁定的区间为(-无穷，10]，(10,11]，(11,13]，(13,20]，(20,+无穷）。 当查询的索引含有唯一属性（主键），则优化为Record Lock，如主键。即此时查询是wan’quan 对于辅助索引，会对包含该键值的上下两个区间上锁，上区间加next-key lock，下区间加gap lock。 如11，则上区间(10,11]，下区间(11,13)。 锁算法规则InnoDB存储引擎的锁算法的一些规则如下所示： 在不通过索引条件查询时，InnoDB 会锁定表中的所有记录。所以，如果考虑性能，WHERE语句中的条件查询的字段都应该加上索引。 InnoDB通过索引来实现行锁，而不是通过锁住记录。因此，当操作的两条不同记录拥有相同的索引时，也会因为行锁被锁而发生等待。 由于InnoDB的索引机制，数据库操作使用了主键索引，InnoDB会锁住主键索引；使用非主键索引时，InnoDB会先锁住非主键索引，再锁定主键索引。 当查询的索引是唯一索引(不存在两个数据行具有完全相同的键值)时，InnoDB存储引擎会将Next-Key Lock降级为Record Lock，即只锁住索引本身，而不是范围。 InnoDB对于辅助索引有特殊的处理，不仅会锁住辅助索引值所在的范围，还会将其下一键值加上Gap LOCK。 InnoDB使用Next-Key Lock机制来避免Phantom Problem（幻读问题）。 解决Phantom Problem幻像问题InnoDB存储引擎使用Next-Key Lock避免幻像问题。 Phantom Problem幻像问题：同一个事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。 锁问题锁提高了并发，但会带来潜在的问题。 脏读脏读即读取到了脏数据，存在的级别为Read Uncommitted 脏数据：事务对缓冲池中行记录的修改，并且还没有被提交 如果读到了脏数据，即一个事务读取到另一个事务未提交的数据，违反了数据库的隔离性 脏页：在缓冲池已经被修改的页，但还没有刷新到磁盘中 由于内存与磁盘的一步造成，不影响数据的一致性，并且最终会到达一致性 不可重复读在一个事务内多次读取同一数据集合，在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。因此在第一个事务中的两次读数据间，由于第二个事务的修改，第一个事务两次读取到的数据可能不一样。 与脏读的区别： 脏读读到未提交的数据，不可重复读读取到已经提交的数据。 不可重复读违反了数据库事务一致性的要求。 由于读取到的是已经提交的数据，一般而言不会带来很大问题，因此一些数据库允许该现象。 丢失更新一个事务的更新操作会被另一个事务的更新操作所覆盖，导致数据的不一致： 事务T1将行记录r更新为v1，但是事务T1未提交。 同时，事务T2将行记录r更新为v2，事务T2未提交。 事务T1提交。 事务T2提交。 在任何隔离级别下都不会发生，但可能出现另一个问题： 事务T1查询一行数据，放入本地内存，显示给一个用户U1。 同时，事务T2查询该记录，显式给用户U2。 U1修改这行记录，更新并提交。 U2修改这行记录，更新并提交。此时没有去读取新的数据。 银行转账场景下会出现问题。 阻塞由于不同锁间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它占用的资源。 参数innodb_lock_wait_timeout用来控制等待的时间，默认是50s；innodb_rollback_on_timeout用来设定是否在等待超时时对进行中的事务进行回滚操作，默认为false； 死锁锁升级锁升级是指将当前锁的粒度降低。例如将一个表的1000行锁升级为一个页锁。 升级保护了系统资源，防止系统使用太多内存来维护锁，一定程度上提高了效率。 InnoDB存储引擎不会有锁升级。因为根据页进行加锁，并采用位图方式，开销很小。如果对3000000数据页，每页100记录进行加锁，如果每个页存储的锁信息占用30个字节，锁对象仅需要90MB。 事务事务指的是满足ACID特性的一组操作，可以通过Commit提交一个事务，也可以使用Rollback进行回滚。 ACID： 原子性（atomicity，或称不可分割性）。一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 一致性（consistency）。在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 隔离性（isolation，又称独立性）。数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（durability）。事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 使用重复日志来保证持久性 这几个特性不是一种平级关系： 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 AUTOCOMMITMySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询都会被当做一个事务自动提交。 事务的使用 transaction rollback commit savepoint：指事务处理中设置的临时占位符，可以对它发布回退，而不是回退整个事务 123456select * from ordertotals;start transactionsavepoint delete1;delete from ordertotals;rollback(commit);(rollback to delete1) 认识事务从事务理论的角度来说，可以将事务分为以下几种类型： 扁平事务。 带有保存点的扁平事务。 链事务。 嵌套事务。 分布式事务 事务的分类扁平事务： 所有操作都处于同一层次，由begin work开始Commit work或rollback work结束，其间的操作都是原子的，要么都执行要么都回滚。 带有保存点的扁平事务： 在扁平事务的基础上，允许事务执行过程中回滚到同一事务中较早的一个状态。保存点用来停止系统应该记住事务当前的状态，以便当之后发生错误时，事务能够回到保存点当时的状态。 当系统崩溃时，所有保存点都会消失，其保存点并非持久的。 链事务： 保存点事务的一种变种。在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。提交事务操作与开始下一个事务操作将合并为一个原子操作，意味着下一个事务可以看到上一个事务的结果。 嵌套事务： 是一个层次结构框架，由一个顶层事务控制着各个层次的事务，顶层事务下嵌套的事务被称为子事务，其控制着每一个局部的变换。 嵌套事务是由若干事务组成的一棵树，子事务既可以是嵌套事务，也可以是扁平事务。 处在叶结点的事务是扁平事务，但每个子事务从根到叶结点的距离可以是不同的。 子事务可以提交也可以回滚，但是它的提交操作不会马上生效，除非父事务已经提交，即所有子事务必须在顶层事务提交后才真正提交。 树的任一个事务回滚都会引起它所有子事务一起回滚。 分布式事务： 通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。 事务的隔离级别 隔离级别 脏读 不可重复读 幻读 未提交读 Read uncommitted 可能 可能 可能 已提交读 Read committed 可能 可能 可重复读 Repeatable read 不可能 不可能 可能 可串行化Serializable 不可能 不可能 不可能 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)。 脏读：即读取到了脏数据。 脏数据：事务对缓冲池中行记录的修改，并且还没有被提交。 如果读到了脏数据，即一个事务读取到另一个事务未提交的数据，违反了数据库的隔离性。 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。 不可重复读：读取到其他事务已经提交的数据： 在一个事务内多次读取同一数据集合，在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。因此在第一个事务中的两次读数据间，由于第二个事务的修改，第一个事务两次读取到的数据可能不一样。 不可重复读违反了数据库事务一致性的要求。 由于读取到的是已经提交的数据，一般而言不会带来很大问题，因此一些数据库允许该现象。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞： 幻读：不可重复读的一种特殊场景： 幻读是指当事务不是独立执行时发生的一种现象。 事务A读取与搜索条件相匹配的若干行。事务B以插入或删除行等方式来修改事务A的结果集，然后再提交。 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检索范围为只读，这样就避免了幻读。 默认的隔离级别：可重复读Repeated Read。采用Next-KeyLock算法避免锁的产生。 同时使用隔离级别的开销基本一致。因此即使使用未提交读也不会得到性能的大幅提升。 事务的实现事务的原子性、一致性、持久性通过数据库的redo log和undo log完成 redo log保证事务的原子性和持久性，恢复提交事务修改的页操作，是物理日志，记录页的物理修改操作。 undo log保证事务的一致性，回滚行记录到某个特定版本，是逻辑日志，根据每行记录进行记录。 redoredo由两部分组成： 内存中的重做日志缓冲redo log buffer是易丢失的 重做日志文件redo log file是是持久的。 InnoDB通过force log at commit机制实现事务的持久性，即当事务提交时，必须先将事务的所有日志写入到重做日志文件进行持久化，待事务的Coomit操作完成才算结束。 在每次将重做日志缓冲写入重做日志文件后，InnoDB都需要调用一次fsunc操作，因此磁盘性能决定了事务提交的性能。 purgepurge负责最终完成delete和update操作，由于MVCC，记录不能在事务提交时立即进行处理。 如果记录不被任何其他事务所引用，那么就可以真正进行delete操作。 group commit若事务为非只读事务，则每次事务提交需要进行一次fsync操作，以确保操作日志都写入磁盘了，而group commit使得一次fsync可以刷新确保多个事务日志文件被写入文件。 分布式事务MySQL数据库分布式事务InnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持对分布式事务的实现。 分布式事务：允许多个独立的事务资源参与到一个全局的事务中。 事务资源：通常是关系型数据库系统，页可以是其他类型的资源。 全局事务要求在其中的所有参与的事务要么都提交，要么都回滚。 实现分布式事务，InnoDB存储引擎的事务隔离级别必须为Serializable。 XA事务允许不同数据库键的分布式事务，如MySQL、oracle数据库，只要参与全局事务中的每个节点都支持XA事务。 XA事务由一个或多个资源管理器、一个事务管理器以及一个应用程序组成。 资源管理器：提供访问事务资源的方法，通常一个数据库就是一个资源管理器。 事务管理器：协调参与全局事务中的各个事务，需要和参与全局事务的所有资源管理器进行通信。 应用程序：定义事务的边界，指定全局事务中的操作。 分布式事务的实现 采用两段式提交的方式： 第一阶段：所有参与全局事务的节点都开始准备，告诉事务管理器它们准备好提交了。 第二阶段：事务管理器告诉资源管理器执行ROLLBACK或COMMIT。 与本地事务不同的是，分布式事务要多一次prepare工作，待收到所有节点的同意信息后，再进行commit或者rollback。 Java实现Java的JTA可以很好的支持MySQL的分布式事务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class MyXid implements Xid&#123; public int formatId; public byte gtrid[]; public byte bqual[]; //get方法 //构造器&#125;public class XaDemo &#123; public static MysqlXADataSource getDataSource(String connStr, String user, String pwd) &#123; try &#123; MysqlXADataSource ds = new MysqlXADataSource(); ds.setUrl(connStr); ds.setUser(user); ds.setPassword(pwd); return ds; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] arg) &#123; String connStr1 = "jdbc:mysql://192.168.0.1:3306/test"; String connStr2 = "jdbc:mysql://192.168.0.2:3306/test"; try &#123; //从不同数据库获取数据库数据源 MysqlXADataSource ds1 = getDataSource(connStr1, "root", "123456"); MysqlXADataSource ds2 = getDataSource(connStr2, "root", "123456"); //数据库1获取连接 XAConnection xaConnection1 = ds1.getXAConnection(); XAResource xaResource1 = xaConnection1.getXAResource(); Connection connection1 = xaConnection1.getConnection(); Statement statement1 = connection1.createStatement(); //数据库2获取连接 XAConnection xaConnection2 = ds2.getXAConnection(); XAResource xaResource2 = xaConnection2.getXAResource(); Connection connection2 = xaConnection2.getConnection(); Statement statement2 = connection2.createStatement(); //创建事务分支的xid Xid xid1 = new MysqlXid(new byte[] &#123; 0x01 &#125;, new byte[] &#123; 0x02 &#125;, 100); Xid xid2 = new MysqlXid(new byte[] &#123; 0x011 &#125;, new byte[] &#123; 0x012 &#125;, 100); try &#123; //事务分支1关联分支事务sql语句 xaResource1.start(xid1, XAResource.TMNOFLAGS); int update1Result = statement1.executeUpdate("update account_from set money=money - 50 where id=1"); xaResource1.end(xid1, XAResource.TMSUCCESS); //事务分支2关联分支事务sql语句 xaResource2.start(xid2, XAResource.TMNOFLAGS); int update2Result = statement2.executeUpdate("update account_to set money= money + 50 where id=1"); xaResource2.end(xid2, XAResource.TMSUCCESS); // 两阶段提交协议第一阶段 int ret1 = xaResource1.prepare(xid1); int ret2 = xaResource2.prepare(xid2); // 两阶段提交协议第二阶段 if (XAResource.XA_OK == ret1 &amp;&amp; XAResource.XA_OK == ret2) &#123; xaResource1.commit(xid1, false); xaResource2.commit(xid2, false); System.out.println("reslut1:" + update1Result + ", result2:" + update2Result); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; 内部XA事务 之前的分布式事务时外部事务，即资源管理器是MySQL数据库本身。 另一种分布式事务在存储引擎与插件间，或者存在于存储引擎与存储引擎间，称为内部XA事务。 常见的为binlog与InnoDB存储引擎间。 参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：InnoDB-表与文件]]></title>
    <url>%2F2019%2F08%2F14%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9AInnoDB-%E8%A1%A8%E4%B8%8E%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[文件参数文件日志文件 redo log重做日志 undo log回滚日志 bin log二进制日志 error log错误日志 slow query log慢查询日志 relay log中继日志 redo log作用 确保事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘。在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。 内容 物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。 对于数据库内所有被更改的数据块（segment），Oracle会把所有更改内容清楚记录在REDO日志缓冲中。 所谓所有更改内容，当然包括数据段，还有索引段和回滚段（rollback segment）。 数据库内任意数据块所发生的一个更改，会被写成一个变更向量（Change Vector）。 修改向量里包含了更改的数据块的地址与更新的数据。 产生时间 在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存。 即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。 释放时间 当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。 log block 在InnoDB中重做日志都是以512字节存储的，即重做日志都是以块的方式保存的，即重做日志块，每块的大小为512字节。 重做日志块大小与磁盘扇区大小一样，都是512字节，因此写入可以保证原子性，不需要double write。 log group 重做日志组，其中有多个重做日志文件。 重做日志格式 header格式为： redo_log_type：重做日志的类型。 space：表空间的ID。 page_no：页的偏移量。 LSN Log Sequence Number，代表日志序列号，占用8字节并单调递增。其代表的含义有： 重做日志写入的总量。 checkpoint的位置。 页的版本。 恢复 InnoDB正在启动时不管上次数据库运行时释放正常关闭，都会尝试进行恢复操作。因为redo log记录的是物理日志因此恢复速度较快。 undo log作用： 保存了事务发生之前的数据的一个版本，可以用于回滚 可以提供多版本并发控制下的读（MVCC），也即非锁定读 内容： 逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。 什么时候产生：事务开始之前，将当前是的版本生成undo log，undo也会产生redo log来保证undo log的可靠性。 undo log存放于数据库内部的一个特殊段当中，称为undo段，位于共享表空间内。 什么时候释放：当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。 回滚 删除记录仅仅是将记录的delete flag置为1，记录并没有被删除。真正的删除在purge操作中进行。 bin log作用： 用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。 用于数据库的基于时间点的还原。 内容： 逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。 在使用mysqlbinlog解析binlog之后一些都会真相大白。因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。 什么时候产生： 事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。 因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。 什么时候释放： binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。 与redo log的不同 二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同 作用不同：redo log是保证事务的持久性的，是事务层面的，bin log作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。 内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，bin log是逻辑日志，可以简单认为记录的就是sql语句。 另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。 恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog。 套接字文件pid文件表结构定义文件InnoDB存储引擎文件表索引组织表InnoDB中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。每张表都会有一个主键，如果在创建表时没有显式定义主键则： 首先判断表中是否有非空的唯一索引，如果有则该列即为主键。选择时根据定义索引的顺序。 如果不符合上述条件，则自动创建一个6字节大小的指针。 InnoDB逻辑存储结构从逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，即表空间。表空间由段、区、页组成。 表空间是逻辑结构的最高层，所有数据都存放在表空间中。默认情况下是一个共享表空间，即所有数据都存在该表空间中；如果启用了innodb_file_per_table则每张表内的数据可以放到一个单独的表空间。 如果是独立表空间，则只存放数据、索引、插入缓冲Bitmap页。其他信息依然在共享表空间中。 段区页行InnoDB行记录格式InnoDB数据页结构Named File Formats 机制约束视图分区表参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法：Graph]]></title>
    <url>%2F2019%2F08%2F13%2F%E7%AE%97%E6%B3%95%2F%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%EF%BC%9AGraph%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常用算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：概述]]></title>
    <url>%2F2019%2F08%2F11%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[概述分类线性结构 数组 栈 队列 链表 哈希表 … 树结构 二叉树 二分搜索树 AVL 红黑树 Treap 堆 Trie 线段树 并查集 哈夫曼树 图结构图论领域以算法为主 邻接矩阵 邻接表 参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：栈和队列]]></title>
    <url>%2F2019%2F08%2F11%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[队列分类 普通队列。 优先队列。 以广义队列的角度来看，栈也可以理解为一个队列。 优先队列普通队列是FIFO的。优先队列的出队顺序与入队顺序无关，和优先级相关。 为什么要用动态选择优先级最高的任务执行。 概述与普通队列的最大区别是出队的操作。 实现接口： 入队与其他队列无区别。 出队需要找出优先级最高的元素。 底层数据结构 普通线性结构。入队O(1)出队O(N)。 顺序线性结构。使用排序好的线性结构，入队O(lg n)出队O(1)。 堆。入队O(lg n)出队O(lg n)。 适用性在N个元素选出前M个元素。在1000000个元素选出前100名。 JavaJava当中的优先队列：PriorityQueue&lt;E&gt;。 参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：数组]]></title>
    <url>%2F2019%2F08%2F11%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组提出问题问题案例概述是什么分类适用性优点 快速查询 应用 数组最好应用于索引有语义的情况 即score[2]代表第3个学生的成绩 解决的问题算法思想堆实现问题案例优化参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：链表]]></title>
    <url>%2F2019%2F08%2F11%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[提出问题问题案例概述是什么分类适用性优点应用解决的问题算法思想实现问题案例优化参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：JUC-AQS]]></title>
    <url>%2F2019%2F08%2F10%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJUC-AQS%2F</url>
    <content type="text"><![CDATA[J.U.C - AQS概述java.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是J.U.C的核心。 AQS：AbstractQueuedSynchronizer，即队列同步器。是许多同步类的基类，它是构建锁或者其他同步组件的基础框架。AQS解决了在实现同步器时设计的大量细节问题。 例如等待线程采用FIFO队列操作顺序 在不同的同步器当中还可以定义一些灵活的标准来判断某个线程是应该通过还是需要等待 适用性基于AQS构建同步器能够极大减少实现工作，而且也不必处理在多个位置上发生的竞争问题。在一般的同步器实现当中，获取许可的操作可能在两个时刻阻塞–当锁保护信号量状态时，以及当许可不可用时（LockSupport）。 基于AQS构建的同步器只可能在一个时刻发生阻塞，从而降低上下文切换的开销，并提高吞吐量，在设计AQS时充分考虑了可伸缩性，因此JUC中所有基于AQS的同步器都能获得这个优势。 实现在基于AQS构建的同步器类中，最基本的操作包括各种形式的获取操作和释放操作。 状态管理如果一个类想要成为状态依赖的类，那么它必须拥有一些状态，AQS负责关联同步器类中的状态，它管理了一个整数状态信息，可以通过getState()、setState()、compareAndSetState()等protected方法来操作。这个整数可以用来表示任意状态。 ReentrantLock用它表示所有者线程以及重复获取该锁的次数 Semaphore用它表示剩余的许可数量 FutureTask用来表示任务的状态 获取\释放操作获取操作是一种依赖状态的操作，并且通常会阻塞。当使用锁或信号量时，获取操作的含义就是获取锁或者许可，并且调用者可能会抑制等待直到同步器类处于可被获取的状态。对于CountDownLatch，意味着等待并直到闭锁到达结束状态。对于FutureTask意味着等待并直到任务以及完成。 根据同步器不同，获取操作可能是独占的，也可能时非独占的。一个获取操作包括两部分 同步器判断当前状态是否允许获得操作。 如果是则允许线程执行，否则获取操作将阻塞或失败，这由同步器的语义决定。 释放操作并不是可阻塞的操作，当执行释放操作时，所有在请求时被阻塞的线程都会开始执行。 1234567891011121314151617181920boolean acquire() throws InterruptedException&#123; while(当前状态不允许获取操作)&#123; if(需要阻塞获取请求)&#123; 如果当前线程不在队列中，则将其插入队列; 阻塞当前线程; &#125;else&#123; 返回失败 &#125; &#125; 可能更新同步器的状态; 如果线程位于队列中，则将其移出队列; 返回成功&#125;void release()&#123; 更新同步器的状态; if(新的状态允许某个被阻塞的线程获取成功)&#123; 解除队列中一个或多个线程的阻塞状态; &#125;&#125; 独占的获取操作如果某个同步器支持独占的获取操作，那么需要实现一些保护方法，包括tryAcquire、tryRelease、isHeldExclusivery等，而对于支持共享获取的同步器，则应该实现tryAcquireShared、tryReleaseShared等方法。AQS的accuire、acquireShared、release、releaseShared等方法都将调用这些方法在子类中带有前缀try的版本来判断某个操作。 源码LockSupportAQS应用ReentrantLock1234567891011121314protected boolean tryAcquire(int ignored)&#123; final Thread current = Thread.currentThread(); int c = getState(); if(c == 0)&#123; if(compareAndSetState(0, 1))&#123; owner = current; return true; &#125; &#125;else if(current == owner)&#123; setState(c+1); return true; &#125; return false;&#125; Semaphore123456789101112131415161718protected int tryAcquireShard(int acquires)&#123; while(true)&#123; int available = getState(); int remaining = available - acquires; if(remaining &lt; 0 || compareAndSetState(available, remaining))&#123; return remaining; &#125; &#125;&#125;protected boolean tryReleaseShared(int release)&#123; while(true)&#123; int p = getState(); if(compareAndSetState(p, p+releases))&#123; return true; &#125; &#125;&#125; CountDownLatchFutureTaskFutureTask.get的语义类似于闭锁(CountDownLatch)的语义，如果发生了某个事件(由FutureTask表示的任务执行完成或被取消)，那么线程就可以恢复执行，否则将停留在队列中并直到该事件发生， FutureTask使用AQS保存任务的状态。 ReentrantReadWriteLock使用单个AQS子类同时管理读锁与写锁，前16为状态表示写锁计数，后16为表示读锁计数。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：JUC-Executor]]></title>
    <url>%2F2019%2F08%2F07%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJUC-Executor%2F</url>
    <content type="text"><![CDATA[Exeutor执行器框架 Future RunnableFuture Callable Executor ThreadPoolExecutor CompletionService RejectedExecutionhandler ThreadPoolExecutor.DiscardPolicy TimeUnit Executor对于并发执行的任务，Executor提供了大量可调节的选项，例如创建、关闭线程的策略，处理队列任务的策略，饱和策略，并且提供了几个钩子方法进行扩展行为。 但是与大部分功能强大的框架一样，有一部分参数并不能很好的工作，某些类型的任务需要特定的执行策略，一些参数组合则可能产生奇怪的结果。 概述JUC提供了一种灵活的线程池实现作为Executor框架的一部分。线程池基于生产者-消费者模式，提交任务的执行者是生产者，执行任务的线程是消费者。 123public interface Executot&#123; void execute(Runnable command);&#125; 为灵活且强大的异步任务执行框架提供了基础 该框架能支持多种不同类型的任务执行策略。它提供了一种标准的方法将任务的提交过程与执行过程解耦 提供了对生命周期的支持，以及统计信息收集、应用程序管理机制以及性能监控等机制 示例 使用一个固定100线程的线程池 而且我们可以很容易地修改提交任务的方式，其对服务器的影响非常小： 12345public class ThreadPerTaskExecutor implements Executors&#123; public void execute(Runnable r)&#123; new Thread(x).start(); &#125;&#125; 执行策略任务的提交与任务的执行解耦，可以更简单地为一个类给定的任务制定执行策略。执行策略是一种资源管理工具，最佳策略取决于可用的计算资源以及对服务质量的需求，通过限制并发任务的数量，可用确保应用程序不会由于资源耗尽而失败，或者由于在稀缺资源上发生竞争而严重影响性能。 将任务的提交与任务的执行分离，有助于在部署阶段选择与可用硬件资源最匹配的执行策略。一个执行策略包含“what where when how”的因素 任务在什么线程执行 what 任务以什么顺序执行 what (FIFO,LIFO,优先级) 可以由多少个任务并发执行 how many 可以有多少个任务进入等待执行队列 how many 如果系统过载，需要放弃一个任务，选择哪一个任务？ which 如何通知应用程序有任务被拒绝 HOW 在一个任务执行之前与之后，应该做什么处理 what 生命周期由于exectuor异步执行任务，所以之前提交的任务状态不能立即可见（有些已经完成，有些正在运行，有些在队列当中），如果将其关闭，可能出现各种问题。 Executor扩展了ExecutorService，其有三种状态：运行、关闭和已终止。 方法 void shutdown()。执行平缓的关闭，不再接受新任务，并等待已提交的任务执行完成 List&lt;Runnable&gt; shutdownNow()。执行粗暴的关闭，尝试取消所有运行中的任务，并不再启动队列中尚未开始的任务 boolean isShutdown()。 boolean isTerminated()。轮询线程池终止 boolean awaitTermination(long timeout, TimeUnit unit) thorws InterruptedException。等待线程池到达终止，调用后通常会立即调用shutdown 当线程池关闭后，提交的任务将由“拒绝执行处理器Rejected Execution Handler”处理，将抛弃任务，或者排除一个未检查异常。 附加功能使用Executor可用实现各种调优、管理、监视、记录日志、错误报告和其他功能。 适用性 只有当任务都是同类型的并且相互独立时，线程池的性能才能达到最佳。 如果将运行时较长于运行时间较短的任务混合一起，除非线程池很大，否则很可能拥塞 如果提交的任务依赖于其他任务，除非线程池无限大，否则可能死锁。 如果执行时间较长的任务存在很大的影响，则可以限定任务等待资源的时间，而不是无限制等待。 为什么要用new Thread弊端 每次新建对象，性能差 线程缺乏统一管理，可能无限新建线程，相互竞争，有可能占用过多系统资源导致死机或OOM 缺少更多功能，如更多执行、定期执行、线程中断 线程池好处 重用存在的线程，减少对象创建、消亡的开销 可有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 提供定时执行、定期执行、单线程、并发控制等功能 在任务与执行策略间的隐性耦合虽然Executor框架可以将任务的提交与任务的执行策略解耦开来，但是这种论断有一点言过其实。虽然Executor为制定和修改执行策略都提供了相当大的灵活性，但并非所有的任务都能适用所有的执行策略。有些类型的任务需要明确指定执行策略 依赖性任务。如果提交给线程池的任务需要依赖其他任务，那么就隐含地给执行策略带来了约束，此时必须小心维持这些执行策略以避免产生活跃性问题 使用线程封闭机制的任务。单线程的Executor能够对并发性做出更强的承诺，能确保任务不会并发执行，使你放宽代码对线程安全的要求。则此时当线程池更改将失去线程安全性 对响应时间敏感的任务。如果将应该运行时间较长的任务提交给单线程的Executor将导致性能下降 使用ThreadLocal的任务。ThreadLocal使得线程可以拥有某个变量的私有版本。但是只要条件允许，Executor可以自由重用这些线程。因此只有当线程本地值的生命周期受限于任务的生命周期，线程池中使用ThreadLocal才有意义。 线程池 可用重用现有的线程而部署创建新线程，可用在处理多个请求时分摊在线程创建和销毁过程中产生的巨大开销 当请求到达时，工作线程通常已经存在，因此不会由于等待创建线程而延迟任务的执行 可通过调整线程池大小，创建足够的线程以便使处理器保持忙碌，并防止多线程相互竞争导致 是什么线程池是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销 线程池包括四个基本组成部分 线程管理器：用于创建并管理线程池，包括创建线程、销毁线程池、添加新任务 工作线程：线程池中线程，在没有任务时处于等待状态，可以循环地执行任务 任务接口：每个任务必须实现的接口，以供工作线程调度任务的执行，主要规定了任务的入口，任务执行完成的收尾工作，任务的执行状态等。 任务队列：用于存放没有处理的任务，提供一种缓冲机制。 线程池实例的状态 running 能接受新提交的任务，并能处理阻塞队列的任务 shutdown 关闭状态，不能接受新提交的任务，但能处理阻塞队列的任务 stop 不能接受新提交的任务，也不能处理阻塞队列的任务 会中断正在处理任务的线程 tidying 如果所有任务都已经中止 terminated 分类newFixedThreadPool创建一个固定长度的线程池，每当提交一个任务就创建一个新的线程，直到达到线程池的最大数量 newCachedThreadPool创建一个可缓存的线程池，如果线程池的当前规模超过了处理需求时，将回收空闲线程，当需求增加时，则可用添加新的线程，其规模不存在限制 当任务间存在依赖时，可以选择。 newSingleThreadExecutor是一个单线程的Executor，创建单个工作线程执行任务，如果线程异常结束，则创建另一个线程来替代。能够确保任务在队列中的顺序来串行执行。 单线程的Executor提供了大量的内部同步机制，确保了任务执行的任何内存写入操作对于后续任务都是可见的，即使这个线程会不时被另一个线程替代，但对象总是可以安全地封闭在任务线程中。 newScheduledThreadExecutor创建了一个固定长度的线程池，而且以延迟或定时的方式来执行任务，类似于Timer。而Timer存在缺陷，应该考虑使用ScheduledThreadPoolExecutor代替。 Timer负责管理延迟任务，例如在100ms后执行该任务，以及周期任务每10ms执行一次该任务。 Timer在执行任务时只会创建应该线程，如果某个任务的执行事件过长，将破坏其他TimerTask的定时精确性。 TimerTask如果抛出了一个未检查异常，而Timer线程并不会捕获异常，此时将终止定时线程，并且Timer也不恢复线程的执行，而是认为整个Timer都被取消了。 方法 execute 提交任务，交给线程池执行 submit 提交任务，能够返回执行结果 shutdown 关闭线程池，等待任务都执行完 shutdownNow 关闭线程池，不等待任务执行完 getTaskCount 线程池已执行和未执行的任务总数 getCompletedTaskCount 已完成的任务数 getPoolSize 线程池当前的线程数量 getActiveCount 当前线程池当中正在执行任务的线程数量 参数 corePoolSize：核心线程数量 maxmumPoolSize：线程最大线程数 当核心线程都在工作，且阻塞队列满，且线程数目小于最大线程数，则创建新线程 如果线程数目等于最大线程数，通过拒绝策略来处理新到来的任务 workQueue：阻塞队列，存储等待执行的任务 直接切换 无界队列，基于链表，创建的最大线程即核心线程数目 有界队列，创建的最大线程数目为最大线程数 keepAliveTime：线程没有任务执行时最多保持多久时间终止 unit：时间单位 threadFactory：线程工厂，创建线程 rejectHandler：拒绝处理任务时的策略 直接抛出异常，默认 用调用者所在的线程执行任务 丢弃队列中最靠前的任务 直接丢弃这个任务 降低系统资源消耗：较大队列容量，较小线程池容量 设置线程池的大小线程池的理想大小取决于被提交任务的类型以及所部署系统的特性。而设计线程池只要避免过大或过小的极端即可。 如果过大，则线程将在相对少的CPU和内存上竞争，会导致更高的内存使用量，还可能耗尽资源。如果国小，将导致许多空闲的CPU无法执行工作，而降低吞吐率。 设置线程池的大小，需要分析 计算环境。即部署的系统有多少CPU 资源预算。即部署的系统有多大的内存 任务的特性。任务时CPU密集型、IO密集型还是二者皆可。是否需要JDBC连接这样的稀缺资源。如果执行不同类别的任务，则应该考虑使用多个线程池 CPU密集型任务，需要尽量压榨CPU，参考值设置为NCPU（CPU数量）+1 IO密集型任务，参照值设置为2*NCPU 并且可以通过在某个基准负载下，分别设置不同大小的线程池来运行应用程序，并观察CPU利用率的水平： 配置ThreadPoolExecutor1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)&#123;...&#125; 线程的创建与销毁线程池的基本大小corePoolSize、最大大小maximumPoolSize、存活时间keepAliveTime等因素共同负责线程的创建与销毁。 当某个线程的空闲时间超过了存活时间，则会被标记为可回收的，并在大小超过基本大小时将其终止。 newFixedThreadPool工厂方法将线程池的基本大小和最大大小设置为参数中指定的值，而且创建的线程池不会超时 newCachedThreadPool工厂方法将线程池的最大大小设置为MAX_VALUE，基本大小为0，并超时时间为1分钟。 管理队列任务在有限的线程池中会限制可并发执行的任务数量。单线程的线程池确保不会有任务并发执行。 即使使用固定大小的线程池，在高负载下，应用程序仍可能耗尽资源。如果新请求的到达速率超过了线程池的处理速率，那么新到来的请求将累计起来。 在线程池当中，累计的请求将在由Executor管理的Runnable队列张等待，而不会像线程那样竞争CPU资源。但是即使如此在请求的速率很高的时候依然可能会耗尽资源。并且在耗尽资源前，响应性能也随着任务队列的增长而增长。 ThreadPoolExecutor允许提供一个BlockingQueue用于保存等待执行的任务。基本的任务排列方法有：无界队列、有界队列、同步移交。队列的选择也与线程池的其他配置有关。 无界队列 无界的LinkedBlockingQueue是newFixedThreadPool与newSingleThreadExecutor的默认选择 有界队列 一种更为稳妥的资源管理策略是使用有界队列，例如有界的ArrayBlockingQueue，有界的LinkedBlockingQueue，PriorityBlockingQueue，但是带来了新的问题：即当队列填满后如何解决新的任务。而且有界队列的大小需要与线程池的大小一同调节 如果线程池较小而队列较大，有助于减少内存使用量，降低CPU利用率，并且减少上下文切换。但可能会限制吞吐率 同步移交 对于非常大的或无界的线程池，可以通过使用SynchronousQueue来避免排队，以及直接将任务从生产者移交给工作者线程。SynchronousQueue不是一个真正的队列，而是一种在线程间进行移交的机制。 要将一个元素放入SynchronousQueue必须有另一个线程正在等待接受这个元素，如果没有线程等待，并且线程池的当前大小小于最大值，那么将创建一个新的线程，否则根据饱和策略将拒绝任务。 使用移交将更加高效，因为任务直接交给了线程而不是放入队列。 控制优先级 使用PriorityBlockingQueue将根据任务的优先级来安排任务。 饱和策略当有界队列被填满，则饱和策略开始发挥作用，ThreadPoolExecutor.setRejectedExecutionHandler进行设置。如果任务被提交到一个已被关闭的Executor时也会使用饱和策略。 JDK提供了几种不同的实现：AbortPolicy、CallerRuns、CallerRunPolicy、DiscardPolicy、DiscardOldestPolicy Abort策略 默认的饱和策略，将抛出未检查的RejectedExecution，调用者可以捕获该异常，然后根据需求编写自己的处理代码。 Discard策略 当新提交的任务无法保存到队列中时，Discard策略将悄悄地抛弃任务 DiscardOldest策略 该策略会抛弃下一个即将执行的任务，然后重新提交新的任务。 CallerRuns策略 实现了一种调节机制，不会抛弃任务也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量。即任务不会由线程池执行，而是由调用了execute的线程执行该任务，因此也会导致提交任务的线程在一段时间内无法提交任务。 线程工厂当线程池需要创建一个线程时，都是提供线程工厂方法来完成的。默认的线程工厂方法会创建一个新的、非守护的线程，并且不包含特殊的配置信息。 可以指定一个线程工厂方法，定制线程池的配置信息。ThreadFactory.newThread()用于创建新线程。实现自己的线程工厂只需要实现该接口。 在调用构造函数后再定制ThreadPoolExecutor即使构造完ThreadPoolExecutor也可以通过Setter修改大多数传递给它的构造函数的参数。 扩展ThreadPoolExecutor任务找出可利用的并行性 当使用线程池时，必须将任务描述为一个Runnable，多数服务器应用程序存在一个明显的任务边界：单个客户请求。而有些时候依然需要去发掘并行性，或者客户请求内部更深层次的并行性。 概述任务的生命周期： 创建 提交 开始 完成 联系 Runnable与Callable都描述的是抽象的计算任务，这些任务通常有范围，即有一个明确的起始点，并且最终会结束。 任务设计只有当大量相互独立且同构的任务可以并发进行处理时，才能体现出将程序的工作负载分配到多个任务中带来的真正性能提升。 而对于异构任务，很难通过并行化来获得重大的性能提升。 RunnableExecutor使用Runnable作为基本的任务表示形式，但它是一种具有很大局限的抽象，它不能返回一个值或者抛出一个受检查异常。 Callable某些任务存在延迟的计算–执行数据库查询、从网络中获取资源、计算某个复杂的功能。Callable可以返回一个值，并抛出一个异常 方法 call。对于完成的任务，立即返回或抛出一个Exception。对于未完成任务，则阻塞直到任务完成。 任务抛出异常，则将异常封装到ExecutionException。如果任务被取消，则CancellationException。 Future表示一个任务的生命周期，并提供相应的方法判断是否已经完成或取消，以及获取任务的结果和取消任务。 在Future规范中包含的隐含意义是，任务的生命周期只能前进，不能后退。Future是一个接口，它的功能: 判断任务是否完成； 能够中断任务； 能够获取任务执行结果。 创建Future。 ExecutorService中的所有submit方法都将返回一个Future，从而将一个Runnable或Callable提交给Executor，并得到一个Future用于获得任务的执行结果或取消任务。 显式指定Runnable或Callable实例化FutureTask FutureTask实现了Runnable接口 方法 boolean cancel(boolean mayInterruptIfRunning);。用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。 参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true boolean isCancelled();表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 boolean isDone();表示任务是否已经完成，若任务完成，则返回true； V get() throwsInterruptedException, ExecutionException;用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； V get(longtimeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 时限如果某个任务无法在指定时间内完成，那么将不再需要它的结果，此时可以放弃。 在支持时限的Future.get中支持这种需求，当结果可用时会立即返回，如果在指定时限中没有计算出结果，将抛出TimeOutException。 FutureTask是什么可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 12345public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; FutureTask有3中状态：Waiting to Run、Running、Completed 应用 用于异步获取执行结果或取消执行任务的场景，表示异步任务。当一个计算任务需要执行很长时间，那么就可以用FutureTask来封装这个任务，主线程在完成自己的任务之后再去获取结果。 用做闭锁，即异步任务没有完成前，无法执行下一步 CodeFutureTask可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用FutureTask来封装这个任务，主线程在完成自己的任务之后再去获取结果。 1234567891011121314151617181920212223242526272829303132public class FutureTaskExample &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int result = 0; for (int i = 0; i &lt; 100; i++) &#123; Thread.sleep(10); result += i; &#125; return result; &#125; &#125;); Thread computeThread = new Thread(futureTask); computeThread.start(); Thread otherThread = new Thread(() -&gt; &#123; System.out.println("other task is running..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); otherThread.start(); System.out.println(futureTask.get()); &#125;&#125;other task is running...4950 原理 Future.get()：取决于任务的状态，如果任务已经完成，则会立即返回结果，否则阻塞直到任务完成，然后返回结果或抛出异常。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：任务执行]]></title>
    <url>%2F2019%2F08%2F07%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[任务执行大多数并发应用程序都是围绕任务执行来构造的，任务通常是一些抽象的且离散的工作单元，通过把应用程序的工作分解到多个任务中，可以简化程序的组织结构，提供一种自然的事务边界优化错误恢复过程，提供一种自然的并行工作结构来提升并发性 在线程中执行任务指明任务的边界，使得任务为一个独立的活动，不依赖其他任务的状态、结果、边界效应。独立性有助于实现并发，而不会导致任务间相互阻塞。 任务边界：在服务器应用程序中通常以单独的客户请求作为边界。 任务执行策略： 串行执行 即收到一个请求，服务器要处理完该请求才能继续accept下一个请求 显式地为任务创建线程，为每一个服务请求创建一个线程 并行处理，并且能同时接受多个请求 任务处理代码必须线程安全 任务处理过程从主线程中分离出来，使得主循环可以更快地重新等待下一个到来的连接。 无限制创建线程的不足线程生命周期的开销、资源消耗。空闲线程会占用很多的内存。 无限制线程的稳定性拖垮系统。该限制与JVM相关，并且受到多个因素制约，包括JVM启动参数、Thread构造函数中请求的栈大小，以及底层系统对线程的限制等。如果破坏了可能导致OOM Exeutor框架详情参见JUC-Executor 任务取消有时候我们希望提前结束任务或线程，或许是因为用户取消了操作，或应用程序需要被快速关闭。Java没有提供任何机制来安全地终止线程，即没有安全的抢占式方法停止线程。但它提供了中断，这是一种协作机制，能够使一个线程终止另一个线程的当前工作。 并且大多数时候我们希望任务可以安全地结束它们的任务，而不是强制停止。 任务取消如果外部代码能在某个操作正常完成前将其置入“完成”状态，那么这个操作就可以称为可取消的，取消操作的原因有 用户请求的取消，cancel 限时活动，超时取消 应用程序事件，当程序的不同任务在搜索，一个任务找到了解决方案，其他任务就取消 错误，IO等错误 关闭，关闭某个服务 一个可取消的任务必须拥有取消策略，定义取消操作的How、When、What。 中断线程中断是一种协作机制，线程可以通过这种机制来通知另一个线程，告诉它在合适或者可能的情况下停止当前工作，并转而执行其他的工作。 实现 在每个线程中都有一个Boolean类型的中断状态，当中断线程时，这个线程的中断状态设置为true。 12345public class Thread&#123; public void interrupt();//中断目标线程 public boolean isInterrupt();//返回目标线程的中断状态 public static boolean interrupted();//清除当前线程的中断状态，并返回它的值。&#125; interrupt： 将线程的中断状态置位(中断状态由false变成true)； 让被中断的线程抛出InterruptedException异常。 调用interrupt并不意味着立即停止目标线程正在进行的工作，而只是传递了请求中断的消息。 阻塞 对于阻塞库方法，例如Thread.sleep()、Object.wait()都会去检查线程何时中断，并且在发现中断时提前返回。 在响应中断时会清除中断状态，并抛出InterruptedException，表示阻塞时由中断而提前结束的。但JVM不会保证阻塞方法检测到中断的速度。 阻塞与中断的关系是，如果在代码中实现中断，则由于阻塞将永远无法检测到中断信号。 当线程在非阻塞的状态下中断，它的中断状态将被设置，然后根据被取消的操作来检查中断状态以判断是否中断（在取消点）。即如果不触发InterruptedException那么中断状态将一直保持，直到明确清除中断状态。 因此如果任务代码能够响应中断，那么可以使用中断作为取消机制。 中断策略中断策略规定线程如何解释某个中断请求——当发现中断请求时，应该做哪些工作，哪些工作单元对于中断来说是原子操作，以及以多快的速度来响应中断。 最合理的中断策略是某种形式的线程级取消操作或服务级取消操作：尽快退出，在必要时进行清理，通知某个所有者该线程已经退出。并可以建立其他中断策略，例如暂停服务或重新开始服务。 要区分线程与任务对中断的反应，可以是取消当前任务，也可以是关闭工作线程。 任务不会在其自己拥有的线程中执行，而是在某个服务(线程池)拥有的线程中执行。对于非线程所有者的代码(例如线程池，即任何在线程池实现以外的代码)，应该小心保存中断状态，这样拥有线程的代码才能对中断做出响应。即大多数可阻塞的函数只是抛出InterruptException的原因，将中断信息传递给调用方线程。 由于每个线程拥有自己的中断策略，因此除非你知道中断对该线程的含义，否则就不应该中断这个线程。 响应中断有两种策略可以处理InterruptedException 传递异常，可能在执行某个特定于任务的清除操作后，从而使你的方法也成为可中断的阻塞方法 throw 恢复中断状态，从而使调用栈中的上层代码能够对其进行处理 再次调用interrupt来恢复中断线程，即不能屏蔽InterruptedException 只有实现了线程中断策略的代码才可以屏蔽中断请求，在常规的任务和库代码中都不应该屏蔽中断请求。 通过Future实现取消处理不可中断的阻塞许多可阻塞的方法都是通过提前返回或者抛出InterruptedException来响应中断请求的，而并非所有的可阻塞方法或者阻塞机制都能响应中断。如果一个线程由于执行同步的socket IO或等待内置锁而阻塞，则中断没有任何作用。 线程阻塞的原因： 同步Socket IO。虽然read或write都不会响应中断，但是可以通过关闭套接字抛出SocketException 同步IO。关闭一个正在InterruptibleChannel上等待的线程时，将抛出ClosedByInterruptException，并关闭链路。 Selector 异步IO。调用close或wake up会导致线程CloasedSelectorException 获取某个锁。Lock类提供了lockInterruptibly方法，允许等待锁时可以中断。 采用newTaskFor封装非标准的取消停止基于线程的服务应用程序通常会创建拥有多个线程的服务，例如线程池，这些服务的生命周期通常比创建它们的方法的生命周期更长。如果应用程序结束，那么这些服务所拥有的线程也要结束。而且由于无法抢占式停止，因此需要它们自行结束。 正确的封装原则是：除非拥有某个线程，否则不能对该线程进行操控。线程有一个相应的所有者，即线程池，如果要中断这些线程，那么应该使用线程池。由于线程的所有权无法传递，因此服务应该提供生命周期方法来关闭他自己以及拥有的线程，因此当服务关闭时就会关闭所有的线程。 处理非正常的线程终止JVM关闭参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL：SQL进阶]]></title>
    <url>%2F2019%2F08%2F06%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9ASQL%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[安全管理创建用户账号 1create user ben inentified by ‘p@$$w0rd’ 查看访问权限 1show grants for ben 授权： 要授予的权限，被授予访问权限的数据库或表、用户名 1grant select on crashcourse.* to ben 撤销权限：revoke 索引索引创建： alter table table_name add [index|key] [index_name] [index_type] [index_col_name,..] [index_option] create [unique] index index_name [index_type] on table_name [index_col_name] 索引删除 alter table table_name drop [index|key] index_name rrop index index_name on table_name 可以只对一个列的一部分数据索引。例如只索引前100个字段：alter table t add key idx_d (b(100)) 使用show index from table查看索引 Table：索引所在的表名。 Non_unique：非唯一的索引，如果是primary key则值为0. Key_name：索引的名字。 Seq_in_index：索引中该列的位置。 Column_name：索引列的名称。 Collation：列以什么方式存储在索引中，A即排序的，Null则为非排序。 Cardinality：表示索引中唯一值的估计值，应该尽量为1. Sub_part：是否是列的部分被索引。 Packed：关键字如何被压缩，如果没有压缩，则为NULL。 Null：是否索引的列含有NULL值。 Index_type：索引的类型，InnoDB只支持BTREE。 Comment：注释。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch：数据]]></title>
    <url>%2F2019%2F08%2F05%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FElasticsearch%EF%BC%9A%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[数据无论程序怎么写，意图都是一样的：组织数据为我们的目标所服务。但数据并不只是由随机的比特和字节组成，我们在数据节点间建立关联来表示现实世界中的实体或某些东西。属于同一个人的名字和Email会有更多的意义。 现实世界中，并不是所有相同类型的实体看起来都是一样的，一个人可能有一个家庭电话，另一个人可能只有一个手机号码，有些人可能都有，甚至有多个。 面向对象编程流行的原因之一，是我们可以用对象来表示和处理现实生活中那些有着潜在关系和复杂结构的实体。 但是当我们想要存储这些实体时，传统的数据库只允许我们以行、列的形式将数据存储在关系型数据库中，这种固定的存储方式导致对象的灵活性不复存在了。因此我们需要能够以对象的形式存储对象，可以让我们专注于使用数据，将对象本来的灵活性找回来。 对象是一种语言相关，记录在内存中的数据结构，为了在网络中传输即需要一些标准的格式来表示。而JSON是一种可读的以文本表示对象的方式。当对象被序列化为JSON，就称为JSON document了。 分布式文档存储引擎Elasticsearch是一个分布式的文档存储引擎，它可以实时存储并检索复杂数据结构——序列化的JSON文档，即文档一旦被存储在ES上，就可以在集群的任一节点上被搜索。 当存储了数据后，我们还需要快速的批量查询，虽然很多NoSQL的解决方案允许我们以文档的形式存储数据，但它们依然需要考虑如何查询这些数据，以及哪些字段需要被索引以便检索时更加快速。 在Elasticsearch中，每一个字段的数据都是默认被索引的。也就是说，每个字段专门有一个反向索引用于快速检索。而且，与其它数据库不同，它可以在同一个查询中利用所有的这些反向索引，以惊人的速度返回结果。 文档程序中大多的实体或对象能够被序列化为包含键值对的JSON对象。通常我们可以认为对象与文档时等价相通的。 对象时应该JSON结构体，类似于HashMap等，内部还可能包含其他对象 文档在Elasticsearch当中特指最顶层结构或者跟对象序列化成的JSON数据，以唯一ID标识并存储在ES中 文档元数据文档不仅仅只有数据，还包含了元数据–关于文档的信息，其中三个必须的元数据节点时： _index：文档存储的地方 在ES当中index类似于数据库，是存储和索引关联数据的地方 实际上数据被存储和索引在分片中，索引只是一个把一个或多个分片分组在一起的逻辑空间。 _type：文档代表的对象的类 应用中，使用对象表示一些事物，每个对象都属于一个类，类定义了属性或与对象关联的数据。在关联数据库中，相同类的对象被存在一个表中 ES当中，使用相同type的文档表示相同的事物，因为它们的数据结构也是相同的。每个type都有自己的mapping或结构定义，类型的mapping会告诉ES不同的文档如何被索引。 _id：文档的唯一标识 与index和type组合时，就可以唯一标识一个文档。 索引 created指同索引、同类型下是否已经存在同ID的文档 version代表版本号，如果原来已经有一个版本，则会将之前的版本覆盖 在内部ES已经标记旧文档，其不会立即删除，但也不能访问，ES会在你继续索引更多数据时清理被删除的文档。 更新文档在ES中是不可变的，即我们不能修改它们，如果需要更新已存在的文档，我们可以使用indexAPI重建索引或替换它。 123PUT /website/blog/123&#123; “title”： “doit”,&#125; 得到响应为： 1234567&#123; "_index":"website", "_type" :"blog", "_id":"123", "_version": 2, "created":false &#125; 局部更新文档是不可变的，updateAPI局部更新也只是进行了相同的检索-修改-重建索引流程。但是我们减少了其他进程可能导致冲突的修改。 为博客增加一个tags字段和views字段 123456POST /website/blog/1/_update&#123; "doc":&#123; "tags" : ["test"], "views": 0 &#125;&#125; 请求成功后： 123456&#123; "_index": "website", "_id": "1", "_type": "blog", "_version": 3&#125; 当API不能满足要求时，使用脚本可以实现我们自己的逻辑。 批量操作bulkAPI允许我们使用单一请求来实现多个文档的create、index、update、delete，这对索引类似于日志活动这样的数据流非常有效，可以以成百上千的数据为一个批次按序进行索引。 bulk的请求体： 1234&#123; action: &#123;metadata&#125;&#125;\n&#123; request body&#125;\n&#123; action: &#123;metadata&#125;&#125;\n&#123; request body&#125;\n 每行必须以”\n”符号结尾，包括最后一行。这些都是作为每行有效的分离而做的标记。 每一行的数据不能包含未被转义的换行符，它们会干扰分析——这意味着JSON不能被美 化打印。 request body由文档的_source组成——文档所包含的一些字段以及其值。 action类型 create index update delete 以delete为例: 1&#123;"delete":&#123;"_index":"website","_type":"blog","_id":"123"&#125;&#125; update: 12&#123;"update":&#123;"_index":"website","_type":"blog","_id":"123", "_retry_on_conflict":"11"&#125;&#125;&#123;"doc":&#123;"title":"My updated blog post"&#125; &#125; 并发控制Java APIQueryBuilder是es中提供的一个查询接口, 可以对其进行参数设置来进行操作。 https://www.cnblogs.com/xxx0624/p/4306226.html 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch：入门]]></title>
    <url>%2F2019%2F08%2F05%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FElasticsearch%EF%BC%9A%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ElasticSearch概念ElasticSearch是一个实时分布式搜索和分析引擎，能够让你以前所未有的速度处理大数据成为可能。 它用于全文搜索、结构化搜索、分析以及将三者混用。并且可以在单机以及集群上运行。ES将三个功能整合成为一个一体化的、实时的应用，其对新用户的门槛很低。 为什么要用大部分数据库在提取可用知识方面显得异常无能。尽管它们能够通过时间戳或者精确匹配做过滤。 但是它们能够进行全文搜索，处理同义词和根据相关性给文档打分吗？它们能根据同一份数据生成分析和聚合的结果吗？最重要的是，它们在没有大量工作进程（线程）的情况下能做到对数据的实时处理吗？ ElasticSearch鼓励你浏览并利用你的数据，而不是烂在数据库里，因为在数据库里太难查询了。 概念ElasticSearch是一个基于Apache Lucene的开源搜索引擎，Apache Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。 但是Lucene只是一个库，如果想要使用，则必须使用Java作为开发语言进行集成，而且Lucene非常复杂，需要深入了解检索的相关知识理解它是如何工作的。 ElasticSearch使用Java开发，并使用Lucene作为核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 ElasticSearch还可以这样描述： 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据。 安装elasticsearch安装后解压到相应目录即可 启动进入bin目录后：elasticsearch-service start 关闭服务：elasticsearch-service stop 如果是第一次启动则需要：elasticsearch-service install 插件安装插件Marvel，Marvel是Elasticsearch的管理和监控工具，包含一个sense的交互控制台，使用户方便地通过浏览器直接于Elasticsearch进行交互。 ./bin/elasticsearch-plugin install elasticsearch/marvel/latest 禁用监控，通过命令关闭Marvel：echo &#39;marvel.agent.enabled: false&#39; &gt;&gt; ./config/elasticsearch.yml 查看Marvel 集群和节点节点node是一个运行着地Elasticsearch实例，集群cluster是一组具有相同cluster.name的节点集合，他们协同工作，共享数据并提供故障转移和扩展功能。 修改cluster.name可以通过修改config/目录下的elasticsearch.yml文件，然后重启Elasticsearch来实现。 与Elasticsearch交互JavaAPIElasticsearch为Java用户提供了两种内置客户端 节点客户端 节点客户端以无数据节点身份加入集群，即自身不存储任何数据，但是它自导数据在集群中的具体位置，并且能够直接转发请求到对应的节点上。 传输客户端 这个更轻量的传输客户端能够发送请求到远端集群，它自己不加入集群，只是简单转发请求给集群中的节点。Java客户端都使用9300端口与集群交互，使用Elasticsearch传输协议(Elasticsearch transport protocol)。 HTTP基于HTTP，以JSON为数据交互格式的Restful API。向Elastic发出的请求的组成部分与其他普通的HTTP请求是一样的。 1curl -X&lt;VERB&gt; &apos;&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;&apos; -d &apos;&lt;BODY&gt;&apos; VERB HTTP方法：get、post、put、head、delete PROTOCOL：http或者https（当Elasticsearch前有https代理时可用） HOST： Elasticsearch集群中的任何一个节点的主机名，如果是在本地的节点，那么就叫localhost PORT： Elasticsearch HTTP服务所在的端口，默认为9200 PATH： API路径，PATH中可以包含多个组件，例如_cluster/stats QUERY_STRING：一些可选的查询请求参数，?pretty可以使得请求返回更加美观易读的JSON数据 BODY：一个JSON格式的请求主体 一个完整的请求： 1curl -XGET “localhost:9200/_count?pretty” -d &apos; 异常 1&#123;&quot;error&quot;:&quot;Content-Type header [application/x-www-form-urlencoded] is not supported 则修改为： 1curl -H &quot;Content-Type: application/json&quot; -XGET &quot;localhost:9200/_count?pretty&quot; -d &apos; 异常2 123456789101112131415&#123; "error": &#123; "root_cause": [&#123; "type": "mapper_parsing_exception", "reason": "failed to parse" &#125;], "type": "mapper_parsing_exception", "reason": "failed to parse", "caused_by": &#123; "type": "not_x_content_exception", "reason": "Compressor detection can only be called on some xcontent bytes or compressed xcontent bytes" &#125; &#125;, "status": 400&#125; 垃圾windows命令行导致的，这边建议使用Ubuntu的WSL 一个put的示例 1234curl -H &quot;Content-Type: application/json&quot; -XPUT &quot;http://localhost:9200/megacorp/employee/1&quot; -d&apos;&#123;&quot;first_name&quot;: &quot;John&quot;,&quot;last_name&quot;: &quot;Smith&quot;,&quot;age&quot;: 25,&quot;about&quot;: &quot;rock&quot;,&quot;interests&quot;: [&quot;sports&quot;, &quot;music&quot;]&#125;&apos; 面向文档应用中的对象很少只是简单的键值列表，例如MySQL数据库那样，更多的时候它拥有复杂的数据结构，例如包含日期、地理位置、另一个对象或数组。 而数据库是行列组成的表格，如果要将一个对象存储到MySQL当中，则就像是将一个丰富、信息表现力强的对象拆散了放入一个非常大的表格中。你不得不拆散对象以适应表模式(一列对应一个字段)，然后在查询时再进行重建 Elasticsearch是面向文档的，意味着它可以存储整个对象或文档，然而它不仅仅时存储，还会索引每个文档的内容使之可以被搜索。再Elasticsearch中，你可以对文档(并非表结构)进行索引、搜索、排序、过滤。这种理解数据的方式与MySQL完全不同，也是Elasticsearch能够进行复杂的全文搜索的原因之一。 Elasticsearch使用JSON作为文档序列化格式。 Start索引在Elasticsearch中索引具有不同的涵义 索引(名词)：一个索引就像时传统关系数据库中的数据库，它时相关文档存储的地方 索引(动词)：索引一个文档，表示把一个文档存储到索引(名词n)中。以便它可以被检索或者查询，很像SQL的insert，但差别是如果文档已经存在，新的文档将覆盖旧的文档 倒排索引：传统数据库为特定列增加一个索引，例如B-Tree索引来加速检索。而Elasticsearch和Lucene使用倒排索引的数据结构达到目的。 默认情况下，文档中的所有字段都会被索引(拥有一个倒排索引)，只有这样他们才是可被搜索的。 实例需求 让我们建立一个员工目录。假设我们刚好在Megacorp工作，这时人力资源部门出于某种目的需要让我们创建一个员工目录，这个目录用于促进人文关怀和用于实时协同工作，所以它有以下不同的需求： 数据能够包含多个值的标签、数字和纯文本。 检索任何员工的所有信息。 支持结构化搜索，例如查找30岁以上的员工。 支持简单的全文搜索和更复杂的短语(phrase)搜索 高亮搜索结果中的关键字。 能够利用图表管理分析这些数据。 索引员工文档 我们首先要做的是存储员工数据，每个文档代表一个员工。在Elasticsearch中存储数据的行为就叫做索引(indexing)，不过在索引之前，我们需要明确数据应该存储在哪里。 在Elasticsearch中，文档归属于一种类型(type),而这些类型存在于索引(index)中，我们可以画一些简单的对比图来类比传统关系型数据库： 12Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。 所以为了创建员工目录，我们将进行如下操作： 为每个员工的文档(document)建立索引，每个文档包含了相应员工的所有信息。 每个文档的类型为employee。 employee类型归属于索引megacorp。 megacorp索引存储在Elasticsearch集群中。 1234567curl -XPUT &apos;localhost:9200/megacorp/employee/1&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;rock&quot;, &quot;interests&quot; : [&quot;sports&quot;,&quot;music&quot;]&#125; 搜索做简单搜索，即只需要执行HTTP GET请求并指出文档的”地址”——索引、类型和ID即可。 简单搜索搜索单个： curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/1?pretty&quot; 响应的数据为，数据存在于_source字段中： 12345678910111213141516171819&#123; "_index" : "megacorp", "_type" : "employee", "_id" : "1", "_version" : 1, "_seq_no" : 0, "_primary_term" : 1, "found" : true, "_source" : &#123; "first_name" : "John", "last_name" : "Smith", "age" : 25, "about" : "rock", "interests" : [ "sports", "music" ] &#125;&#125; 搜索全部员工 curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; 使用_search代替原来的文档ID，默认下会返回前10个结果，响应内容的hits数组会包含我们的文档。 1234567891011121314151617181920212223242526272829303132333435&#123; "took" : 117, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 1.0, "hits" : [ &#123; "_index" : "megacorp", "_type" : "employee", "_id" : "1", "_score" : 1.0, "_source" : &#123; "first_name" : "John", "last_name" : "Smith", "age" : 25, "about" : "rock", "interests" : [ "sports", "music" ] &#125; &#125; ] &#125;&#125; query string搜索first_name包含”Smith”的员工，我们将在命令行中使用轻量级的搜索方法，这种方法被称为查询字符串(query string)搜索，因为像我们传递URL参数一样去传递查询语句。 1curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?q=first_name:Jo&amp;pretty&quot; 查询字符串搜索便于通过命令行完成特定(ad hoc)的搜索 但查询字符串搜索存在局限性 DSLElasticsearch提供丰富且灵活的查询语言叫做DSL查询，允许你构建更加复杂、强大的查询。 DSL以JSON请求体的形式出现，可以这样表示之前对first_name的查询 123456curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123;&quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;first_name&quot;: &quot;John&quot; &#125;&#125;&#125;&apos; 更复杂的搜索让搜索更为复杂一些，依旧想要找到姓氏为“John”的员工，但是我们只想得到年龄大于30岁的员工，即为语句添加过滤器，使得我们高效率地执行员工结构化的搜索 1234567891011121314151617curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123; &quot;query&quot;:&#123; &quot;filtered&quot;:&#123; &quot;filter&quot;:&#123; &quot;range&quot;:&#123; &quot;age&quot;:&#123;&quot;gt&quot;: 0&#125; &#125; &#125;, &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;first_name&quot;:&quot;John&quot; &#125; &#125; &#125; &#125;&#125;&apos; gt：greater than。 全文搜索检索所有喜欢&quot;rock climbing&quot;的员工 12345678curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;about&quot;: &quot;rock climbing&quot; &#125; &#125;&#125; 默认情况下，Elasticsearch根据结果相关性评分来对结果集进行排序，即文档与查询条件的匹配程序。而在上述搜索中，如果about中只是出现了rock也会出现在结果集合当中。 因此，该全文搜索不仅仅是匹配或不匹配，而且还有着相关性 短语搜索不仅可以在字段中搜索单独的一个词，还可以匹配若干个词或者短语，例如想要查询同时包含rock和climbing（并且是相邻的）的记录。使用match_parse即可 12345678curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123; &quot;query&quot;:&#123; &quot;match_parse&quot;:&#123; &quot;about&quot;: &quot;rock climbing&quot; &#125; &#125;&#125; 高亮搜索在语句中增加hightlight参数，将会高亮匹配到的关键字。 12345678910111213curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123; &quot;query&quot;:&#123; &quot;match_parse&quot;:&#123; &quot;about&quot;: &quot;rock climbing&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;about&quot;:&#123;&#125; &#125; &#125;&#125; 在返回语句中会增加一个新的部分highlight，内部会包含来自about字段中的文本，并且用&lt;em&gt;和&lt;/em&gt;来标识匹配到的单词 12345678910111213141516171819202122232425262728293031323334353637383940&#123; "took" : 111, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 0.2876821, "hits" : [ &#123; "_index" : "megacorp", "_type" : "employee", "_id" : "1", "_score" : 0.2876821, "_source" : &#123; "first_name" : "John", "last_name" : "Smith", "age" : 25, "about" : "rock", "interests" : [ "sports", "music" ] &#125;, "highlight" : &#123; "about" : [ "&lt;em&gt;rock&lt;/em&gt;" ] &#125; &#125; ] &#125;&#125; 聚合ES的聚合(aggregations)允许你在数据上生成复杂的分析统计，类似于Group by但是功能更强大。 例如找到所有职员中最大的共同点(兴趣爱好)是什么： 1234567curl -H &quot;Content-Type: application/json&quot; -XGET &quot;http://localhost:9200/megacorp/employee/_search?pretty&quot; -d&apos;&#123; &quot;aggs&quot;:&#123; &quot;all_interests&quot;:&#123; &quot;terms&quot;:&#123;&quot;field&quot;: &quot;interests&quot;&#125; &#125; &#125;&#125; 分布式Elasticsearch可以扩展到上百、千的服务器来处理PB级的数据，Elasticsearch的设计隐藏了分布式本身的复杂性。 Elasticsearch在分布式概念上做了很大程度上的透明化，在教程中你不需要知道任何关于分布式系统、分片、集群发现或者其他大量的分布式概念。所有的教程你既可以运行在你的笔记本上，也可以运行在拥有100个节点的集群上，其工作方式是一样的。 Elasticsearch致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的： 将你的文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。 冗余每一个分片，防止硬件故障造成的数据丢失。 将集群中任意一个节点上的请求路由到相应数据所在的节点。 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单元测试]]></title>
    <url>%2F2019%2F08%2F05%2F%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[单元测试容易被测试的代码总是设计优良的。 FIRST原则 写单测junit+mockit+powermock(mockit的扩展) 或testng 准备：被测试对象，Mock脚本、数据 执行：被测试对象在mock环境中执行 验证：被测试对象状态，mock脚本是否正确执行 assertEquals mock调用mock类的方法并不会真正执行该方法，只是允许向下执行。 如果真的需要mock类的方法，则需要 1`when`(clearFlowRepository).thenReturn()//指定在调用方法提供特定参数时返回什么值。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发：线程安全-实现]]></title>
    <url>%2F2019%2F08%2F04%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8-%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[线程安全性当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为。 无状态的对象永远是安全的。即指这个对象没有状态域，也没有引用其他对象的域，是一次特定计算的瞬时状态，会唯一存放在一个本地变量当中，即线程的栈当中。而两个线程并不共享状态。 三个方面 原子性：提供了互斥访问，同一时刻只能有一个线程对它进行操作 可见性：一个线程对主内存的修改可以及时被其他线程观察到 有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般无序 原子性原子性：能作为一个单独的、不可分割的操作去执行 当向一个无状态的对象添加一个域，并进行long++操作（读+改+写），则不是线程安全。 将long换作一个atomic包下的AtomicLong变量，则由于该变量是一个原子变量类，该计数器是线程安全的，该对象的状态即该计数器的对象，即该对象线程安全。（利用已有的线程安全类进行管理，如果只有一个，则线程安全，如果多个，则未必线程安全）。当变量之间相互关联，则在一个原子操作当中，要将几个相互关联的变量同时更新 AtomicJDK的Atomic包，通过CAS完成原子性 int类型变为AtomicInteger，自增的方法为incrementAndGet CAS核心12345 //计数方法 private static void add()&#123; count.incrementAndGet();//先执行增加操作，再获取值// count.getAndIncrement(); //先获取当前的值，再执行增加操作 &#125; 源码实现，基于一个unsafe类 123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 以dowhile语句为核心实现,CompareAndSwap是C.A.S的核心. 因为使用循环，如果修改很频繁，会不断循环尝试修改，使得性能受到影响 12345678910111213141516/** * var1:当前的对象 */public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; //通过调用底层方法,获得var1对象底层当前的值 //如果没有其他线程更改,则var5就会等于var2 var5 = this.getIntVolatile(var1, var2); //比较底层的值var5与传入的值var2 //如果底层的值与传入值相同,那么更新为var5+增量var4 //如果值不相同,则将var2的值更改为底层当前的值,然后重新do,获得var5的值,进行比较 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 以native标识，即java底层的实现，不是java的实现 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 源码解析AtomicLong 对于很精确的数值需要使用 LongAdder 原理：JVM对于普通的long与double，允许将64位的读操作与写操作拆分为两个32位的操作。 核心：将热点数据分离，将一个value分割为一个数组，每个线程针对一个数值，最后的value由数组的值合成，将单点的更新压力分散为多点的更新压力。在低并行的时候，对value直接更新。 优点：在高并发下，效率很高 缺点：如果有并行更新，可能导致统计数据有一些误差 AtomicReference 1234567891011 private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;&gt;(0);//输出4 public static void main(String[] args) &#123; count.compareAndSet(0,2); // 2 count.compareAndSet(0,1); // no count.compareAndSet(1,3); // no count.compareAndSet(2,4); // 4 count.compareAndSet(3,5); // no log.info("count:&#123;&#125;",count.get()); &#125; AtomicReferenceFieldUpdater 以原子性更新某个类的一个实例的一个字段，字段必须volatile，并且非static 12345678910111213141516171819private static AtomicIntegerFieldUpdater&lt;AtomicExample5&gt; updater = AtomicIntegerFieldUpdater.newUpdater(AtomicExample5.class,"count");@Getterpublic volatile int count = 100;private static AtomicExample5 atomicExample5 = new AtomicExample5();public static void main(String[] args) &#123; if (updater.compareAndSet(atomicExample5,100,120))&#123; log.info("update success,&#123;&#125;",atomicExample5.getCount()); &#125; if (updater.compareAndSet(atomicExample5,100,120))&#123; log.info("update success,&#123;&#125;",atomicExample5.getCount()); &#125;else &#123; log.error("update error&#123;&#125;",atomicExample5.getCount()); &#125;&#125; AtomicLongArray 更新一个long的数组 AtomicBoolean 实现代码只执行一次 1234567private static AtomicBoolean isHappend = new AtomicBoolean(false);private static void test()&#123; if (isHappend.compareAndSet(false, true)) &#123; log.info("execute"); &#125; &#125; CAS的ABA问题ABA问题：在CAS操作中，其他线程将数据A改为B，又改为A。 解决：在每次更新的时候，记录一个版本号，每次更新+1 通过AtomicStampReference实现，核心方法为CompareAndSet 原子性：锁synchronized：依赖JVM，在该关键字作用对象的作用范围内，只有一个线程可以操作 Lock：依赖特殊的CPU指令，由代码实现。ReentrantLock synchronized同步锁，修饰的对象： 修饰代码块：大括号括起来的代码，作用于调用的对象 修饰方法：整个方法，作用于调用的对象 修饰静态方法：整个静态方法，作用于所有对象 修饰类：括号括起来部分，作用于所有对象 作用于所有的对象。则如果两个对象调用一个修饰的方法，他们会并行执行。而如果调用一个静态方法，则他们无法并行执行。 对于修饰代码块与修饰方法，不同的调用对象互相不影响 继承 如果子类调用继承于父类的synchronize方法（synchronize不属于一个类），是没有synchronize效果的，必须显式声明 特性 重进入：内部锁是重进入的，当线程试图获得它自己所占有的锁时候，请求会成功，即重进入是基于每线程的，而不是调用。 实现是通过为每个锁关联一个请求计数与一个占有它的线程，当同一线程访问，则计数++，线程退出该锁，则计数–，直到计数为0，释放该锁（父类与子类的使用） 用锁来保持状态 如果每个可被多个线程访问的可变状态变量，如果所有访问它的线程在执行状态当中占有同一个锁，则称该变量是由这个锁保护的 每个共享的可变变量都需要唯一一个确定的锁保护 设计 决定synchronize块大小需要权衡安全性（不能妥协）、简单性、性能。通常简单性与性能相互牵制，实现一个同步策略时候，不要过早地为了性能而牺牲简单性（是对安全性潜在的妥协） 有些耗时的计算或操作，如网络或者控制台IO，难以快速完成，执行它们的时候不要占有锁 Lock原子性对比： synchronize；不可中断锁，适合竞争不激烈，可读性好 Lock：可中断锁，多样化同步，竞争激烈能维持常态 Atomic：竞争激烈能维持常态，比lock性能好，但是只能同步一个值 活跃度与性能​ 不能武断地将整个方法设置为synchronize的，通过缩小synchronize的范围来提高并发性 可见性一个线程对主内存的修改可以及时被其他线程观察到。 导致共享变量在线程间不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存间及时更新 synchronizedJVM对synchronize的规定 线程解锁前，必须把共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享内存是需要从主内存中重新读取最新的值 volatile通过加入内存屏障与禁止重排序优化来实现。 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存。（每次写之后都刷新），CPU指令级别进行操作。 对volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量。（每次读从主内存读） 但是volatile无法保证线程安全。 1234count++;// 1、count//获得的是最新值// 2、+1 //两个进程同时++// 3、count//同时写回,即丢掉了一次. volatile使用 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中。 可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 使用场景 很适合作为状态标示量 检查两次 有序性一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般无序 方式：volatile、synchronized、lock、java内存模型的先天有序性（happens before原则） happens before原则 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定操作：一个unlock操作先行发生于后面对同一个锁的lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对于这个变量的读操作 传递规则；如果操作A先行发生于操作B，而操作B又先行发生于操作C，则操作A先行发生于操作C 线程启动规则：Thread对象的start（）方法先行发生于此线程的每一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测 对象终结规则：一个对象的初始化完成先行发生于它的finalize（）方法的开始 如果两个操作的执行次序无法从happens before推导出来，则JVM可以对它进行随意的重排序。 安全发布对象的四种方法 通过静态初始化器初始化对象的引用（JVM内部的同步机制） 将它的引用存储到volatile域或者atomicReference对象中 将它的引用存储到正确创建的对象的final域 或者将它的引用存储到由锁正确保护的域中 单例发布对象懒汉式线程不安全法12345678910111213141516171819202122232425/** * 懒汉模式 * 单例实例在第一次使用时候进行创建 */@NotRecommendpublic class SingletonExample1 &#123; //私有的构造函数 //即其他途径无法创建这个类的对象 private SingletonExample1()&#123; //包含对资源的处理等等 &#125; //单例对象 private static SingletonExample1 instance = null; //静态的工厂方法 private static SingletonExample1 getInstance()&#123; //多线程环境很容易出现问题 if (instance == null)&#123; instance = new SingletonExample1(); &#125; return instance; &#125;&#125; 双重检测机制(线程不安全) 12345678910111213141516171819202122232425262728293031323334353637/** * 懒汉模式 --&gt; 双重同步锁单例模式 * 单例实例在第一次使用时候进行创建 */@NotRecommendpublic class SingletonExample4 &#123; //私有的构造函数 private SingletonExample4()&#123;&#125; // 1.memory = allocate() 分配对象的内存空间 // 2.ctorInstance() 初始化对象 // 3. instance = memory 设置instance 指向刚分配的内存 //JVM和CPU优化，发生了指令重排 // 1.memory = allocate() 分配对象的内存空间 // 3. instance = memory 设置instance 指向刚分配的内存 // 2.ctorInstance() 初始化对象 //在第三步的时候,instance!=null //而此时在指令重排下,另一个线程就会获得一个没有初始化对象的引用,并将其返回 //单例对象 private static SingletonExample4 instance = null; //静态的工厂方法 private static SingletonExample4 getInstance()&#123; if (instance == null)&#123; //双重检测机制 //B synchronized (SingletonExample4.class)&#123; //同步锁 if (instance == null)&#123; instance = new SingletonExample4(); //A - 3 &#125; &#125; &#125; return instance; &#125; 线程安全法不推荐法 1234567891011121314151617public class SingletonExample3 &#123; //私有的构造函数 private SingletonExample3()&#123;&#125; //单例对象 private static SingletonExample3 instance = null; //静态的工厂方法 //synchronized限制,而存在性能开销 private static synchronized SingletonExample3 getInstance()&#123; if (instance == null)&#123; instance = new SingletonExample3(); &#125; return instance; &#125;&#125; 双重同步锁 基于volatile 1234567891011121314151617181920212223242526272829/** * 懒汉模式 --&gt; 双重同步锁单例模式 * 单例实例在第一次使用时候进行创建 */@ThreadSafepublic class SingletonExample5 &#123; //私有的构造函数 private SingletonExample5()&#123;&#125; // 1.memory = allocate() 分配对象的内存空间 // 2.ctorInstance() 初始化对象 // 3. instance = memory 设置instance 指向刚分配的内存 //单例对象 volatitle+ 双重检测机制 -&gt; 禁止指令重排序 private volatile static SingletonExample5 instance = null; //静态的工厂方法 private static SingletonExample5 getInstance()&#123; if (instance == null)&#123; //双重检测机制 //B synchronized (SingletonExample5.class)&#123; //同步锁 if (instance == null)&#123; instance = new SingletonExample5(); //A - 3 &#125; &#125; &#125; return instance; &#125;&#125; 饿汉模式通过静态域实现 123456789101112131415161718192021/** * 饿汉模式 * 单例实例在装载使用时候进行创建 */@ThreadSafepublic class SingletonExample2 &#123; //私有的构造函数 private SingletonExample2()&#123; //如果构造方法中存在过多的功能,则在加载时会过慢,存在性能问题 //只进行资源加载而没有实际调用,则会导致资源浪费 &#125; //单例对象 private static SingletonExample2 instance = new SingletonExample2(); //静态的工厂方法 private static SingletonExample2 getInstance()&#123; return instance; &#125;&#125; 通过静态块实现 123456789101112131415161718192021222324@ThreadSafepublic class SingletonExample6 &#123; //私有的构造函数 private SingletonExample6()&#123;&#125; //静态资源是顺序执行的 //单例对象 private static SingletonExample6 instance = null; //必须写在后面,如果写在前面,则会被上一句赋值为null static &#123; instance = new SingletonExample6(); &#125; //静态的工厂方法 private static SingletonExample6 getInstance()&#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance().hashCode()); System.out.println(getInstance().hashCode()); &#125;&#125; 枚举模式12345678910111213141516171819202122232425262728/** * 枚举模式：最安全 */@ThreadSafe@Recommendpublic class SingletonExample7 &#123; //私有的构造函数 private SingletonExample7()&#123;&#125; public static SingletonExample7 getInstance()&#123; //在实际使用的时候才会初始化 return Singleton.INSTANCE.getSingleton(); &#125; private enum Singleton&#123; INSTANCE; private SingletonExample7 singleton; //JVM保证这个方法绝对只调用一次 Singleton()&#123; singleton = new SingletonExample7(); &#125; public SingletonExample7 getSingleton()&#123; return singleton; &#125; &#125;&#125; 线程安全策略进行共享和发布对象，使得多个线程可以安全地访问他们。 线程限制 一个被线程限制的对象，由线程独占，并且只能被占有它的线程修改 线程封闭：把对象封装到一个线程当中，只有一个线程可以看到它 共享只读 一个共享只读的对象，在没有额外同步的情况下，可以被多个线程并发访问，但是任何线程都不能修改它 不可变对象：一种对象只要发布了就是安全的，即不可变对象，是一种躲避并发的方法 线程安全对象 一个线程安全的对象或者容器，在内部通过同步机制来保证线程安全，所有其他线程无需额外同步就可以通过公共接口随意访问它 被守护对象 只能通过获取特定的锁来访问 线程不安全类与写法线程不安全类： 如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。 如果一个类的对象可以同时被多个线程访问，如果没有做并发处理，则会出现异常 StringBuilder是线程不安全的。 StringBuffer是线程安全的，它内部方法添加了synchronized，但也因此它的性能有损耗。 ArrayList、hashMap、hashSet等collection 线程不安全 示例 以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。 123456789101112131415161718192021222324252627public class ThreadUnsafeExample &#123; private int cnt = 0; public void add() &#123; cnt++; &#125; public int get() &#123; return cnt; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; ThreadUnsafeExample example = new ThreadUnsafeExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 安全发布如果希望跨线程共享对象，则必须安全地共享它 对象的引用对其他线程可见，但它的状态可能是过期的，即对象的状态不一定对消费线程可见。 安全发布的模式 通过静态初始化器初始化对象的引用（JVM内部的同步机制） 将它的引用存储到volatile域或者atomicReference 将它的引用存储到正确创建的对象的final域 或者将它的引用存储到由锁正确保护的域中 线程安全容器 线程安全容器的内部同步，即将对象置入这些容器的操作符合最后一条要求 HashTable、synchronizedMap、concurrentMap Vector、CopyOnWriteArrayList、synchronizedList BlockingQueue、concurrentLinkedQueue 高效不可变对象 一个对象在技术上不是不可变得，但是它的状态在发布后不会再更改，即有效不可变对象。 任何线程都可以在没有额外同步的情况下安全使用一个安全发布的高效不可变对象 可变对象 安全发布仅仅保证发布当时的可见性，对于可变性，还需要线程安全或锁 可变对象必须要安全发布，同时必须要线程安全或者是锁保护的 线程限制：一个线程限制的对象，通过限制在线程中，而被线程独占，且只能被占有它的线程修改 共享只读：在没有额外同步的情况下可以被多个对象并发访问，但是任何线程都不可以修改它，包括可变对象和高效不可变对象 共享线程安全：一个线程安全的对象在内部同步，所以其他线程无须额外同步，就可以通过公共接口访问 被守护的：一个被守护的对象只能通过特定的锁来访问。被守护的对象包括那些被线程安全对象封装的对象，和已知被特定的锁保护起来的已发布对象 线程安全实现方式（共享） 适合于从开开始构建一个类，或者将多个非线程安全的类组合成一个类 不可变不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 不可变的类型： final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 不可变对象需要满足的条件 对象创建以后状态就不能修改 将类声明为final 对象所有域都是final类型 所有域声明为私有 不通过set方法 将所有可变数据声明为final 对象是正确创建的，this引用没有逸出 通过构造器初始化所有成员 在get方法不直接返回对象本身，而是返回一个clone final关键字：类、方法、变量 修饰类： 不能被继承 所有成员方法会隐式选择为final 修饰方法 锁定方法不能被继承修改 修饰变量 基本数据类型变量 引用类型变量（初始化后，不能指向另一个对象） 其他创建不可变对象方法 对于集合类型，Collections.unmodifiableXXX：Collection、List、Set、Map… 123456789101112131415161718public class ImmutableExample2 &#123; private static Map&lt;Integer,Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1,2); map.put(3,4); map.put(5,6); //创建final的map map = Collections.unmodifiableMap(map); &#125; public static void main(String[] args) &#123; //会抛出异常, map无法被修改 map.put(1,3); log.info("&#123;&#125;",map.get(1)); &#125;&#125; 将返回一个新的map，将数据拷贝过去，然后将所有更改数据转换为了抛出异常 123public static &lt;K,V&gt; Map&lt;K,V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; return new UnmodifiableMap&lt;&gt;(m);&#125; Guava：ImmutableXXX：Collection、List、Set、Map… 1234567891011121314151617public class ImmutableExample3 &#123; private final static ImmutableList&lt;Integer&gt; list = ImmutableList.of(1,2,3); private final static ImmutableSet set = ImmutableSet.copyOf(list); private final static ImmutableMap&lt;Integer,Integer&gt; map = ImmutableMap.of(1,2,3,4); private final static ImmutableMap&lt;Integer,Integer&gt; map2 = ImmutableMap.&lt;Integer,Integer&gt;builder() .put(1,2).put(3,4).put(5,6).build(); public static void main(String[] args) &#123;// set.add(4);// map2.put(1,4); System.out.println(map2.get(3)); &#125;&#125; 互斥同步 同步指多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个(或一些)线程使用。 互斥是实现同步的一种手段。 互斥同步最主要的问题是进行线程阻塞与唤醒带来的性能问题。悲观的并发策略。 临界区、互斥量、信号量都是主要互斥实现方法。 synchronized关键字：需要系统帮助完成 J.U.C包下的重入锁，例如ReentrantLock 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 CAS随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。 AtomicIntegerJ.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。 以下代码使用了 AtomicInteger 执行了自增的操作。 12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123; cnt.incrementAndGet();&#125; 以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。 123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。 可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; ABA如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。 线程封闭访问共享的、可变的数据要求使用同步。一个可以避免同步的方法就是不共享数据，如果数据仅仅在单线程当中访问，则不需要任何同步。当对象封装在一个线程当中，则自动成为线程安全的。 Swing将事件分发到线程当中 JDBC从池中分配一个对象给线程。 线程封闭方法： Ad-hoc线程封闭：程序控制实现，最糟糕。 指维护线程限制性的任务全部落在实现上的情况 确保只通过单一线程写入共享的volatile变量，则操作便是共享 堆栈封闭：局部变量，无并发问题。 是线程限制的特例，只能通过本地变量才可以触及对象。本地变量使得对象更容易被限制在线程本地中，本地变量本身就被限制在执行线程中，它们存在于执行线程栈。其他线程无法访问这个栈 示例 123456789101112131415161718public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125;public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125;100100 例如方法当中的numPairs。在该方法当中，实例化的animals只有一个引用指向它，因此它保存在线程的栈当中，倘若发布了animals或其内部对象的引用，则破坏了限制，并导致了对象逸出 ThreadLocal如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 ThreadLocal线程封闭：特别好的封闭方法。 内部维护了一个map，key是线程名称，值是对象 更规范的方式，允许将每个线程与持有数值的对象关联在一起。ThradLocal提供了get和set，为每个使用它的线程维护一份单独的拷贝，所以get总是返回当前执行线程通过set设置的最新值。 ThreadLocal 提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。 总的来说，ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 12345678910111213141516171819202122public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125;1 为了理解 ThreadLocal，先看以下代码： 12345678910111213141516public class ThreadLocalExample1 &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal1.set(1); threadLocal2.set(1); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal1.set(2); threadLocal2.set(2); &#125;); thread1.start(); thread2.start(); &#125;&#125; 底层原理它所对应的底层结构图为： 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; get() 方法类似。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。 在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 可重入代码（Reentrant Code）这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 基础构建模块委托是创建线程安全的一个最有效的策略，只需让现有的线程安全类关联所有的状态即可。 同步容器包括Vector和HashTable，这些类通过封装它们的状态，并对每一个公共方法进行同步实现了线程安全，这样一次只能有一个线程访问容器。通过对容器的所有状态串行访问实现的线程安全，削弱了并发性。 容器本身是线程安全的，无论有多少线程同时调用容器，也不会破坏容器。但是对于方法的调用者来说，当线程在并发地修改容器，最后得到的结果并不是所预期的结果。面对这种情况，需要对容器类自身进行加锁，synchronized(list)，保证复合操作的原子性。因为它们的线程安全是相对线程安全 迭代 对容器进行迭代的时候，需要对容器进行加锁，防止容器数据更改，但是这么一来对并发的性能就大大下降，会在相当长时间加锁，甚至产生死锁。一个解决办法是复制容器，因为是存在线程当中，但是在复制过程中依然需要加锁，而且占用空间。 正如封装一个对象的状态，能够使它更容易地保持不变约束一样，封装它的同步则可以迫使它符合同步策略 隐藏迭代器：有些迭代器是隐藏的，比如toString方法，hashCode方法，equals方法都会对容器进行迭代 ConcurrentModificationException当对Vector等容器进行迭代时，如果有并发的线程进行修改，则会表现出及时失败，即当它们发现容器在迭代过程中被修改，就会抛出一个ConcurrentModificationException。 及时失败的迭代器只是善意地捕获并发错误，因此只能作为并发问题的预警指示器。其实现时将计数器与容器关联起来，如果在迭代期间计数器被修改，那么hasNext或next会抛出ConcurrentModificationException 并发容器为多线程的并发访问而设计。 ConcurrentHashMap代替同步的HashMap ConcurrentMap接口增加了常见复合操作的支持 ConcurrentSkipListMap代替同步的SortedMap ConcurrentSkipListSet代替同步的SortedSet 当多数操作为读取，CopyOnWriteArrayList是List的同步 ConcurrentLinkedQueue，传统的先进先出队列 BlockingQueue，增加了可阻塞的插入和获取等操作 用并发容器替换同步容器，这种做法以有很小的风险带来了可扩展性显著提高 阻塞队列和生产者-消费者模式阻塞队列提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。如果队列已满，则put方法将阻塞直到有空间可用；如果队列为空，则take将阻塞直到有元素可用。 put方法的阻塞特性，当队列充满，生产者将阻塞并不能继续生成工作。offer方法的阻塞特性，如果数据项不能添加到队列中，将返回一个失败状态，这样可以创建更多灵活的策略处理符合过载的情况。例如将多余的工作项序列化写入磁盘、减少生产者线程、通过某种方式抑制生产者线程。 构建高可靠应用程序时，有界队列是一种强大的资源管理工具，它们能抑制并防止产生过多的工作项，使应用程序在负荷过载的情况下变得更加健壮。 阻塞方法与中断方法阻塞状态：blocked，waiting，Timed_waiting 中断： thread.interrupt()，用于中断线程或者查询线程是否已经被中断。中断是一种协作机制，当A中断B只是要求B在执行到某个可以暂停的地方停止执行，并且前提是B愿意停下来。 中断一般用于取消某个操作。 当代码中调用了一个将抛出InterruptedException异常的方法（即该方法是一个阻塞方法）时，自己的方法也就变成了阻塞方法，并且必须要处理对中断的响应。 传递InterruptedException 恢复中断，捕获异常，并通过调用当前线程的interrupt方法恢复中断，这样在调用栈中更高层的代码将看到引发了一个中断 构建高效且可伸缩的结果缓存简单的缓存可能会将性能瓶颈转变为可伸缩性瓶颈 first Compute是一个需要很长事件计算结果的方法。Memorizerl是包装器，并将缓存的结果保存。 为确保线程安全使用了synchronized，但是带来了明显的伸缩性问题。 second 使用ConcurrentHashMap改进HashMap，避免了compute方法同步带来的串行性。 但是在两个线程同时调用compute时，可能导致计算得到相同的值，因为从缓存获取值与计算并不是一个原子操作。 final 使用FutureTask，表示一个计算的过程，即将Map修改为ConcurrentHashMap&lt;A,Future&lt;V&gt;&gt; 会先检查某个相应的结果是否以及开始，如果没有启动就创建一个FutureTask并注册到Map，然后计算。 如果已经启动，则等待现有的计算结果。 使用putIfAbsent实现原子操作。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：Java虚拟机规范]]></title>
    <url>%2F2019%2F08%2F02%2FJava%2Fbase%2FJVM%EF%BC%9AJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[JVM结构要正确地实现一台JVM，只需要能正确读取class文件中地每一条字节码指令，并且能正确地执行这些指令所蕴含的操作即可。 对于设计者，可以完全自主决定所有规范中不曾描述的虚拟机内部细节，例如运行时数据区的内存如何布局、选择哪种垃圾收集算法、是否对虚拟机字节码指令进行一些内部的优化操作等。 class文件格式编译后被JVM所执行的代码使用了一种平台中立(不依赖于特定硬件与OS)的二进制格式来表示，并且经常以文件的形式存储。class文件格式精确定义了类与接口的表示形式。 数据类型JVM当中可以操作的数据类型分为两类：原始类型和引用类型，也存在原始值和引用值两种类型的数值，它们可以用于变量赋值、参数传递、方法返回和运算操作。 JVM希望尽可能多的类型检查能够在程序运行前完成，即编译器应该在编译期间尽最大努力完成可能的类型检查，使得虚拟机在运行期间无须进行这些操作。 对于原始类型，不需要通过特殊标记或额外手段来在运行期确定它们的实际数据类型，即无需刻意将它们与引用类型分开，JVM的字节码指令本身就可以确定它的指令操作数的类型是声明，因此可以利用该特性直接确定操作数的类型。 JVM是直接支持对象的，对象可以指动态分配的某个类的实例，也可以指某个数组。虚拟机中使用reference类型来表示对某个对象的引用。 原始类型与值原始数据类型包括： 数值类型： 整数类型 byte：8位有符号二进制补码整数。-2^7^~2^7^-1 short：16位有符号二进制补码整数-2^15^~2^15^-1 int：32位有符号二进制补码整数-2^31^~2^31^-1 long：64位有符号二进制补码帧整数-2^63^~2^63^-1 char：16位无符号整数、指向基于多文种平面的Unicode码点，以UTF-16编码，默认值位Unicode的null码点。0~2^16^ 浮点数类型： float：32位，单精度浮点数集合中的元素 double：64位，双精度浮点数集合中的元素 包括了符号量，还包括了正负0、正负无穷大、NaN（无效的运算操作） boolean类型。默认为false 没有提供boolean值专用的字节码指令，Java语言表达式操作的boolean值会在编译后使用int代替 returnAddress类型。指向某个操作码(opcode)的指针，此操作码与JVM指令对应，在JVM支持的所有原始类型中，只有该类型不能直接与Java语言的数据类型对应。 会被jsr、ret、jsr_w指令所使用。并且无法在程序运行期间修改 引用类型与值JVM中有3种引用类型：类类型、数组类型、接口类型。这些分别指向动态创建的类实例、数组实例、实现了某个接口的类实例或数组实例。 对于数组的元素类型，其必须是原生类型、类类型或接口类型之一。 在引用类型的值中有一个特殊的值null，当一个引用不指向任何对象的时候，它的值就为null。引用类型的默认值就是null 运行时数据区详情参见 JVM：内存管理 栈帧栈帧是用来存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回值和异常分派。 栈帧随着方法调用而创建，随着方法结束而销毁。无论方法是正常完成还是异常完成都算作方法结束。 栈帧的存储空间分配在虚拟机栈当中，并且每一个栈帧有自己的局部变量表、操作数栈、和指向当前方法所属的类的运行时常量池的引用。并且栈帧还允许携带与JVM实现相关的一些附加信息，例如对程序调试提供支持。 在某条线程执行过程中的某个时间点上，只有目前正在执行的那个方法的栈帧是活动的。当方法返回时，当前栈帧会传回此方法的执行结果给前一个栈帧，然后JVM丢弃该栈帧。 局部变量表每个栈帧内部都包含一组称为局部变量表的变量列表（其中包括基础数据类型，例如boolean等、对象的引用或returnAddress），栈帧内的局部变量表的长度由编译器决定，并且存储于类或接口的二进制表示中，即存储在方法的Code属性当中，并提供给栈帧使用。 局部变量表需要的内存空间在编译期间完成分配，当进入一个方法时这个需要分配多大的局部变量空间时完全确定的，运行期间不会改变局部变量表的大小，64位的long和double会占据两个局部变量空间。 局部变量使用索引来进行访问定位，0=&lt;index=&lt;length。当调用实例方法时，index=0的变量一定是this引用，之后是方法的参数。 操作数栈JVM底层字节码指令集是基于栈类型的，索引的操作码都是对操作数栈上的数据进行操作。对每一个方法调用，JVM会建立一个操作数栈，以供计算使用。栈的深度在源码编译成class文件后就已经确定，保存在方法的Code属性中。 在开始时操作数栈是空的，JVM提供了一些字节码指令来从局部变量表或对象实例的字段中复制常量值到操作数栈中，以及从操作数栈中取走数据、操作数据以及将操作结果重新入栈。在方法调用时，也用来准备调用方法的参数以及接收方法返回的结果。 iadd指令要求执行前操作数栈的栈顶已经存在两个由前面其他指令放入的int类型数值，执行iadd时将两个int值出栈，相加求和并将求和结果重新入栈。 对于一部分指令可以不关注操作数的具体数据类型，将所有在运行时数据区中的数据当作裸类型数据来操作，例如swap。它们的操作的正确性会通过class文件的校验过程来强制保障 动态链接包含一个指向当前方法所在类型的运行时常量池的引用，以支持对当前方法的代码实现动态链接。 在class文件中，一个方法若调用其他方法或访问成员变量，则需要通过符号引用来表示，动态链接的作用就是将这些符号引用所表示的方法转换为对实际方法的直接引用。类加载过程中将要解析尚未被解析的符号引用，并且将对变量的访问转化为变量在程序运行时，位于数据结构中的正确偏移量。 方法调用正常完成若方法正常返回，当前栈帧承担着恢复调用者状态的责任，其状态包括调用者的局部变量表、操作数栈和正确增加过来表示执行了该方法调用指令的程序计数器等。使得调用者的代码能在被调用的方法返回并且返回值被推入调用者栈帧的操作数栈后继续正常执行。 方法调用异常完成若在方法的执行过程中，某些指令导致了JVM抛出异常并且虚拟机抛出的异常在方法中没有办法处理，并且该方法内部没有将异常捕获，如果方法异常调用完成，一定没有方法返回值返回给调用者。 其他引用对象的表示JVM并不强制规定对象的内部结构应当如何表示。 句柄与直接引用。 浮点算法特殊方法在JVM层面上，对于对象，Java中的构造器是以应该名为&lt;init&gt;的特殊实例初始化方法的形式出现的，其是由编译器命名的，因为无法通过程序编码的方式实现。实例初始化方法只能在实例的初始化期间，通过JVM的invokespecial指令调用，并且只能在尚未初始化的实例上调用该指令。 对于类或接口，则最多可以包含不超过应该类或接口的初始化方法，该方法是一个不包含参数的、返回类型为void的方法&lt;clinit&gt;。类或接口的初始化方法由JVM自身隐式调用，没有任何JVM字节码指令可以调用这个方法，只会在类的初始化阶段中由JVM自身调用。 当一个方法具有签名多态性则意味着这个方法满足以下全部条件 通过java.lang.invoke.MethodHandle类声明 只有一个类型为Object[]的形参 返回值为Object ACC_VARAGS和ACC_NATIVE标志被设置 Java8中，只有java.lang.invoke.MethodHandle的invoke和invokeExact是签名多态性方法。invokevirtual指令会对具有签名多态性的方法进行特殊处理。 异常异常使用Throwable或其子类的实例来表示，抛异常本质实际上是程序控制权的一种即时的、非局部的转换，从异常排除的地方转换至处理异常的地方。 绝大部分异常的产生是由于当前线程执行的某个操作导致的，即同步异常。而异步异常可以在程序执行过程中随时发生。JVM中异常的出现总是由以下三种原因之一导致的 athrow字节码指令被执行，即代码中写了throw 虚拟机同步检测到程序发生了非正常的执行情况，这时异常必将紧接着发生非正常执行情况的字节码指令后抛出，而不会在执行程序的过程中随时抛出 程序所执行的操作可能会引发异常。 字节码指令所蕴含的操作违反了Java语言的语义，例如访问一个超出数组边界范围的元素 当程序在加载或链接时出错 使用某些资源的时候产生资源限制，例如使用了太多内存 异步异常的发生 调用了Thread或者ThreadGroup的stop方法。则此时该线程会影响到其他线程，此时其他线程中出现的异常就是异步异常，因为它可能出现在线程执行过程中的任何位置。 JVM发生了内部错误 抛出异常JVM允许在异步异常抛出前额外执行一小段有限的代码，使得代码优化器能够在不违反Java语言语义的前提下检测并将异常在可以处理它们的地方抛出。 当异常抛出、程序控制权发生转移的那一刻，所有在异常抛出的位置之前的字节码指令所产生的影响都应当时是可以观察到的，而在异常抛出的位置之后的字节码指令则不应当产生执行效果。如果虚拟机执行的代码是优化过的代码，有一些在异常之后的代码可能已经执行了，则这些优化过的代码必须保证它们提前执行所产生的影响对用户程序来说是不可见的。 异常处理器JVM执行的每个方法都会配有0-N个异常处理器，异常处理器描述了其在方法代码中的有效作用范围、能处理的异常类型以及处理异常的代码所在的位置。 要判断某个异常处理器能否处理某个具体的异常，需要同时检查异常出现的位置是否在异常处理的有效作用范围内，出现的异常是否是异常处理器声明可以处理的异常类型。当抛出异常，JVM会去搜索当前方法包含的各个异常处理器。 异常完成如果当前方法没有找到任何的异常处理器，并且确实异常了，则当前方法的操作数栈和局部变量表都将被丢弃，随后对应的栈帧出战，恢复到该方法调用者的栈帧中，未被处理的异常将在方法调用者的栈帧中重新被抛出，并在整个调用链不断重复。如果在顶端依然没有找到合适的处理器，则整个线程终止。 字节码指令集简介类库公有设计、私有实现JVM实现必须能够读取class文件并精确实现包含在其中的JVM代码的语义。 实现者可以在规范约束下对具体实现做出修改和优化，并且推荐如此做，只要优化后的class文件依然可以正确读取，并且包含在其中的语义能够得到保持，实现者就可以选择任何方式去实现这些语义。 JVM编译器理解编译器是如何与JVM协同工作的，编译器在某些场景中专指将JVM指令集转换未特定CPU指令集的翻译器。 格式可以使用javap生成，虚拟机汇编语言格式： 1&lt;index&gt;&lt;opcode&gt; [&lt;operand1&gt;[&lt;operand2&gt;...]] [&lt;comment] &lt;index&gt;是指令操作码在数组中的下表，该数组以字节形式来存储当前方法的JVM代码。也可以认为是相对于方法起始处的字节偏移量 &lt;opcode&gt;为指令的操作数，一条指令可以有0-N个操作数 &lt;comment&gt;为行尾注释，器部分内容为javap加入，其余为作者添加。 每条指令前的&lt;index&gt;可以作为控制转移指令的跳转目标。 访问运行时常量池很多数值常量、对象、字段和方法，都是通过当前类的运行时常量池进行访问的。 ldc、ldc_w、ldc2_w 接收参数方法调用普通实例方法调用时在运行时根据对象类型进行分派的，这类方法调用通过invokevirtual指令实现，invokevirtual指令都会带有一个表示索引的参数，运行时常量池在该索引处的项为某个方法的符号引用，这个符号引用可以提供方法所在对象的类型的内部二进制名称、方法名称和方法描述符。 123int add12and13()&#123; return addTwo(12, 13);&#125; 编译后如下 123456Method int add12and13()0 aload_01 bipush 123 bipush 135 invokevirtual #48 ireturn 使用类实例同步JVM中的synchronization是由monitor的进入和退出来实现的，无论是显式同步还是隐式同步。 注解参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：从JVM角度观察实际问题]]></title>
    <url>%2F2019%2F08%2F01%2FJava%2Fbase%2FJVM%EF%BC%9A%E4%BB%8EJVM%E8%A7%92%E5%BA%A6%E8%A7%82%E5%AF%9F%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[JVM方法调用的内部机制JVM作为一款虚拟机，必然要涉及计算机核心的3大功能。 方法调用。方法作为程序组成的基本单元，作为原子指令的初步封装，计算机必须能够支持方法的调用。同样，Java语言的原子指令是字节码，Java方法是对字节码的封装，因此，JVM必须支持对Java方法的调用。 取值。计算机进入方法后，最终需要逐条取出指令并逐条执行。Java方法也不例外，因此JVM进入方法后，也要模拟硬件CPU，能够从Java方法中逐条去除字节码指令。 运算。计算机取出指令后，就要根据指令进行相应的逻辑运算，实现指令的功能。JVM作为虚拟机，也需要具备对Java字节码的运算能力。 即方法调用与方法执行 提出问题 JVM到底是如何run起来的。即计算机的核心3大功能 在JVM的方法调用中，其变量、方法的执行是一个什么样的角色，在一个什么位置。 概述是什么Java源代码需要编译成字节码文件，由JVM解释执行。 分类 方法调用 静态 动态 方法执行 为什么要理解内存管理虚拟机栈Java虚拟机在运行时会为每一个线程在内存中分配了一个虚拟机栈，来表示线程的运行状态和信息，虚拟机栈中的元素称之为栈帧（JVM stack frame）,每一个栈帧表示这对一个方法的调用信息。如下所示： 方法调用大致过程1234567891011public class Bootstrap &#123; public static void main(String[] args) &#123; String name = "Louis"; greeting(name); &#125; public static void greeting(String name)&#123; System.out.println("Hello,"+name); &#125;&#125; 首先JVM会先将这个Bootstrap.class信息加载到 内存中的方法区(Method Area)中。Bootstrap.class中包含了常量池信息，方法的定义 以及编译后的方法实现的二进制形式的机器指令，所有的线程共享一个方法区，从中读取方法定义和方法的指令集。 接着，JVM会在Heap堆上为Bootstrap.class 创建一个Class\&lt;Bootstrap&gt;实例用来表示Bootstrap.class 的 类实例。 JVM开始执行main方法，这时会为main方法创建一个栈帧，以表示main方法的整个执行过程； main方法在执行的过程之中，调用了greeting静态方法，则JVM会为greeting方法创建一个栈帧，推到虚拟机栈顶。 当greeting方法运行完成后，则greeting方法出栈，main方法继续运行； JVM方法调用的过程是通过栈帧来实现的，那么，方法的指令是如何运行的呢？弄清楚这个之前，我们要先了解对于JVM而言，方法的结构是什么样的。我们知道，class文件是JVM能够识别的二进制文件，其中通过特定的结构描述了每个方法的定义。 JVM在编译Bootstrap.java的过程中，在将源代码编译成二进制机器码的同时，会判断其中的每一个方法的三个信息： 在运行时会使用到的局部变量的数量（作用是：当JVM为方法创建栈帧的时候，在栈帧中为该方法创建一个局部变量表，来存储方法指令在运算时的局部变量值） 其机器指令执行时所需要的最大的操作数栈的大小（当JVM为方法创建栈帧的时候，在栈帧中为方法创建一个操作数栈，保证方法内指令可以完成工作） 方法的参数的数量 子类方法与父类方法的关系如果子类中不显式调用父类的方法，即不super.method，则不会执行父类的方法。 因此synchronized关键字在子类中是需要显式声明的。 JVM对一个方法执行的基本策略一般地，对于java方法的执行，在JVM在其某一特定线程的虚拟机栈(JVM Stack) 中会为方法分配一个 局部变量表，一个操作数栈，用以存储方法的运行过程中的中间值存储。 由于JVM的指令是基于栈的，即大部分的指令的执行，都伴随着操作数的出栈和入栈。所以在学习JVM的机器指令的时候，一定要铭记一点：每个机器指令的执行，对操作数栈和局部变量的影响，充分地了解了这个机制，你就可以非常顺畅地读懂class文件中的二进制机器指令了。 如下是栈帧信息的简化图，在分析JVM指令时，脑海中对栈帧有个清晰的认识： 方法调用的字节码指令JVM里面提供了4条方法调用字节码指令。分别如下： invokestatic:调用静态方法 invokespecial:调用实例构造器&lt;init&gt;方法、私有方法和父类方法（super(),super.method()） invokevirtual:调用所有的虚方法(静态方法、私有方法、实例构造器、父类方法、final方法都是非虚方法) invokeinterface:调用接口方法，会在运行时期再确定一个实现此接口的对象 invokestatic和invokespecial指令调用的方法都可以在解析阶段中确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类加载阶段就会把符号引用解析为该方法的直接引用。直接引用就是一个指针或偏移量，可以让JVM快速定位到具体要调用的方法。 invokevirtual和invokeinterface指令调用的方法是在运行时确定具体的方法地址，接口方法和实例对象公有方法可以用这两个指令来调用。 123456789101112public class Test &#123; private void run() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); // invokespecial 构造器调用 list.add("a"); // invokeinterface 接口调用 ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); // invokespecial 构造器调用 arrayList.add("b"); // invokevirtual 虚函数调用 &#125; public static void main(String[] args) &#123; Test test = new Test(); // invokespecial 构造器调用 test.run(); // invokespecial 私有函数调用 &#125;&#125; 反编译字节码： 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; public Test(); Code: 0: aload_0 1: invokespecial #1 // Object init 4: return private void run(); Code: 0: new #2 // class java/util/ArrayList 3: dup 4: invokespecial #3 // Method java/util/ArrayList."&lt;init&gt;":()V 7: astore_1 //初始化一个字符串a，并存入常量池 8: aload_1 //加载一个字符串 9: ldc #4 // String a 11: invokeinterface #5, 2 // 执行list.add 16: pop 17: new #2 // class java/util/ArrayList 20: dup 21: invokespecial #3 //init ArrayList 24: astore_2 25: aload_2 26: ldc #6 // String b 28: invokevirtual #7 // Method java/util/ArrayList.add:(Ljava/lang/Object;)Z 31: pop 32: return public static void main(java.lang.String[]); Code: 0: new #8 // class Test 3: dup 4: invokespecial #9 // Method List init 7: astore_1 8: aload_1 9: invokespecial #10 // Method run:()V 12: return&#125; 从上面的字节码可以看出，每一条方法调用指令后面都带一个Index值，JVM可以通过这个索引值从常量池中获取到方法的符号引用。 每个class文件都有一个常量池，主要是关于类、方法、接口等中的常量，也包括字符串常量和符号引用。方法的符号引用是唯一标识一个方法的信息结构体，包含类名，方法名和方法描述符，方法描述符又包含返回值、函数名和参数列表。这些字符值都存放到class文件的常量池中，通过整型的Index来标识和索引。 动态链接Java中的实例方法默认是虚方法，因此父类引用调用被子类覆盖的方法时能体现多态性。方法调用阶段的唯一任务是确定被调用方法的版本，即调用哪一个方法。而Class文件的编译过程是不涉及传统编译器中的连接步骤，一切方法调用在Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用），即需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。 动态链接即Java当中的多态特性，而到JVM层面即当JVM遇到invokevirtual或invokeinterface时，需要运行时根据方法的符号引用查找到方法地址。具体过程如下： 在方法调用指令之前，需要将对象的引用压入操作数栈 在执行方法调用时，找到操作数栈顶的第一个元素所指向的对象实际类型，记作C 在类型C中找到与常量池中的描述符和方法名称都相符的方法，并校验访问权限。如果找到该方法并通过校验，则返回这个方法的引用； 否则，按照继承关系往上查找方法并校验访问权限； 如果始终没找到方法，则抛出java.lang.AbstractMethodError异常； 可以看到，JVM是通过继承关系从子类往上查找的对应的方法的，为了提高动态分派时方法查找的效率，JVM为每个类都维护一个虚函数表。 虚函数表JVM里引入虚函数表的目的是加快虚方法的索引。JVM 会在链接类的过程中，给类分配相应的方法表内存空间。每个类对应一个方法表。这些都是存在于方法区中的。Java中每个对象的对象头有一个类型指针，可以索引到对应的类，在对应的类数据中对应一个方法表。 一个类的方法表包含类的所有方法入口地址，从父类继承的方法放在前面，接下来是接口方法和自定义的方法。如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类相同的方法的入口地址一致。如果子类重写了这个方法，子类方法表中的地址将会替换为指向子类实现版本的入口地址。 方法执行参考 JVM方法调用的内部机制 《Java虚拟机原理图解》4.JVM机器指令集 深入理解JVM方法调用的内部机制 Java执行引擎工作原理——方法调用]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：JMM-并发机制的原理]]></title>
    <url>%2F2019%2F07%2F31%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJMM-%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E7%9A%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[并发编程volatile当声明共享变量为volatile后，对这个变量的读/写将会很特别。JMM堆volatile专门定义了一些特殊的访问规则。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 概述 轻量级synchronized 在使用恰当情况下，比synchronized的使用和执行成本更低。它不会引起线程的上下文切换与调度 保证共享变量的可见性 可见性：当一个线程修改一个共享变量的值，另外一个线程能读到这个修改的值 volatile的内存语义可见性volatile变量特性： 可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 理解volatile特性的一个好方法是把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。 示例代码： 123456789101112class VolatileFeaturesExample &#123; volatile long vl = 0L; // 使用volatile声明64位的long型变量 public void set(long l) &#123; vl = l; // 单个volatile变量的写 &#125; public void getAndIncrement () &#123; vl++; // 复合（多个）volatile变量的读/写 &#125; public long get() &#123; return vl; // 单个volatile变量的读 &#125;&#125; 假设有多个线程分别调用上面程序的3个方法，这个程序在语义上和下面程序等价。 1234567891011121314class VolatileFeaturesExample &#123; long vl = 0L; // 64位的long型普通变量 public synchronized void set(long l) &#123; // 对单个的普通变量的写用同一个锁同步 vl = l; &#125; public void getAndIncrement () &#123; // 普通方法调用 long temp = get(); // 调用已同步的读方法 temp += 1L; // 普通写操作 set(temp); // 调用已同步的写方法 &#125; public synchronized long get() &#123; // 对单个的普通变量的读用同一个锁同步 return vl; &#125;&#125; 禁止指令重排序优化普通的变量只能保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量的赋值操作的顺序与程序代码中的执行顺序一致。 而volatile禁止了指令重排序优化 内存屏障： 对于volatile修饰的变量，赋值后会多执行一个lock addl操作，这个操作相当于一个内存屏障，指重排序时不能把后面的指令重排序到内存屏障前的位置。 指令重排序是CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理，但是如果指令间有依赖则不会重排。当进行volatile变量赋值，则会将缓存数据写入内存，即此时前面所有操作都已经执行完成，因此无法越过内存屏障。 JMM实现为实现volatile，JMM限制编译器重排序与处理器重排序 volatile重排序规则表： 第三行最后一个单元格的意思是：在程序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。 适用性volatile只保证了可见性，因此只适用于一下规则的运算场景 运算结果不依赖变量的当前值，或者能保证只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 volatile写-读建立的happens-before关系volatile对线程的内存可见性的影响比volatile自身的特性更为重要。JDK5开始，volatile变量的写-读可以实现线程间的通信。 从内存语义的角度来说 volatile的写-读与锁的释放-获取有相同的内存效果。 volatile写和锁的释放有相同的内存语义。 volatile读与锁的获取有相同的内存语义。 1234567891011121314class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a; // 4 …… &#125; &#125;&#125; 当线程A执行writer()，线程B执行reader()，则根据happens-before 根据程序次序规则，1 before 2,3 before 4 根据volatile规则，2 before 3 根据传递性规则，1 before 4 即这里A线程写一个volatile变量后，B线程读同一个volatile变量。 A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。 volatile写-读的内存语义volatile写内存语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 volatile读的内存语义：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 图为线程B读同一个volatile变量后，共享变量的状态示意图。 总结 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 JSR-133为什么要增强volatile的内存语义在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量重排序。 为了提供一种比锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和锁的释放-获取具有相同的内存语义。 synchronizedsynchronized在编译后会在同步块前后分别形成monitorenter与monitorexit两个字节码指令。这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，如果Java中synchronized明确指定了对象参数，即这个对象的reference，如果没有指定即根据修饰的是实例方法还是类方法，去取相应的对象实例或Class对象来作为锁对象。 原子变量与非阻塞同步机制非阻塞算法用底层的原子机器指令代替锁来确保数据在并发访问中的一致性。与基于锁的方案相比，非阻塞算法在设计和实现上要复杂很多，但它们在可伸缩性和活跃性上有巨大的优势，由于非阻塞算法可以使多个线程在竞争相同的数据时不会发生阻塞，因此能够在粒度更细的层次上进行协调，并极大减少调度开销 在非阻塞算法中不存在死锁与其他活跃性问题，Java中可以使用原子变量类来构建高效的非阻塞算法，原子变量也可以用作一种更好的volatile类型变量 锁的劣势当多个线程同时请求锁，此时JVM需要借助OS的功能，此时一些线程将被挂起并在稍后恢复运行，线程恢复执行时，还需等待其他线程执行完它们的时间片才能被调度执行。即存在很大的开销与较长时间的中断。 当一个线程在等待锁时不能做任何其他事情，让一个线程在持有锁情况下被延迟执行(缺页、调度延迟等)，则所有需要锁的线程将无法执行。并且可能出现优先级反转问题。 与锁相比，volatile是一种更轻量级的同步机制，但是虽然提供了可见性，但不能用于构建原子的复合操作。 硬件对并发的支持独占锁是一种悲观的技术，而对于细粒度的操作，乐观锁更加高效，可以在不发生干扰的情况下完成更新操作，需要借助冲突检查机制来判断在更新过程中是否存在来自其他线程的干扰。 测试并设置 Test and Set 获取并增加 Fetch and Increment 交换 Swap 比较并交换 Compare and Swap CAS ABA问题，如果要解决ABA问题可以使用Atomic，但是可能互斥同步更高效一些。 加载链接/条件存储 Load-Linked/Store-Conditional LL/SC 非阻塞算法如果在某种算法中，一个线程的失败或挂起不会导致其他线程也失败或挂起，即称为非阻塞算法。如果在算法的每个步骤张都存在某个线程能够执行下去，这种算法也被称为无锁算法。 在非阻塞算法中，多个线程竞争一个CAS，总会有一个线程在竞争中胜出并执行。非阻塞算法中通常不会出现死锁与优先级反转。但是可能会出现饥饿与活锁问题。 非阻塞的栈创建非阻塞算法的关键在于，找出如何将原子修改的范围缩小到单个变量上，同时还要维护数据的一致性。 push创建一个新节点，该节点的Next域指向当前栈顶 使用CAS将节点放入栈顶，如果插入时栈顶节点没有变化，那么成功 否则根据栈当前状态重试更新 锁的内存语义锁可以让临界区互斥执行。 锁的释放-获取建立的happens-before参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：CPU]]></title>
    <url>%2F2019%2F07%2F31%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9ACPU%2F</url>
    <content type="text"><![CDATA[CPU概述重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。而重排序对于Java并发存在一定的影响 指令重排序从硬件架构上讲，指令重排序是指CPU采用了允许将多条指令不按程序规定的顺序分开发送发送给各相应电路单元处理。但并不是说指令任意重排，CPU需要能够正确处理指令依赖情况以保障程序能够得出正确的执行结果。 指令重排序的一个原则是不违反数据依赖性。 数据依赖性数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作间就存在数据依赖性。（只考虑单个处理器中执行的指令序列和单个线程中执行的操作） 分类： 写后读。a=1;b=a; 写后写。a=1;a=2; 读后写。a=b;b=1; 在数据依赖性下，只要重排序两个操作的执行顺序，程序的执行结果就会改变。 as-if-serial语义as-if-serial语义指：不管怎么重排序，单线程程序的执行结果不能被改变。编译器、runtime和处理器必须遵守as-if-serial语义。 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但如果操作间不存在数据依赖关系，则这些操作可能被重排序。 as-if-serial语义将单线程保护了起来，编译器、runtime、处理器共同为单线程程序员创造了一个幻觉，即单线程程序是按照程序的顺序来执行的。因此单线程程序员无需担心重排序、内存可见性问题。 程序顺序规则对于代码段 123double pi=3.14;double r=1.0;double area=pi*r*r; 根据程序顺序规则，则有 A happens-before B、B happens-before C、A happens-before C 但是在实际操作中，B可以排在A之前执行 这里的A结果不需要对B可见，因此这种重排序并不非法，JMM允许这种重排序。 A happens-before B，JMM仅仅要求前一个操作执行的结果对后又改操作可见，且前一个操作按顺序排在第二个操作之前。 软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能提高并行度。 重排序对多线程的影响但在多线程程序中，对存在控制依赖的操作会产生重排序，因为它们存在与不同的线程当中，可能会改变程序的执行结果。 从源代码到指令序列的重排序在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。 编译器重排序：编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 处理器重排序： 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 对于Java源代码到最终执行的指令序列，会经历三种重排序，可能导致内存可见性问题： JMM属于语言级别的内存模型，确保在不同的编译器和处理器平台上，通过禁止特定类型的编译器重排序和处理器重排序，保证一致性的内存可见性。 对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序 对于处理器重排序。JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，禁止特定类型的处理器重排序 示例123456789101112131415Map configOptions;char[] configText;boolean initialized = false;//假设以下代码在线程A中执行//则由于指令重排序，首先initizlized = true，之后才进行读取configTextconfigOptions = new HashMap();configText = readConfigFile(fileName);initizlized = true;//假设以下代码在线程B中执行//由于受重排序影响，initizlized=true的时候，并没有初始化配置信息，因此之后的动作错误。while(!initialized)&#123; sleep();&#125;doSomethingWithConfig(); 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 总结对于Java程序而言，向下依赖于JVM，向业务层依赖于数据库等第三方服务，向网络方依赖IO的数据流，对外暴露接口。 因此想要程序稳定运行、快速Debug，就要解决JVM、IO、第三方服务的稳定性。并测试自己接口的健壮。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM：字节码]]></title>
    <url>%2F2019%2F07%2F30%2FJava%2Fbase%2FJVM%EF%BC%9A%E5%AD%97%E8%8A%82%E7%A0%81%2F</url>
    <content type="text"><![CDATA[字节码指令简介Java虚拟机的指令由一个字节长度的、代表某种特定操作含义的数字（操作码）以及跟随其后的零至多个代表此操作所需的参数（操作数）而构成。 Java虚拟机采用面向操作数栈而不是寄存器的架构，因此大多数指令不包含操作数 Class文件格式放弃了长度对齐，处理超过一个字节的数据时，不得不在运行时从字节中重建具体数据的结构。尽管需要解释执行字节码时损失一些性能，但是可以节约很多空间。 字节码与数据类型 在Java虚拟机的指令集中，大多数指令都包含了其操作所对应的数据类型信息。iload用于从局部变量表中加载int类型的数据到操作数栈中，fload加载float数据。两条指令的操作在虚拟机内部可能由同一段代码实现，但在Class文件中必须拥有各自独立的操作码。 对于大部分与数据类型相关的字节码指令，他们的操作码助记符中都有特殊注明专门为哪种数据类型服务。i代表int，l代表long等。 …待续 同步指令monitor&lt;enter/exit&gt;执行monitorenter指令时，首先要尝试获取对象的锁，如果对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器+1。即是可重入的 执行monitorexit时将锁计数器-1，当计数器为0，锁就被释放。 如果对象获取对象锁失败，当前线程就要阻塞等待，直到对象锁被另一个线程释放为止。 虚拟机字节码执行引擎参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：流]]></title>
    <url>%2F2019%2F07%2F28%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E6%B5%81%2F</url>
    <content type="text"><![CDATA[流提出问题集合是Java中的重要API，但是集合操作却远远算不上完美。 很多业务逻辑都涉及到类似数据库的操作，例如对菜品按类别进行分组。利用SQL可以声明式地进行这些操作，但是在集合当中，我们只能用迭代器进行操作。 要处理大量元素时，为了提高性能需要并行处理，使用多核架构，但是并行比迭代器还要复杂并且难以调试。 概述是什么流是JavaAPI的新成员，允许你一声明性的方式处理数据集合(通过查询语句来表达，而不是临时编写一个实现)，可以看作是遍历数据集的高级迭代器。流可以透明地并行处理，无需写多线程代码。 分类，各个分类是什么应用适用性 对于复杂的集合操作，例如对元素进行分类、筛选等，或者需要以多核架构处理大量元素： 流使得代码以声明性编写，说明想要完成什么而不是如何实现一个操作（if或者for)，可以轻松应对变化的需求。 可以将几个基础操作链接起来，表达复杂的数据处理流水线，使得代码清晰可读。 优点 声明性。更简洁易读。 可符合。更灵活。 可并行。性能更好。 应用场景实际案例使用集合进行对菜品进行按照分类筛选 123456789101112131415List&lt;Dish&gt; lowCaloricDishes = new ArrayList&lt;&gt;(); for(Dish d: menu)&#123; if(d.getCalories() &lt; 400)&#123; lowCaloricDishes.add(d);//累加器筛选元素 &#125; &#125; Collections.sort(lowCaloricDishes, new Comparator&lt;Dish&gt;() &#123;//进行排序 public int compare(Dish d1, Dish d2)&#123; return Integer.compare(d1.getCalories(), d2.getCalories()); &#125; &#125;);List&lt;String&gt; lowCaloricDishesName = new ArrayList&lt;&gt;();for(Dish d: lowCaloricDishes)&#123; lowCaloricDishesName.add(d.getName()); //处理后的菜单&#125; 在上述案例当中，有一个中介变量lowCaloricDishes，其唯一作用就是作为一次中介容器。 使用流处理 以流水线的方式进行表达复杂的数据处理： filter的结果传递给sorted。 sorted的结果传递给了map。 map的结果传递到了collect。 12345678import static java.util.Comparator.comparing; import static java.util.stream.Collectors.toList; List&lt;String&gt; lowCaloricDishesName = menu.stream() .filter(d -&gt; d.getCalories() &lt; 400) //选出400以下的菜品 .sorted(comparing(Dish::getCalories)) //根据某个值进行排序 .map(Dish::getName) //提取菜的名称 .collect(toList()); //将其保存到list当中 使用多核架构处理，只需要将stream换成parallelStream。 12345menu.parallelStream() .filter(d -&gt; d.getCalories() &lt; 400) //选出400以下的菜品 .sorted(comparing(Dish::getCalories)) //根据某个值进行排序 .map(Dish::getName) //提取菜的名称 .collect(toList()); //将其保存到list当中 流简介流是从支持数据处理操作的源生成的元素序列： 元素序列。像集合一样，流也提供了一个接口可以访问特定元素类需的一组有序值。 集合是数据结构，其主要目的是以特定的时间/空间复杂度存储和访问元素。 流在与表达计算，如filter、sort、map。即集合讲数据，流讲计算。 源。流会使用一个提供数据的源，如集合、数组或输入/输出资源。从有序集合生成流时会保留原有的顺序。 数据处理操作。流的数据处理支持类似于数据库的操作，以及函数式编程语言中的常用操作，流操作可以顺序也可以并行。 流拥有两个重要特点： 流水线。很多流操作本身会返回一个流，使得多个操作可以连接起来，形成一个大的流水线。 内部迭代。流的迭代操作时在背后进行的。 流与集合考虑将一个电影作为一个集合，因为它包含了整个数据结构，再考虑通过视频流观看电影，则流媒体只需要提前下载用户观看位置的那几帧即可，而不用将流中的大部分值计算出来，就可以观看流了。 差异就在于什么时候进行计算 集合是一个内存中的数据结构，包含数据结构中目前所有的值。每个元素都得先算出来才能添加到集合中。无论什么时候集合中的元素都是放在内存中的，即使你可以在里面增加\删除元素 流则是在概念上固定的数据结构（不能增删)，元素是按需计算的。流可以使得仅仅提取所需要的值，即一个延迟创建的集合。 考虑另一个概念即搜索，如果使用集合，则需要将所有的数据存储进去，而流就可以先读取10个，当用户需要点下一页时再计算接下来10个的值。 流只能遍历一次流与迭代器一样只能遍历一次，当遍历完之后即这个流已经被消费掉了。当然如果时遍历集合的话，你还可以去生成一个新的流去遍历，但它已经是新的流了。 外部迭代与内部迭代 外部迭代：使用Collection接口需要用户去迭代(for-each等)。 内部迭代：Streams库，它将帮助你完成迭代，并且将流的值存在了某个地方，你只需要给出一个函数说要做什么即可。 项目可以透明地并行处理，或者用更优化的顺序进行处理。使用外部迭代时则需要自己管理所有并行问题。 流操作java。util.stram.Stram中的Stream接口定义了许多操作，基本可以分为两大类： 中间操作(流水线操作)：filter、map、limit可以连成一条流水线。 终端操作(触发或关闭流水线)：collect。 123456List&lt;String&gt; lowCaloricDishesName = menu.stream() .filter(d -&gt; d.getCalories() &lt; 400) //选出400以下的菜品 .sorted(comparing(Dish::getCalories)) //根据某个值进行排序 .map(Dish::getName) //提取菜的名称 .collect(toList()); //将其保存到list当中 对于中间操作会返回一个流，让多个操作可以连接起来形成一个查询。并且除非流水线上触发一个终端操作，否则中间操作不会执行任何处理，他们会很懒，并且一般可以合并到终端操作时一次执行。 对于终端操作，它会从流的流水线生成结果，并且生成不是流的值，例如List等。 使用流流的使用包括三件事： 一个数据源来执行一个查询。 一个中间操作链，形成一条流的流水线。 一个终端操作，执行流水线，并能生成结果。 流水线背后的理念类似于构建器模式，再构建器中有一个调用链来设置一套配置，之后调用build方法。 Stream支持许多操作，能够让你快速完成复杂的数据查询，如筛选、切片、映射、查找、匹配和归约。 函数介绍中间操作： 筛选 filter。接受lambda，返回Stream。从流中排除某些元素 映射 map。接受一个lambda，返回Stream。将元素转换成为其他形式或提取信息（例如提取对象的Name） floatMap。扁平化为一个流，将数组流的内容映射成为一个流 切片 limit。返回Stream。截断流，使得元素不超过给定数量 sorted。返回Stream。 distinct。返回Stream。 终端操作 forEach。返回void。消费流中的每个元素并对其应用Lamda count。返回long。返回流中元素的个数 归约。 collect。将流转换为一个其他形式，例如list reduce。进行元素计算，例如求和、最大值等 接受参数(初始值，BinaryOperator&lt;T&gt;)，返回初始值类型 接受参数(BinaryOperator&lt;T&gt;)，返回Optional 匹配 anyMatch。返回Boolean。流中是否有一个元素能匹配给定的谓词 allMatch。返回Boolean。检查谓词是否匹配所有元素 noneMatch。返回Boolean。确保流中没有任何元素与给定谓词匹配 查找 findFirst。返回类型是Optional&lt;T&gt;，返回第一个值。findAny在并行运行下返回的可能并不是真正的第一个值 findAny。返回类型是Optional&lt;T&gt;，Optional是容器类代表一个值存在或者不存在。返回当前流中的任意元素。可以与filter等配合使用，会再找到第一个值时立即返回 筛选和切片如何选择流中的元素：用谓词筛选，筛选出不同的元素，忽略流中的头几个元素或将流截短至指定长度。 筛选 stream支持filter方法，该操作接受一个谓词(返回boolean的函数)作为参数，并返回一个包括所有符合谓词的元素的流 筛选各异的元素 流支持一个distinct方法，它会返回一个元素各异（根据流所生成元素的hashcode和equals方法实现）的流。即确保没有重复 截断流 流支持limit方法，返回一个不超过给定长度的流，如果流时有序的，则最多返回前n个元素。 若用于无序流，例如set，则结果不会以任何顺序排列。 跳过元素 流支持skip方法，返回一个扔掉了前n个元素的流，如果流中元素不足n个，则返回一个空流 映射一个常见的数据处理的套路就是从某些对象中选择信息，例如再SQL中可以从表中选择一列，Stream通过map和floatMap提供了类似的工具 对流中的每一个元素应用函数 流支持map方法，会接受一个函数作为参数，这个函数会被应用到每个元素上，并将其映射成一个新的元素。下面的例子将单词流映射成为了单词长度流 12List&lt;String&gt; dishNameLength=menu.Stream() ,map(String::length) 流的扁平化 对于一张单词表，如何列出一张列表，列出里面各不相同的字符呢？第一个例子可能时 1234words.stream() .map(word-&gt;word.split(" ")) .distinct() .collect(toList()); 但这个方法中传给map的方法实际上时返回了一个String[]，因此map返回的流就是Stream&lt;String[]&gt;，而不是Stream&lt;String&gt;。 解决方案 尝试使用Map与Arrays.stream 首先我们需要一个字符流，而不是数组流。Arrays.toStream()可以接受一个数组并产生一个流，我们获得的时一个String[] arrayOfWords，将其转换为一个流，即Arrays.stream(arrayOfWords)即 12345words.stream() .map(word-&gt;word.split(" ")) .map(Arrays::stream) .distinct() .collect(toList()); 此时得到的时一个流的列表，而不是一个单独的流，因此依然不可行 使用flatMap解决 12345words.stream() .map(word-&gt;word.split(" ")) .flatMap(Arrays::stream) .distinct() .collect(toList()); flatMap使得各个数组并不是分别映射成一个流，而是映射成流的内容，将多个流合并起来，扁平化成为一个流。 查找和匹配查看数据集中的某些元素是否匹配一个给定的属性，Stream提供allMatch、anyMatch、noneMatch、findFirst、findAny方法提供了这样的工具。 归约如何把一个流中的元素组合起来，使用reduce操作表达更复杂的查询，例如计算整个菜单的总卡路里、找到值最大的那一个等。此类查询需要将流中的元素反复结合起来。这样的查询可以被归类为归约操作。 元素求和 假设有一个numbers数组，则求和为： 1int sum = numbers.stream().reduce(0, (a, b) -&gt; a + b) 特殊的流考虑一些特殊的流：数值流、来自文件和数组等多种来源的流、无限流 数值流构建流可以通过stream从集合生成流，还可以根据数值范围创建数值流。并且可以从值序列、数组、文件创建流 由值创建流 静态方法Stream.of(任意参数) 由数组创建流 Arrays.stream(数组) 由文件生成流 用流收集数据收集器简介归约和汇总分组分区收集器接口并行数据处理进阶参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux：WSL]]></title>
    <url>%2F2019%2F07%2F27%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2FLinux%EF%BC%9AWSL%2F</url>
    <content type="text"><![CDATA[WSL 连接阿里云ssh root@47.102.124.245 -i /root/xxx.pem 修改文件夹配色选择文件夹的颜色配色方案 git clone https://github.com/seebi/dircolors-solarized.git 移动需要的配色方案到目录下 cp dircolors.256dark ~/.dircolors 将以下的代码加入到/.bashrc与/.zshrc中 123if [ -f ~/.dircolors ]; then eval `dircolors ~/.dircolors`fi 自定义指令使用alias指令 输入完成后执行 source .zshrc 修改vim颜色参考 调教你的WSL终端 黑科技]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：注解]]></title>
    <url>%2F2019%2F07%2F25%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[注解提出问题概述是什么 注解（元数据）为我们在代码中添加信息提供了一种形式化的方法，使我们可以在稍后某个时刻非常方便地使用这些数据。 分类，各个分类是什么 标记注解，没有元素的注解 优缺 注解可以提供用来完整地描述程序所需的信息，而这些信息是无法用Java表达的 注解使得我们能够以将由编译器来测试和验证的格式，存储有关程序的额外信息，注解可以用来生成描述符文件，甚至是新的类定义，并且有助于减轻编写“样板”代码的负担。 可以将元数据保存在Java源代码中，并利用annotationAPI为自己的注解构造处理工具 更加干净易读的代码以及编译期类型检查 为什么要用（作用） 每当你创建描述符性质的类或接口时，一旦其中包含了重复性的工作，那就可以考虑使用注解来简化与自动化该过程 应用场景常见注解Java内置 @Override。表示当前方法定义将覆盖超类中的错误，如果没有覆盖，则编译器发出错误提示 @Deprecated。如果程序使用了注解为它的元素，编译器会发出警告 @SuppressWarnings，关闭不当的编译器警告信息。 基本语法定义注解1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Test &#123;&#125; 注解的定义类似于定义一个接口，除了多出一个@，在定义注解时会需要一些元注解。 成员 在注解中会包含一些元素来表示某些值，当分析处理注解时，程序可以利用这些值，注解的元素类似接口的方法，唯一的区别是你可以为其指定默认值。 示例 123456@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface UseCase &#123; public int id(); public String description() default "no description";&#125; 该注解用于跟踪一个项目中的用例，如果一个方法实现了某个用例的需求则可以加上该注解 1234@UseCase(id = 47)public boolean validatePassword(Stirng pws)&#123; &#125; 注解的元素在使用时表现为键值对的形式，置于@UseCase声明后的括号内。 元注解 @Target：定义你的注解将运用到什么地方，例如一个方法或者域 Retention：定义该注解在哪个级别可用，Source（源代码）、CLASS（类文件）、RUNTIME（运行时） @Documented，将此注解包含在JavaDoc中 @Inherited，允许子类继承父类中的注解。 注解元素注解@UseCase由UseCase.jva定义，其中可以包含的可用类型有： 所有基本类型int 、float、boolean String Class、enum Annotation 数组 默认值限制 编译器要求元素不能有不确定的值，即元素要么具有默认值，要么在使用注解时提供元素的值 对于非基本类型的元素，无论是源代码声明或者定义默认值均不能为null。即所有元素都存在，因此只能以空字符串、负数来表示元素不存在 嵌套注解将Constraints注解嵌入到SQLString当中，并且值是默认的 123public @interface SQLString &#123; Constraints constraints() default @Constraints;&#125; ///:~ 若想要改变内部的值，则需要 123public @interface SQLString &#123; Constraints constraints() default @Constraints(unique=true);&#125; ///:~ 快捷方式当注解中定义了名为value的元素，并且在赋值时是唯一需要赋值的一个元素，此时无需使用键值对的语法，只需要赋值即可，这可以用于任何类型的元素。 编写注解处理器Java通过反射机制构造注解处理器。并且Java提供了外部工具apt解析带有注解的Java代码 1234567891011121314151617181920212223242526public class UseCaseTracker &#123; public static void trackUseCases(List&lt;Integer&gt; useCases, Class&lt;?&gt; cl) &#123; for(Method m : cl.getDeclaredMethods()) &#123;//获得该类声明的所有方法 UseCase uc = m.getAnnotation(UseCase.class);//如果该方法存在UseCase的注解 if(uc != null) &#123; System.out.println("Found Use Case:" + uc.id() + " " + uc.description()); useCases.remove(new Integer(uc.id())); &#125; &#125; for(int i : useCases) &#123; System.out.println("Warning: Missing use case-" + i); &#125; &#125; public static void main(String[] args) &#123; List&lt;Integer&gt; useCases = new ArrayList&lt;Integer&gt;(); Collections.addAll(useCases, 47, 48, 49, 50); trackUseCases(useCases, PasswordUtils.class); &#125;&#125; /* Output:Found Use Case:47 Passwords must contain at least one numericFound Use Case:48 no descriptionFound Use Case:49 New passwords can't equal previously used onesWarning: Missing use case-50*///:~ 生成外部文件有些framework需要一些额外的信息才能与你的源代码协同工作，而这种情况最适合注解实现价值。 如果你希望提供一些基本的对象/关系映射功能，能够自动生成数据库表用于存储JavaBean对象 可以选择XML描述文件，指明类的名字、每个成员以及数据库映射的相关信息。 使用注解将所有信息保存在Java源文件中。 首先定义@DBTable 12345@Target(ElementType.TYPE) // Applies to classes only@Retention(RetentionPolicy.RUNTIME)public @interface DBTable &#123; public String name() default "";&#125; ///:~ 为修饰JavaBean准备的注解 注解处理器通过@Constraints提取出数据库表的元数据，尽管该注解只提供了数据库约束的一个很小的子集，但依然是一种帮助 1234567@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Constraints &#123; boolean primaryKey() default false; boolean allowNull() default true; boolean unique() default false;&#125; ///:~ 内部使用了嵌套注解@Constraints将CoLumn的约束嵌入， 1234567@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLString &#123; int value() default 0; String name() default ""; Constraints constraints() default @Constraints;&#125; ///:~ 123456@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLInteger &#123; String name() default ""; Constraints constraints() default @Constraints;&#125; ///:~ 示例123456789101112131415@DBTable(name = "MEMBER")public class Member &#123; @SQLString(30) String firstName; @SQLString(50) String lastName; @SQLInteger Integer age; @SQLString(value = 30, constraints = @Constraints(primaryKey = true)) String handle; static int memberCount; public String getHandle() &#123; return handle; &#125; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public String toString() &#123; return handle; &#125; public Integer getAge() &#123; return age; &#125;&#125; ///:~ Bean对应的表名为MEMBER，其内部有firstName等元素，值为30、50. 注解处理器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class TableCreator &#123; public static void main(String[] args) throws Exception &#123; if(args.length &lt; 1) &#123; System.out.println("arguments: annotated classes"); System.exit(0); &#125; for(String className : args) &#123; Class&lt;?&gt; cl = Class.forName(className); DBTable dbTable = cl.getAnnotation(DBTable.class); if(dbTable == null) &#123; System.out.println( "No DBTable annotations in class " + className); continue; &#125; String tableName = dbTable.name(); // If the name is empty, use the Class name: if(tableName.length() &lt; 1) tableName = cl.getName().toUpperCase(); List&lt;String&gt; columnDefs = new ArrayList&lt;String&gt;(); for(Field field : cl.getDeclaredFields()) &#123; String columnName = null; Annotation[] anns = field.getDeclaredAnnotations(); if(anns.length &lt; 1) continue; // Not a db table column if(anns[0] instanceof SQLInteger) &#123; SQLInteger sInt = (SQLInteger) anns[0]; // Use field name if name not specified if(sInt.name().length() &lt; 1) columnName = field.getName().toUpperCase(); else columnName = sInt.name(); columnDefs.add(columnName + " INT" + getConstraints(sInt.constraints())); &#125; if(anns[0] instanceof SQLString) &#123; SQLString sString = (SQLString) anns[0]; // Use field name if name not specified. if(sString.name().length() &lt; 1) columnName = field.getName().toUpperCase(); else columnName = sString.name(); columnDefs.add(columnName + " VARCHAR(" + sString.value() + ")" + getConstraints(sString.constraints())); &#125; StringBuilder createCommand = new StringBuilder( "CREATE TABLE " + tableName + "("); for(String columnDef : columnDefs) createCommand.append("\n " + columnDef + ","); // Remove trailing comma String tableCreate = createCommand.substring( 0, createCommand.length() - 1) + ");"; System.out.println("Table Creation SQL for " + className + " is :\n" + tableCreate); &#125; &#125; &#125; private static String getConstraints(Constraints con) &#123; String constraints = ""; if(!con.allowNull()) constraints += " NOT NULL"; if(con.primaryKey()) constraints += " PRIMARY KEY"; if(con.unique()) constraints += " UNIQUE"; return constraints; &#125;&#125;/* Output:Table Creation SQL for annotations.database.Member is :CREATE TABLE MEMBER( FIRSTNAME VARCHAR(30));Table Creation SQL for annotations.database.Member is :CREATE TABLE MEMBER( FIRSTNAME VARCHAR(30), LASTNAME VARCHAR(50));Table Creation SQL for annotations.database.Member is :CREATE TABLE MEMBER( FIRSTNAME VARCHAR(30), LASTNAME VARCHAR(50), AGE INT);Table Creation SQL for annotations.database.Member is :CREATE TABLE MEMBER( FIRSTNAME VARCHAR(30), LASTNAME VARCHAR(50), AGE INT, HANDLE VARCHAR(30) PRIMARY KEY);*///:~ Main方法会处理命令行传入的每个类名，用forName加载每个类，并检查类是否带有@DBTable注解，如果有就将发现的表名保存，并读取所有域。等等 注解处理器使用apt处理注解将观察者模式用于apt基于注解的单元测试反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：类型信息]]></title>
    <url>%2F2019%2F07%2F22%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E7%B1%BB%E5%9E%8B%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[类型(Class)信息运行时类型信息使得你可以在程序运行时发现和使用类型信息。他使你从只能在编译期执行面向类型的操作的禁锢中解脱了出来，并且可以使用某些非常强大的程序。 Java是如何让我们在运行时识别对象和类的信息的 传统的RTTI，假定我们在编译时已经知道了所有的类型 反射机制，允许我们在运行时发现和使用类的信息。 RTTI的形式包括： 传统的类型转换，保证类型转换的正确性，如果执行了一个错误的转换，抛出ClassCastException 代表对象的类型的Class对象，通过查询Class对象可以获取运行时所需的信息 instanceof，返回一个布尔值，告诉我们对象是不是某个特定类型的实例。 为什么需要RTTIRTTI:Run-Time Type Identification运行时类型信息，通过运行时类型信息程序能够使用基类的指针或引用来检查这些指针或引用对象的实际派生类型。 考虑一个常见的多态场景 1234567891011121314151617181920212223242526272829public abstract class Shapes &#123; void draw() &#123; //传递this，间接使用toString打印类标识符。 System.out.println(this + ".draw"); &#125; //强制子类重写该方法 @Override abstract public String toString();&#125;public class Circle extends Shapes &#123; @Override public String toString() &#123; return "Circle"; &#125;&#125;public class Squre extends Shapes &#123; @Override public String toString() &#123; return "Shape"; &#125;&#125; public static void main(String[] args) &#123; List&lt;Shapes&gt; shapeList = Arrays.asList(new Circle(), new Squre()); for (Shapes shape : shapeList) &#123; shape.draw(); &#125; &#125; 在这个例子中，当将Shape放入到List会向上转型，但向上转型的过程中也丢失了Shape对象的具体类型，对于List而言，只是Shape类对象 当从数组中取出对象，List是将所有的事物都当作Object持有，会自动将结果转型回Shape，这是RTTI最基本的使用，即在运行时识别对象的类型。在Java中所有的类型转换都是在运行时进行正确性检查的。 应用 用于泛型，在编译期，我们可以知道的是List内包含的是Shape对象，因此RTTI可以完成转换，即符合假定我们在编译时已经知道了所有的类型。 用于类型指定，RTTI可以查询某个Shape引用所指向的对象的确切类型，然后选择或者剔除特例 Class对象Class对象表示着类型信息在运行时的表现，它包含了与类有关的信息，并且Class对象就是用来创建类的所有常规对象的。Java使用Class对象来执行其RTTI， 创建对象 类是程序的一部分，每个类有一个Class对象，每当编译一个新类，则会产生一个Class对象（保存在.class文件中），为了生成类的对象，JVM将使用类加载器进行加载，具体加载过程不展开描述了，可以去看JVM类加载器相关。 运用类型信息 无论何时想要在运行时使用类型信息，就必须先获得对恰当Class对象的引用，Class.forName是一个合适的方法，因为不必为了获得Class引用而持有该类型的对象。 层次结构12345public final class Class&lt;T&gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement 类字面常量例如：UserInfo.class。这样做不仅更简单，而且更安全，因为在编译时就能受到检查，因此不需要try catch，并且根除了对forName的调用，更高效。 可以应用与普通类、接口、数组、基本数据类型。对于基本数据类型的包装类型，有一个标准字段TYPE，是一个指向对应基本数据类型的Clas对象。 12boolean.class == Boolean.TYPEint.class == Integer.TYPE 创建Class对象的引用 使用.class创建对class对象的引用时，不会自动初始化Class对象，初始化被延迟到了对静态方法或非常数静态域进行首次引用。即初始化有效地实现了尽可能惰性。 如果一个static&amp;final值是编译器常量，即=47，那么这个值不需要对类进行初始化就可以立即读取，如果是static|final则需要初始化。 对比forName forName在获得类的引用时，会立即进行初始化，而.class方法获得引用时，不会立即初始化。 泛化的Class引用在Java SE5中将Class的类型变的更具体了一些，即允许对Class引用所指向的CLass对象的类型进行限定而实现，即使用泛型， 123Class&lt;Integer&gt; genericIntClass = Integer.class;//报警genericIntClass = double.class 普通的类引用可以被重新赋值指向任何其他的Class对象，通过使用泛型，可以让编译器强制执行额外的检测 为了在使用泛化的Class引用时放松限制，则需要使用通配符”?”，并且可以使用extends进行一定程度的限制 12345Class&lt;?&gt; genericIntClass = Integer.class;Class&lt;? extends Number&gt; genericIntClass = Integer.class;genericIntClass = double.class;//报警genericIntClass = User.class; 获得Class对象 Class.forName(String name)，一般使用类字面常量。 常见的应用场景为：在 JDBC 开发中常用此方法加载数据库驱动。 123456789101112131415161718package io.github.dunwu.javacore.reflect;public class ReflectClassDemo01 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class c1 = Class.forName("io.github.dunwu.javacore.reflect.ReflectClassDemo01"); System.out.println(c1.getCanonicalName()); Class c2 = Class.forName("[D"); System.out.println(c2.getCanonicalName()); Class c3 = Class.forName("[[Ljava.lang.String;"); System.out.println(c3.getCanonicalName()); &#125;&#125;//Output://io.github.dunwu.javacore.reflect.ReflectClassDemo01//double[]//java.lang.String[][] Object.getClass() Object 类中有 getClass 方法，因为所有类都继承 Object 类。从而调用 Object 类来获取 1234567891011121314151617181920212223242526272829package io.github.dunwu.javacore.reflect;import java.util.HashSet;import java.util.Set;public class ReflectClassDemo03 &#123; enum E &#123;A, B&#125; public static void main(String[] args) &#123; Class c = "foo".getClass(); System.out.println(c.getCanonicalName()); Class c2 = ReflectClassDemo03.E.A.getClass(); System.out.println(c2.getCanonicalName()); byte[] bytes = new byte[1024]; Class c3 = bytes.getClass(); System.out.println(c3.getCanonicalName()); Set&lt;String&gt; set = new HashSet&lt;&gt;(); Class c4 = set.getClass(); System.out.println(c4.getCanonicalName()); &#125;&#125;//Output://java.lang.String//io.github.dunwu.javacore.reflect.ReflectClassDemo.E//byte[]//java.util.HashSet 类字面常量 123456789101112131415161718public class ReflectClassDemo02 &#123; public static void main(String[] args) &#123; boolean b; // Class c = b.getClass(); // 编译错误 Class c1 = boolean.class; System.out.println(c1.getCanonicalName()); Class c2 = java.io.PrintStream.class; System.out.println(c2.getCanonicalName()); Class c3 = int[][][].class; System.out.println(c3.getCanonicalName()); &#125;&#125;//Output://boolean//java.io.PrintStream//int[][][] 获得ClassClass.forName(String) 该方法是Class类的一个static成员，forName()是取得Class引用的一种方法，其参数为目标类的文本名称(需要包括包名称)，返回一个Class对象的引用。 如果找不到需要加载的类，则会抛出异常ClassNotFoundException ClassObj.getSuperClass() 获得Clss对象的直接基类 ClassObj.getInterfaces() 返回Class对象，表示在感兴趣的Class对象中包含的接口 类型转换Class.cast(Object) 接受参数对象，并转型为Class引用的类型。对于无法使用普通转型的情况比较有用。例如有时存储了Class引用，并希望以后通过这个引用来执行转型 123Building b = new House();Class&lt;House&gt; houseClass = House.class;House h = houseClass.cast(b); Class.isInstance(Object) 接收一个对象参数，判断该对象是否属于该Class，返回boolean值 1234567891011121314public class InstanceofDemo &#123; public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); if (arrayList instanceof List) &#123; System.out.println("ArrayList is List"); &#125; if (List.class.isInstance(arrayList)) &#123; System.out.println("ArrayList is List"); &#125; &#125;&#125;//Output://ArrayList is List//ArrayList is List 创建实例Class对象创建实例对象主要有两种方式 用 Class 对象的 newInstance 方法。 用 Constructor 对象的 newInstance 方法。 1234567891011121314151617181920public class NewInstanceDemo &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; c1 = StringBuilder.class; StringBuilder sb = (StringBuilder) c1.newInstance(); sb.append("aaa"); System.out.println(sb.toString()); //获取String所对应的Class对象 Class&lt;?&gt; c2 = String.class; //获取String类带一个String参数的构造器 Constructor constructor = c2.getConstructor(String.class); //根据构造器创建实例 String str2 = (String) constructor.newInstance("bbb"); System.out.println(str2); &#125;&#125;//Output://aaa//bbb ClassObj.newInstance() 是实现虚拟构造器的一种途径。虚拟构造器允许你声明“我不知道你的确切类型，但是无论如何要正确地创建你自己”。 返回的类型为Class，当创建新的实例时，会得到Object的引用，但是这个引用指向的是具体类型的对象，因此需要转型。 使用newInstance()创建新类必须带有默认的构造器（无参） FieldClass 对象提供以下方法获取对象的成员（Field）： getFiled - 根据名称获取公有的（public）类成员。 getDeclaredField - 根据名称获取已声明的类成员。但不能得到其父类的类成员。 getFields - 获取所有公有的（public）类成员。 getDeclaredFields - 获取所有已声明的类成员。 示例如下： 123456789101112131415161718192021222324252627public class ReflectFieldDemo &#123; class FieldSpy&lt;T&gt; &#123; public boolean[][] b = &#123;&#123;false, false&#125;, &#123;true, true&#125;&#125;; public String name = "Alice"; public List&lt;Integer&gt; list; public T val; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; Field f1 = FieldSpy.class.getField("b"); System.out.format("Type: %s%n", f1.getType()); Field f2 = FieldSpy.class.getField("name"); System.out.format("Type: %s%n", f2.getType()); Field f3 = FieldSpy.class.getField("list"); System.out.format("Type: %s%n", f3.getType()); Field f4 = FieldSpy.class.getField("val"); System.out.format("Type: %s%n", f4.getType()); &#125;&#125;//Output://Type: class [[Z//Type: class java.lang.String//Type: interface java.util.List//Type: class java.lang.Object MethodClass 对象提供以下方法获取对象的方法（Method）： getMethod - 返回类或接口的特定方法。其中第一个参数为方法名称，后面的参数为方法参数对应 Class 的对象。 getDeclaredMethod - 返回类或接口的特定声明方法。其中第一个参数为方法名称，后面的参数为方法参数对应 Class 的对象。 getMethods - 返回类或接口的所有 public 方法，包括其父类的 public 方法。 getDeclaredMethods - 返回类或接口声明的所有方法，包括 public、protected、默认（包）访问和 private 方法，但不包括继承的方法。 获取一个 Method 对象后，可以用 invoke 方法来调用这个方法。 invoke 方法的原型为: 123public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException 示例： 123456789101112131415161718192021222324public class ReflectMethodDemo &#123; public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; // 返回所有方法 Method[] methods1 = System.class.getDeclaredMethods(); System.out.println("System getDeclaredMethods 清单（数量 = " + methods1.length + "）："); for (Method m : methods1) &#123; System.out.println(m); &#125; // 返回所有 public 方法 Method[] methods2 = System.class.getMethods(); System.out.println("System getMethods 清单（数量 = " + methods2.length + "）："); for (Method m : methods2) &#123; System.out.println(m); &#125; // 利用 Method 的 invoke 方法调用 System.currentTimeMillis() Method method = System.class.getMethod("currentTimeMillis"); System.out.println(method); System.out.println(method.invoke(null)); &#125;&#125; ConstructorClass 对象提供以下方法获取对象的构造方法（Constructor）： getConstructor - 返回类的特定 public 构造方法。参数为方法参数对应 Class 的对象。 getDeclaredConstructor - 返回类的特定构造方法。参数为方法参数对应 Class 的对象。 getConstructors - 返回类的所有 public 构造方法。 getDeclaredConstructors - 返回类的所有构造方法。 获取一个 Constructor 对象后，可以用 newInstance 方法来创建类实例。 示例： 12345678910111213141516171819202122public class ReflectMethodConstructorDemo &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; Constructor&lt;?&gt;[] constructors1 = String.class.getDeclaredConstructors(); System.out.println("String getDeclaredConstructors 清单（数量 = " + constructors1.length + "）："); for (Constructor c : constructors1) &#123; System.out.println(c); &#125; Constructor&lt;?&gt;[] constructors2 = String.class.getConstructors(); System.out.println("String getConstructors 清单（数量 = " + constructors2.length + "）："); for (Constructor c : constructors2) &#123; System.out.println(c); &#125; System.out.println("===================="); Constructor constructor = String.class.getConstructor(String.class); System.out.println(constructor); String str = (String) constructor.newInstance("bbb"); System.out.println(str); &#125;&#125; Array数组在 Java 里是比较特殊的一种类型，它可以赋值给一个对象引用。下面我们看一看利用反射创建数组的例子： 12345678910111213141516public class ReflectArrayDemo &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class&lt;?&gt; cls = Class.forName("java.lang.String"); Object array = Array.newInstance(cls, 25); //往数组里添加内容 Array.set(array, 0, "Scala"); Array.set(array, 1, "Java"); Array.set(array, 2, "Groovy"); Array.set(array, 3, "Scala"); Array.set(array, 4, "Clojure"); //获取某一项的内容 System.out.println(Array.get(array, 3)); &#125;&#125;//Output://Scala 其中的 Array 类为 java.lang.reflect.Array 类。我们通过 Array.newInstance 创建数组对象，它的原型是： 1234public static Object newInstance(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException &#123; return newArray(componentType, length);&#125; Method对象java.lang.reflect.Method提供有关类或接口上单个方法的信息和访问权限。反映的方法可以是类方法或实例方法(包括抽象方法) 层次结构 public final class Method extends Executable Annotation T getAnnotation(Class annotationClass)。如果存在这样的注解则返回该元素的指定类型的注解，否则返回Null Annotation[] getAnnotation()。返回此元素上直接存在的所有注释 Field对象层次结构 public final class Field extends AccessibleObject implements Member Parameter对象层次结构 public final class Parameter implements AnnotatedElement Constructor对象层次结构 public final class Constructor&lt;T&gt; extends Executable 公共接口 abstract Class Executable Interface Member Interface GenericDeclaration Class AccessibleObject Interface AnnotatedElement Interface Type 类型转换前先检查 关键字instanceof返回一个布尔值，告诉我们对象是不是某个特定类型的实例 1if(object instanceof Dog) 若不使用instanceof，并且object并不是Dog类型，则会得到ClassCastException异常 Class.isInstance()方法，（Native方法） 动态的instanceof12345678910111213141516171819202122232425262728293031323334353637383940414243public class PetCount3 &#123; static class PetCounter extends LinkedHashMap&lt;Class&lt;? extends Pet&gt;, Integer&gt; &#123; public PetCounter() &#123; //加载LiteralPetCreator.allTypes里所有的类型，当新增一个类型也只需要在List里面新增值 //MapData接收一个list作为键，0作为值构造一个Map super(MapData.map(LiteralPetCreator.allTypes, 0)); &#125; public void count(Pet pet) &#123; // Class.isInstance() eliminates instanceofs: for (Map.Entry&lt;Class&lt;? extends Pet&gt;, Integer&gt; pair : entrySet()) &#123; //IsInstance判断是否属于该类型 if (pair.getKey().isInstance(pet)) &#123; put(pair.getKey(), pair.getValue() + 1); &#125; &#125; &#125; public String toString() &#123; StringBuilder result = new StringBuilder("&#123;"); for (Map.Entry&lt;Class&lt;? extends Pet&gt;, Integer&gt; pair : entrySet()) &#123; result.append(pair.getKey().getSimpleName()); result.append("="); result.append(pair.getValue()); result.append(", "); &#125; result.delete(result.length() - 2, result.length()); result.append("&#125;"); return result.toString(); &#125; &#125; public static void main(String[] args) &#123; PetCounter petCount = new PetCounter(); for (Pet pet : Pets.createArray(20)) &#123; printnb(pet.getClass().getSimpleName() + " "); petCount.count(pet); &#125; print(); print(petCount); &#125;&#125; instanceof与Class的等价性在查询类型信息时，instanceof与直接比较Class对象有一个重要差别 instanceof保持了类型的概念，指的是该对象是这个类吗，或者是这个类的派生类吗。 比较Class对象，则没有考虑继承问题，即它是这个确切的类吗 接口与类型信息interface的一种重要目标就是允许程序员隔离构件，进而降低耦合性，但是通过类型信息，这种耦合性还是会传播出去，即接口并非是对解耦的无懈可击的保障。 12345678910111213141516171819202122public interface a&#123; void f();&#125;class B implements A &#123; public void f() &#123;&#125; public void g() &#123;&#125;&#125;public class InterfaceViolation &#123; public static void main(String[] args) &#123; A a = new B(); a.f(); // a.g(); // Compile error System.out.println(a.getClass().getName()); if(a instanceof B) &#123; B b = (B)a; b.g(); &#125; &#125;&#125; /* Output:B*///:~ 通过RTTI，a是被当做B实现的，通过将a转型为B，可以调用不在A中的方法。但是这种方式给了一个机会即代码耦合度很高。 解决的办法即使用包访问权限，其中只有HiddenC是public的，在调用时产生一个A接口类型的对象，虽然返回的是C类型，但是在包外部不能使用A外的任何方法，因为无法在包外部命名C 123456789101112//包访问权限class C implements A &#123; public void f() &#123; print("public C.f()"); &#125; public void g() &#123; print("public C.g()"); &#125; void u() &#123; print("package C.u()"); &#125; protected void v() &#123; print("protected C.v()"); &#125; private void w() &#123; print("private C.w()"); &#125;&#125;public class HiddenC &#123; public static A makeA() &#123; return new C(); &#125;&#125; ///:~ 但是即使RTTI无效，利用反射依然可以到达并调用所有方法，即使是private方法。 总结 不使用多态的时候，很容易出现一系列的switch语句，而使用RTTI可以做到简洁，但是会损失多态机制的重要价值 使用多态机制的方法调用，要求我们有基类定义的控制权，而当我们扩展的基类并没有包含我们想要的方法，这时RTTI是一种解决之道，你可以检查自己特定类型然后调用自己的方法。因此不需要switch语句。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo：源码分析]]></title>
    <url>%2F2019%2F07%2F22%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FDubbo%EF%BC%9A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Dubbo的服务Dubbo SPI简介SPI全称为Service Provider Interface，是一种服务发现机制。SPI的本质是将接口类的全限定名配置在文件中，由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。 基于此特性，可以很容易地通过SPI机制为我们的程序提供拓展功能。 SPI示例Java SPI首先定义一个接口，声明为Robot 123public interface Robot &#123; void sayHello();&#125; 定义两个实现类 123456789101112131415public class OptimusPrime implements Robot &#123; @Override public void sayHello() &#123; System.out.println("Hello, I am Optimus Prime."); &#125;&#125;public class Bumblebee implements Robot &#123; @Override public void sayHello() &#123; System.out.println("Hello, I am Bumblebee."); &#125;&#125; 在META-INF/services 文件夹下创建一个文件，名称为 Robot 的全限定名 org.apache.spi.Robot。文件内容为实现类的全限定的类名，如下： 12org.apache.spi.OptimusPrimeorg.apache.spi.Bumblebee 编写测试代码 123456789public class JavaSPITest &#123; @Test public void sayHello() throws Exception &#123; ServiceLoader&lt;Robot&gt; serviceLoader = ServiceLoader.load(Robot.class); System.out.println("Java SPI"); serviceLoader.forEach(Robot::sayHello); &#125;&#125; 测试结果 从测试结果可以看出，我们的两个实现类被成功的加载，并输出了相应的内容。关于 Java SPI 的演示先到这里，接下来演示 Dubbo SPI。 Dubbo SPIDubbo 并未使用 Java SPI，而是重新实现了一套功能更强的 SPI 机制。Dubbo SPI 的相关逻辑被封装在了 ExtensionLoader 类中，通过 ExtensionLoader，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 META-INF/dubbo 路径下，配置内容如下。 12optimusPrime = org.apache.spi.OptimusPrimebumblebee = org.apache.spi.Bumblebee 与 Java SPI 实现类配置不同，Dubbo SPI 是通过键值对的方式进行配置，这样我们可以按需加载指定的实现类。另外，在测试 Dubbo SPI 时，需要在 Robot 接口上标注 @SPI 注解。下面来演示 Dubbo SPI 的用法： 123456789101112public class DubboSPITest &#123; @Test public void sayHello() throws Exception &#123; ExtensionLoader&lt;Robot&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Robot.class); Robot optimusPrime = extensionLoader.getExtension("optimusPrime"); optimusPrime.sayHello(); Robot bumblebee = extensionLoader.getExtension("bumblebee"); bumblebee.sayHello(); &#125;&#125; 测试结果如下： Dubbo SPI 除了支持按需加载接口实现类，还增加了 IOC 和 AOP 等特性 Dubbo SPI源码分析ExtensionLoader的getExtensionLoader 会获取一个ExtensionLoader 实例，然后再通过 ExtensionLoader 的 getExtension 方法获取拓展类对象。这其中，getExtensionLoader 方法用于从缓存中获取与拓展类对应的 ExtensionLoader，若缓存未命中，则创建一个新的实例。 12345678910111213public class DubboSPITest &#123; @Test public void sayHello() throws Exception &#123; ExtensionLoader&lt;Robot&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Robot.class); //获取拓展类 Robot optimusPrime = extensionLoader.getExtension("optimusPrime"); optimusPrime.sayHello(); Robot bumblebee = extensionLoader.getExtension("bumblebee"); bumblebee.sayHello(); &#125;&#125; 分析拓展类对象的获取过程首先分析ExtensionLoader 的 getExtension 方法 12345678910111213141516171819202122232425262728public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException("Extension name == null"); if ("true".equals(name)) &#123; // 获取默认的拓展实现类 return getDefaultExtension(); &#125; // Holder，顾名思义，用于持有目标对象 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); // 双重检查 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 创建拓展实例 instance = createExtension(name); // 设置实例到 holder 中 holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 创建拓展对象的过程 123456789101112131415161718192021222324252627282930private T createExtension(String name) &#123; // 从配置文件中加载所有的拓展类，可得到“配置项名称”到“配置类”的映射关系表 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) &#123; throw findException(name); &#125; try &#123; T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; // 通过反射创建实例 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; // 向实例中注入依赖 injectExtension(instance); Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123; // 循环创建 Wrapper 实例 for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; // 将当前 instance 作为参数传给 Wrapper 的构造方法，并通过反射创建 Wrapper 实例。 // 然后向 Wrapper 实例中注入依赖，最后将 Wrapper 实例再次赋值给 instance 变量 instance = injectExtension( (T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException("..."); &#125;&#125; createExtension 方法的逻辑稍复杂一下，包含了如下的步骤： 通过 getExtensionClasses 获取所有的拓展类 通过反射创建拓展对象 向拓展对象中注入依赖 将拓展对象包裹在相应的 Wrapper 对象中 以上步骤中，第一个步骤是加载拓展类的关键，第三和第四个步骤是 Dubbo IOC 与 AOP 的具体实现。在接下来的章节中，将会重点分析 getExtensionClasses 方法的逻辑，以及简单介绍 Dubbo IOC 的具体实现。 Dubbo IOCDubbo IOC 是通过 setter 方法注入依赖。Dubbo 首先会通过反射获取到实例的所有方法，然后再遍历方法列表，检测方法名是否具有 setter 方法特征。若有，则通过 ObjectFactory 获取依赖对象，最后通过反射调用 setter 方法将依赖设置到目标对象中。整个过程对应的代码如下： 123456789101112131415161718192021222324252627282930313233private T injectExtension(T instance) &#123; try &#123; if (objectFactory != null) &#123; // 遍历目标类的所有方法 for (Method method : instance.getClass().getMethods()) &#123; // 检测方法是否以 set 开头，且方法仅有一个参数，且方法访问级别为 public if (method.getName().startsWith("set") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // 获取 setter 方法参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try &#123; // 获取属性名，比如 setName 方法对应属性名 name String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : ""; // 从 ObjectFactory 中获取依赖对象 Object object = objectFactory.getExtension(pt, property); if (object != null) &#123; // 通过反射调用 setter 方法设置依赖 method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error("fail to inject via method..."); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125; 在上面代码中，objectFactory 变量的类型为 AdaptiveExtensionFactory，AdaptiveExtensionFactory 内部维护了一个 ExtensionFactory 列表，用于存储其他类型的 ExtensionFactory。Dubbo 目前提供了两种 ExtensionFactory，分别是 SpiExtensionFactory 和 SpringExtensionFactory。前者用于创建自适应的拓展，后者是用于从 Spring 的 IOC 容器中获取所需的拓展。这两个类的类的代码不是很复杂，这里就不一一分析了。 Dubbo IOC 目前仅支持 setter 方式注入，总的来说，逻辑比较简单易懂。 总结本篇文章简单分别介绍了 Java SPI 与 Dubbo SPI 用法，并对 Dubbo SPI 的加载拓展类的过程进行了分析。另外，在 Dubbo SPI 中还有一块重要的逻辑这里没有进行分析，即 Dubbo SPI 的扩展点自适应机制。该机制的逻辑较为复杂，我们将会在下一篇文章中进行详细的分析。 # RPCRPC的核心实现是Protocol层，协议层主要由Protocol、Invoker、Exporter三个接口实现，他们的关系是： Protocol首先看Protocol的接口方法 export12345678910111213141516171819暴露远程服务协议在接收请求时，应记录请求来源方的地址信息export必须是幂等的，即暴露一个URL的invoke两次，和暴露一次没有区别export传入的invoke由框架实现并传入，协议不需要关心/** * Export service for remote invocation: &lt;br&gt; * 1. Protocol should record request source address after receive a request: * RpcContext.getContext().setRemoteAddress();&lt;br&gt; * 2. export() must be idempotent, that is, there's no difference between invoking once and invoking twice when * export the same URL&lt;br&gt; * 3. Invoker instance is passed in by the framework, protocol needs not to care &lt;br&gt; * * @param &lt;T&gt; Service type 服务的类型 * @param invoker Service invoker 服务的执行者 * @return exporter reference for exported service, useful for unexport the service later 暴露服务的引用，用于取消暴露 * @throws RpcException thrown when error occurs during export the service, for example: port is occupied 在暴露服务出错时抛出，比如端口已占用 */@Adaptive&lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; refer123456789101112131415161718192021引用远程服务在用户调用refer返回的Invoker对象的invoke方法时，协议需要执行同URL远端export传入的Invoker对象的invoke方法refer返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求在URL中设置check=false时，连接失败不能抛出异常，并在内部自动恢复/** * Refer a remote service: &lt;br&gt; * 1. When user calls `invoke()` method of `Invoker` object which's returned from `refer()` call, the protocol * needs to correspondingly execute `invoke()` method of `Invoker` object &lt;br&gt; * 2. It's protocol's responsibility to implement `Invoker` which's returned from `refer()`. Generally speaking, * protocol sends remote request in the `Invoker` implementation. &lt;br&gt; * 3. When there's check=false set in URL, the implementation must not throw exception but try to recover when * connection fails. * * @param &lt;T&gt; Service type 服务的类型 * @param type Service class 服务的类型 * @param url URL address for the remote service 远程服务的URL地址 * @return invoker service's local proxy 服务的本地代理 * @throws RpcException when there's any error while connecting to the service provider 在连接服务提供者失败时抛出 */@Adaptive&lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; InvokerExporter服务导出Dubbo 服务导出过程始于 Spring 容器发布刷新事件，Dubbo 在接收到事件后，会立即执行服务导出逻辑。整个逻辑大致可分为三个部分 第一部分是前置工作，主要用于检查参数，组装 URL。 第二部分是导出服务，包含导出服务到本地 (JVM)，和导出服务到远程两个过程。 第三部分是向注册中心注册服务，用于服务发现。 源码分析服务导出的入口方法是 ServiceBean 的 onApplicationEvent。onApplicationEvent 是一个事件响应方法，该方法会在收到 Spring 上下文刷新事件后执行服务导出操作。方法代码如下： 1234567public void onApplicationEvent(ContextRefreshedEvent event) &#123; // 是否有延迟导出 &amp;&amp; 是否已导出 &amp;&amp; 是不是已被取消导出 if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) &#123; // 导出服务 export(); &#125;&#125; 这个方法首先会根据条件决定是否导出服务，比如有些服务设置了延时导出，那么此时就不应该在此处导出。还有一些服务已经被导出了，或者当前服务被取消导出了，此时也不能再次导出相关服务。 注意这里的 isDelay 方法，这个方法字面意思是“是否延迟导出服务”，返回 true 表示延迟导出，false 表示不延迟导出。但是该方法真实意思却并非如此，当方法返回 true 时，表示无需延迟导出。返回 false 时，表示需要延迟导出。与字面意思恰恰相反，这个需要大家注意一下。下面我们来看一下这个方法的逻辑。 123456789101112// -☆- ServiceBeanprivate boolean isDelay() &#123; // 获取 delay Integer delay = getDelay(); ProviderConfig provider = getProvider(); if (delay == null &amp;&amp; provider != null) &#123; // 如果前面获取的 delay 为空，这里继续获取 delay = provider.getDelay(); &#125; // 判断 delay 是否为空，或者等于 -1 return supportedApplicationListener &amp;&amp; (delay == null || delay == -1);&#125; 暂时忽略 supportedApplicationListener 这个条件，当 delay 为空，或者等于-1时，该方法返回 true，而不是 false。这个方法的返回值让人有点困惑。该方法目前已被重构，详细请参考 dubbo #2686。 现在解释一下 supportedApplicationListener 变量含义，该变量用于表示当前的 Spring 容器是否支持 ApplicationListener，这个值初始为 false。在 Spring 容器将自己设置到 ServiceBean 中时，ServiceBean 的 setApplicationContext 方法会检测 Spring 容器是否支持 ApplicationListener。若支持，则将 supportedApplicationListener 置为 true。ServiceBean 是 Dubbo 与 Spring 框架进行整合的关键，可以看做是两个框架之间的桥梁。具有同样作用的类还有 ReferenceBean。 现在我们知道了 Dubbo 服务导出过程的起点，接下来对服务导出export的前置逻辑进行分析。 前置工作前置工作主要包含两个部分 配置检查。在导出服务之前，Dubbo 需要检查用户的配置是否合理，或者为用户补充缺省配置。 URL 装配。配置检查完成后，接下来需要根据这些配置组装 URL。在 Dubbo 中，URL 的作用十分重要。Dubbo 使用 URL 作为配置载体，所有的拓展点都是通过 URL 获取配置。这一点，官方文档中有所说明。 采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。 接下来，我们先来分析配置检查部分的源码，随后再来分析 URL 组装部分的源码。 检查配置本节我们接着前面的源码向下分析，前面说过 onApplicationEvent 方法在经过一些判断后，会决定是否调用 export 方法导出服务。那么下面我们从 export 方法开始进行分析，如下： 1234567891011121314151617181920212223242526272829public synchronized void export() &#123; if (provider != null) &#123; // 获取 export 和 delay 配置 if (export == null) &#123; export = provider.getExport(); &#125; if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; // 如果 export 为 false，则不导出服务 if (export != null &amp;&amp; !export) &#123; return; &#125; // delay &gt; 0，延时导出服务 if (delay != null &amp;&amp; delay &gt; 0) &#123; delayExportExecutor.schedule(new Runnable() &#123; @Override public void run() &#123; doExport(); &#125; &#125;, delay, TimeUnit.MILLISECONDS); // 立即导出服务 &#125; else &#123; doExport(); &#125;&#125; export 方法对两项配置进行了检查，并根据配置执行相应的动作。首先是 export 配置，这个配置决定了是否导出服务。有时候我们只是想本地启动服务进行一些调试工作，我们并不希望把本地启动的服务暴露出去给别人调用。此时，我们可通过配置 export 禁止服务导出，比如： 1&lt;dubbo:provider export="false" /&gt; delay 配置顾名思义，用于延迟导出服务，这个就不分析了。下面，我们继续分析源码，这次要分析的是 doExport 方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//立即导出服务protected synchronized void doExport() &#123; if (unexported) &#123; throw new IllegalStateException("Already unexported!"); &#125; if (exported) &#123; return; &#125; exported = true; // 检测 interfaceName 是否合法 if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException("interface not allow null!"); &#125; // 检测 provider 是否为空，为空则新建一个，并通过系统变量为其初始化 checkDefault(); // 下面几个 if 语句用于检测 provider、application 等核心配置类对象是否为空， // 若为空，则尝试从其他配置类对象中获取相应的实例。 if (provider != null) &#123; if (application == null) &#123; application = provider.getApplication(); &#125; if (module == null) &#123; module = provider.getModule(); &#125; if (registries == null) &#123;...&#125; if (monitor == null) &#123;...&#125; if (protocols == null) &#123;...&#125; &#125; if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123;...&#125; &#125; if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123;...&#125; &#125; // 检测 ref 是否为泛化服务类型 if (ref instanceof GenericService) &#123; // 设置 interfaceClass 为 GenericService.class interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) &#123; // 设置 generic = "true" generic = Boolean.TRUE.toString(); &#125; // ref 非 GenericService 类型 &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 对 interfaceClass，以及 &lt;dubbo:method&gt; 标签中的必要字段进行检查 checkInterfaceAndMethods(interfaceClass, methods); // 对 ref 合法性进行检测 checkRef(); // 设置 generic = "false" generic = Boolean.FALSE.toString(); &#125; // local 和 stub 在功能应该是一致的，用于配置本地存根 if (local != null) &#123; if ("true".equals(local)) &#123; local = interfaceName + "Local"; &#125; Class&lt;?&gt; localClass; try &#123; // 获取本地存根类 localClass = ClassHelper.forNameWithThreadContextClassLoader(local); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法 if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException("The local implementation class " + localClass.getName() + " not implement interface " + interfaceName); &#125; &#125; if (stub != null) &#123; // 此处的代码和上一个 if 分支的代码基本一致，这里省略 &#125; // 检测各种对象是否为空，为空则新建，或者抛出异常 checkApplication(); checkRegistry(); checkProtocol(); appendProperties(this); checkStubAndMock(interfaceClass); if (path == null || path.length() == 0) &#123; path = interfaceName; &#125; // 导出服务 doExportUrls(); // ProviderModel 表示服务提供者模型，此对象中存储了与服务提供者相关的信息。 // 比如服务的配置信息，服务实例等。每个被导出的服务对应一个 ProviderModel。 // ApplicationModel 持有所有的 ProviderModel。 ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel);&#125; 以上就是配置检查的相关分析，代码比较多，需要大家耐心看一下。下面对配置检查的逻辑进行简单的总结，如下： 检测 dubbo:service 标签的 interface 属性合法性，不合法则抛出异常 检测 ProviderConfig、ApplicationConfig 等核心配置类对象是否为空，若为空，则尝试从其他配置类对象中获取相应的实例。 检测并处理泛化服务和普通服务类 检测本地存根配置，并进行相应的处理 对 ApplicationConfig、RegistryConfig 等配置类进行检测，为空则尝试创建，若无法创建则抛出异常 配置检查并非本文重点，因此这里不打算对 doExport 方法所调用的方法进行分析（doExportUrls 方法除外）。在这些方法中，除了 appendProperties 方法稍微复杂一些，其他方法逻辑不是很复杂。因此，大家可自行分析。 多协议多注册中心导出服务Dubbo 允许我们使用不同的协议导出服务，也允许我们向多个注册中心注册服务。Dubbo 在 doExportUrls 方法中对多协议，多注册中心进行了支持。相关代码如下： 12345678private void doExportUrls() &#123; // 加载注册中心链接 List&lt;URL&gt; registryURLs = loadRegistries(true); // 遍历 protocols，并在每个协议下导出服务 for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125;&#125; 上面代码首先是通过 loadRegistries 加载注册中心链接，然后再遍历 ProtocolConfig 集合导出每个服务。并在导出服务的过程中，将服务注册到注册中心。下面，我们先来看一下 loadRegistries 方法的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected List&lt;URL&gt; loadRegistries(boolean provider) &#123; // 检测是否存在注册中心配置类，不存在则抛出异常 checkRegistry(); List&lt;URL&gt; registryList = new ArrayList&lt;URL&gt;(); if (registries != null &amp;&amp; !registries.isEmpty()) &#123; for (RegistryConfig config : registries) &#123; String address = config.getAddress(); if (address == null || address.length() == 0) &#123; // 若 address 为空，则将其设为 0.0.0.0 address = Constants.ANYHOST_VALUE; &#125; // 从系统属性中加载注册中心地址 String sysaddress = System.getProperty("dubbo.registry.address"); if (sysaddress != null &amp;&amp; sysaddress.length() &gt; 0) &#123; address = sysaddress; &#125; // 检测 address 是否合法 if (address.length() &gt; 0 &amp;&amp; !RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(address)) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 添加 ApplicationConfig 中的字段信息到 map 中 appendParameters(map, application); // 添加 RegistryConfig 字段信息到 map 中 appendParameters(map, config); // 添加 path、pid，protocol 等信息到 map 中 map.put("path", RegistryService.class.getName()); map.put("dubbo", Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; if (!map.containsKey("protocol")) &#123; if (ExtensionLoader.getExtensionLoader(RegistryFactory.class).hasExtension("remote")) &#123; map.put("protocol", "remote"); &#125; else &#123; map.put("protocol", "dubbo"); &#125; &#125; // 解析得到 URL 列表，address 可能包含多个注册中心 ip， // 因此解析得到的是一个 URL 列表 List&lt;URL&gt; urls = UrlUtils.parseURLs(address, map); for (URL url : urls) &#123; url = url.addParameter(Constants.REGISTRY_KEY, url.getProtocol()); // 将 URL 协议头设置为 registry url = url.setProtocol(Constants.REGISTRY_PROTOCOL); // 通过判断条件，决定是否添加 url 到 registryList 中，条件如下： // (服务提供者 &amp;&amp; register = true 或 null) // || (非服务提供者 &amp;&amp; subscribe = true 或 null) if ((provider &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) || (!provider &amp;&amp; url.getParameter(Constants.SUBSCRIBE_KEY, true))) &#123; registryList.add(url); &#125; &#125; &#125; &#125; &#125; return registryList;&#125; loadRegistries 方法主要包含如下的逻辑： 检测是否存在注册中心配置类，不存在则抛出异常 构建参数映射集合，也就是 map 构建注册中心链接列表 遍历链接列表，并根据条件决定是否将其添加到 registryList 中 关于多协议多注册中心导出服务就先分析到这，代码不是很多，接下来分析 URL 组装过程。 组装 URL配置检查完毕后，紧接着要做的事情是根据配置，以及其他一些信息组装 URL。前面说过，URL 是 Dubbo 配置的载体，通过 URL 可让 Dubbo 的各种配置在各个模块之间传递。URL 之于 Dubbo，犹如水之于鱼，非常重要。大家在阅读 Dubbo 服务导出相关源码的过程中，要注意 URL 内容的变化。既然 URL 如此重要，那么下面我们来了解一下 URL 组装的过程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; String name = protocolConfig.getName(); // 如果协议名为空，或空串，则将协议名变量设置为 dubbo if (name == null || name.length() == 0) &#123; name = "dubbo"; &#125; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 添加 side、版本、时间戳以及进程号等信息到 map 中 map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 通过反射将对象的字段信息添加到 map 中 appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method&gt; 标签的配置信息 if (methods != null &amp;&amp; !methods.isEmpty()) &#123; // 这段代码用于添加 Callback 配置到 map 中，代码太长，待会单独分析 &#125; // 检测 generic 是否为 "true"，并根据检测结果向 map 中添加不同的信息 if (ProtocolUtils.isGeneric(generic)) &#123; map.put(Constants.GENERIC_KEY, generic); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; // 为接口生成包裹类 Wrapper，Wrapper 中包含了接口的详细信息，比如接口方法名数组，字段信息等 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); // 添加方法名到 map 中，如果包含多个方法名，则用逗号隔开，比如 method = init,destroy if (methods.length == 0) &#123; logger.warn("NO method found in service interface ..."); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; // 将逗号作为分隔符连接方法名，并将连接后的字符串放入 map 中 map.put(Constants.METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; // 添加 token 到 map 中 if (!ConfigUtils.isEmpty(token)) &#123; if (ConfigUtils.isDefault(token)) &#123; // 随机生成 token map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString()); &#125; else &#123; map.put(Constants.TOKEN_KEY, token); &#125; &#125; // 判断协议名是否为 injvm if (Constants.LOCAL_PROTOCOL.equals(protocolConfig.getName())) &#123; protocolConfig.setRegister(false); map.put("notify", "false"); &#125; // 获取上下文路径 String contextPath = protocolConfig.getContextpath(); if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) &#123; contextPath = provider.getContextpath(); &#125; // 获取 host 和 port String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); // 组装 URL URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? "" : contextPath + "/") + path, map); // 省略无关代码&#125; 上面的代码首先是将一些信息，比如版本、时间戳、方法名以及各种配置对象的字段信息放入到 map 中，map 中的内容将作为 URL 的查询字符串。构建好 map 后，紧接着是获取上下文路径、主机名以及端口号等信息。最后将 map 和主机名等数据传给 URL 构造方法创建 URL 对象。需要注意的是，这里出现的 URL 并非 java.net.URL，而是 com.alibaba.dubbo.common.URL。 上面省略了一段代码，这里简单分析一下。这段代码用于检测 dubbo:method 标签中的配置信息，并将相关配置添加到 map 中。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; // ... // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method&gt; 标签的配置信息 if (methods != null &amp;&amp; !methods.isEmpty()) &#123; for (MethodConfig method : methods) &#123; // 添加 MethodConfig 对象的字段信息到 map 中，键 = 方法名.属性名。 // 比如存储 &lt;dubbo:method name="sayHello" retries="2"&gt; 对应的 MethodConfig， // 键 = sayHello.retries，map = &#123;"sayHello.retries": 2, "xxx": "yyy"&#125; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); // 检测 MethodConfig retry 是否为 false，若是，则设置重试次数为0 if ("false".equals(retryValue)) &#123; map.put(method.getName() + ".retries", "0"); &#125; &#125; // 获取 ArgumentConfig 列表 List&lt;ArgumentConfig&gt; arguments = method.getArguments(); if (arguments != null &amp;&amp; !arguments.isEmpty()) &#123; for (ArgumentConfig argument : arguments) &#123; // 检测 type 属性是否为空，或者空串（分支1 ⭐️） if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) &#123; Method[] methods = interfaceClass.getMethods(); if (methods != null &amp;&amp; methods.length &gt; 0) &#123; for (int i = 0; i &lt; methods.length; i++) &#123; String methodName = methods[i].getName(); // 比对方法名，查找目标方法 if (methodName.equals(method.getName())) &#123; Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); if (argument.getIndex() != -1) &#123; // 检测 ArgumentConfig 中的 type 属性与方法参数列表 // 中的参数名称是否一致，不一致则抛出异常(分支2 ⭐️) if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123; // 添加 ArgumentConfig 字段信息到 map 中， // 键前缀 = 方法名.index，比如: // map = &#123;"sayHello.3": true&#125; appendParameters(map, argument, method.getName() + "." + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException("argument config error: ..."); &#125; &#125; else &#123; // 分支3 ⭐️ for (int j = 0; j &lt; argtypes.length; j++) &#123; Class&lt;?&gt; argclazz = argtypes[j]; // 从参数类型列表中查找类型名称为 argument.type 的参数 if (argclazz.getName().equals(argument.getType())) &#123; appendParameters(map, argument, method.getName() + "." + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123; throw new IllegalArgumentException("argument config error: ..."); &#125; &#125; &#125; &#125; &#125; &#125; &#125; // 用户未配置 type 属性，但配置了 index 属性，且 index != -1 &#125; else if (argument.getIndex() != -1) &#123; // 分支4 ⭐️ // 添加 ArgumentConfig 字段信息到 map 中 appendParameters(map, argument, method.getName() + "." + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException("argument config must set index or type"); &#125; &#125; &#125; &#125; &#125; // ...&#125; 上面这段代码 for 循环和 if else 分支嵌套太多，导致层次太深，不利于阅读，需要耐心看一下。大家在看这段代码时，注意把几个重要的条件分支找出来。只要理解了这几个分支的意图，就可以弄懂这段代码。请注意上面代码中⭐️符号，这几个符号标识出了4个重要的分支，下面用伪代码解释一下这几个分支的含义。 1234567891011121314151617181920// 获取 ArgumentConfig 列表for (遍历 ArgumentConfig 列表) &#123; if (type 不为 null，也不为空串) &#123; // 分支1 1. 通过反射获取 interfaceClass 的方法列表 for (遍历方法列表) &#123; 1. 比对方法名，查找目标方法 2. 通过反射获取目标方法的参数类型数组 argtypes if (index != -1) &#123; // 分支2 1. 从 argtypes 数组中获取下标 index 处的元素 argType 2. 检测 argType 的名称与 ArgumentConfig 中的 type 属性是否一致 3. 添加 ArgumentConfig 字段信息到 map 中，或抛出异常 &#125; else &#123; // 分支3 1. 遍历参数类型数组 argtypes，查找 argument.type 类型的参数 2. 添加 ArgumentConfig 字段信息到 map 中 &#125; &#125; &#125; else if (index != -1) &#123; // 分支4 1. 添加 ArgumentConfig 字段信息到 map 中 &#125;&#125; 在本节分析的源码中，appendParameters 这个方法出现的次数比较多，该方法用于将对象字段信息添加到 map 中。实现上则是通过反射获取目标对象的 getter 方法，并调用该方法获取属性值。然后再通过 getter 方法名解析出属性名，比如从方法名 getName 中可解析出属性 name。如果用户传入了属性名前缀，此时需要将属性名加入前缀内容。最后将 &lt;属性名，属性值&gt; 键值对存入到 map 中就行了。限于篇幅原因，这里就不分析 appendParameters 方法的源码了，大家请自行分析。 导出 Dubbo 服务前置工作做完，接下来就可以进行服务导出了。服务导出分为导出到本地 (JVM)，和导出到远程。在深入分析服务导出的源码前，我们先来从宏观层面上看一下服务导出逻辑。如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; // 省略无关代码 if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .hasExtension(url.getProtocol())) &#123; // 加载 ConfiguratorFactory，并生成 Configurator 实例，然后通过实例配置 url url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .getExtension(url.getProtocol()).getConfigurator(url).configure(url); &#125; String scope = url.getParameter(Constants.SCOPE_KEY); // 如果 scope = none，则什么都不做 if (!Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) &#123; // scope != remote，导出到本地 if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) &#123; exportLocal(url); &#125; // scope != local，导出到远程 if (!Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope)) &#123; if (registryURLs != null &amp;&amp; !registryURLs.isEmpty()) &#123; for (URL registryURL : registryURLs) &#123; url = url.addParameterIfAbsent(Constants.DYNAMIC_KEY, registryURL.getParameter(Constants.DYNAMIC_KEY)); // 加载监视器链接 URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) &#123; // 将监视器链接作为参数添加到 url 中 url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); &#125; String proxy = url.getParameter(Constants.PROXY_KEY); if (StringUtils.isNotEmpty(proxy)) &#123; registryURL = registryURL.addParameter(Constants.PROXY_KEY, proxy); &#125; // 为服务提供类(ref)生成 Invoker Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); // DelegateProviderMetaDataInvoker 用于持有 Invoker 和 ServiceConfig DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 导出服务，并生成 Exporter Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; // 不存在注册中心，仅导出服务 &#125; else &#123; Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; &#125; this.urls.add(url);&#125; 上面代码根据 url 中的 scope 参数决定服务导出方式，分别如下： scope = none，不导出服务 scope != remote，导出到本地 scope != local，导出到远程 不管是导出到本地，还是远程。进行服务导出之前，均需要先创建 Invoker，这是一个很重要的步骤。因此下面先来分析 Invoker 的创建过程。 Invoker 创建过程在 Dubbo 中，Invoker 是一个非常重要的模型。在服务提供端，以及服务引用端均会出现 Invoker。Dubbo 官方文档中对 Invoker 进行了说明，这里引用一下。 Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 既然 Invoker 如此重要，那么我们很有必要搞清楚 Invoker 的用途。Invoker 是由 ProxyFactory 创建而来，Dubbo 默认的 ProxyFactory 实现类是 JavassistProxyFactory。下面我们到 JavassistProxyFactory 代码中，探索 Invoker 的创建过程。如下： 1234567891011121314public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // 为目标类创建 Wrapper final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); // 创建匿名 Invoker 类对象，并实现 doInvoke 方法。 return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 调用 Wrapper 的 invokeMethod 方法，invokeMethod 最终会调用目标方法 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 如上，JavassistProxyFactory 创建了一个继承自 AbstractProxyInvoker 类的匿名对象，并覆写了抽象方法 doInvoke。覆写后的 doInvoke 逻辑比较简单，仅是将调用请求转发给了 Wrapper 类的 invokeMethod 方法。Wrapper 用于“包裹”目标类，Wrapper 是一个抽象类，仅可通过 getWrapper(Class) 方法创建子类。在创建 Wrapper 子类的过程中，子类代码生成逻辑会对 getWrapper 方法传入的 Class 对象进行解析，拿到诸如类方法，类成员变量等信息。以及生成 invokeMethod 方法代码和其他一些方法代码。代码生成完毕后，通过 Javassist 生成 Class 对象，最后再通过反射创建 Wrapper 实例。相关的代码如下： 1234567891011121314151617 public static Wrapper getWrapper(Class&lt;?&gt; c) &#123; while (ClassGenerator.isDynamicClass(c)) c = c.getSuperclass(); if (c == Object.class) return OBJECT_WRAPPER; // 从缓存中获取 Wrapper 实例 Wrapper ret = WRAPPER_MAP.get(c); if (ret == null) &#123; // 缓存未命中，创建 Wrapper ret = makeWrapper(c); // 写入缓存 WRAPPER_MAP.put(c, ret); &#125; return ret;&#125; getWrapper 方法仅包含一些缓存操作逻辑，不难理解。下面我们看一下 makeWrapper 方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239private static Wrapper makeWrapper(Class&lt;?&gt; c) &#123; // 检测 c 是否为基本类型，若是则抛出异常 if (c.isPrimitive()) throw new IllegalArgumentException("Can not create wrapper for primitive type: " + c); String name = c.getName(); ClassLoader cl = ClassHelper.getClassLoader(c); // c1 用于存储 setPropertyValue 方法代码 StringBuilder c1 = new StringBuilder("public void setPropertyValue(Object o, String n, Object v)&#123; "); // c2 用于存储 getPropertyValue 方法代码 StringBuilder c2 = new StringBuilder("public Object getPropertyValue(Object o, String n)&#123; "); // c3 用于存储 invokeMethod 方法代码 StringBuilder c3 = new StringBuilder("public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws " + InvocationTargetException.class.getName() + "&#123; "); // 生成类型转换代码及异常捕捉代码，比如： // DemoService w; try &#123; w = ((DemoServcie) $1); &#125;&#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125; c1.append(name).append(" w; try&#123; w = ((").append(name).append(")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;"); c2.append(name).append(" w; try&#123; w = ((").append(name).append(")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;"); c3.append(name).append(" w; try&#123; w = ((").append(name).append(")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;"); // pts 用于存储成员变量名和类型 Map&lt;String, Class&lt;?&gt;&gt; pts = new HashMap&lt;String, Class&lt;?&gt;&gt;(); // ms 用于存储方法描述信息（可理解为方法签名）及 Method 实例 Map&lt;String, Method&gt; ms = new LinkedHashMap&lt;String, Method&gt;(); // mns 为方法名列表 List&lt;String&gt; mns = new ArrayList&lt;String&gt;(); // dmns 用于存储“定义在当前类中的方法”的名称 List&lt;String&gt; dmns = new ArrayList&lt;String&gt;(); // --------------------------------✨ 分割线1 ✨------------------------------------- // 获取 public 访问级别的字段，并为所有字段生成条件判断语句 for (Field f : c.getFields()) &#123; String fn = f.getName(); Class&lt;?&gt; ft = f.getType(); if (Modifier.isStatic(f.getModifiers()) || Modifier.isTransient(f.getModifiers())) // 忽略关键字 static 或 transient 修饰的变量 continue; // 生成条件判断及赋值语句，比如： // if( $2.equals("name") ) &#123; w.name = (java.lang.String) $3; return;&#125; // if( $2.equals("age") ) &#123; w.age = ((Number) $3).intValue(); return;&#125; c1.append(" if( $2.equals(\"").append(fn).append("\") )&#123; w.").append(fn).append("=").append(arg(ft, "$3")).append("; return; &#125;"); // 生成条件判断及返回语句，比如： // if( $2.equals("name") ) &#123; return ($w)w.name; &#125; c2.append(" if( $2.equals(\"").append(fn).append("\") )&#123; return ($w)w.").append(fn).append("; &#125;"); // 存储 &lt;字段名, 字段类型&gt; 键值对到 pts 中 pts.put(fn, ft); &#125; // --------------------------------✨ 分割线2 ✨------------------------------------- Method[] methods = c.getMethods(); // 检测 c 中是否包含在当前类中声明的方法 boolean hasMethod = hasMethods(methods); if (hasMethod) &#123; c3.append(" try&#123;"); &#125; for (Method m : methods) &#123; if (m.getDeclaringClass() == Object.class) // 忽略 Object 中定义的方法 continue; String mn = m.getName(); // 生成方法名判断语句，比如： // if ( "sayHello".equals( $2 ) c3.append(" if( \"").append(mn).append("\".equals( $2 ) "); int len = m.getParameterTypes().length; // 生成“运行时传入的参数数量与方法参数列表长度”判断语句，比如： // &amp;&amp; $3.length == 2 c3.append(" &amp;&amp; ").append(" $3.length == ").append(len); boolean override = false; for (Method m2 : methods) &#123; // 检测方法是否存在重载情况，条件为：方法对象不同 &amp;&amp; 方法名相同 if (m != m2 &amp;&amp; m.getName().equals(m2.getName())) &#123; override = true; break; &#125; &#125; // 对重载方法进行处理，考虑下面的方法： // 1. void sayHello(Integer, String) // 2. void sayHello(Integer, Integer) // 方法名相同，参数列表长度也相同，因此不能仅通过这两项判断两个方法是否相等。 // 需要进一步判断方法的参数类型 if (override) &#123; if (len &gt; 0) &#123; for (int l = 0; l &lt; len; l++) &#123; // 生成参数类型进行检测代码，比如： // &amp;&amp; $3[0].getName().equals("java.lang.Integer") // &amp;&amp; $3[1].getName().equals("java.lang.String") c3.append(" &amp;&amp; ").append(" $3[").append(l).append("].getName().equals(\"") .append(m.getParameterTypes()[l].getName()).append("\")"); &#125; &#125; &#125; // 添加 ) &#123;，完成方法判断语句，此时生成的代码可能如下（已格式化）： // if ("sayHello".equals($2) // &amp;&amp; $3.length == 2 // &amp;&amp; $3[0].getName().equals("java.lang.Integer") // &amp;&amp; $3[1].getName().equals("java.lang.String")) &#123; c3.append(" ) &#123; "); // 根据返回值类型生成目标方法调用语句 if (m.getReturnType() == Void.TYPE) // w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]); return null; c3.append(" w.").append(mn).append('(').append(args(m.getParameterTypes(), "$4")).append(");").append(" return null;"); else // return w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]); c3.append(" return ($w)w.").append(mn).append('(').append(args(m.getParameterTypes(), "$4")).append(");"); // 添加 &#125;, 生成的代码形如（已格式化）： // if ("sayHello".equals($2) // &amp;&amp; $3.length == 2 // &amp;&amp; $3[0].getName().equals("java.lang.Integer") // &amp;&amp; $3[1].getName().equals("java.lang.String")) &#123; // // w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]); // return null; // &#125; c3.append(" &#125;"); // 添加方法名到 mns 集合中 mns.add(mn); // 检测当前方法是否在 c 中被声明的 if (m.getDeclaringClass() == c) // 若是，则将当前方法名添加到 dmns 中 dmns.add(mn); ms.put(ReflectUtils.getDesc(m), m); &#125; if (hasMethod) &#123; // 添加异常捕捉语句 c3.append(" &#125; catch(Throwable e) &#123; "); c3.append(" throw new java.lang.reflect.InvocationTargetException(e); "); c3.append(" &#125;"); &#125; // 添加 NoSuchMethodException 异常抛出代码 c3.append(" throw new " + NoSuchMethodException.class.getName() + "(\"Not found method \\\"\"+$2+\"\\\" in class " + c.getName() + ".\"); &#125;"); // --------------------------------✨ 分割线3 ✨------------------------------------- Matcher matcher; // 处理 get/set 方法 for (Map.Entry&lt;String, Method&gt; entry : ms.entrySet()) &#123; String md = entry.getKey(); Method method = (Method) entry.getValue(); // 匹配以 get 开头的方法 if ((matcher = ReflectUtils.GETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; // 获取属性名 String pn = propertyName(matcher.group(1)); // 生成属性判断以及返回语句，示例如下： // if( $2.equals("name") ) &#123; return ($w).w.getName(); &#125; c2.append(" if( $2.equals(\"").append(pn).append("\") )&#123; return ($w)w.").append(method.getName()).append("(); &#125;"); pts.put(pn, method.getReturnType()); // 匹配以 is/has/can 开头的方法 &#125; else if ((matcher = ReflectUtils.IS_HAS_CAN_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; String pn = propertyName(matcher.group(1)); // 生成属性判断以及返回语句，示例如下： // if( $2.equals("dream") ) &#123; return ($w).w.hasDream(); &#125; c2.append(" if( $2.equals(\"").append(pn).append("\") )&#123; return ($w)w.").append(method.getName()).append("(); &#125;"); pts.put(pn, method.getReturnType()); // 匹配以 set 开头的方法 &#125; else if ((matcher = ReflectUtils.SETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; Class&lt;?&gt; pt = method.getParameterTypes()[0]; String pn = propertyName(matcher.group(1)); // 生成属性判断以及 setter 调用语句，示例如下： // if( $2.equals("name") ) &#123; w.setName((java.lang.String)$3); return; &#125; c1.append(" if( $2.equals(\"").append(pn).append("\") )&#123; w.").append(method.getName()).append("(").append(arg(pt, "$3")).append("); return; &#125;"); pts.put(pn, pt); &#125; &#125; // 添加 NoSuchPropertyException 异常抛出代码 c1.append(" throw new " + NoSuchPropertyException.class.getName() + "(\"Not found property \\\"\"+$2+\"\\\" filed or setter method in class " + c.getName() + ".\"); &#125;"); c2.append(" throw new " + NoSuchPropertyException.class.getName() + "(\"Not found property \\\"\"+$2+\"\\\" filed or setter method in class " + c.getName() + ".\"); &#125;"); // --------------------------------✨ 分割线4 ✨------------------------------------- long id = WRAPPER_CLASS_COUNTER.getAndIncrement(); // 创建类生成器 ClassGenerator cc = ClassGenerator.newInstance(cl); // 设置类名及超类 cc.setClassName((Modifier.isPublic(c.getModifiers()) ? Wrapper.class.getName() : c.getName() + "$sw") + id); cc.setSuperClass(Wrapper.class); // 添加默认构造方法 cc.addDefaultConstructor(); // 添加字段 cc.addField("public static String[] pns;"); cc.addField("public static " + Map.class.getName() + " pts;"); cc.addField("public static String[] mns;"); cc.addField("public static String[] dmns;"); for (int i = 0, len = ms.size(); i &lt; len; i++) cc.addField("public static Class[] mts" + i + ";"); // 添加方法代码 cc.addMethod("public String[] getPropertyNames()&#123; return pns; &#125;"); cc.addMethod("public boolean hasProperty(String n)&#123; return pts.containsKey($1); &#125;"); cc.addMethod("public Class getPropertyType(String n)&#123; return (Class)pts.get($1); &#125;"); cc.addMethod("public String[] getMethodNames()&#123; return mns; &#125;"); cc.addMethod("public String[] getDeclaredMethodNames()&#123; return dmns; &#125;"); cc.addMethod(c1.toString()); cc.addMethod(c2.toString()); cc.addMethod(c3.toString()); try &#123; // 生成类 Class&lt;?&gt; wc = cc.toClass(); // 设置字段值 wc.getField("pts").set(null, pts); wc.getField("pns").set(null, pts.keySet().toArray(new String[0])); wc.getField("mns").set(null, mns.toArray(new String[0])); wc.getField("dmns").set(null, dmns.toArray(new String[0])); int ix = 0; for (Method m : ms.values()) wc.getField("mts" + ix++).set(null, m.getParameterTypes()); // 创建 Wrapper 实例 return (Wrapper) wc.newInstance(); &#125; catch (RuntimeException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; cc.release(); ms.clear(); mns.clear(); dmns.clear(); &#125;&#125; 上面代码很长，大家耐心看一下。我们在上面代码中做了大量的注释，并按功能对代码进行了分块，以帮助大家理解代码逻辑。下面对这段代码进行讲解。首先我们把目光移到分割线1之上的代码，这段代码主要用于进行一些初始化操作。比如创建 c1、c2、c3 以及 pts、ms、mns 等变量，以及向 c1、c2、c3 中添加方法定义和类型转换代码。接下来是分割线1到分割线2之间的代码，这段代码用于为 public 级别的字段生成条件判断取值与赋值代码。这段代码不是很难看懂，就不多说了。继续向下看，分割线2和分隔线3之间的代码用于为定义在当前类中的方法生成判断语句，和方法调用语句。因为需要对方法重载进行校验，因此到这这段代码看起来有点复杂。不过耐心看一下，也不是很难理解。接下来是分割线3和分隔线4之间的代码，这段代码用于处理 getter、setter 以及以 is/has/can 开头的方法。处理方式是通过正则表达式获取方法类型（get/set/is/…），以及属性名。之后为属性名生成判断语句，然后为方法生成调用语句。最后我们再来看一下分隔线4以下的代码，这段代码通过 ClassGenerator 为刚刚生成的代码构建 Class 类，并通过反射创建对象。ClassGenerator 是 Dubbo 自己封装的，该类的核心是 toClass() 的重载方法 toClass(ClassLoader, ProtectionDomain)，该方法通过 javassist 构建 Class。这里就不分析 toClass 方法了，大家请自行分析。 阅读 Wrapper 类代码需要对 javassist 框架有所了解。关于 javassist，大家如果不熟悉，请自行查阅资料，本节不打算介绍 javassist 相关内容。 好了，关于 Wrapper 类生成过程就分析到这。如果大家看的不是很明白，可以单独为 Wrapper 创建单元测试，然后单步调试。并将生成的代码拷贝出来，格式化后再进行观察和理解。 导出服务到本地本节我们来看一下服务导出相关的代码，按照代码执行顺序，本节先来分析导出服务到本地的过程。相关代码如下： 1234567891011121314private void exportLocal(URL url) &#123; // 如果 URL 的协议头等于 injvm，说明已经导出到本地了，无需再次导出 if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; URL local = URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) // 设置协议头为 injvm .setHost(LOCALHOST) .setPort(0); ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref)); // 创建 Invoker，并导出服务，这里的 protocol 会在运行时调用 InjvmProtocol 的 export 方法 Exporter&lt;?&gt; exporter = protocol.export( proxyFactory.getInvoker(ref, (Class) interfaceClass, local)); exporters.add(exporter); &#125;&#125; exportLocal 方法比较简单，首先根据 URL 协议头决定是否导出服务。若需导出，则创建一个新的 URL 并将协议头、主机名以及端口设置成新的值。然后创建 Invoker，并调用 InjvmProtocol 的 export 方法导出服务。下面我们来看一下 InjvmProtocol 的 export 方法都做了哪些事情。 1234public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 创建 InjvmExporter return new InjvmExporter&lt;T&gt;(invoker, invoker.getUrl().getServiceKey(), exporterMap);&#125; 如上，InjvmProtocol 的 export 方法仅创建了一个 InjvmExporter，无其他逻辑。到此导出服务到本地就分析完了，接下来，我们继续分析导出服务到远程的过程。 导出服务到远程与导出服务到本地相比，导出服务到远程的过程要复杂不少，其包含了服务导出与服务注册两个过程。这两个过程涉及到了大量的调用，比较复杂。按照代码执行顺序，本节先来分析服务导出逻辑，服务注册逻辑将在下一节进行分析。下面开始分析，我们把目光移动到 RegistryProtocol 的 export 方法上。 123456789101112131415161718192021222324252627282930313233343536373839public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; // 导出服务 final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); // 获取注册中心 URL，以 zookeeper 注册中心为例，得到的示例 URL 如下： // zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.2&amp;export=dubbo%3A%2F%2F172.17.48.52%3A20880%2Fcom.alibaba.dubbo.demo.DemoService%3Fanyhost%3Dtrue%26application%3Ddemo-provider URL registryUrl = getRegistryUrl(originInvoker); // 根据 URL 加载 Registry 实现类，比如 ZookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取已注册的服务提供者 URL，比如： // dubbo://172.17.48.52:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello final URL registeredProviderUrl = getRegisteredProviderUrl(originInvoker); // 获取 register 参数 boolean register = registeredProviderUrl.getParameter("register", true); // 向服务提供者与消费者注册表中注册服务提供者 ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); // 根据 register 的值决定是否注册服务 if (register) &#123; // 向注册中心注册服务 register(registryUrl, registeredProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); &#125; // 获取订阅 URL，比如： // provider://172.17.48.52:20880/com.alibaba.dubbo.demo.DemoService?category=configurators&amp;check=false&amp;anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl); // 创建监听器 final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); // 向注册中心进行订阅 override 数据 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); // 创建并返回 DestroyableExporter return new DestroyableExporter&lt;T&gt;(exporter, originInvoker, overrideSubscribeUrl, registeredProviderUrl);&#125; 上面代码看起来比较复杂，主要做如下一些操作： 调用 doLocalExport 导出服务 向注册中心注册服务 向注册中心进行订阅 override 数据 创建并返回 DestroyableExporter 在以上操作中，除了创建并返回 DestroyableExporter 没什么难度外，其他几步操作都不是很简单。这其中，导出服务和注册服务是本章要重点分析的逻辑。 订阅 override 数据并非本文重点内容，后面会简单介绍一下。下面先来分析 doLocalExport 方法的逻辑，如下： 1234567891011121314151617181920private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker) &#123; String key = getCacheKey(originInvoker); // 访问缓存 ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; synchronized (bounds) &#123; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; // 创建 Invoker 为委托类对象 final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); // 调用 protocol 的 export 方法导出服务 exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegete), originInvoker); // 写缓存 bounds.put(key, exporter); &#125; &#125; &#125; return exporter;&#125; 上面的代码是典型的双重检查锁，大家在阅读 Dubbo 的源码中，会多次见到。接下来，我们把重点放在 Protocol 的 export 方法上。假设运行时协议为 dubbo，此处的 protocol 变量会在运行时加载 DubboProtocol，并调用 DubboProtocol 的 export 方法。所以，接下来我们目光转移到 DubboProtocol 的 export 方法上，相关分析如下： 1234567891011121314151617181920212223242526272829public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); // 获取服务标识，理解成服务坐标也行。由服务组名，服务名，服务版本号以及端口组成。比如： // demoGroup/com.alibaba.dubbo.demo.DemoService:1.0.1:20880 String key = serviceKey(url); // 创建 DubboExporter DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); // 将 &lt;key, exporter&gt; 键值对放入缓存中 exporterMap.put(key, exporter); // 本地存根相关代码 Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &#123; // 省略日志打印代码 &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; // 启动服务器 openServer(url); // 优化序列化 optimizeSerialization(url); return exporter;&#125; 如上，我们重点关注 DubboExporter 的创建以及 openServer 方法，其他逻辑看不懂也没关系，不影响理解服务导出过程。另外，DubboExporter 的代码比较简单，就不分析了。下面分析 openServer 方法。 12345678910111213141516private void openServer(URL url) &#123; // 获取 host:port，并将其作为服务器实例的 key，用于标识当前的服务器实例 String key = url.getAddress(); boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true); if (isServer) &#123; // 访问缓存 ExchangeServer server = serverMap.get(key); if (server == null) &#123; // 创建服务器实例 serverMap.put(key, createServer(url)); &#125; else &#123; // 服务器已创建，则根据 url 中的配置重置服务器 server.reset(url); &#125; &#125;&#125; 如上，在同一台机器上（单网卡），同一个端口上仅允许启动一个服务器实例。若某个端口上已有服务器实例，此时则调用 reset 方法重置服务器的一些配置。考虑到篇幅问题，关于服务器实例重置的代码就不分析了。接下来分析服务器实例的创建过程。如下： 12345678910111213141516171819202122232425262728293031323334private ExchangeServer createServer(URL url) &#123; url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, // 添加心跳检测配置到 url 中 url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // 获取 server 参数，默认为 netty String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); // 通过 SPI 检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常 if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException("Unsupported server type: " + str + ", url: " + url); // 添加编码解码器参数 url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); ExchangeServer server; try &#123; // 创建 ExchangeServer server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; throw new RpcException("Fail to start server..."); &#125; // 获取 client 参数，可指定 netty，mina str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) &#123; // 获取所有的 Transporter 实现类名称集合，比如 supportedTypes = [netty, mina] Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); // 检测当前 Dubbo 所支持的 Transporter 实现类名称列表中， // 是否包含 client 所表示的 Transporter，若不包含，则抛出异常 if (!supportedTypes.contains(str)) &#123; throw new RpcException("Unsupported client type..."); &#125; &#125; return server;&#125; 如上，createServer 包含三个核心的逻辑。第一是检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常。第二是创建服务器实例。第三是检测是否支持 client 参数所表示的 Transporter 拓展，不存在也是抛出异常。两次检测操作所对应的代码比较直白了，无需多说。但创建服务器的操作目前还不是很清晰，我们继续往下看。 123456789101112public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handler == null) &#123; throw new IllegalArgumentException("handler == null"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, "exchange"); // 获取 Exchanger，默认为 HeaderExchanger。 // 紧接着调用 HeaderExchanger 的 bind 方法创建 ExchangeServer 实例 return getExchanger(url).bind(url, handler);&#125; 上面代码比较简单，就不多说了。下面看一下 HeaderExchanger 的 bind 方法。 1234567public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; // 创建 HeaderExchangeServer 实例，该方法包含了多个逻辑，分别如下： // 1. new HeaderExchangeHandler(handler) // 2. new DecodeHandler(new HeaderExchangeHandler(handler)) // 3. Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))) return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; HeaderExchanger 的 bind 方法包含的逻辑比较多，但目前我们仅需关心 Transporters 的 bind 方法逻辑即可。该方法的代码如下： 1234567891011121314151617public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handlers == null || handlers.length == 0) &#123; throw new IllegalArgumentException("handlers == null"); &#125; ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; // 如果 handlers 元素数量大于1，则创建 ChannelHandler 分发器 handler = new ChannelHandlerDispatcher(handlers); &#125; // 获取自适应 Transporter 实例，并调用实例方法 return getTransporter().bind(url, handler);&#125; 如上，getTransporter() 方法获取的 Transporter 是在运行时动态创建的，类名为 TransporterAdaptive，也就是自适应拓展类。TransporterAdaptive 会在运行时根据传入的 URL 参数决定加载什么类型的 Transporter，默认为 NettyTransporter。下面我们继续跟下去，这次分析的是 NettyTransporter 的 bind 方法。 1234public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; // 创建 NettyServer return new NettyServer(url, listener);&#125; 这里仅有一句创建 NettyServer 的代码，无需多说，我们继续向下看。 12345678910111213141516171819202122232425262728293031323334353637383940public class NettyServer extends AbstractServer implements Server &#123; public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; // 调用父类构造方法 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125;&#125;public abstract class AbstractServer extends AbstractEndpoint implements Server &#123; public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; // 调用父类构造方法，这里就不用跟进去了，没什么复杂逻辑 super(url, handler); localAddress = getUrl().toInetSocketAddress(); // 获取 ip 和端口 String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &#123; // 设置 ip 为 0.0.0.0 bindIp = NetUtils.ANYHOST; &#125; bindAddress = new InetSocketAddress(bindIp, bindPort); // 获取最大可接受连接数 this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try &#123; // 调用模板方法 doOpen 启动服务器 doOpen(); &#125; catch (Throwable t) &#123; throw new RemotingException("Failed to bind "); &#125; DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort())); &#125; protected abstract void doOpen() throws Throwable; protected abstract void doClose() throws Throwable;&#125; 上面代码多为赋值代码，不需要多讲。我们重点关注 doOpen 抽象方法，该方法需要子类实现。下面回到 NettyServer 中。 12345678910111213141516171819202122232425262728protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); // 创建 boss 和 worker 线程池 ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerBoss", true)); ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerWorker", true)); ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); // 创建 ServerBootstrap bootstrap = new ServerBootstrap(channelFactory); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); bootstrap.setOption("child.tcpNoDelay", true); // 设置 PipelineFactory bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; @Override public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast("decoder", adapter.getDecoder()); pipeline.addLast("encoder", adapter.getEncoder()); pipeline.addLast("handler", nettyHandler); return pipeline; &#125; &#125;); // 绑定到指定的 ip 和端口上 channel = bootstrap.bind(getBindAddress());&#125; 以上就是 NettyServer 创建的过程，dubbo 默认使用的 NettyServer 是基于 netty 3.x 版本实现的，比较老了。因此 Dubbo 另外提供了 netty 4.x 版本的 NettyServer，大家可在使用 Dubbo 的过程中按需进行配置。 到此，关于服务导出的过程就分析完了。整个过程比较复杂，大家在分析的过程中耐心一些。并且多写 Demo 进行调试，以便能够更好的理解代码逻辑。 本节内容先到这里，接下来分析服务导出的另一块逻辑 — 服务注册。 服务注册本节我们来分析服务注册过程，服务注册操作对于 Dubbo 来说不是必需的，通过服务直连的方式就可以绕过注册中心。但通常我们不会这么做，直连方式不利于服务治理，仅推荐在测试服务时使用。对于 Dubbo 来说，注册中心虽不是必需，但却是必要的。因此，关于注册中心以及服务注册相关逻辑，我们也需要搞懂。 本节内容以 Zookeeper 注册中心作为分析目标，其他类型注册中心大家可自行分析。下面从服务注册的入口方法开始分析，我们把目光再次移到 RegistryProtocol 的 export 方法上。如下： 123456789101112131415161718192021public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; // $&#123;导出服务&#125; // 省略其他代码 boolean register = registeredProviderUrl.getParameter("register", true); if (register) &#123; // 注册服务 register(registryUrl, registeredProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); &#125; final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); // 订阅 override 数据 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); // 省略部分代码&#125; RegistryProtocol 的 export 方法包含了服务导出，注册，以及数据订阅等逻辑。其中服务导出逻辑上一节已经分析过了，本节将分析服务注册逻辑，相关代码如下： 123456public void register(URL registryUrl, URL registedProviderUrl) &#123; // 获取 Registry Registry registry = registryFactory.getRegistry(registryUrl); // 注册服务 registry.register(registedProviderUrl);&#125; register 方法包含两步操作，第一步是获取注册中心实例，第二步是向注册中心注册服务。接下来分两节内容对这两步操作进行分析。 创建注册中心本节内容以 Zookeeper 注册中心为例进行分析。下面先来看一下 getRegistry 方法的源码，这个方法由 AbstractRegistryFactory 实现。如下： 12345678910111213141516171819202122232425262728public Registry getRegistry(URL url) &#123; url = url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); String key = url.toServiceString(); LOCK.lock(); try &#123; // 访问缓存 Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; // 缓存未命中，创建 Registry 实例 registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException("Can not create registry..."); &#125; // 写入缓存 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; LOCK.unlock(); &#125;&#125;protected abstract Registry createRegistry(URL url); 如上，getRegistry 方法先访问缓存，缓存未命中则调用 createRegistry 创建 Registry，然后写入缓存。这里的 createRegistry 是一个模板方法，由具体的子类实现。因此，下面我们到 ZookeeperRegistryFactory 中探究一番。 123456789101112131415public class ZookeeperRegistryFactory extends AbstractRegistryFactory &#123; // zookeeperTransporter 由 SPI 在运行时注入，类型为 ZookeeperTransporter$Adaptive private ZookeeperTransporter zookeeperTransporter; public void setZookeeperTransporter(ZookeeperTransporter zookeeperTransporter) &#123; this.zookeeperTransporter = zookeeperTransporter; &#125; @Override public Registry createRegistry(URL url) &#123; // 创建 ZookeeperRegistry return new ZookeeperRegistry(url, zookeeperTransporter); &#125;&#125; ZookeeperRegistryFactory 的 createRegistry 方法仅包含一句代码，无需解释，继续跟下去。 1234567891011121314151617181920212223242526272829public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException("registry address == null"); &#125; // 获取组名，默认为 dubbo String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(Constants.PATH_SEPARATOR)) &#123; // group = "/" + group group = Constants.PATH_SEPARATOR + group; &#125; this.root = group; // 创建 Zookeeper 客户端，默认为 CuratorZookeeperTransporter zkClient = zookeeperTransporter.connect(url); // 添加状态监听器 zkClient.addStateListener(new StateListener() &#123; @Override public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;);&#125; 在上面的代码代码中，我们重点关注 ZookeeperTransporter 的 connect 方法调用，这个方法用于创建 Zookeeper 客户端。创建好 Zookeeper 客户端，意味着注册中心的创建过程就结束了。接下来，再来分析一下 Zookeeper 客户端的创建过程。 前面说过，这里的 zookeeperTransporter 类型为自适应拓展类，因此 connect 方法会在被调用时决定加载什么类型的 ZookeeperTransporter 拓展，默认为 CuratorZookeeperTransporter。下面我们到 CuratorZookeeperTransporter 中看一看。 1234public ZookeeperClient connect(URL url) &#123; // 创建 CuratorZookeeperClient return new CuratorZookeeperClient(url);&#125; 继续向下看。 123456789101112131415161718192021222324252627282930313233343536373839public class CuratorZookeeperClient extends AbstractZookeeperClient&lt;CuratorWatcher&gt; &#123; private final CuratorFramework client; public CuratorZookeeperClient(URL url) &#123; super(url); try &#123; // 创建 CuratorFramework 构造器 CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder() .connectString(url.getBackupAddress()) .retryPolicy(new RetryNTimes(1, 1000)) .connectionTimeoutMs(5000); String authority = url.getAuthority(); if (authority != null &amp;&amp; authority.length() &gt; 0) &#123; builder = builder.authorization("digest", authority.getBytes()); &#125; // 构建 CuratorFramework 实例 client = builder.build(); // 添加监听器 client.getConnectionStateListenable().addListener(new ConnectionStateListener() &#123; @Override public void stateChanged(CuratorFramework client, ConnectionState state) &#123; if (state == ConnectionState.LOST) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED); &#125; else if (state == ConnectionState.CONNECTED) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED); &#125; else if (state == ConnectionState.RECONNECTED) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED); &#125; &#125; &#125;); // 启动客户端 client.start(); &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125;&#125; CuratorZookeeperClient 构造方法主要用于创建和启动 CuratorFramework 实例。以上基本上都是 Curator 框架的代码，大家如果对 Curator 框架不是很了解，可以参考 Curator 官方文档。 本节分析了 ZookeeperRegistry 实例的创建过程，整个过程并不是很复杂。大家在看完分析后，可以自行调试，以加深理解。现在注册中心实例创建好了，接下来要做的事情是向注册中心注册服务，我们继续往下看。 节点创建以 Zookeeper 为例，所谓的服务注册，本质上是将服务配置数据写入到 Zookeeper 的某个路径的节点下。为了让大家有一个直观的了解，下面我们将 Dubbo 的 demo 跑起来，然后通过 Zookeeper 可视化客户端 ZooInspector 查看节点数据。如下： 从上图中可以看到 com.alibaba.dubbo.demo.DemoService 这个服务对应的配置信息（存储在 URL 中）最终被注册到了 /dubbo/com.alibaba.dubbo.demo.DemoService/providers/ 节点下。搞懂了服务注册的本质，那么接下来我们就可以去阅读服务注册的代码了。服务注册的接口为 register(URL)，这个方法定义在 FailbackRegistry 抽象类中。代码如下： 123456789101112131415161718192021222324252627282930public void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 模板方法，由子类实现 doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // 获取 check 参数，若 check = true 将会直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException("Failed to register"); &#125; else &#123; logger.error("Failed to register"); &#125; // 记录注册失败的链接 failedRegistered.add(url); &#125;&#125;protected abstract void doRegister(URL url); 如上，我们重点关注 doRegister 方法调用即可，其他的代码先忽略。doRegister 方法是一个模板方法，因此我们到 FailbackRegistry 子类 ZookeeperRegistry 中进行分析。如下： 1234567891011protected void doRegister(URL url) &#123; try &#123; // 通过 Zookeeper 客户端创建节点，节点路径由 toUrlPath 方法生成，路径格式如下: // /$&#123;group&#125;/$&#123;serviceInterface&#125;/providers/$&#123;url&#125; // 比如 // /dubbo/org.apache.dubbo.DemoService/providers/dubbo%3A%2F%2F127.0.0.1...... zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException("Failed to register..."); &#125;&#125; 如上，ZookeeperRegistry 在 doRegister 中调用了 Zookeeper 客户端创建服务节点。节点路径由 toUrlPath 方法生成，该方法逻辑不难理解，就不分析了。接下来分析 create 方法，如下： 1234567891011121314151617181920public void create(String path, boolean ephemeral) &#123; if (!ephemeral) &#123; // 如果要创建的节点类型非临时节点，那么这里要检测节点是否存在 if (checkExists(path)) &#123; return; &#125; &#125; int i = path.lastIndexOf('/'); if (i &gt; 0) &#123; // 递归创建上一级路径 create(path.substring(0, i), false); &#125; // 根据 ephemeral 的值创建临时或持久节点 if (ephemeral) &#123; createEphemeral(path); &#125; else &#123; createPersistent(path); &#125;&#125; 上面方法先是通过递归创建当前节点的上一级路径，然后再根据 ephemeral 的值决定创建临时还是持久节点。createEphemeral 和 createPersistent 这两个方法都比较简单，这里简单分析其中的一个。如下： 123456789public void createEphemeral(String path) &#123; try &#123; // 通过 Curator 框架创建节点 client.create().withMode(CreateMode.EPHEMERAL).forPath(path); &#125; catch (NodeExistsException e) &#123; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125;&#125; 好了，到此关于服务注册的过程就分析完了。整个过程可简单总结为：先创建注册中心实例，之后再通过注册中心实例注册服务。本节先到这，接下来分析数据订阅过程。 订阅 override 数据// 待补充 总结本篇文章详细分析了 Dubbo 服务导出过程，包括配置检测，URL 组装，Invoker 创建过程、导出服务以及注册服务等等。篇幅比较大，需要大家耐心阅读。本篇文章先就到这，如果文章有不妥错误之处，希望大家能够进行反馈或修正。 服务引入1. 简介上一篇文章详细分析了服务导出的过程，本篇文章我们趁热打铁，继续分析服务引用过程。在 Dubbo 中，我们可以通过两种方式引用远程服务。第一种是使用服务直连的方式引用服务，第二种方式是基于注册中心进行引用。服务直连的方式仅适合在调试或测试服务的场景下使用，不适合在线上环境使用。因此，本文我将重点分析通过注册中心引用服务的过程。从注册中心中获取服务配置只是服务引用过程中的一环，除此之外，服务消费者还需要经历 Invoker 创建、代理类创建等步骤。这些步骤，将在后续章节中一一进行分析。 2.服务引用原理Dubbo 服务引用的时机有两个，第一个是在 Spring 容器调用 ReferenceBean 的 afterPropertiesSet 方法时引用服务，第二个是在 ReferenceBean 对应的服务被注入到其他类中时引用。这两个引用服务的时机区别在于，第一个是饿汉式的，第二个是懒汉式的。默认情况下，Dubbo 使用懒汉式引用服务。如果需要使用饿汉式，可通过配置 dubbo:reference 的 init 属性开启。下面我们按照 Dubbo 默认配置进行分析，整个分析过程从 ReferenceBean 的 getObject 方法开始。当我们的服务被注入到其他类中时，Spring 会第一时间调用 getObject 方法，并由该方法执行服务引用逻辑。按照惯例，在进行具体工作之前，需先进行配置检查与收集工作。接着根据收集到的信息决定服务用的方式，有三种，第一种是引用本地 (JVM) 服务，第二是通过直连方式引用远程服务，第三是通过注册中心引用远程服务。不管是哪种引用方式，最后都会得到一个 Invoker 实例。如果有多个注册中心，多个服务提供者，这个时候会得到一组 Invoker 实例，此时需要通过集群管理类 Cluster 将多个 Invoker 合并成一个实例。合并后的 Invoker 实例已经具备调用本地或远程服务的能力了，但并不能将此实例暴露给用户使用，这会对用户业务代码造成侵入。此时框架还需要通过代理工厂类 (ProxyFactory) 为服务接口生成代理类，并让代理类去调用 Invoker 逻辑。避免了 Dubbo 框架代码对业务代码的侵入，同时也让框架更容易使用。 以上就是服务引用的大致原理，下面我们深入到代码中，详细分析服务引用细节。 3.源码分析服务引用的入口方法为 ReferenceBean 的 getObject 方法，该方法定义在 Spring 的 FactoryBean 接口中，ReferenceBean 实现了这个方法。实现代码如下： 123456789101112131415public Object getObject() throws Exception &#123; return get();&#125;public synchronized T get() &#123; if (destroyed) &#123; throw new IllegalStateException("Already destroyed!"); &#125; // 检测 ref 是否为空，为空则通过 init 方法创建 if (ref == null) &#123; // init 方法主要用于处理配置，以及调用 createProxy 生成代理类 init(); &#125; return ref;&#125; 以上两个方法的代码比较简短，并不难理解。这里需要特别说明一下，如果你对 2.6.4 及以下版本的 getObject 方法进行调试时，会碰到比较奇怪的的问题。这里假设你使用 IDEA，且保持了 IDEA 的默认配置。当你面调试到 get 方法的if (ref == null)时，你会发现 ref 不为空，导致你无法进入到 init 方法中继续调试。导致这个现象的原因是 Dubbo 框架本身有一些小问题。该问题已经在 pull request #2754 修复了此问题，并跟随 2.6.5 版本发布了。如果你正在学习 2.6.4 及以下版本，可通过修改 IDEA 配置规避这个问题。首先 IDEA 配置弹窗中搜索 toString，然后取消Enable &#39;toString&#39; object view勾选。具体如下： 3.1 处理配置Dubbo 提供了丰富的配置，用于调整和优化框架行为，性能等。Dubbo 在引用或导出服务时，首先会对这些配置进行检查和处理，以保证配置的正确性。配置解析逻辑封装在 ReferenceConfig 的 init 方法中，下面进行分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194private void init() &#123; // 避免重复初始化 if (initialized) &#123; return; &#125; initialized = true; // 检测接口名合法性 if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException("interface not allow null!"); &#125; // 检测 consumer 变量是否为空，为空则创建 checkDefault(); appendProperties(this); if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; // 设置 generic setGeneric(getConsumer().getGeneric()); &#125; // 检测是否为泛化接口 if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; // 加载类 interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; // -------------------------------✨ 分割线1 ✨------------------------------ // 从系统变量中获取与接口名对应的属性值 String resolve = System.getProperty(interfaceName); String resolveFile = null; if (resolve == null || resolve.length() == 0) &#123; // 从系统属性中获取解析文件路径 resolveFile = System.getProperty("dubbo.resolve.file"); if (resolveFile == null || resolveFile.length() == 0) &#123; // 从指定位置加载配置文件 File userResolveFile = new File(new File(System.getProperty("user.home")), "dubbo-resolve.properties"); if (userResolveFile.exists()) &#123; // 获取文件绝对路径 resolveFile = userResolveFile.getAbsolutePath(); &#125; &#125; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; Properties properties = new Properties(); FileInputStream fis = null; try &#123; fis = new FileInputStream(new File(resolveFile)); // 从文件中加载配置 properties.load(fis); &#125; catch (IOException e) &#123; throw new IllegalStateException("Unload ..., cause:..."); &#125; finally &#123; try &#123; if (null != fis) fis.close(); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; // 获取与接口名对应的配置 resolve = properties.getProperty(interfaceName); &#125; &#125; if (resolve != null &amp;&amp; resolve.length() &gt; 0) &#123; // 将 resolve 赋值给 url url = resolve; &#125; // -------------------------------✨ 分割线2 ✨------------------------------ if (consumer != null) &#123; if (application == null) &#123; // 从 consumer 中获取 Application 实例，下同 application = consumer.getApplication(); &#125; if (module == null) &#123; module = consumer.getModule(); &#125; if (registries == null) &#123; registries = consumer.getRegistries(); &#125; if (monitor == null) &#123; monitor = consumer.getMonitor(); &#125; &#125; if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; // 检测 Application 合法性 checkApplication(); // 检测本地存根配置合法性 checkStubAndMock(interfaceClass); // -------------------------------✨ 分割线3 ✨------------------------------ Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); // 添加 side、协议版本信息、时间戳和进程号等信息到 map 中 map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 非泛化服务 if (!isGeneric()) &#123; // 获取版本 String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; // 获取接口方法列表，并添加到 map 中 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; map.put("methods", Constants.ANY_VALUE); &#125; else &#123; map.put("methods", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; map.put(Constants.INTERFACE_KEY, interfaceName); // 将 ApplicationConfig、ConsumerConfig、ReferenceConfig 等对象的字段信息添加到 map 中 appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); // -------------------------------✨ 分割线4 ✨------------------------------ String prefix = StringUtils.getServiceKey(map); if (methods != null &amp;&amp; !methods.isEmpty()) &#123; // 遍历 MethodConfig 列表 for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; // 检测 map 是否包含 methodName.retry if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if ("false".equals(retryValue)) &#123; // 添加重试次数配置 methodName.retries map.put(method.getName() + ".retries", "0"); &#125; &#125; // 添加 MethodConfig 中的“属性”字段到 attributes // 比如 onreturn、onthrow、oninvoke 等 appendAttributes(attributes, method, prefix + "." + method.getName()); checkAndConvertImplicitConfig(method, map, attributes); &#125; &#125; // -------------------------------✨ 分割线5 ✨------------------------------ // 获取服务消费者 ip 地址 String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY); if (hostToRegistry == null || hostToRegistry.length() == 0) &#123; hostToRegistry = NetUtils.getLocalHost(); &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123; throw new IllegalArgumentException("Specified invalid registry ip from property..." ); &#125; map.put(Constants.REGISTER_IP_KEY, hostToRegistry); // 存储 attributes 到系统上下文中 StaticContext.getSystemContext().putAll(attributes); // 创建代理类 ref = createProxy(map); // 根据服务名，ReferenceConfig，代理类构建 ConsumerModel， // 并将 ConsumerModel 存入到 ApplicationModel 中 ConsumerModel consumerModel = new ConsumerModel(getUniqueServiceName(), this, ref, interfaceClass.getMethods()); ApplicationModel.initConsumerModel(getUniqueServiceName(), consumerModel);&#125; 上面的代码很长，做的事情比较多。这里根据代码逻辑，对代码进行了分块，下面我们一起来看一下。 首先是方法开始到分割线1之间的代码。这段代码主要用于检测 ConsumerConfig 实例是否存在，如不存在则创建一个新的实例，然后通过系统变量或 dubbo.properties 配置文件填充 ConsumerConfig 的字段。接着是检测泛化配置，并根据配置设置 interfaceClass 的值。接着来看分割线1到分割线2之间的逻辑。这段逻辑用于从系统属性或配置文件中加载与接口名相对应的配置，并将解析结果赋值给 url 字段。url 字段的作用一般是用于点对点调用。继续向下看，分割线2和分割线3之间的代码用于检测几个核心配置类是否为空，为空则尝试从其他配置类中获取。分割线3与分割线4之间的代码主要用于收集各种配置，并将配置存储到 map 中。分割线4和分割线5之间的代码用于处理 MethodConfig 实例。该实例包含了事件通知配置，比如 onreturn、onthrow、oninvoke 等。分割线5到方法结尾的代码主要用于解析服务消费者 ip，以及调用 createProxy 创建代理对象。关于该方法的详细分析，将会在接下来的章节中展开。 3.2 引用服务本节我们要从 createProxy 开始看起。从字面意思上来看，createProxy 似乎只是用于创建代理对象的。但实际上并非如此，该方法还会调用其他方法构建以及合并 Invoker 实例。具体细节如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118private T createProxy(Map&lt;String, String&gt; map) &#123; URL tmpUrl = new URL("temp", "localhost", 0, map); final boolean isJvmRefer; if (isInjvm() == null) &#123; // url 配置被指定，则不做本地引用 if (url != null &amp;&amp; url.length() &gt; 0) &#123; isJvmRefer = false; // 根据 url 的协议、scope 以及 injvm 等参数检测是否需要本地引用 // 比如如果用户显式配置了 scope=local，此时 isInjvmRefer 返回 true &#125; else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) &#123; isJvmRefer = true; &#125; else &#123; isJvmRefer = false; &#125; &#125; else &#123; // 获取 injvm 配置值 isJvmRefer = isInjvm().booleanValue(); &#125; // 本地引用 if (isJvmRefer) &#123; // 生成本地引用 URL，协议为 injvm URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); // 调用 refer 方法构建 InjvmInvoker 实例 invoker = refprotocol.refer(interfaceClass, url); // 远程引用 &#125; else &#123; // url 不为空，表明用户可能想进行点对点调用 if (url != null &amp;&amp; url.length() &gt; 0) &#123; // 当需要配置多个 url 时，可用分号进行分割，这里会进行切分 String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) &#123; // 设置接口全限定名为 url 路径 url = url.setPath(interfaceName); &#125; // 检测 url 协议是否为 registry，若是，表明用户想使用指定的注册中心 if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; // 将 map 转换为查询字符串，并作为 refer 参数的值添加到 url 中 urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; else &#123; // 合并 url，移除服务提供者的一些配置（这些配置来源于用户配置的 url 属性）， // 比如线程池相关配置。并保留服务提供者的部分配置，比如版本，group，时间戳等 // 最后将合并后的配置设置为 url 查询字符串中。 urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // 加载注册中心 url List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; !us.isEmpty()) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; // 添加 refer 参数到 url 中，并将 url 添加到 urls 中 urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; &#125; // 未配置注册中心，抛出异常 if (urls.isEmpty()) &#123; throw new IllegalStateException("No such any registry to reference..."); &#125; &#125; // 单个注册中心或服务提供者(服务直连，下同) if (urls.size() == 1) &#123; // 调用 RegistryProtocol 的 refer 构建 Invoker 实例 invoker = refprotocol.refer(interfaceClass, urls.get(0)); // 多个注册中心或多个服务提供者，或者两者混合 &#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; // 获取所有的 Invoker for (URL url : urls) &#123; // 通过 refprotocol 调用 refer 构建 Invoker，refprotocol 会在运行时 // 根据 url 协议头加载指定的 Protocol 实例，并调用实例的 refer 方法 invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; &#125; &#125; if (registryURL != null) &#123; // 如果注册中心链接不为空，则将使用 AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); // 创建 StaticDirectory 实例，并由 Cluster 对多个 Invoker 进行合并 invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; invoker = cluster.join(new StaticDirectory(invokers)); &#125; &#125; &#125; Boolean c = check; if (c == null &amp;&amp; consumer != null) &#123; c = consumer.isCheck(); &#125; if (c == null) &#123; c = true; &#125; // invoker 可用性检查 if (c &amp;&amp; !invoker.isAvailable()) &#123; throw new IllegalStateException("No provider available for the service..."); &#125; // 生成代理类 return (T) proxyFactory.getProxy(invoker);&#125; 上面代码很多，不过逻辑比较清晰。首先根据配置检查是否为本地调用，若是，则调用 InjvmProtocol 的 refer 方法生成 InjvmInvoker 实例。若不是，则读取直连配置项，或注册中心 url，并将读取到的 url 存储到 urls 中。然后根据 urls 元素数量进行后续操作。若 urls 元素数量为1，则直接通过 Protocol 自适应拓展类构建 Invoker 实例接口。若 urls 元素数量大于1，即存在多个注册中心或服务直连 url，此时先根据 url 构建 Invoker。然后再通过 Cluster 合并多个 Invoker，最后调用 ProxyFactory 生成代理类。Invoker 的构建过程以及代理类的过程比较重要，因此接下来将分两小节对这两个过程进行分析。 3.2.1 创建 InvokerInvoker 是 Dubbo 的核心模型，代表一个可执行体。在服务提供方，Invoker 用于调用服务提供类。在服务消费方，Invoker 用于执行远程调用。Invoker 是由 Protocol 实现类构建而来。Protocol 实现类有很多，本节会分析最常用的两个，分别是 RegistryProtocol 和 DubboProtocol，其他的大家自行分析。下面先来分析 DubboProtocol 的 refer 方法源码。如下： 1234567public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; optimizeSerialization(url); // 创建 DubboInvoker DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;&#125; 上面方法看起来比较简单，不过这里有一个调用需要我们注意一下，即 getClients。这个方法用于获取客户端实例，实例类型为 ExchangeClient。ExchangeClient 实际上并不具备通信能力，它需要基于更底层的客户端实例进行通信。比如 NettyClient、MinaClient 等，默认情况下，Dubbo 使用 NettyClient 进行通信。接下来，我们简单看一下 getClients 方法的逻辑。 1234567891011121314151617181920212223private ExchangeClient[] getClients(URL url) &#123; // 是否共享连接 boolean service_share_connect = false; // 获取连接数，默认为0，表示未配置 int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); // 如果未配置 connections，则共享连接 if (connections == 0) &#123; service_share_connect = true; connections = 1; &#125; ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &#123; if (service_share_connect) &#123; // 获取共享客户端 clients[i] = getSharedClient(url); &#125; else &#123; // 初始化新的客户端 clients[i] = initClient(url); &#125; &#125; return clients;&#125; 这里根据 connections 数量决定是获取共享客户端还是创建新的客户端实例，默认情况下，使用共享客户端实例。getSharedClient 方法中也会调用 initClient 方法，因此下面我们一起看一下这两个方法。 123456789101112131415161718192021222324252627282930private ExchangeClient getSharedClient(URL url) &#123; String key = url.getAddress(); // 获取带有“引用计数”功能的 ExchangeClient ReferenceCountExchangeClient client = referenceClientMap.get(key); if (client != null) &#123; if (!client.isClosed()) &#123; // 增加引用计数 client.incrementAndGetCount(); return client; &#125; else &#123; referenceClientMap.remove(key); &#125; &#125; locks.putIfAbsent(key, new Object()); synchronized (locks.get(key)) &#123; if (referenceClientMap.containsKey(key)) &#123; return referenceClientMap.get(key); &#125; // 创建 ExchangeClient 客户端 ExchangeClient exchangeClient = initClient(url); // 将 ExchangeClient 实例传给 ReferenceCountExchangeClient，这里使用了装饰模式 client = new ReferenceCountExchangeClient(exchangeClient, ghostClientMap); referenceClientMap.put(key, client); ghostClientMap.remove(key); locks.remove(key); return client; &#125;&#125; 上面方法先访问缓存，若缓存未命中，则通过 initClient 方法创建新的 ExchangeClient 实例，并将该实例传给 ReferenceCountExchangeClient 构造方法创建一个带有引用计数功能的 ExchangeClient 实例。ReferenceCountExchangeClient 内部实现比较简单，就不分析了。下面我们再来看一下 initClient 方法的代码。 1234567891011121314151617181920212223242526272829private ExchangeClient initClient(URL url) &#123; // 获取客户端类型，默认为 netty String str = url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT)); // 添加编解码和心跳包参数到 url 中 url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // 检测客户端类型是否存在，不存在则抛出异常 if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException("Unsupported client type: ..."); &#125; ExchangeClient client; try &#123; // 获取 lazy 配置，并根据配置值决定创建的客户端类型 if (url.getParameter(Constants.LAZY_CONNECT_KEY, false)) &#123; // 创建懒加载 ExchangeClient 实例 client = new LazyConnectExchangeClient(url, requestHandler); &#125; else &#123; // 创建普通 ExchangeClient 实例 client = Exchangers.connect(url, requestHandler); &#125; &#125; catch (RemotingException e) &#123; throw new RpcException("Fail to create remoting client for service..."); &#125; return client;&#125; initClient 方法首先获取用户配置的客户端类型，默认为 netty。然后检测用户配置的客户端类型是否存在，不存在则抛出异常。最后根据 lazy 配置决定创建什么类型的客户端。这里的 LazyConnectExchangeClient 代码并不是很复杂，该类会在 request 方法被调用时通过 Exchangers 的 connect 方法创建 ExchangeClient 客户端，该类的代码本节就不分析了。下面我们分析一下 Exchangers 的 connect 方法。 1234567891011public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handler == null) &#123; throw new IllegalArgumentException("handler == null"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, "exchange"); // 获取 Exchanger 实例，默认为 HeaderExchangeClient return getExchanger(url).connect(url, handler);&#125; 如上，getExchanger 会通过 SPI 加载 HeaderExchangeClient 实例，这个方法比较简单，大家自己看一下吧。接下来分析 HeaderExchangeClient 的实现。 12345678public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; // 这里包含了多个调用，分别如下： // 1. 创建 HeaderExchangeHandler 对象 // 2. 创建 DecodeHandler 对象 // 3. 通过 Transporters 构建 Client 实例 // 4. 创建 HeaderExchangeClient 对象 return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);&#125; 这里的调用比较多，我们这里重点看一下 Transporters 的 connect 方法。如下： 1234567891011121314151617public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; ChannelHandler handler; if (handlers == null || handlers.length == 0) &#123; handler = new ChannelHandlerAdapter(); &#125; else if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; // 如果 handler 数量大于1，则创建一个 ChannelHandler 分发器 handler = new ChannelHandlerDispatcher(handlers); &#125; // 获取 Transporter 自适应拓展类，并调用 connect 方法生成 Client 实例 return getTransporter().connect(url, handler);&#125; 如上，getTransporter 方法返回的是自适应拓展类，该类会在运行时根据客户端类型加载指定的 Transporter 实现类。若用户未配置客户端类型，则默认加载 NettyTransporter，并调用该类的 connect 方法。如下： 1234public Client connect(URL url, ChannelHandler listener) throws RemotingException &#123; // 创建 NettyClient 对象 return new NettyClient(url, listener);&#125; 到这里就不继续跟下去了，在往下就是通过 Netty 提供的 API 构建 Netty 客户端了，大家有兴趣自己看看。到这里，关于 DubboProtocol 的 refer 方法就分析完了。接下来，继续分析 RegistryProtocol 的 refer 方法逻辑。 123456789101112131415161718192021222324public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 取 registry 参数值，并将其设置为协议头 url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); // 获取注册中心实例 Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // 将 url 查询字符串转为 Map Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); // 获取 group 配置 String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) &#123; if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || "*".equals(group)) &#123; // 通过 SPI 加载 MergeableCluster 实例，并调用 doRefer 继续执行服务引用逻辑 return doRefer(getMergeableCluster(), registry, type, url); &#125; &#125; // 调用 doRefer 继续执行服务引用逻辑 return doRefer(cluster, registry, type, url);&#125; 上面代码首先为 url 设置协议头，然后根据 url 参数加载注册中心实例。然后获取 group 配置，根据 group 配置决定 doRefer 第一个参数的类型。这里的重点是 doRefer 方法，如下： 12345678910111213141516171819202122232425262728private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; // 创建 RegistryDirectory 实例 RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); // 设置注册中心和协议 directory.setRegistry(registry); directory.setProtocol(protocol); Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); // 生成服务消费者链接 URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters); // 注册服务消费者，在 consumers 目录下新节点 if (!Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; // 订阅 providers、configurators、routers 等节点数据 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); // 一个注册中心可能有多个服务提供者，因此这里需要将多个服务提供者合并为一个 Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker;&#125; 如上，doRefer 方法创建一个 RegistryDirectory 实例，然后生成服务者消费者链接，并向注册中心进行注册。注册完毕后，紧接着订阅 providers、configurators、routers 等节点下的数据。完成订阅后，RegistryDirectory 会收到这几个节点下的子节点信息。由于一个服务可能部署在多台服务器上，这样就会在 providers 产生多个节点，这个时候就需要 Cluster 将多个服务节点合并为一个，并生成一个 Invoker。关于 RegistryDirectory 和 Cluster，本文不打算进行分析，相关分析将会在随后的文章中展开。 3.2.2 创建代理Invoker 创建完毕后，接下来要做的事情是为服务接口生成代理对象。有了代理对象，即可进行远程调用。代理对象生成的入口方法为 ProxyFactory 的 getProxy，接下来进行分析。 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 调用重载方法 return getProxy(invoker, false);&#125;public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException &#123; Class&lt;?&gt;[] interfaces = null; // 获取接口列表 String config = invoker.getUrl().getParameter("interfaces"); if (config != null &amp;&amp; config.length() &gt; 0) &#123; // 切分接口列表 String[] types = Constants.COMMA_SPLIT_PATTERN.split(config); if (types != null &amp;&amp; types.length &gt; 0) &#123; interfaces = new Class&lt;?&gt;[types.length + 2]; // 设置服务接口类和 EchoService.class 到 interfaces 中 interfaces[0] = invoker.getInterface(); interfaces[1] = EchoService.class; for (int i = 0; i &lt; types.length; i++) &#123; // 加载接口类 interfaces[i + 1] = ReflectUtils.forName(types[i]); &#125; &#125; &#125; if (interfaces == null) &#123; interfaces = new Class&lt;?&gt;[]&#123;invoker.getInterface(), EchoService.class&#125;; &#125; // 为 http 和 hessian 协议提供泛化调用支持，参考 pull request #1827 if (!invoker.getInterface().equals(GenericService.class) &amp;&amp; generic) &#123; int len = interfaces.length; Class&lt;?&gt;[] temp = interfaces; // 创建新的 interfaces 数组 interfaces = new Class&lt;?&gt;[len + 1]; System.arraycopy(temp, 0, interfaces, 0, len); // 设置 GenericService.class 到数组中 interfaces[len] = GenericService.class; &#125; // 调用重载方法 return getProxy(invoker, interfaces);&#125;public abstract &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] types); 如上，上面大段代码都是用来获取 interfaces 数组的，我们继续往下看。getProxy(Invoker, Class&lt;?&gt;[]) 这个方法是一个抽象方法，下面我们到 JavassistProxyFactory 类中看一下该方法的实现代码。 1234public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; // 生成 Proxy 子类（Proxy 是抽象类）。并调用 Proxy 子类的 newInstance 方法创建 Proxy 实例 return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));&#125; 上面代码并不多，首先是通过 Proxy 的 getProxy 方法获取 Proxy 子类，然后创建 InvokerInvocationHandler 对象，并将该对象传给 newInstance 生成 Proxy 实例。InvokerInvocationHandler 实现自 JDK 的 InvocationHandler 接口，具体的用途是拦截接口类调用。该类逻辑比较简单，这里就不分析了。下面我们重点关注一下 Proxy 的 getProxy 方法，如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194public static Proxy getProxy(Class&lt;?&gt;... ics) &#123; // 调用重载方法 return getProxy(ClassHelper.getClassLoader(Proxy.class), ics);&#125;public static Proxy getProxy(ClassLoader cl, Class&lt;?&gt;... ics) &#123; if (ics.length &gt; 65535) throw new IllegalArgumentException("interface limit exceeded"); StringBuilder sb = new StringBuilder(); // 遍历接口列表 for (int i = 0; i &lt; ics.length; i++) &#123; String itf = ics[i].getName(); // 检测类型是否为接口 if (!ics[i].isInterface()) throw new RuntimeException(itf + " is not a interface."); Class&lt;?&gt; tmp = null; try &#123; // 重新加载接口类 tmp = Class.forName(itf, false, cl); &#125; catch (ClassNotFoundException e) &#123; &#125; // 检测接口是否相同，这里 tmp 有可能为空 if (tmp != ics[i]) throw new IllegalArgumentException(ics[i] + " is not visible from class loader"); // 拼接接口全限定名，分隔符为 ; sb.append(itf).append(';'); &#125; // 使用拼接后的接口名作为 key String key = sb.toString(); Map&lt;String, Object&gt; cache; synchronized (ProxyCacheMap) &#123; cache = ProxyCacheMap.get(cl); if (cache == null) &#123; cache = new HashMap&lt;String, Object&gt;(); ProxyCacheMap.put(cl, cache); &#125; &#125; Proxy proxy = null; synchronized (cache) &#123; do &#123; // 从缓存中获取 Reference&lt;Proxy&gt; 实例 Object value = cache.get(key); if (value instanceof Reference&lt;?&gt;) &#123; proxy = (Proxy) ((Reference&lt;?&gt;) value).get(); if (proxy != null) &#123; return proxy; &#125; &#125; // 并发控制，保证只有一个线程可以进行后续操作 if (value == PendingGenerationMarker) &#123; try &#123; // 其他线程在此处进行等待 cache.wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; else &#123; // 放置标志位到缓存中，并跳出 while 循环进行后续操作 cache.put(key, PendingGenerationMarker); break; &#125; &#125; while (true); &#125; long id = PROXY_CLASS_COUNTER.getAndIncrement(); String pkg = null; ClassGenerator ccp = null, ccm = null; try &#123; // 创建 ClassGenerator 对象 ccp = ClassGenerator.newInstance(cl); Set&lt;String&gt; worked = new HashSet&lt;String&gt;(); List&lt;Method&gt; methods = new ArrayList&lt;Method&gt;(); for (int i = 0; i &lt; ics.length; i++) &#123; // 检测接口访问级别是否为 protected 或 privete if (!Modifier.isPublic(ics[i].getModifiers())) &#123; // 获取接口包名 String npkg = ics[i].getPackage().getName(); if (pkg == null) &#123; pkg = npkg; &#125; else &#123; if (!pkg.equals(npkg)) // 非 public 级别的接口必须在同一个包下，否者抛出异常 throw new IllegalArgumentException("non-public interfaces from different packages"); &#125; &#125; // 添加接口到 ClassGenerator 中 ccp.addInterface(ics[i]); // 遍历接口方法 for (Method method : ics[i].getMethods()) &#123; // 获取方法描述，可理解为方法签名 String desc = ReflectUtils.getDesc(method); // 如果方法描述字符串已在 worked 中，则忽略。考虑这种情况， // A 接口和 B 接口中包含一个完全相同的方法 if (worked.contains(desc)) continue; worked.add(desc); int ix = methods.size(); // 获取方法返回值类型 Class&lt;?&gt; rt = method.getReturnType(); // 获取参数列表 Class&lt;?&gt;[] pts = method.getParameterTypes(); // 生成 Object[] args = new Object[1...N] StringBuilder code = new StringBuilder("Object[] args = new Object[").append(pts.length).append("];"); for (int j = 0; j &lt; pts.length; j++) // 生成 args[1...N] = ($w)$1...N; code.append(" args[").append(j).append("] = ($w)$").append(j + 1).append(";"); // 生成 InvokerHandler 接口的 invoker 方法调用语句，如下： // Object ret = handler.invoke(this, methods[1...N], args); code.append(" Object ret = handler.invoke(this, methods[" + ix + "], args);"); // 返回值不为 void if (!Void.TYPE.equals(rt)) // 生成返回语句，形如 return (java.lang.String) ret; code.append(" return ").append(asArgument(rt, "ret")).append(";"); methods.add(method); // 添加方法名、访问控制符、参数列表、方法代码等信息到 ClassGenerator 中 ccp.addMethod(method.getName(), method.getModifiers(), rt, pts, method.getExceptionTypes(), code.toString()); &#125; &#125; if (pkg == null) pkg = PACKAGE_NAME; // 构建接口代理类名称：pkg + ".proxy" + id，比如 org.apache.dubbo.proxy0 String pcn = pkg + ".proxy" + id; ccp.setClassName(pcn); ccp.addField("public static java.lang.reflect.Method[] methods;"); // 生成 private java.lang.reflect.InvocationHandler handler; ccp.addField("private " + InvocationHandler.class.getName() + " handler;"); // 为接口代理类添加带有 InvocationHandler 参数的构造方法，比如： // porxy0(java.lang.reflect.InvocationHandler arg0) &#123; // handler=$1; // &#125; ccp.addConstructor(Modifier.PUBLIC, new Class&lt;?&gt;[]&#123;InvocationHandler.class&#125;, new Class&lt;?&gt;[0], "handler=$1;"); // 为接口代理类添加默认构造方法 ccp.addDefaultConstructor(); // 生成接口代理类 Class&lt;?&gt; clazz = ccp.toClass(); clazz.getField("methods").set(null, methods.toArray(new Method[0])); // 构建 Proxy 子类名称，比如 Proxy1，Proxy2 等 String fcn = Proxy.class.getName() + id; ccm = ClassGenerator.newInstance(cl); ccm.setClassName(fcn); ccm.addDefaultConstructor(); ccm.setSuperClass(Proxy.class); // 为 Proxy 的抽象方法 newInstance 生成实现代码，形如： // public Object newInstance(java.lang.reflect.InvocationHandler h) &#123; // return new org.apache.dubbo.proxy0($1); // &#125; ccm.addMethod("public Object newInstance(" + InvocationHandler.class.getName() + " h)&#123; return new " + pcn + "($1); &#125;"); // 生成 Proxy 实现类 Class&lt;?&gt; pc = ccm.toClass(); // 通过反射创建 Proxy 实例 proxy = (Proxy) pc.newInstance(); &#125; catch (RuntimeException e) &#123; throw e; &#125; catch (Exception e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; if (ccp != null) // 释放资源 ccp.release(); if (ccm != null) ccm.release(); synchronized (cache) &#123; if (proxy == null) cache.remove(key); else // 写缓存 cache.put(key, new WeakReference&lt;Proxy&gt;(proxy)); // 唤醒其他等待线程 cache.notifyAll(); &#125; &#125; return proxy;&#125; 上面代码比较复杂，我们写了大量的注释。大家在阅读这段代码时，要搞清楚 ccp 和 ccm 的用途，不然会被搞晕。ccp 用于为服务接口生成代理类，比如我们有一个 DemoService 接口，这个接口代理类就是由 ccp 生成的。ccm 则是用于为 org.apache.dubbo.common.bytecode.Proxy 抽象类生成子类，主要是实现 Proxy 类的抽象方法。下面以 org.apache.dubbo.demo.DemoService 这个接口为例，来看一下该接口代理类代码大致是怎样的（忽略 EchoService 接口）。 12345678910111213141516171819202122package org.apache.dubbo.common.bytecode;public class proxy0 implements org.apache.dubbo.demo.DemoService &#123; public static java.lang.reflect.Method[] methods; private java.lang.reflect.InvocationHandler handler; public proxy0() &#123; &#125; public proxy0(java.lang.reflect.InvocationHandler arg0) &#123; handler = $1; &#125; public java.lang.String sayHello(java.lang.String arg0) &#123; Object[] args = new Object[1]; args[0] = ($w) $1; Object ret = handler.invoke(this, methods[0], args); return (java.lang.String) ret; &#125;&#125; 好了，到这里代理类生成逻辑就分析完了。整个过程比较复杂，大家需要耐心看一下。 4.总结本篇文章对服务引用的过程进行了较为详尽的分析，还有一些逻辑暂时没有分析到，比如 Directory、Cluster。这些接口及实现类功能比较独立，后续会单独成文进行分析。暂时我们可以先把这些类看成黑盒，只要知道这些类的用途即可。关于服务引用过程就分析到这里。 服务字典服务路由负载均衡服务调用过程参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC：概述]]></title>
    <url>%2F2019%2F07%2F22%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FRPC%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[RPC提出问题 考虑将“无所不在”的对象作为所有问题的解决之道，其思想是所有相互协作的对象彼此都知道对方在哪里 当在一台计算机上的某个对象需要调 用在另一台计算机上的某个对象时就会发送一个包含这个请求的详细信息的网络消息。 远程对象响应请求，并返回客户端 概述客户端服务器角色我们需要的机制并不是HTTP的机制，而是客户端程序员以常规的方式进行方法调用而无需操心将数据发送到网络上或解析响应之类的问题。 即在客户端为远程对象安装一个代理，对于客户端来说就像是要访问的远程对象一样，客户调用该代理时只需要进行常规的方法调用。代理负责使用网络协议与服务器联系。 什么是RPC服务RPC协议是一种通过网络从远程计算机程序上请求服务来得到计算服务或数据服务，且不需要了解底层网络技术的协议和框架。RPC框架负责屏蔽底层的传输方式（TCP或者UDP）、序列化方式（XML/Json/二进制）和通信细节。框架使用者只需要了解谁在什么位置提供了什么样的远程服务接口即可，开发者不需要关心底层通信细节和调用过程。 简单，RPC的语义十分清晰和简单，便于建立分布式系统 高效，能够高效地实现远程的过程调用 通用，RPC导出的服务可以供多个使用者用于不同的目的。 核心技术点RPC框架实现的几个核心技术点总结如下： 远程服务提供者需要以某种形式提供服务调用相关的信息，包括但不限于服务接口定义、数据结构，或者中间态的服务定义文件，例如 Thrift 的 IDL 文件，WS-RPC 的 WSDL 文件定义，甚至也可以是服务端的接口说明文档；服务调用者需要通过一定的途径获取远程服务调用相关信息，例如服务端接口定义 Jar 包导入，获取服务端 IDL 文件等。 远程代理对象：服务调用者调用的服务实际是远程服务的本地代理，对于 Java 语言，它的实现就是 JDK 的动态代理，通过动态代理的拦截机制，将本地调用封装成远程服务调用。 通信：RPC 框架与具体的协议无关，例如 Spring 的远程调用支持 HTTP Invoke、RMI Invoke，MessagePack 使用的是私有的二进制压缩协议。 序列化：远程通信，需要将对象转换成二进制码流进行网络传输，不同的序列化框架，支持的数据类型、数据包大小、异常类型以及性能等都不同。不同的 RPC 框架应用场景不同，因此技术选择也会存在很大差异。一些做的比较好的 RPC 框架，可以支持多种序列化方式，有的甚至支持用户自定义序列化框架（Hadoop Avro）。 RPC协议实现 RPC协议以传输协议（HTTP，又或者TCP/UDP）为基础，为两个不同的应用程序传递数据。 RPC采用客户端/服务端模式，请求程序就是一个客户端，服务提供程序就是一个服务端 RPC服务的原理Socket套接字 网络上的两个程序通过一个双向通信连接实现数据的交换，这个连接的一端被称为Socket，用于描述IP地址和端口，是一个通信连接的句柄，可以用来实现不同计算机间的通信，是网络编程接口的具体实现。 本地调用过程考虑C语言的调用 1234//fd：一个整形数，表示一个文件//buf：一个字符数组，用于存储读入的数据//nbytes：另一个整形数，记录实际读入的字节数，即数组长度count = read(fd , buf , nbytes); 在主程序中进行调用该函数，则调用之前堆栈的状态如图2(a)所示。 为了进行调用，调用方首先把参数反序压入堆栈，即为最后一个参数先压入，如图2(b)所示。 在read操作运行完毕后，它将返回值放在某个寄存器中，移出返回地址，并将控制权交回给调用方。 调用方随后将参数从堆栈中移出，使堆栈还原到最初的状态。 一般为阻塞send，因为如同本地方法调用一般，需要先执行完需要执行的函数，才执行之后的 RPC调用过程在本地调用过程中，read例程由链接器从库中提取出来，然后插入到目标程序当中。即通过编译的方式实现这一过程。而在RPC调用中并不可行，因为目标函数是存在于远端程序上， 因此RPC调用是建立在语言级别的，必须使用socket通信完成，为使得RPC调用如同本地调用一般透明，则出现了几个新的概念 客户存根：存根就像代理一样，当read实际上是一个远程过程时（位于文件服务器所在机器上运行的过程），库中就放入read的另一个版本（代理代码），即客户存根 在具体调用过程中，调用者调用存根如同调用本地代码一样方便 服务器存根：客户存根的等价物 其具体的原理为： 对于每个独立的远程过程都有一个存根。当客户机调用远程过程时，RPC系统调用合适的存根，并传递远程过程的参数 该存根位于服务器的端口，并编组参数（涉及将参数打包成可通过网络传输的形式），接着存根使用消息传递向服务器发送一个消息。 服务器的一个类似存根接收这一消息，并调用服务器上的过程。如有必要，返回值可通过同样的技术返回客户机 客户端以正常的方式调用客户存根。 从客户端的角度来看，这个调用仿佛就是调用一个本地方法，而它的真正执行是发生在远端服务器上的。客户存根的方法将参数打包并封装成一个或多个网络消息体并发送到服务端。 将参数封装到网络消息中的过程称为编码，它将所有的数据化为字节数组格式 客户存根生成一个消息，然后调用本地操作系统； 调用OS的socket套接字接口来向远程服务发送我们编码的网络消息 客户端操作系统将消息发送给远程操作系统； OS使用某种协议，如TCP传输到远程服务端 远程操作系统将消息交给服务器存根； 远程OS套接字收到消息，并将消息传递到指定端口 服务器存根调将参数提取出来，而后调用服务器； 服务器存根对参数进行解码，通常会将参数从标准的网络格式转换为特定的语言格式 服务器执行要求的操作，操作完成后将结果返回给服务器存根； 服务器存根调用服务端的方法，并且将从客户端接收的参数传递给该方法，它运行具体的功能并返回，这部分代码的执行对于客户端来说就是远程过程调用 服务器存根将结果打包成一个消息，而后调用本地操作系统； 将最后的结果进行编码并序列化，打包成网络参数等， 服务器操作系统将含有结果的消息发送给客户端操作系统； 客户端操作系统将消息交给客户存根； 客户存根将结果从消息中提取出来，返回给调用它的客户存根。 RPC实现Java RMI对象被抽离出类，类里面包含操作，对这些类和方法的注册形成了第二代RPC JavaRMI使程序员可以创建分布式应用程序，能够从其他JVM中调用远程对象的方法。 只要客户端应用程序具有对远程对象的引用，就可以进行远程调用，该引用是通过查找RMI提供的命名服务（RMI注册表）中的远程对象得到的，调用该引用就可以像调用本地方法一样调用远程方法，然后接收方法执行之后传递回来的返回值。 RMI架构 RMI中分布式对象模型的特点 服务对象的引用可以作为参数传递或作为结果返回 调用远程服务对象的方法就像调用本地对象的方法一样 内置的Java的instanceof可以测试远程对象实现的远程接口，就像本地使用方法一样 调用远程对象的方法实际上是与远程服务接口进行交互，而不是实现类 远程方法调用过程中，参数和返回值是通过传递值类实现的，而不是传递引用 远程对象的引用是通过引用传递的，一切真实的操作发生在远程的服务端 客户端必须处理因为远程调用而导致的额外的异常。 存根与参数编码客户端的存根构造了一个信息块： 被使用的远程对象的标识符 被调用的方法的描述 编组后的参数 存根将此消息发送给服务器，在服务器的另一端，接收器对象执行以下动作： 定位要调用的远程对象 调用所需要的方法，并传递客户端提供的参数 捕获返回值或该调用产生的异常 将返回值编组，打包送回给客户端存根 实现主要包括接口和对象类、远程接口实现类、生成存根代码、注册接口和查找对象、分布式的垃圾回收器 接口和对象类 首先定义一个要被传输的对象类，它需要实现Serializable，以能够序列化 12345public class Person implements Serializable &#123; private int id; private String name; private int age;&#125; 远程对象的接口需要扩展Remote接口，并且当远程方法调用失败后会抛出异常 123public interface PersonService extends Remote &#123; public Person getPersonInf(int n) throws RemoteException;&#125; 远程接口实现类 可以使用java.rmi.server.RemoteServer和它的子类来实现远程调用功能， 1234567public class PersonServiceImpl extends UnicastRemoteObject implements PersonService &#123; @Override public Person getPersonInf(int n) throws RemoteException &#123; Person person = new Person(); return person; &#125;&#125; 生成存根代码 存根可以由rmic编译器生成，Java1.5后，支持运行时动态生成存根类 注册接口和查找对象 创建Server代码，绑定特定的端口并注册远程接口的实现类，远程对象接口也可以通过java.rmi.Naming使用基于URL的方法进行注册。 RMI的URL以rmi:开头，后接服务器与一个可选的端口号，服务器告诉注册表在给定位置将这个名字关联到该对象 123456789101112131415public class Server &#123; public static void main(String[] args) &#123; try &#123; PersonService personService = new PersonServiceImpl(); LocateRegistry.createRegistry(6600); Context namingContext = new InitialContext(); namingContext.rebind("rmi://127.0.0.1:8800/person-service", personService); System.out.println("service started"); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; catch (NamingException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 创建Client，获取远程接口对应的远程实现类，并通过远程接口操作，以Nmaing.lookup绑定远程对象。 123456789101112131415public class Client &#123; public static void main(String[] args) &#123; try &#123; PersonService personService = (PersonService) Naming.lookup("rmi://127.0.0.1:8800/person-service"); Person person = personService.getPersonInf(5); System.out.println(person.toString()); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; catch (NotBoundException e) &#123; e.printStackTrace(); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 分布式的垃圾回收器 启动服务端，再运行客户端即可以看到远程调用结果，然而如何判断服务器上的引用对象何时被垃圾回收。 RMI创建了一个分布式环境，运行在一个JVM上的进程可以访问运行在不同JVM进程上驻留的对象，即一个服务器上的进程需要知道一个对象在什么时候不会被客户引用，并且可以删除。 使用RMI的JVM中支持两种操作：标记脏数据和清理。 当对象仍在使用时，本地JVM会定期向服务器的JVM发送一个标记脏数据的调用。标记脏数据基于服务器给定的时间间隔定期重新发送心跳信息 当客户端没有更多的本地引用远程对象时，会发送一个清理调用给服务器，因此服务器只需要计算客户端发送的清理调用或者说心跳超时，即可删除对象。 RMI架构 顶层是存根/骨架层，通过对将要传输的数据编码成流的行驶传递到远程引用层。 远程引用层定义了RMI连接的调用语义并给予实现，RMI在进行远程调用时，用到JRMP协议，这一层提供了专门用于引用远程服务的RemoteRef对象 传输层在JVM间建立基于流的网络连接，并负责设置和管理这些连接。 远程方法中的参数与返回值对于从一个JVM向另一个JVM传递值，我们将其区分为两种情况，传递远程对象和传递非远程对象。 若客户端传递了一个对WareHouse的引用，即通过它可以调用远程的仓库对象的一个存根给另一个对象，即传递远程对象的实例 传递一般的Java对象，即传递非远程对象，即序列化 传递远程对象 当一个对远程对象的引用从一个虚拟机传递到另一个虚拟机时，该远程对象的发送者和接收者都将持有一个对同一个对象的引用，这个引用并非是一个内存位置，而是由网络地址和该远程对象的唯一标识符组成的。 动态类加载 当服务器返回了一个Product接口的一个实例，客户端编译时需要Product.class的类文件，但是客户端本身是没有其实例Book类，说明客户端需要拥有在运行时加载额外类的能力。 客户端使用了与RMI注册表相同的机制，即类由服务器提供服务， SOA与微服务第三代RPC框架已经超越了RPC本身，主要是面向服务的实现，实现了服务的管理和治理，提供了服务监控的方法等。 SOA面向服务的架构（SOA）是一种软件架构模式，一些应用程序组件通过网络通信协议向其他组件传递服务，这种服务间的通信可以是简单的数据传递，也可以是两个或更多个彼此需要协调的服务间相互连接。 在SOA中根据服务的功能，将服务分为服务消费者和服务生产者两个主要角色。 Web Service和ESB根据场景SOA具体可以分为标准的WebService和企业服务总线ESB Web Service底层使用HTTP，类似一个远程服务提供者，可以通过SOAP协议或RESTful协议实现。Web Service是一个平台独立、低耦合、自包含的基于可编程的Web应用程序，可使用开放的XML和JSON描述、发布、发现、协调和配置这些应用程序，用于开发分布式的应用程序。 其特点是服务独立，服务间通过SOAP协议调用，服务内容通过WSDL描述，服务注册与发现通过UDDI实现 ESB是集成架构的分割，允许通过公共通信总线进行通信。 微服务微服务与SOA一脉相承，更侧重与服务间的隔离，让服务做专门的事情，可以敏捷迭代与上线。服务是一种软件架构模式，其中的复杂应用程序由微小而独立的进程组成，使用与语言无关的API通信。 微服务与SOA的差异 微服务中，服务可以独立于其他服务进行操作和部署，更容易经常部署新版本的服务或独立扩展服务。 微服务容错方面表现良好，若在一个微服务机器上存在内存泄漏，则只有该服务器受影响，因为微服务与微服务间是隔离的 SOA服务可能共享数据存储，而微服务中每个服务都具有独立的数据存储 SOA与微服务的主要区别是规模和范围，微服务发展了异步等，但微服务概念是包含在大的SOA体系中。从实现层次角度讲，某个子系统可能是由微服务实现的，多个这样的子系统可能是采用SOA实现的。 RPC协议选型RPC协议的具体实现方式可以不同，RPC调用的协议选择包含两部分 协议栈：广义上协议栈可以分为公有协议和私有协议，例如 HTTP、SMPP、WebService 等都是公有协议；如果是某个公司或者组织内部自定义、自己使用的协议，没有被国际标准化组织接纳和认可的，往往划为私有协议，例如 Thrift 协议。 序列化方式：同一种协议也可以承载多种序列化方式，以 HTTP 协议为例，它可以承载文本类序列化方式，例如：XML、JSON 等，也可以承载二进制序列化方式，例如谷歌的 Protobuf。 而不同的协议选择对RPC调用的性能、开发难度和问题定位效率都有影响，因此，选择哪种协议，对RPC框架而言至关重要。由于各个协议都有自己的优缺点，有的看重性能和时延、有的更看重跨语言和可维护性。 私有协议流行的原因 由某个企业自己制订，协议实现细节不愿公开，只在企业自己生产的设备之间使用的协议。私有协议具有封闭性、垄断性、排他性等特点。如果网上大量存在私有（非标准）协议，现行网络或用户一旦使用了它，后进入的厂家设备就必须跟着使用这种非标准协议，才能够互连互通，否则根本不可能进入现行网络。这样，使用非标准协议的厂家就实现了垄断市场的愿望。 RPC通信方式在传统的 Java 应用中，通常使用以下 4 种方式进行跨节点通信。 1．通过 RMI 进行远程服务调用。 2．通过 Java 的 Socket+Java 序列化的方式进行跨节点调用。 3．利用一些开源的 RPC 框架进行远程服务调用，例如 Facebook 的 Thrift，Google 的 gRPC 等。 4．利用标准的公有协议进行跨节点服务调用，例如 HTTP+XML、Restful+JSON 或者 WebService。 跨节点的远程服务调用，除了链路层的物理连接外，还需要对请求和响应消息进行编解码。在请求和应答消息本身以外，也需要携带一些其他控制和管理类指令，例如链路建立的握手请求和响应消息、链路检测的心跳消息等。当这些功能组合到一起之后，就会形成私有协议。 私有协议的优点：灵活性高，可以按照业务的使用场景来设计和优化，在某个公司或者组织内部使用时也可以按需定制和演进，所以大部分 RPC 框架都支持私有二进制协议，例如阿里的 Dubbo、华为的 ServiceComb、Apache 的 Thrift 等。 序列化方式当进行远程跨进程服务调用时，需要把被传输的数据结构 / 对象序列化为字节数组或者 ByteBuffer。而当远程服务读取到 ByteBuffer 对象或者字节数组时，需要将其反序列化为原始的数据结构/对象。利用序列化框架可以实现上述转换工作。 Java 序列化从JDK 1.1版本就已经提供，它不需要添加额外的类库，只需实现 java.io.Serializable并生成序列ID即可，因此，它从诞生之初就得到了广泛的应用。但是在远程服务调用（RPC）时，很少直接使用Java序列化进行消息的编解码和传输，这又是什么原因呢？下面通过分析 Java 序列化的缺点来找出答案: 无法跨语言，是 Java 序列化最致命的问题。对于跨进程的服务调用，服务提供者可能会使用 C++ 或者其他语言开发，当我们需要和异构语言进程交互时，Java 序列化就难以胜任。由于 Java 序列化技术是 Java 语言内部的私有协议，其它语言并不支持，对于用户来说它完全是黑盒。对于 Java 序列化后的字节数组，别的语言无法进行反序列化，这就严重阻碍了它的应用。事实上，目前几乎所有流行的Java RPC通信框架，都没有使用 Java 序列化作为编解码框架，原因就在于它无法跨语言，而这些RPC框架往往需要支持跨语言调用。 相比于业界的一些序列化框架，Java默认的序列化效能较低，主要体现在：序列化之后的字节数组体积较大，性能较低。在同等情况下，编码后的字节数组越大，存储的时候就越占空间，存储的硬件成本就越高，并且在网络传输时更占带宽，导致系统的吞吐量降低。Java 序列化后的码流偏大也一直被业界所诟病，导致它的应用范围受到了很大限制。 当前比较流行的序列化方式可以分为两大类: 文本类序列化方式：主要包括 JSON 和 XML，它们的优点是：支持跨语言、可读性好、配套的支持工具比较全。缺点就是：序列化之后的码流比较大、冗余内容多，性能相对比较差。 私有的二进制类序列化方式：比较流行的有 Thrift 序列化框架、MessagePack 和谷歌的 Protobuf 框架。它的优点是性能高，缺点就是可读性差，支撑的工具链不健全。 协议选型尽管公有协议种类繁多，例如之前非常流行的 WebService、WADL 等，但目前来看，如果选择公有协议，HTTP 协议还是首选，具有 Rest 风格的 Restful + JSON 接口是当前最流行的方式。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper：概述]]></title>
    <url>%2F2019%2F07%2F21%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FZookeeper%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Zookeeper简介提出问题概述 中间件，提供协调服务。 作用于分布式系统，发挥其优势，可以为大数据服务。 支持Java，提供Java和C语言的客户端API。 Zookeeper的特性 一致性：数据一致性(非强一致性)，数据按照顺序分批入库。 原子性：事务要么成功，要么失败，不会局部化。 单一视图：客户端连接集群中的任一zk节点，数据都是一致的。 可靠性：每次对zk的操作状态都会保存在服务端。 实时性：客户端可以读取到zk服务端的最新数据。 Zookeeper目录结构 bin：主要的一些运行命令。 conf：存放配置文件。 zoo.cfg。 tickTime：用于计算的时间单元，是基本的时间单元。比如session超时：N*tickTime。 initLimit：用于集群，允许从节点连接并同步到master节点的初始化连接时间，以tickTime的倍数表示。 syncLimit：用于集群，master主节点与从节点间发送消息，请求和应答的时间长度（心跳机制）。 dataDir：数据存放的目录。 dataLogDir：日志目录，不配置则值为dataDir。 clientPort：连接服务器的端口，默认2181。 contrib：附加的功能。 dist-maven：mvn编译后的目录。 docs：文档。 lib：需要依赖的jar包。 recipes：案例demo代码。 src：源码。 Zookeeper作用 master节点选举：主节点挂了后，从节点就会接手工作，并且保证这个节点是唯一的，即首脑模式，从而保证我们的集群是高可用的。 统一配置文件管理：即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他所有服务器，此操作在云计算中运用很多（如修改了redis统一配置）。 发布与订阅，类似消息队列，dubbo发布者将数据存在znode中，订阅者会读取这个数据。 提供分布式锁，分布式环境中不同进程间争夺资源，类似于多线程中的锁。 集群管理，集群中保证数据的强一致性。 会将主节点的数据同步到子节点中。 应用适用性案例1对比Zookeeper基本数据模型 是一个树形结构，类似于前端开发中的tree.js： 即zookeeper的数据模型可以理解为一个文件目录：/user/local等。 每一个节点都称为znode，可以有子节点，也可以有数据。 每个节点分为临时节点和永久节点，临时节点在客户端断开后消失。 每个zk节点都有各自的版本号，可以通过命令行来显示节点信息。 每当节点数据发生变化，则节点的版本号会累加（乐观锁）。 删除/修改过时节点，版本号不匹配会报错（乐观锁）。 每个zk节点存储的数据不宜过大，几K即可。 节点可以设置权限acl，通过权限限制用户的访问。 Zookeeper数据模型基本操作启动zookeeper：sh zkServer.sh start 常用命令行操作进入zookeeper 在bin目录下的sh zkCli.sh &lt;server&gt; 则会进入到zookeeper当中。 命令 ls：查看zookeeper的节点或数据。 ls2：会显示状态信息，ls+stat。 get：提前当前目录的数据。 stat：状态信息，==status。 cZxid：创建后，zookeeper为这个节点所分配的ID。 cTime：创建时间。 mZxid：修改后的ID。 pZxid：子节点的ID。 cversion：子节点的version。 dataVersion：当前数据的版本号。 aclVersion：权限。 ephemeralOwner：如果有值则为临时节点。 dataLength：数据长度。 numChildren：下面子节点的数目。 create命令： create [-s] [-e] path data acl -e：创建一个临时节点。 -s：顺序节点。 set命令 set path data [version] 每次set后，dataversion都会改变。 乐观锁：set path data [originalVersion] [version] delete命令 delete path [version] Zookeeper特性session的基本原理客户端与服务端之间的连接存在会话。 每个会话都可以设置一个超时时间。 心跳结束，session则过期。 session过期，则临时节点znode会被抛弃。 心跳机制，客户端向服务端的ping包请求。 watcher机制 针对每个节点的操作，都会有一个监督者-&gt;watcher。 即当节点发生一些变化，都会触发一个watcher，即一个事件。 当监控的某个对象发生了变化，则触发watcher事件。 zk中的watcher是一次性的，触发后立即销毁。 也可以设置为永久性的。 父节点、子节点的增删改都能够触发其watcher。 不同的操作会触发不同的watcher事件。 (子)节点创建(删除\数据变化)事件。 watcher设置 get path [watch]。设置watcher。 stat path [watch]。 ls path [watch]。 ls2 path [watch]。 事件类型 创建父节点触发：NodeCreated。 123watcher::WatchedEvent state:SyncConnected type:NodeCreated path:/path 修改父节点数据触发：NodeDataChanged。 删除父节点触发：NodeDeleted。 创建子节点触发：NodeChildrenChanged。 删除子节点触发：NodeChildrenChanged。 修改子节点不会触发事件。如果要监听子节点的修改事件，必须将其当作父节点。而删除等操作，其与父节点存在联系，对其有影响。 适用性 统一资源配置。 当更新了节点为新的配置信息，则触发watcher去更新其他的客户端配置。 ACLaccess control lists。 针对节点可以设置相关读写等权限，目的是为了保障数据安全性。 权限permissions可以指定不同的权限范围与角色。 概述默认权限 ： 12‘world,&apos;anyone:cdrwa ACL构成 [scheme: id:permissions​]来构成权限列表。 scheme：代表采用的某种权限机制。 world：world下只有一个id，即只有一个用户，也就是anyone。 auth：代表认证登录，需要注册用户有权限就可以，需要明文密码。 digest：需要对密码加密才可以访问。digest:username:BASE64(SHA1(password)):[permissions]，需要密文密码。 id：代表允许访问的用户。 ip：当设置为IP指定的IP地址，此时限制IP进行访问，例如ip:192.168.1.1:[permisssion]。 super：代表超级管理员，拥有所有的权限。 permissions：权限组合字符串，缩写crdwa。 赋值时可以任意组合，例如crw。 CREATA：创建子节点。READ：获得节点/子节点。WRITE：设置节点数据。DELETE：删除子节点。ADMIN：设置权限，即是最高的权限。 命令行 getAcl path：获取某个节点的acl权限信息。 setAcl path acl：设置某个节点的acl权限信息。 addauth：输入认证授权信息，注册时输入密码登录。 适用性 开发/测试环境分离，开发者无权操作测试库的节点，只能看。 生产环境上控制指定IP的服务可以访问相关节点，防止混乱。 四字命令Four Letter Words zk可以通过它自身提供的简写命令来与服务器进行交互。 需要使用nc命令，yum install nc。 echo [command] | nc [ip] [port] stat：查看zk的状态信息，以及是否mode，即是集群模式还是单例模式。 ruok：查看当前zkserver是否启动，返回imok，即已启动。 dump：列出未经处理的会话和临时节点。 conf：查看服务器配置。 cons：展示连接到服务器的客户端信息。 envi：环境变量。 mntr：监控zk健康信息。 node数目、watch数目，临时节点等 wchs：展示watch的信息。 wchc与wchp：session与watch以及path与watch信息。 Zookeeper集群zk集群： 主从节点。 心跳机制（选举模式）。 最少的集群至少有3个节点。当master挂掉后，经过选举模式，zz上位。如果xx节点恢复重连，则也无法回到Master位置上，而是作为一个Slave。 集群搭建注意点： 配置数据文件myid 1/2/3对应server1/2/3。即存在3台服务器。 通过./zkCli.sh -server [ip]:[port]检测是否配置成功。 选举模式Zookeeper Java客户端原生Java API会话的连接与恢复接待你的增删改查watch与ACLApache curator参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：链路层]]></title>
    <url>%2F2019%2F07%2F20%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[概述多路访问链路和协议交换局域网数据中心网络负载均衡Web页面请求历程参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统：多处理机系统]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%A4%9A%E5%A4%84%E7%90%86%E6%9C%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[多处理机系统人们对更强计算力的追求促进着计算机的发展，而所有的一切都需要更多的CPU周期（又称机器周期，CPU周期定义为从内存读取一条指令字的最短时间。一个指令周期常由若干CPU周期构成。 时钟解决方案 过去的解决方案是使时钟走得更快，而现在遇到了对时钟速度的限制，即电子信号的速度不可能超过光速，这个速度在铜线或光纤中约为20cm/ns，意味着10GHZ的时钟信号的传送距离不会超过2cm，对于1THZ的时钟，传送距离不足100um，这在一个时钟周期内正好让信号从一端到另一端并返回。 而让计算机变小是可能的，但是散热却是不可能的。因此从1MHZ到1GHZ需要更好的芯片工艺，而1GHZ到1THZ需要完全不同的方法 并行计算机 大规模使用并行计算机，每个CPU都以正常的速度运行，但是整体上会有比单个CPU强大的多的计算能力。高强度的数据处理中经常采用高度并行计算机。 互联网的发展使得将全世界的计算机连接起来变得方便快捷也促使了并行计算机的使用。 对上图的三个模型进行简单介绍： 在电子（光学）部件间的所有通信，归根结底是在它们之间发送消息–良好定义的协议，其差别在于所涉及的时间范围、距离范围和逻辑组织。以共享存储器多处理机为例，系统中有2到1000个CPU通过一个共享存储器通信，每个CPU可同样访问存储器，使用LOAD和Stroe读写单个的字，访问一个存储器字需要1-10ns。 模型较为简略，但是实现并不简单，通常涉及底层大量的消息传递 许多CPU-存储器通过某种高速互联网连接在一起，称为消息传递多计算机，每个存储器局部对应一个CPU，且只能被该CPU访问，CPU通过互联发送多字消息通信，存在良好连接时，一条短消息可以在10-50us发出。 其比前一个模型容易构建，但是编程困难，是紧密耦合系统 所有计算机通过一个广域网连接起来，如因特网，构成一个分布式系统，每台计算机有自己的存储器，通过消息传递进行通信 本模型使用了完整的计算机而且消息传递通常需要10-100ms，是一种松散耦合系统 三者的通信延迟有3个数量级的差别 多处理机 共享存储器多处理机：两个或更多的CPU全部共享访问一个公用的RAM，运行在任何一个CPU上的程序都看到一个普通的虚拟地址空间 性质： CPU可以对存储器的某个字写入某个值，然后读回该字，并得到一个不同的值（因为另一个CPU改写了它）。在进行恰当的组织后，这种性质是CPU间通信的基础，一个CPU写入，另一个CPU读取 在进程同步、资源管理以及调度方面也有一些独特的性质。 多处理机硬件所有的多处理机都具有每个CPU可以访问全部存储器的性质，还有一些多处理机拥有其他的性质。 UMA：统一存储器访问，读出每个存储器字的速度是一样快的 NUMA：非一致存储器访问，没有上面的性质 基于总线的UMA多处理机体系结构使用交叉开关的UMA多处理机使用多级交换网络的UMA多处理机NUMA多处理机多核芯片众核芯片异构多核在多核上编程多处理机操作系统类型多处理机同步多处理机调度多计算机多计算机硬件低层通信软件用户层通信软件远程过程调用分布式共享存储器多计算机调度负载均衡分布式系统网络硬件网络服务和协议基于对象的中间件基于协作的中间件参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统：虚拟化与云]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%2F</url>
    <content type="text"><![CDATA[参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统：死锁]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统：I/O]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9AI-O%2F</url>
    <content type="text"><![CDATA[IOIO硬件原理IO设备IO设备可以大致分为两类：块设备与字符设备。 块设备将信息存储在固定大小的块中，每个块有自己的地址，所有传输以一个或多个完整的块位单位。每个块可以独立于其他块而读写。硬盘、USB等都是块设备。 字符设备以字符位单位发送或接收一个字符流，而不考虑任何块结构。字符设备不可寻址，也没有任何寻道操作，例如打印机、网络接口、鼠标等。 其他类别还有 时钟：按照预先规定好的时间间隔产生中断 内存映射的显示器等。 设备控制器IO设备一般分机械部件与电子部件。电子部件称为设备控制器，常以芯片形式出现。 内存映射IO每个控制器有几个寄存器用来与CPU进行通信，通过写入这些寄存器，OS可以命令设备发送数据、接收数据、开启或关闭，或执行某些其他操作。通过读取寄存器，OS可以了解设备的状态，是否准备好接收一个新的命令等。 通常设备还会有一个OS可以读写的数据缓冲区。 CPU与IO通信CPU如何与设备的控制寄存器或缓冲区进行通信？ 方法1：早期的OS工作方式，每个控制寄存器被分配一个IO端口号，是一个8/16位的整数。所有IO端口形成IO端口空间，并只有OS可以进行访问。 使用一条特殊的IO指令例如IN REG ，PORT。CPU可以读取控制寄存器PORT的内容，并将结果存到CPU寄存器REG当中。 方法2：内存映射IO。将所有控制寄存器映射到内存空间中，每个控制寄存器被分配唯一的一个内存地址，并且不会有内存被分配这一地址， 混合方法。 当CPU想要读入一个字的时候，无论是从IO端口还是内存读入，都要将需要的地址放到总线的地址线上，然后在总线的一条控制线上置起一个READ信号。如果是内存空间，内存将响应请求，内存当中的每个内存模块和IO设备都会将地址线与它所服务的地址范围比较，比较成功则响应请求。 中断在硬件层面上，中断的工作是当一个IO设备完成交给它的工作时，它就产生一个中断，它是通过在分配给它的一条总线信号线上置起信号而产生中断的。 处理中断设备与中断控制器之间的连接实际上使用的是总线上的中断线。如果有更高优先级或有其他中断正在处理，则暂时不会理会中断。 为了处理中断，中断控制器在地址线上放置一个数字表明哪个设备需要关注，并置起一个中断CPU的信号。中断信号导致CPU停止当前正在做的工作并且开始做其他的事情，地址线上的数字被用作指向一个被称为中断向量的表格索引，以便读取一个新的程序计数器。 中断服务过程开始运行后，立刻通过将一个确定的值写入中断控制器的某个IO端口来对中断作出应答。 精确中断和不精确中断由于现代OS的乱序执行以及CPU优化操作，当发生中断时，可能之前的指令还没有执行完，并且由于并行处理，则在处理中断时，很多指令还处于不同的执行阶段，即很难明确当前程序计数器到底执行到了哪里。 将机器留在一个明确状态的中断称为精确中断，其具有4个特性： PC(程序计数器)保存在一个已知的地方 PC所指向的指令之前的所有指令已经完全执行 PC所指向的指令之后的所有指令都没有执行。并非禁止执行，只是中断发生前必须撤销它们对寄存器或内存的修改。 PC所指向的指令的执行状态是已知的。 不满足这些要求的称为不精确中断。 IO软件层次IO软件通常组织成四个层次，每一层具有一个要执行的定义明确的功能和一个定义明确的与临近层次的接口。 中断处理程序当中断发生时，中断处理程序 215 设备驱动程序与设备无关的操作系统软件用户级IO软件时钟时钟负责维护时间，并且防止一个进程垄断CPU，此外还有其他功能。 时钟硬件通常使用两种类型的时钟，简单的时钟连接到电源线上，每个电压周期产生一个中断，现在非常少。 另一种时钟由三个部件组成：晶体振荡器、计数器和存储寄存器。它用来给计算机的各种电路提供同步信号，该信号被送到计数器，使其递减计数至0，当计数器变为0产生一个CPU中断。 可编程时钟通常具有几种操作模式， 一次完成模式：当时钟启动时，它把存储寄存器的值赋值到计数器中，然后来自晶体的每一个脉冲使计数器-1，当计数器位0产生一个中断，并停止工作，直到软件再一次显式启动它 方波模式。当计数器变为0并且产生中断后，存储寄存器的值自动复制到计数器中，并且整个过程无限期继续下去。 时钟软件软定时器参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统：进程与线程]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程操作系统最核心的概念是进程，是对正在运行程序的一个抽象。 现代计算机经常会在同一时间做许多事情。例如当系统启动时，会秘密启动很多线程，例如启动一个进程用来等待邮件、启动一个防病毒进程周期性检查等。这些进程的活动都需要管理，因此一个支持多进程的多道程序系统在这里十分必要。 在多道程序设计系统中，CPU由一个进程快速切换至另一个进程，使各个进程各运行几十或几百毫秒。即在某一个瞬间CPU只能运行一个进程，但在1S内可以运行多个进程，因此产生了并行的错觉，即伪并行。而多处理器系统有多个CPU共享一个物理内存的真正硬件并行，而由于人们难以对多个并行活动进行跟踪，因此设计了描述并行的概念模型（顺序进程）使得并行容易处理 进程模型进程模型中，计算机上所有可运行的软件，被组织成若干顺序进程（进程）,一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。 一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。 而若是一个程序运行了两遍，他们依然是两个进程，OS使得他们共享代码，只是一个副本放在内存当中，但其他的并不一样。 在本部分只考虑一个CPU的模型，即每个时间点只能运行一个进程。 多道程序系统设计 考虑多道程序系统设计，4个程序被抽象为4个各自拥有自己控制流程（每个程序自己的逻辑程序计数器）的进程，并且每个程序都独立运行。 而实际上只有一个物理程序计数器，当每个程序运行时，逻辑程序计数器被装入实际的程序计数器中，当该程序执行结束，物理程序寄存器被保存在内存中该进程的逻辑程序计数器中。从时间上可见，所有进程都运行了，但每个时间点只有一个进程运行。 进程执行时序上的无序性 由于CPU在各个进程间来回快速的切换，因此每个进程执行其运算的速度并不确定，当同一进程再次运行时，其运算速度通常也不可再现，即对进程编程时不能对时序做任何想当然的假想。 考虑一个IO进程，用流式磁带机恢复备份的文件，它执行一个10000次的空循环以等待磁带机到达正常速度，但是CPU决定在空循环时切换到其他进程，则IO进程可能在第一条记录通过磁头后还未运行 因此当一个进程具有此类严格的时序要求时，必须采取特殊的措施以保证他们在这段时间一定发生。 进程的创建四种主要事件会导致进程的创建 系统初始化 正在运行的程序执行了创建进程的系统调用 用户请求创建一个新进程 一个批处理作业的初始化 系统初始化 启动OS通常会创建若干进程。有前台进程，即同用户交互的进程。其余是后台进程，与特定用户无关但有专门的功能，如一个接收电子邮件的后台进程，大多数时间在睡眠但在电子邮件到达时被唤醒。停留在后台诸如电子邮件等进程称为守护进程 正在运行的程序执行了创建进程的系统调用 一个正在运行的进程经常发出系统调用以便创建一个或多个新进程协助其工作。例如如果有大量的数据要通过网络调取并进行顺序处理，那么创建一个进程取数据并把数据放入公共缓冲区中，让第二个进程取走并处理速度会更快一些 一个批处理作业的初始化 用户提交批处理作业，OS认为有资源可以运行另一个作业时，创建一个新的进程，并运行其输入队列中的下一个作业。 OS进行进程创建从技术上看，新进程都是由一个已经存在的进程执行了一个用户创建进程的系统调用而实现的。这个进程的工作是执行一个用来创建进程的系统调用，这个系统调用通知OS创建一个新进程，并且直接或间接指定在该进程中运行的程序。 进程创建后，父进程与子进程拥有各自不同的地址空间，若其中某个进程在其地址空间修改了一个字，则这个修改对其他进程是不可见的。某些UNIX的实现使得程序正文在两者间共享，但是它不可修改。或者子进程共享父进程的内存，但这种情况下内存通过写时复制共享，一旦想修改内存，这块内存首先被明确地复制，确保修改在自己的地址空间中。即可写的内存不可共享 进程是有可能共享打开的文件等资源的。 进程的终止进程的终止通常是由以下条件 正常退出（自愿）、出错退出（自愿） 严重错误（非自愿）、被其他进程杀死（非自愿） 进程的层次结构某些系统当中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联，子进程自身可以创建更多的进程，组成一个进程的层次结构。 UNIX当中，进程和它所有子进程共同组成一个进程组，当用户从键盘发出一个信号，该信号被送给当前与键盘相关的进程组中的所有成员，每个进程可以分别捕获该信号，忽略该信号或采取默认的动作等。 进程的状态案例尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是进程间经常需要相互作用，一个进程的输出结果可能作为另一个进程的输入 1cat c1 c2 c3 |grep tree 第一个进程运行cat，将三个文件连接并输出，第二个进程运行grep，从输入中选择包含tree的行，根据两个进程的相对速度（两个程序的相对复杂度和各自分配到的CPU时间）可能发生这种情况，grep已经准备就绪，但输入未完成，则必须阻塞grep直到输入到来。 状态模型 当一个进程在逻辑上不能继续运行就会被阻塞，例如正在等待可以使用的输入。进程挂起是由于程序自身的固有原因 概念上能够运行的进程被迫停止，因为OS调度另一个进程占用了CPU。程序挂起是由于系统技术上的原因，没有足够的CPU 进程的状态 运行态：该时刻进程实际占用CPU 就绪态：可运行，但因为其他进程正在运行而暂停 阻塞：除非某种外部事件发生，否则进程不能运行 等待中断等 OS的最底层是调度程序，在它上面有许多进程，所有关于中断处理、启动进程和停止进程的细节都被隐藏在调度程序中。不过很少有真实的系统是以这样的理想方式构造的。 进程的实现为了实现进程模型，OS维护一张表格，即进程表，每个进程占用一个进程表项（进程控制块），表内包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、打开的文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。 单个CPU实现伪并行与每一个IO类关联的是一个称作中断向量的位置（靠近内存底部的固定区域），包含中断服务程序的入口地址，假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字、寄存器压入堆栈，随后计算机跳转到中断向量所指示的地址。这些是硬件的操作，随后是软件，特别是中断服务例程就接管剩余工作。 中断发生后OS最底层的工作步骤 多道程序设计模型CPU利用率（吞吐量）多道程序设计可以提高CPU的利用率，如果进程用于计算的平均时间是进程在内存中停留时间的20%，并且内存中同时有5个进程， 则CPU会一直满负载运行。但是这个模型过于乐观，并且假设了进程不会同时等待IO 更好的模型是从概率角度看CPU利用率，假设一个进程等待IO操作的时间与停留在内存的时间比为p，在内存中同时有n个进程，则n个进程都在等待IO的概率为p^n，则有$$CPU利用率=1-p^n$$则有 该模型只是描述了一个大致的状况，假设所有n个进程是独立的，即5个进程中，3个运行两个等待是完全可以接受的，但在单CPU中，不能同时运行3个进程，因此当CPU忙时，已就绪的进程也必须等待CPU，因而进程并不独立。 更精确的模型则应该以排队论构建，然而原有模型依然很有效。 计算模式：当计算机有8G内存，OS占用2GB，用户程序占用2GB，则内存空间允许3个程序同时驻留在内存中，若80%时间用于IO等待，则CPU利用率约为1-0.8^3，即大约49%；若增加8GB的内存，则可以允许7道程序设计，CPU利用率提高到1-0.8^7，即79%，扩大8GB内存提高了30%的吞吐量 线程经常存在在同一个地址空间中准并行运行多个控制线程的情形，这些线程就像分离的进程（共享地址空间除外） 线程的使用使用线程的原因： 在许多应用当中同时发生着多种活动，其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成准并行运行的多个顺序线程，程序设计模型将会变得很简单。 多进程可以共享同一个地址空间与所有可用数据的能力，对某些应用是必须的。 线程比起进程更加轻量级，因此比进程更容易创建、撤销，在许多OS当中，创建一个线程比创建一个进程快10-100倍 从性能方面考量，若多个CPU都是CPU密集型的，那么并不能获得性能上的增强，但如果存在大量的计算与大量的IO，多个线程允许这些活动重叠进行，加快应用程序的执行速度 在多CPU系统中，线程使得实现了真正的并行 多线程应用举例 以WEB服务器为例，对页面的请求发给服务器，而所请求的页面发回给客户机。而组织Web服务器的方式如下所示 一个分派线程负责从网络中读入工作请求，检查请求后挑选一个空转的工作线程，提交该请求。通常是在 每个线程所分配有的某个专门字中写入一个消息指针，接着分派线程唤醒睡眠的工作线程，从阻塞转为就绪 若没有多线程，则只能是线程进行循环等待请求，若是在请求到来的时候，工作线程正在任务中，则无法处理新的请求 多线程解决方案 多线程使得顺序进程的思想保留了下来。有关的进程可以用一个输入线程、处理线程、输出线程构造，输入线程将数据读入到输入缓冲区，处理线程从输入缓冲区读取数据，并把结果放到输出缓冲区，输出线程将结果写入到磁盘中，这种模式下，三个线程可以同时进行。 经典线程模型进程模型 进程模型基于两种独立的概念：资源分组处理和执行。有时将这两种概念分开会更好，即引入了线程这一概念。 理解进程的一个角度是：用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等 另一个角度是：进程拥有一个执行的线程，在线程中有一个程序计数器，用来记录接着要执行哪一条指令，线程拥有寄存器，用来保存线程当前的工作变量，拥有堆栈用来记录执行历史。 进程用于将资源集中到一起，而进程则是在CPU上被调度执行的实体 线程模型 线程的出现在进程模型的基础上增加了一项内容，即在同一个进程的基础上允许彼此之间有较大独立性的多个线程执行。 当多线程进程在单CPU系统上运行时，线程轮流运行，CPU在线程间快速切换，系统制造了线程并行运行的假象，好似它们在一个比实际CPU慢一些的CPU上同时运行。 进程中的不同线程不像不同进程间那样存在很大的独立性，所有线程都有完全一样的地址空间，意味着他们也共享相同的全局变量,因此一个线程可以读、写甚至清除另一个线程的堆栈。即线程之间是没有保护的。 线程拥有它自己的堆栈，供各个被调用了但是还要从中返回的过程使用，该栈帧中存放着相应过程的局部变量以及过程调用完之后使用的返回地址。该栈帧是每个线程执行过程的过程历史，由于每个线程通常会调用不同的过程，从而有不同的执行历史，因此他们需要有自己的堆栈。 线程状态与传统进程一样，线程可以处于若干种状态中的一个：运行、就绪或终止。并且其状态转换与进程也是一致的 线程调用 通常线程有能力去创建另一个线程，即thread_cretate 线程可以调用一个库函数thread_exit退出 线程可以等待一个特定的线程退出，thread_join，在某些线程系统中，它会使得线程阻塞调用线程直到那个特定线程退出 允许线程放弃CPU，thread_yield从而让另一个线程运行 线程实现线程的实现有3种方式，包括内核态、用户态、混合实现 在用户空间实现线程当在用户态实现线程，则内核对线程一无所知，内核来看的时候，就是一个单线程进程。具体实现是将整个的线程包放在用户态中 线程可以在不支持多线程的OS上实现， 在内核态实现线程混合实现调度程序激活机制内核态的线程在一些关键优点上优于用户级线程，但是速度略慢，因此设计了调度程序激活工作，其目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。 弹出式线程分布式系统经常使用线程，一个例子是如何处理到来的消息，例如服务请求。传统的方式是将进程或线程阻塞在一个receive系统调用上，等待消息到来，当消息到达时，系统调用接收消息，并打开消息检查内容然后处理。 另一种方式是一个消息的到来导致系统创建一个处理该消息的线程，该线程称为弹出式线程，其好处是线程相当新，即没有必须存储的寄存器、堆栈等，每一个线程彼此间完全一样，因此有可能快速创建线程，使用该方式使得消息到达与处理开始间的时间非常短。 在内核中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间的弹出式线程可以很容易地访问所有的IO设备等，在处理中断时比较有用 出错的内核线程会比出错的用户线程导致更大的损害。 使单线程代码多线程化将原有的单线程代码改写为多线程需要比直接写多线程程序更高的技巧 代码角度。单线程的代码如同进程一样，通常包含多个进程、局部变量、全局变量和过程函数 其中的局部变量和参数不会引起问题。 全局变量：对线程而言是全局变量，并不是对整个程序也是全局的，许多变量之所以是全局的，是因为线程中的许多过程都用到它，但是其他线程在逻辑上和这些变量无关 案例：考虑一个对象当中的errno变量，当进程进行系统调用失败时，错误码会放入errno中，线程1执行系统调用确定是否允许访问某个文件，OS将返回值放入errno，而此时线程1使用完CPU时间，切换到线程2，线程2执行一个系统调用并写入errno，因此之前的errno值丢失，随后线程1由于errno值不正常会执行错误的操作 解决方案：全面禁止全局变量。或为每个线程赋予私有的全局变量。 进程间通信进程经常需要与其他进程通信，如在一个shell管道中，第一个进程的输出必须传送给第二个进程，沿着管道传递下去。因此进程间需要通信。进程通信IPC需要解决三个问题 一个进程如何把信息传递给另一个 确保两个或更多的进程在关键活动中不会出现交叉 与正确的顺序相关，若进程A产生数据，而进程B消费数据，则进程B需要等待进程A 而这些问题对于线程同样适用。 竞争条件在OS当中，协作的进程可能共享一些彼此都能读取的公用存储区。例如脱机打印程序，一个进程需要打印一个文件时，将文件名放在一个脱机目录中，另一个进程周期性检查是否有文件需要打印，若有则将该文件从目录下删除。 具体案例 则假设打印机目录有多个槽位，其编号为0，1，2…等，每个槽位存放一个文件名，假设有两个共享变量：out指向下一个要打印的文件、in指向目录中下一个空闲槽位。 则在该情境下，考虑进程A1与进程A2都要将一个文件排队打印，则可能会出现以下情况，进程A1读取得到in=7，并将其存到临时变量index当中，而此时发生时钟中断，CPU切换到进程A2，A2读取in得到in=7，同样存到局部变量index=7，而这两个index分属于不同的进程。此刻两个进程都认为下一个可用位为7. 进程A2将文件存到槽位7当中，并更新in=8，离开，当CPU切换回A1时，则检查自己的局部变量index=7，与是将新的文件存到槽位7，并刷新in=8。在该情况下，丢失了一个需要打印的文件，然而打印机进程发现不了任何问题。 竞争条件：两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序。 竞争条件导致大多数的测试运行结果都很好，但是在极少数的情况下会出现一些无法解释的现象，而多核增长带来的并行使得竞争条件越来越普遍 互斥如何避免竞争条件？凡是涉及到共享内存、共享文件以及共享任何资源的情况都会引发类似错误。 解决竞争条件，即需要找出某种途径阻止多个进程同时读写共享的数据，即需要做到互斥，以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。 临界区以抽象的角度进行描述即：一个进程的一部分时间可能会访问共享内存或文件，我们将对共享内存进行访问的程序片段称为临界区，若能适当地安排，使得两个进程不可能同时位于临时区内，就能避免竞争条件。 解决竞争条件 对于一个好的解决方案，需要满足以下4个条件 任何两个进程不能同时处于临界区 不应对CPU的速度和数量做任何假设 临界区外运行的进程不得阻塞其他进程 不得使进程无限期等待进入临界区 考虑多种实现互斥的方案，当一个进程在临界区中，这些方案都可以使得进程将不会进入临界区 忙等待的互斥忙等待的互斥本质上是当一个进程想进入临界区时，先检测是否允许进入，若不允许则该进程原地等待直到允许为止。 并且倘若进程A优先级高于进程B，若调度规则规定进程A就绪就可运行。则假设当进程B处于临界区时，进程A准备就绪，因此进程B不会被调度，则进程A将永远忙等待下去 屏蔽中断屏蔽中断：屏蔽包括时间中断等中断，CPU只有在发生时钟中断或其他中断时才会进行进程切换 在单处理器系统中，最简单的方法是让每个进程在钢管进入临界区后立即屏蔽所有中断，并在就要离开前再打开中断。这样CPU就不会切换到其他进程，此时进程就不担心其他进程的进入 缺陷 将屏蔽中断的权力交给用户并不明智，若一个进程屏蔽中断后并不打开，则整个系统可能会终止。 如果系统是多处理器，则屏蔽中断仅仅对当前CPU有效，其他CPU依然可以访问共享内存 对内核而言，当它在更新变量或列表的几条指令期间屏蔽中断是有效地，当就绪进程队列等数据状态不一致时发生中断，则导致竞争条件 锁变量寻找软件解决方案，设想有一个共享锁变量，初始值为0，当一个进程想进入临界区，则首先测试这把锁，如果锁的值为0，则设置其值为1并进入临界区。如果锁的值已经为1，则等待其值变为0 但是该方案依然会导致竞争条件，即在读取值为0，并且恰好在它将值设置为1前，另一个进程被调度，则会导致两个进程进入临界区 严格轮换法设置一个整形变量，用于记录轮到哪个进程进入临界区，并检查或更新共享内存，连续测试一个变量值直到某个值出现为止，称为忙等待。 123456while(true)&#123; while(turn!=0); critical_region(); turn=1; noncritical_region();&#125; 这种方式浪费CPU时间，通常应当避免，只有在有理由认为等待时间是非常短的情形下才使用忙等待。用于忙等待的锁称为自旋锁。当进程0试图进入临界区时，可能当前OS将turn=1，而此时进程1并没有占用临界区，是对资源的浪费。 而这种方法违反了之前的条件3，即进程被一个临界区外的进程阻挡。 Peterson解法将锁变量与警告变量的思想结合，提出不需要严格轮换的软件互斥算法 起始时，没有任何进程在临界区中，进程0调用enter_region，设置数组元素与turn=0标识希望进入临界区 若进程1现在调用enter_region，进程1将在此处挂起直到interest=false。即进程0退出 当两个进程同时调用enter_region，则由于前一个写入turn被刷新，则只有后一个才可以进入临界区 TSL指令由硬件支持的解决方案，TSL指令即test and set lock 将一个内存字读取到寄存器中，然后在该内存地址上存一个非零值，读与写操作保证是不可分割的，即该指令结束前其他处理器均不允许访问该内存字，执行TSL的CPU将锁住内存总线，以禁止其他CPU在本指令结束前访问内存 XCHG指令：是可替代TSL的指令，原子性地交换两个位置的内容。 睡眠和唤醒考虑几条进程间的通信原语： sleep：将引起调用进程阻塞的系统调用，即将挂起，直到另外一个进程将其唤醒 wakeup调用有一个参数，即要被唤醒的进程。 生产者-消费者问题 考虑存在一个生产者与消费者的情形 当缓冲区已满，且生产者还想向其中放入一个新的数据项的情况，即让生产者睡眠，直到消费者从缓冲区取出一个或多个数据项再唤醒生产者。 12345678910111213141516#define N 100int count = 0;void producer(void)&#123; int item; while(true)&#123; item = produce_item(); if(count == N)&#123; sleep(); &#125; insert_item(); count = count + 1 ; if(count == 1)&#123; wakeup(consumer); &#125; &#125;&#125; 则在该方法中其实会存在竞争条件，生产者与消费者都要去检查count的值，并且对count访问没有限制。 若缓冲区为空，消费者刚刚读取count==0，此时调度程序决定暂停消费者运行生产者。 生产者向缓冲区加入一个数据项，count=1，推断刚刚count==0，因此消费者一定在睡眠，于是发出wakeup 调度程序切换到消费者，消费者检查之前读到的值为0，即判定睡眠。 因此在整个过程中，wakeup信号丢失，于是最后生产者会填满缓冲区，导致两个进程永远睡眠 弥补手段：增加修改规则，加上一个唤醒等待位，当一个wakeup发送给一个清醒的进程时，将该位置置为1，当进程要睡眠时，如果该唤醒等待位为1，则清除该位，保持清醒。 但是如果进程更多的时候，该方法无法根本上解决问题。 信号量使用一个整形变量来累计唤醒次数。一个信号量取值可以为0（没有保存下来的唤醒操作）或者为正值（有一个或多个唤醒操作），信号量的操作有： down与up均为不可分割的原子操作，即检查数值、修改变量值、可能发生的睡眠操作都是不可分割的。保证一旦一个信号量操作开始，则在该操作完成或阻塞前其他进程均不允许访问该信号量。 其实现是在几条指令间屏蔽中断 当有多个CPU时，每个信号量应有一个锁变量保护，通过TSL或XCHG确保同一时刻只有1个CPU可以操作 down：检查其值是否大于0，若大于0则减1，即用掉一个保存的唤醒信号并继续。若值为0，则进程将睡眠。 12345678910111213141516#define N 100 //缓冲区的槽位typedef int semaphore; //定义信号量数据类型semaphone mutex = 1; //控制对临界区的访问semaphone empty = N; //缓冲区的空槽数目semaphone full = 0; //缓冲区的满槽数目void producer(void)&#123; // int item; // while(true)&#123; // item = produce_item(); //产生数据 down(&amp;empty); //将空槽数目减一 down(&amp;mutex); //进入临界区 insert_item(item); //将新增数据放到缓冲区 up(&amp;mutex); //离开临界区 up(&amp;full); //将满槽数目+！ &#125;&#125; 信号量可以用于实现同步，保证某种事件顺序发生或不发生。 缺陷 对信号量操作的次序要非常谨慎 若两个down的操作交换顺序，则让mutex的值先-1，若缓冲区完全满了，则生产者将阻塞。当消费者访问缓冲区，则由于mutex值为0，消费者阻塞，因此产生死锁。 互斥量若是不需要信号量的计数能力，则可以使用其简化版本：互斥量。互斥量仅仅适用于管理共享资源或一小段代码。 互斥量是一个处于两态之一的变量：解锁与加锁。当互斥量已经加锁，则调用线程阻塞，直到在临界区中的线程完成解锁，若多个线程被阻塞在该互斥量上，将随机选择一个线程允许其获得锁。 具体实现 管程为了编写正确的程序，提出了一种高级同步原语，即管程。一个管程是一个由过程、变量、数据结构等组成的一个集合，他们组成一个特殊的模块或软件包。进程可以在任何需要的时候调用管程中的过程，但他们不能在管程之外声明的过程中直接访问管程内的数据结构。 任一时刻管程内只有一个活跃进程，使得管程有效地互斥。当一个进程调用管程过程时，该过程的前几条指令将检查管程中是否有其他活跃进程，若有则进程挂起，直到另一个进程离开管程时将其唤醒。 消息传递消息传递的方法使用两条原语：send与receive，它们像信号量，是系统调用而不是语言成分。send向一个给定目标发送一条消息，后一个调用从一个给定的源接收一条消息，若没有消息可用，则接收者可能堵塞直到一条消息到达。 消息传递系统设计的要点 对于消息传递，特别是位于网络中不同机器上的通信进程的情况，消息可能被网络丢失，为防止消息丢失：接收方与发送方需要达成一致：一旦接收到消息，接收方马上回送一条特殊的确认，如果发送方在一段时间间隔内未收到确认，则重发消息 但是若消息被正确接收，而返回的确认消息丢失，则会导致接收方收到两条同样的消息。因此区分新的消息与重发的消息很重要，一般解决方案是嵌入一个连续的序号来解决问题。 消息系统还需要解决进程命名问题，即send指向的进程必须没有二义性，身份认证也是需要的，即客户确认是与真正的服务器通信而不是冒充者 用消息传递解决生产者-消费者问题 屏障屏障是用于进程组而不是双进程的生产者-消费者情形，有些应用划分了若干阶段，并规定除非所有的进程都就绪着手下一个阶段，否则任何进程都不能进入下一个阶段。 通过在每个阶段的结尾安置屏障来实现该行为，当进程到达屏障时，就会被屏障阻拦直到所有进程都到达屏障为止。 避免锁 读-复制-更新调度调度简介批处理系统中的调度交互式系统的调度实时系统中的调度策略和机制线程调度经典IPC问题哲学家就餐问题读者-写者问题参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统]]></title>
    <url>%2F2019%2F07%2F17%2FOS%2F%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式：享元模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：桥接模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Bridge提出问题 当一个抽象可能有多个实现时，通常使用继承进行协调。抽象类定义对该接口的抽象，而具体的子类用不同的方式加以实现。 但是此方法不够灵活，继承机制将抽象部分与实现部分固定在一起， 为什么要用（作用） 将抽象部分与它的实现部分分离，使他们都可以独立变化 应用适用性 不希望在抽象和它的实现部分间有一个固定的绑定关系。可能是因为在程序运行时刻实现部分应可以被选择或切换 类的抽象以及它的实现都应该可以通过生成子类的方法进行扩充。这时Bridge模式使你可以对不同的抽象接口和实现部分进行组合，并分别对他们进行扩充 对一个抽象的实现部分的修改应该对客户不产生影响，即客户的代码不必重新编译 你想在多个对象间共享实现（可能使用引用计数），但同时要求客户不知道这一点 案例是什么结构协作参与者协作效果需要权衡优缺实现步骤示例1相关模式框架中的设计模式总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：中介者模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：备忘录模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：访问者模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：责任链模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：原型模式]]></title>
    <url>%2F2019%2F07%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven：插件]]></title>
    <url>%2F2019%2F07%2F14%2F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2FMaven%2FMaven%EF%BC%9A%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[插件build 插件，如package、install、deploy 包括compile test package等都是插件 versions-maven-plugin插件：version管理 Maven 是一个执行插件的框架，每一个任务实际上是由插件完成的。Maven 插件通常用于： 创建 jar 文件 创建 war 文件 编译代码文件 进行代码单元测试 创建项目文档 创建项目报告 一个插件通常提供了一组目标，可使用以下语法来执行： 1mvn [plugin-name]:[goal-name] 例如，一个 Java 项目可以使用 Maven 编译器插件来编译目标，通过运行以下命令编译 1mvn compiler:compile 插件类型Maven 提供以下两种类型插件： 类型 描述 构建插件 在生成过程中执行，并在 pom.xml 中的 元素进行配置 报告插件 在网站生成期间执行，在 pom.xml 中的 元素进行配置 以下是一些常见的插件列表： 插件 描述 clean 编译后的清理目标，删除目标目录 compiler 编译 Java 源文件 surefile 运行JUnit单元测试，创建测试报告 jar 从当前项目构建 JAR 文件 war 从当前项目构建 WAR 文件 javadoc 产生用于该项目的 Javadoc antrun 从构建所述的任何阶段运行一组 Ant 任务 例子我们使用 maven-antrun-plugin 插件在例子中来在控制台打印数据。现在在 C:\MVN\project 文件夹 创建一个 pom.xml 文件，内容如下： 1234567891011121314151617181920212223242526272829303132&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.companyname.projectgroup&lt;/groupId&gt;&lt;artifactId&gt;project&lt;/artifactId&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;build&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;id.clean&lt;/id&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;tasks&gt; &lt;echo&gt;clean phase&lt;/echo&gt; &lt;/tasks&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt; 接下来，打开命令控制台，并转到包含 pom.xml 的文件夹并执行以下命令 mvn 命令。 1C:\MVN\project&gt;mvn clean Maven 将开始处理并显示清洁周期/阶段，如下图中输出： 1234567891011121314151617[INFO] Scanning for projects...[INFO] ------------------------------------------------------------------[INFO] Building Unnamed - com.companyname.projectgroup:project:jar:1.0[INFO] task-segment: [post-clean][INFO] ------------------------------------------------------------------[INFO] [clean:clean &#123;execution: default-clean&#125;][INFO] [antrun:run &#123;execution: id.clean&#125;][INFO] Executing tasks [echo] clean phase[INFO] Executed tasks[INFO] ------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ------------------------------------------------------------------[INFO] Total time: &lt; 1 second[INFO] Finished at: Sat Jul 07 13:38:59 IST 2012[INFO] Final Memory: 4M/44M[INFO] ------------------------------------------------------------------ 上面的例子说明了以下关键概念： 插件可在 pom.xml 使用的 plugin 元素来指定； 每个插件可以有多个目标； 从插件应使用它的相位元素开始处理定义阶段。这里已经使用 clean 阶段； 可以通过将它们绑定到插件的目标来执行配置任务。这里已经绑定 echo 任务到 maven-antrun-plugin 的运行目标； 就这样，Maven将处理其余部分。如果没有可用的本地存储库，它会下载这个插件； 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式：外观模式]]></title>
    <url>%2F2019%2F07%2F13%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[外观模式提出问题将一组类转换，提供一个简易接口 为什么要用（作用）应用场景当面对一个场景：需要挑选一个DVD，则需要进行 打开爆米花机、开始爆米花、调暗灯光、放下屏幕、打开投影机、输入切换道DVD、打开功放、功放切换道DVD、设置立体声、设置音量、打开DVD、播放DVD 倘若关闭，还需要反向操作。非常复杂 基础概述是什么外观模式是一个改变接口的新模式，改变接口的原因是为了简化接口。 外观模式将一个或多个类复杂的一切隐藏在背后，只露出一个干净美好的外观。 定义：外观模式提供了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。 分类，各个分类是什么基础优缺 外观模式允许将客户实现从任何子系统中解耦。 当想要升级自己的家庭影院，只需要修改外观代码即可。不需要去更改底部爆米花机的实现等 实现实现步骤示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class HomeTheaterFacade &#123; //看DVD所需要的全部组件 Amplifier amp; Tuner tuner; DvdPlayer dvd; CdPlayer cd; Projector projector; TheaterLights lights; Screen screen; PopcornPopper popper; public HomeTheaterFacade(Amplifier amp, Tuner tuner, DvdPlayer dvd, CdPlayer cd, Projector projector, Screen screen, TheaterLights lights, PopcornPopper popper) &#123; this.amp = amp; this.tuner = tuner; this.dvd = dvd; this.cd = cd; this.projector = projector; this.screen = screen; this.lights = lights; this.popper = popper; &#125; //将操作全部封装到外观当中 public void watchMovie(String movie) &#123; System.out.println("Get ready to watch a movie..."); popper.on(); popper.pop(); lights.dim(10); screen.down(); projector.on(); projector.wideScreenMode(); amp.on(); amp.setDvd(dvd); amp.setSurroundSound(); amp.setVolume(5); dvd.on(); dvd.play(movie); &#125; public void endMovie() &#123; System.out.println("Shutting movie theater down..."); popper.off(); lights.on(); screen.up(); projector.off(); amp.off(); dvd.stop(); dvd.eject(); dvd.off(); &#125; public void listenToCd(String cdTitle) &#123; System.out.println("Get ready for an audiopile experence..."); lights.on(); amp.on(); amp.setVolume(5); amp.setCd(cd); amp.setStereoSound(); cd.on(); cd.play(cdTitle); &#125; public void endCd() &#123; System.out.println("Shutting down CD..."); amp.off(); amp.setCd(cd); cd.eject(); cd.off(); &#125; public void listenToRadio(double frequency) &#123; System.out.println("Tuning in the airwaves..."); tuner.on(); tuner.setFrequency(frequency); amp.on(); amp.setVolume(5); amp.setTuner(tuner); &#125; public void endRadio() &#123; System.out.println("Shutting down the tuner..."); tuner.off(); amp.off(); &#125;&#125; 底层原理与其他的区别UML类图 设计思想进阶反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：概述]]></title>
    <url>%2F2019%2F07%2F10%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是设计模式每一个模式描述了一个在周围不断重复发生的问题，以及该文件的解决方案的核心。这样呢就能一次又一次地使用该方案而不必做重复劳动。设计模式是对被用来在特定场景下解决一般设计问题的类和互相通信的对象的描述。 模式的四个要素： 模式的名称。 问题。描述应该在何时使用模式。解释了设计问题和问题存在的前因后果，可能描述了特定的设计问题，包含使用模式必须满足的一系列先决条件。 解决方案。描述了设计的组成部分，它们间的相互关系以及格子的职责和协作方式。 效果。描述了模式应用的效果以及使用模式应该权衡的问题。包括对时间、空间的衡量，对系统灵活性、扩展性、可移植性的影响。 描述设计模式 模式名和分类 意图。设计模式是做什么的；它的基本原理和意图是什么；它解决的是什么样的特定设计问题 别名 动机。说明一个设计问题以及如何用模式中的类、对象来解决该问题的特定情境。帮助理解随后对模式更抽象的描述 适用性。 什么情况下可以使用该设计模式 适用案例 该模式可以用来改进哪些不良设计 怎样识别这些情况 结构。 参与者。设计模式中的类或对象以及他们各自的职责 协作。模式的参与者怎样协作已实现他们的职责 效果。模式怎样支持它的目标；使用模式的效果和所需要做的权衡取舍；系统结构哪些方面可以独立改； 实现。实现模式时需要知道的一些提示、技术要点以及代码示例 已知应用。实际系统中发现的模式的例子，每个模式至少包括了两个不同领域的实例 相关模式、与这个模式紧密相关的模式有哪些，其间重要的不同之处是什么，这个模式应该与哪些其他模式一起使用 设计模式的编目详见：设计模式：目录 设计模式怎样解决设计问题寻找合适的对象客户请求是使对象执行操作的唯一方法，操作又是对象改变内部数据的唯一方法。对象的内部状态是被封装的，不能被直接访问，它的表示对于对象外部是不可见的。 面向对象设计最困难的部分是将系统分解成对象集合，因为要考虑许多因素：封装、粒度、依赖关系、灵活性、性能、演化、复用等。它们都影响系统的分解，并且这些因素通常还是互相冲突的。 设计方法面向对象设计方法学支持很多设计方法 可以写出一个问题描述，挑出名词、动词进而创建相应的类和操作； 关注系统的协作与职责关系 对现实世界进行建模，再将分析时发现的对象转化至设计中等等 设计的许多对象来源于现实世界的分析模型，但是设计结果所得到的的类通常在现实世界中并不存在。设计模式帮助确定并不明显的抽象和描述这些抽象的对象。 决定对象的粒度对象在大小和数目上变化极大。它们能表示下自硬件，上自整个应用的任何事物，如何决定一个对象应该是什么呢？ Facade描述了怎样用对象表示完整的子系统 Flyweight描述了如何支持大量的最小粒度的对象 visitor和command生成的对象专门负责实现对其他对象或对象组的请求 指定对象接口对象声明的每一个操作指定操作名、作为参数的对象和返回值，构成了操作的型构。对象操作所定义的所有操作型构的集合被称为该对象的接口。 设计模式通过确定接口的主要组成成分以及经接口发送的数据类型，帮助定义接口。设计模式也指定了接口间的关系，如要求一些类具有相似的接口或对一些类的接口做了限制。 运用复用机制继承和组合的比较复用最常用的技巧即继承与组合。 继承允许根据其他类的实现来定义一个类的实现，这种通过生成子类的复用通常被称为白箱（父类的内部细节对子类可见）复用 编译时静态定义，可直接使用。较方便地改变被复用的实现 无法再运行时刻改变从父类继承的实现。父类至少定义了部分子类的具体表示，并且破坏了封装性。他们之间具有强依赖关系。一定程度上限制了灵活性与复用性 新的复杂功能通过组装或组合对象来获得，要求被组合的对象具有良好定义的接口。称为黑箱复用（内部不可见） 运行时刻动态确定。要求对象遵守彼此的接口约定，要求更仔细定义接口。通过接口访问，依赖关系较少。有助于保持每个类被封装 委托委托是一种组合方法，使得组合具有与继承同样的复用能力。委托方式下，有两个对象参与处理一个请求，接受请求的对象将操作委托给它的代理者。 即类似于子类将请求交给它的父类进行处理。在使用继承时，被继承的操作总能够引用接受请求的对象，则接受请求的对象将自己传给被委托者（代理者），使得被委托的操作可以引用接受请求的对象。 缺陷 动态的、高度参数化的软件比静态软件更难于理解。 当委托使得设计比较简单而不是复杂时，才是更好地选择 设计模式： state，一个对象将请求委托给一个描述当前状态的state进行处理 strategy，一个对象将一个特定的请求委托给一个描述请求执行策略的对象，一个对象只有一个状态，但对不同的请求是有很多策略 visitor，对象结构的每个元素上的操作都总是被委托到visitor 关联运行时刻和编译时刻的结构代码结构在编译时刻就被确定下来了，它由继承关系固定的类组成。程序的运行时刻结构是由快速变化的通信对象组成。 聚合意味着一个对象拥有另一个对象或对一个另对象负责，意味着聚合对象和其所有者具有相同的生命周期。关联意味着一个对象仅仅知道另一个对象，关联的对象可能请求彼此的操作，但是不为对方负责，表示较松散的耦合。 设计应支持变化获得最大限度复用的关键在于对新需求和已有需求发生变化时的预见性，要求系统设计能够相应地改进。因此要考虑在系统的生命周期内会发生怎样的变化。 设计模式可以确保系统能以特定方式变化，从而帮助避免重新设计系统，每一个设计模式允许系统结构的某个人方面的变化独立于其他方面 导致系统重新设计的一般原因 显式指定一个类来创建对象。 在创建对象时指定类名将使得你受特定实现的约束而不是特定接口的约束，使得未来变化更复杂，应该间接创建对象 factory、prototype 对特殊操作的依赖 当为请求指定一个特殊的操作时，完成该请求的方式就固定下来了，为了避免将代码写死。你将可以在编译期或运行期很方便改变响应请求的方法 chainof resposibility 、command 对硬件和软件平台的依赖 外部的操作系统接口和API在不同的平台上是不同的，依赖于特定平台的软件将很难移植，因此设计系统时限制其平台相关性就很重要 factory、bridge 对对象表示或实现的依赖 知道对象怎样表示、保存、定位或实现的客户在对象发生变化时可能也需要变化。对客户隐藏这些信息能阻止连锁变化 factory、bridge、memento、proxy 算法依赖 算法在开发和复用时常常被扩展、优化、代替。依赖于某个特定算法的对象在算法发生变化时不得不变化。因此有可能发生变化的算法应该被孤立起来。 Builder、Iterator、Starategy、Template Method、Visitor 紧耦合 紧耦合的类很难独立地被复用，因为他们是相互依赖的。紧耦合产生的系统，要改变或删掉一个类必须理解 和改变其他很多类。这样系统很难维护。实现松耦合很必要 factory、command、facade、mediator、observer、chain of responsibility 通过生成子类来扩展功能 通常很难通过子类来定制对象，每一个新类都有固定的实现开销。定义子类需要对父类有深入的理解。重定义一个操作可能需要重定义其他操作，即使一个简单的扩充也不得不引入许多新的子类 使用组合、委托是继承外的灵活方式。但是过多使用对象组合会使得设计难以理解。可以去定义一个子类，将它的实例和已经存在的实例进行组合来引进定制的功能 bridge、chain of responsibility、composite、decorator、observer、strategy 不能方便地对类进行修改 有时不得不改变一个难以修改的类，对于商业类库（没有源代码），或可能对类的任何修改会要求修改许多已经存在的其他子类。 adapter、Decorator、Visitor 如何选择设计模式考虑设计模式是怎样解决问题的从上一节：设计模式怎样解决设计问题研究 浏览模式的意图部分 目的准则，即模式用来完成什么工作 创建型模式与对象创建有关 结构型模式处理类或对象的组合 行为型模式对类或对象怎么样交互和怎样分配职责进行描述 范围准则，指定模式主要是用于类还是用于对象。 类模式处理类和子类间的关系，通过继承建立，是静态的，编译期确定 对象模式处理对象间关系，是动态的。 创建型类模式将对象的部分创建工作延迟到子类 创建型对象模式将它延迟到另一个对象中 结构型类模式使用继承机制来组合类 结构型对象模式描述了对象的组装方式 行为型类模式使用继承描述算法和控制流 行为型对象模式描述一组对象怎样协作完成单个对象无法完成的任务 研究模式怎样相互关联研究以获得合适的模式或模式组 研究目的相似的模式创建型、行为型、结构型模式 检查重新设计的原因从设计应当支持变化研究引起重新设计的原因，再观察问题是否与它们有关，然后再找出哪些模式可以帮助避免这些会导致重新设计的因素 考虑设计中哪些是可变的 考虑想要什么变化却又不会引起重新设计，即封装变化的概念。 下表是设计模式允许独立变化的方面，改变它们而不会导致需要重新设计。 怎样使用设计模式 大致浏览一遍模式。特别注意其适用性部分和效果部分，确定适合你的问题 研究结构部分、参与者部分和协作部分。确保理解这个模式的类和对象以及它们是怎样关联的 看代码示例部分。看模式代码如何具体实现 选择模式参与者的名字。使他们在应用上下文当中有意义。并且将模式作为后缀是有意义的 定义类。声明他们的接口，建立继承关系，定义代表数据和对象引用的实例变量 定义模式中专用于应用的操作名称。 实现执行模式中的责任和协作的操作。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统：概述]]></title>
    <url>%2F2019%2F07%2F10%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[OS引论操作系统的任务是为用户程序提供一个更好、更简单、更清晰的计算机模型，并管理计算机的所有设备（1到多个处理器、主存、磁盘、打印机、键盘、鼠标、显示器、网络接口以及其他输入输出设备）。 多数计算机拥有两种运行模式：内核态和用户态。软件中最基础的部分为操作系统，运行在内核态，为所有其他软件提供基础的运行环境。 在这个模式中，操作系统具有对所有硬件的完全访问权，可以直行机器能够运行的任何指令。而软件的其余部分运行在用户态，只使用了机器指令的一个子集，特别是与IO操作与影响机器的控制的指令，在用户态当中是禁止的。 但是有时在嵌入式系统(无内核态)或解释系统（JVM，采用解释方式而不是硬件方式区分组件）当中上述区别是模糊的 什么是操作系统操作系统比较难给出准确定义。原因有 为应用程序提供一个资源集的清晰抽象，并管理这些硬件资源，而不仅仅是一堆硬件 取决于从什么角度看待操作系统 作为扩展机器的操作系统把操作系统看作是向应用程序提供基本抽象的概念，是一种自顶向下的观点。 背景 在语言层面上，计算机的体系结构（指令集、存储组织、IO、总线结构）是相当原始的，并且编程很困难，尤其是对IO操作而言。硬盘接口的书籍页数超过450页，并且改动较为频繁。 因此程序员使用硬盘驱动进行交互，提供接口，并且不用深入细节。驱动相对还是较为底层，因此使用又一层抽象即文件。使用该抽象程序能够创建、读写文件，而不用处理硬件实际工作中的恼人细节。 操作系统的任务 操作系统的任务是创建好的抽象，并实现和管理它所创建的抽象对象。对于真实的硬件，其设计非常复杂，操作系统的一个主要任务是隐藏硬件，呈现给程序良好、清晰、优雅、一致的抽象。 作为资源管理者的操作系统操作系统用来管理一个复杂系统的的各个部分，包含CPU、存储器、时钟、磁盘、鼠标、IO、打印机等，操作系统的任务是在相互竞争的程序中有序地控制对处理器、存储器等的分配。 并发问题 现代操作系统允许同时在内存当中运行多道程序，假设在一台计算机上运行的三个程序试图同时在同一台打印机上输出结果，那么开始几行可能是程序1的输出，后面是程序2，之后又是程序1、程序3等。即没有一个程序可以完整的进行输出，因此最终的结果将是一团糟。 采用缓冲区的方式，操作系统可以将打印结果送到缓冲区当中，在程序结束后，将暂存在磁盘上的文件送到打印机输出，同时其他程序可以继续输出结果。 多用户 当计算机或网络具有多个用户时，管理和保护存储器、IO设备等需求较为强烈。用户间会互相干扰，他们共享硬件，还要共享文件、数据库等数据。因此认为数据库的主要任务是记录那个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。 时间复用 不同的程序或用户轮流使用，操作系统控制谁应该下一个使用并且使用多长时间。 空间复用 每个客户都得到资源的一部分，在若干运行程序间分割内存，这样每一个运行程序都可以同时入驻内存。若干用户分配磁盘空间，每一个用户使用一定的磁盘块等。 如此做法会引起公平、保护等问题，有赖于操作系统进行解决 计算机硬件简介简单的个人计算机可以抽象为如下图模型，CPU、内存以及IO设备都由一条系统总线连接起来并通过总线与其他设备通信。 现代计算机结构更为复杂，包含多重总线等 处理器最初CPU的执行过程 首先从内存中取出指令，解码以确定其类型和操作数，之后执行，然后取值、解码并执行下一条指令。直到程序被执行完成 CPU构成 CPU指令集。每个CPU都有一套可执行的专门指令集，因此x86CPU不能执行ARM程序。 寄存器。 保存变量与临时结果的寄存器。由于用来访问内存以得到指令或数据的时间比执行指令要花费的时间长的多，因此CPU内有一部分用来保存关键变量或临时数据的寄存器。 对程序员可见的寄存器 程序计数器。保存了将要取出的下一条指令的内存地址，在指令取出后，程序计数器被更新以便指向后继的指针 堆栈指针。指向内存中当前栈的顶端，该栈包含了每个执行过程的栈帧。 程序状态字PSW寄存器。包含了条件码位、CPU优先级、模式（用户态或内核态）、以及各控制位。用户程序通常读入整个PSW，但是只是对很少字段写入，在系统调用和IO中PSW很重要。 在时间多路复用CPU中，OS会经常终止正在运行中的某程序并启动另一个程序，此时OS必须保存所有的寄存器值，并在之后该程序再次运行时，将寄存器重新装入 CPU流水线模型为了改善性能，当代CPU具有同时取出多条指令的机制。如一个CPU可以具有单独的取值单元、解码单元和执行单元，因此当它执行指令n时，还可以对指令n+1解码，并且读取指令n+2。这样的机制称为流水线。并且其长度不仅仅只是三个阶段 在大多数流水线机制当中，一旦一条指令被取进流水线当中，则必须被执行完毕，即使前一条取出的指令是条件转移（以标志位的状态或者以标志位的逻辑运算结果作为转移依据，如果满足转移条件，则转到目标地址所指示的指令执行否则继续执行下一条指令）。这使得编译器与操作系统的编写很困难，造成了软件的复杂性问题。 超标量CPU模型有多个执行单元，如一个CPU用于整形运算，一个用于浮点型，一个用于Boolean。两个或更多个指令被同时去除、解码并装入暂存缓冲区中，直至它们执行完毕，只要有一个执行单元空闲，则检查保持缓冲区是否还要可以处理的指令，若有则将指令移出并执行。 这种设计使得程序的指令经常不按顺序执行，多数情况下硬件负责保证这种运算的结果与顺序执行的结果相同，但仍有复杂情况需要OS处理 内核态与用户态在PSW中有一个二进制位控制这两种模式。 当在内核态运行时，CPU可以执行指令集中的每一条指令，并使用硬件的每种功能。 用户程序在用户态下运行，仅允许执行整个指令集的一个子集和访问所有功能的一个子集。 为了从OS获取服务，用户程序必须使用系统调用以陷入内核并调用OS，TRAP指令把用户态切换成内核态并启用OS，当调用完成后，将控制权返回个iyonghu程序。 计算机使用陷阱（陷入内核态）而不是一条指令来执行系统调用，其他的多数陷阱是由硬件引起用于警告异常情况。如出错、index为0等。 多线程和多核芯片之前仅仅是有多个功能部件，而现在出现多个控制逻辑 多线程允许CPU保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。若某个进程需要从内存中读取一个字（需要多个时钟周期），则多线程CPU可以切换至另一个线程。多线程CPU不提供真正的并行处理，在一个时刻只有一个进程在运行，但进程的切换时间减少到纳秒级。 多线程对于操作系统而言，每个线程都像一个单独的CPU，若是有两个双线程的CPU即像是有4个CPU一样。 多核CPU，即包含2个或4个完整处理器或内核的CPU芯片，每个小芯片都是一个独立的CPU GPUGPU是由成千上万个微核组成的处理器，擅长处理大量并行的简单计算，如渲染等。但他们不太能胜任串行任务，并且很难编程。 存储器存储器应该极为迅速（快于执行任何指令，CPU就不会受到存储器限制）、充分大、非常便宜。但是由于无法满足该目标因此出现了分层结构 寄存器寄存器的速度与CPU一样快，访问他们是没有试验的。典型的存储容量在32位CPU中为32*32，在64位CPU是64 *64，即小于1KB，程序必须在软件自行管理这些寄存器 高速缓存多数由硬件控制，主存被分割成高速缓存行，典型大小为64字节，地址0-63对应高速缓存行0，64-127对应高速缓存行1，以此类推。最常用的高速缓存行放在CPU内部或非常接近CPU的高速缓存当中。 高速缓存命中：当某个程序在读取一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中，如果是，则高速缓存命中。即不需要通过总线将请求送往主存。 CPU缓存 L1缓存，总是在CPU当中，通常用来将已解码的指令调入CPU的执行引擎，访问不存在延时 L2缓存，存放近来使用过的若干兆字节的内存字。L1与L2的差别在于时序，L2访问延时1或2个时钟周期 对于多核芯片，设计师必须确定缓存的位置。 Intel芯片中一个L2缓存被所有CPU共享。因此Intel需要一个更复杂的缓存控制器 AMD芯片中，每个核具有自己的L2缓存。因此在保持L2缓存一致性上存在困难 分级高速缓存：将高速缓存分成二到三级，如L1与L2就是两级 缓存需要考虑 何时把一个新的内容放入缓存当中 把新内容放在缓存的哪一行上 在需要时，应该把哪个内容从缓存中移走 应该把新移走的内容放在某个较大存储器的何处 主存主存即随机访问存储器（RAM）， 除了主存，计算机已经在使用少量的非易失性随机访问存储器（ROM，只读存储器），电源切断后，其内容也不会丢失 磁盘磁盘是一种机械装置，因此其随机访问数据时间大约慢了三个数量级。 磁盘中有一个或多个金属片，以某个转速进行旋转。边缘处有一个机械臂悬横在盘面上，信息写在磁盘一系列的同心圆上。磁道：在任意一个给定臂的位置，每个磁头可以读取一段环形区域。柱面：把一个给定臂的位置上的所有磁道合并起来。 固态硬盘 并没有可以移动的部分，外形也不会像唱片一样，并且数据是存储在存储器（闪存）中的 虚拟内存与上下文切换 将程序放在磁盘上，将主存作为缓存的一部分，用来保存最频繁使用的部分程序。这种机制需要快速地映像内存地址。这种映像由CPU中的一个MMU（存储器管理单元）完成 MMU与缓存对系统性能有重要影响，从一个程序切换到另一个程序时，有必要对来自缓存行的所有修改过的块进行写回磁盘操作，并修改MMU中的映像寄存器。这些操作的代价十分昂贵 IO设备IO设备一般包括两个部分：设备控制器与设备本身。 控制器是插在电路板上的一块或一组芯片，从操作系统接收命令。对于设备的控制是非常复杂和具体的，控制器的任务是为操作系统提供一个简单的接口。 IO设备的设备本身有一个相对简单的接口，接口既不能做很多工作，又已经被标准化了，如任何一个SATA磁盘控制器都可以适配任何一种的SATA磁盘。 设备驱动程序操作系统看到的是对控制器的接口，因为每类设备控制器都是不同的，因此需要不同的软件进行控制。专门与控制器对话，发出命令并接收响应的软件称为设备驱动程序。 为使用设备驱动程序，必须将其装入操作系统当中，它可以在核心态或用户态运行，但若是在用户态运行则必须能够以某种受控的方式访问设备。 输入/输出的三种方式忙等待 用户程序发出一个系统调用，内核将其翻译成一个对应设备驱动程序的过程调用 然后设备驱动程序启动IO并在一个连续不断的循环中检查该设备，查看该设备是否完成了工作。 当IO结束后，设备驱动程序将数据送到指定的地方并返回。OS将控制权返回给调用者 缺陷：占据CPU，CPU需要一直轮询设备直到IO完成 中断通知 设备驱动程序启动设备，并且让该设备在操作完成时发出一个中断，设备驱动程序在此时返回。 操作系统之后在需要时阻塞调用者并安排其他工作进行，当设备驱动程序检测到操作完毕时，发出一个中断通知操作完成。 示例 设备驱动程序通过写设备寄存器通知设备控制器做什么，然后设备控制器启动该设备，当设备控制器传送完毕给告知要进行读取的字节数量后 使用特定的总线发信号给中断控制器芯片，如果中断控制器准备接收中断（或正忙于一个更高级的中断，或不接收） 中断经常会在非常不合适的时间发生，如在另一个中断正在运行时。因此CPU有办法关闭中断并稍后再次开启 中断关闭时，任何已经发出中断的设备可以继续保持中断信号，但CPU不会中断。 在关闭中断时，中断控制器将决定先处理哪一个中断，这取决于优先级 中断控制器在CPU芯片的一个管脚上声明 中断控制器将设备的编号放到总线上，CPU读取总线，并知道哪个设备刚刚完成了操作。 当CPU决定中断，程序计数器和PSW就被压入了当前堆栈。CPU切换到用户态。设备编号可以成为部分内存的一个引用，用于寻找该设备中断处理程序的地址，这部分内存称为中断向量 当中断处理程序开始后（中断设备），取走程序计数器和PSW并保存，查询设备状态，在中断全部完成后，返回到先前执行的用户程序中尚未执行的第一条指令、 直接存储器访问芯片 为IO使用直接存储器访问芯片（DMA），它可以控制在内存和某些控制器间的位流，无需持续CPU干预。CPU对DMA设置，说明需要传送的字节数、有关设备、内存地址、操作方向，启动DMA，当DMA完成后发送中断。 总线随着计算机的发展，单总线很难处理总线的交通流量，因此导致其他总线的出现，他们处理IO以及CPU到存储器的速度都更快 包括有高速缓存、内存、PCIe、PCI、USB、SATA和DMI总线等。其中主要的总线是PCIe总线 共享总线架构、并行总线架构是PCIe之前的架构，即多个设备使用一些相同的导线传输数据，因此当多个设备需要同时发送数据时，需要仲裁器决定哪个设备使用。设备通过多条并行的导线发送s护具的每一个字，如32位数据需要32条并行导线发送 PCIe采用分离的端到端的链路，因此不需要仲裁。而且通过一条称为数据通路的链路传递集合了所有位的一条消息，如同网络包一样。 待续 启动计算机操作系统概念进程进程本质上是正在执行的一个程序，与每个进程相关的是地址空间（从某个最小值的存储位置到某个最大值的存储位置列表）。与进程相关的有进程地址空间，进程可以对其地址空间进行读写，该地址空间存放有可执行程序、程序的数据、堆栈。还有资源集，包括寄存器，打开文件的清单等等。即进程基本上是容纳运行一个程序所有信息的容器。 多道程序系统 操作系统会周期性地挂起一个进程然后启动运行另一个进程，可能原因是前一个进程已经用完分配给它的时间片。 一个进程暂时被挂起后，在随后的某个时间，该进程再次启动时的状态必须与先前暂停时完全相同，即挂起时该进程的全部信息都要保存下来。 如打开的文件，与每个被打开文件有关的是指向当前位置的指针等 在许多OS当中，与一个进程有关的所有信息，除了该进程自身的地址空间的内容外均存放在OS的一张表中，称为进程表。 一个（挂起的）进程包括：进程的地址空间、对应的进程表项 地址空间操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合，该地址空间与机器的物理内存解耦，可能大于（虚拟内存）物理空间。 文件输入/输出保护shell个体重复系统发育系统调用任何单CPU系统一次只能执行一条指令，如果一个进程正在用户态运行一个用户程序，并且需要一个系统服务，则必须执行一次陷阱或系统调用指令，将控制返回给在系统调用后需要执行的指令。即类似于一个特殊的过程调用，但是系统调用是可以进入内核的 考察read系统调用，如果系统调用不能执行，无论是因为无效的参数还是磁盘错误，结果都会是-1，而在全局变量errno中放入错误号，程序应该经常检查系统调用结果以了解是否出错。 1read(fd,buffer,nbytes) 在执行read后，其具体步骤如下所示 用于进程管理的系统调用操作系统结构单体系统在大多数常见的组织中，整个操作系统在内核态以单一程序的方式运行，以过程集合的方式编写，链接成一个大型可执行的二进制文件。 层次式系统上层软件都是在下层软件的基础上构建的，系统分为六层。在第0层上，系统由一些连续的进程组成，编写这些进程时不需要考虑在单处理器上多进程运行的细节，即由第0层提供基本的CPU多道程序功能，以此类推 微内核在分层方式中，设计者要确定在哪里划分内核-用户的边界。传统上所有的层都在内核中，而这样并没有必要，尽可能减少内核态中的功能会更好一些，因为内核态的错误会迅速拖累整个系统，相反可以将用户进程设置为具有较小的权限，则某个错误的后果就不会致命。 微内核的思想是，为了实现高可靠性，将OS划分为小的、定义良好的模块，只有微内核（CPU中断处理、进程调度、进程通信等）运行在内核态，其他模块由于功能相对较弱作为普通的用户程序运行。因此一个错误虽然会使得程序崩溃，但不会使得系统死机 CS模式微内核的略微变体，将进程划分为客户端-服务器， 虚拟机外核与虚拟机克隆真实机器不同，另一种策略是对机器进行分区。即为每个用户提供整个资源的一个子集。 在底层中，一种称为外核的程序在内核态运行，任务是为虚拟机分配资源，并检查使用这些资源的企图，以确保没有使用他人的资源。 外核机制的优点是减少了映像层，即不需要像虚拟机将硬盘重新映射为0-xxx。只需要记录已经分配给虚拟机的相关资源即可。并且外核将多道程序与用户操作系统代码分离，而且相应负载并不重 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：操作]]></title>
    <url>%2F2019%2F07%2F09%2F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2FGit%EF%BC%9A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Git工作流程一般工作流程如下： 将Git的一个存储库克隆为工作副本。 可以通过添加/编辑文件修改工作副本。 如有必要，还可以通过让其他开发人员一起来更改/更新工作副本。 在提交之前查看更改。 提交更改：如果一切正常，那么将您的更改推送到存储库。 提交后，如果意识到某些错误并修改错误后，则将最后一个正确的修改提交并将推送到存储库。 下面显示的是工作流程的图示 - gerrit提交代码到Gerrit git stash。将自己的代码进行隐藏 git pull –rebase 拉取其他人的修改，进行合并最新的修改 git stash pop 将自己的代码合并进入最新的分支当中 若他人与自己修改了同一个文件则进行冲突解决 git add //需要提交的文件 git commit -m “注释” git push origin HEAD:refs/for/&lt;分支名&gt; 代码提交之后需要修改 git stash git pull –rebase git stash pop 冲突解决 git add git commit –amend vim操作退出 git push origin HEAD:refs/for/&lt;分支名&gt; PS. 如果不使用amend会导致提交两个code review 到 gerrit上面 如果提交了两次commit ，将gerrit上面的最新的一次提交abandon 同时本地执行 git log，git reset &lt;前一次提交的commit id&gt; reset之后再执行 5 开始的步骤 查看更改git log适用场景 查看git的历史提交 git log -n（查看前n条） 查看一次的详细提交 git show commitId 如何查看 Git 存储库的文件和提交记录，并对存储库中的文件作修改和提交。 比如，我们查看提交详细信息后，需要修改代码，或添加更多的代码，或者对比提交结果。 下面使用git log命令查看日志详细信息。 1$ git log 执行上面命令后，得到以下输出结果 - 123456789101112131415161718192021222324$ git logcommit be24e214620fa072efa877e1967571731c465884Author: your_name &lt;your_email@mail.com&gt;Date: Fri Jul 7 18:58:16 2017 +0800 ？？markcommit 5eccf92e28eae94ec5fce7c687f6f92bf32a6a8dAuthor: your_name &lt;your_email@mail.com&gt;Date: Fri Jul 7 18:52:06 2017 +0800 this is main.py file commit mark use -m optioncommit 6e5f31067466795c522b01692871f202c26ff948Author: your_name &lt;your_email@mail.com&gt;Date: Fri Jul 7 18:42:43 2017 +0800 this is main.py file commit mark without use "-m" optioncommit 290342c270bc90f861ccc3d83afa920169e3b07eAuthor: Maxsu &lt;769728683@qq.com&gt;Date: Fri Jul 7 16:55:12 2017 +0800 Initial commit 使用git show命令查看某一次提交详细信息。 git show命令采用SHA-1提交ID作为参数。 1234567891011121314151617$ git show be24e214620fa072efa877e1967571731c465884commit be24e214620fa072efa877e1967571731c465884Author: your_name &lt;your_email@mail.com&gt;Date: Fri Jul 7 18:58:16 2017 +0800 ？？markdiff --git a/main.py b/main.pyindex 91a1389..657c8d0 100644--- a/main.py+++ b/main.py@@ -3,3 +3,5 @@ print ("Life is short, you need Python !")+# this is a comment line+ 上面显示的结果中，可以看到符号 “+“ ，表示添加的内容。如果有 “-”则表示删除的内容，现在我们打开 main.py ，把注释行去掉并定义一个变量。修改后的 main.py 的内容如下所示 - 12345#!/usr/bin/python3#coding=utf-8print ("Life is short, you need Python !")a = 10b = 20 然后使用命令：git stauts 查看当前工作区状态 - 123456789101112$ git statusOn branch masterYour branch is ahead of 'origin/master' by 3 commits. (use "git push" to publish your local commits)Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: main.pyno changes added to commit (use "git add" and/or "git commit -a") 测试代码后，通过运行git diff命令来回顾他的更改。 12345678910111213$ git diffdiff --git a/main.py b/main.pyindex 95053b4..a4f953e 100644--- a/main.py+++ b/main.py@@ -4,4 +4,6 @@ print ("Life is short, you need Python !")-number = 100+a = 10++b = 20 可以看到符号 “+“ (绿色)，表示添加的内容。如果有 “-”(红色)则表示删除的内容。执行的效果如下所示 - 现在使用以下命令将文件：main.py 添加到 git 暂存区，然后提交代码完成 - 12$ git add main.py$ git commit -m "define two var a &amp; b " 最近修改的代码已提交完成。 提交修改git commit 增补提交，会使用与当前提交节点相同的父节点进行一次新的提交，旧的提交将会被取消 git commit –amend 合并commit 要从HEAD版本呢开始合并过往的1-3条comit git rebase -i HEAD~3(-i是指不需要合并的commit的hash值) 或者是git rebase -i commitId 执行命令后会出现vim 123pick 3ca6ec3 '注释**********'pick 1b40566 '注释*********'pick 53f244a '注释**********' pick 的意思是要会执行这个 commit squash(简写为s) 的意思是这个 commit 会被合并到前一个commit，因此修改后两个的pick为s 123pick 3ca6ec3 '注释**********'s 1b40566 '注释*********'s 53f244a '注释**********' :wq保存退出，此时git会进行合并，并弹出提示信息 12345678# This is a combination of 3 commits.# This is the 1st commit message:update3 # This is the commit message #2: update2 # This is the commit message #3: update1 # Please enter the commit message for your changes. Lines starting 修改我们最终需要的Commit msg。即改为,:wq保存退出 123# This is a combination of 3 commits.合并提交的文本msg# Please enter the commit message for your changes. Lines starting 查看log则有 123commit 4a51759fae9bbd84904029473fe09f8a77f143edAuthor: pan Date: Sun Apr 22 08:54:55 2018 +0800 合并提交的文本msg 注意事项：如果这个过程中有操作错误，可以使用 git rebase --abort来撤销修改，回到没有开始操作合并之前的状态。 推送操作git push1$ git push origin master 上述命令将产生以下结果： 12345678910$ git push origin masterUsername for 'http://git.oschina.net': 76972883@qq.com &lt;输入帐号&gt;Password for 'http://76972883@qq.com@git.oschina.net': &lt;输入登录密码&gt;Counting objects: 13, done.Delta compression using up to 4 threads.Compressing objects: 100% (12/12), done.Writing objects: 100% (12/12), 1.20 KiB | 0 bytes/s, done.Total 12 (delta 3), reused 0 (delta 0)To http://git.oschina.net/yiibai/sample.git 290342c..51de0f0 master -&gt; master 隐藏操作Git Stash应用场景假设您正在为产品新的功能编写/实现代码，当正在编写代码时，突然出现软件客户端升级。这时，您必须将新编写的功能代码保留几个小时然后去处理升级的问题。在这段时间内不能提交代码，也不能丢弃您的代码更改。 所以需要一些临时等待一段时间，您可以存储部分更改，然后再提交它。 使用在Git中，隐藏操作将使您能够修改跟踪文件，阶段更改，并将其保存在一系列未完成的更改中，并可以随时重新应用。 1234567891011$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: main.pyno changes added to commit (use "git add" and/or "git commit -a") 现在，要切换分支以进行客户升级，但不想提交一直在做的工作; 那么可以把当前工作的改变隐藏起来。 要将一个新的存根推到堆栈上，运行git stash命令。 123$ git stashSaved working directory and index state WIP on master: ef07ab5 synchronized with the remote repositoryHEAD is now at ef07ab5 synchronized with the remote repository 现在，工作目录是干净的，所有更改都保存在堆栈中。 现在使用git status命令来查看当前工作区状态。 12345$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.nothing to commit, working directory clean 现在，可以安全地切换分支并在其他地方工作。通过使用git stash list命令来查看已存在更改的列表。 12$ git stash liststash@&#123;0&#125;: WIP on master: ef07ab5 synchronized with the remote repository 假设您已经解决了客户升级问题，想要重新开始新的功能的代码编写，查找上次没有写完成的代码，只需执行git stash pop命令即可从堆栈中删除更改并将其放置在当前工作目录中。 12345$ git status -sAdministrator@MY-PC /D/worksp/sample (master)[jerry@CentOS project]$ git stash pop 上述命令将产生以下结果： 1234567891011121314151617181920212223242526$ git stash popOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: main.pyno changes added to commit (use "git add" and/or "git commit -a")Dropped refs/stash@&#123;0&#125; (e713780380632c142ed5833a9087aca883a826fa)Administrator@MY-PC /D/worksp/sample (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: main.pyno changes added to commit (use "git add" and/or "git commit -a") 可以看到，工作区中修改的文件(main.py)又显示了。现在我们就可以继续编写上次编写了未完成的代码。 隐藏部分文件git stash --keep-index只会隐藏没有被add的文件 修正错误撤销暂存适用场景 当我们将不想暂存的文件被git add到了索引后，想要回退取消 git reset HEAD &lt;file&gt; 恢复未提交的更改git checkout适用场景 假设我们不小心修改（删除）了本地存储库中的一个文件，此时想撤销这些修改 为了处理这种情况，我们可以使用git checkout命令。可以使用此命令来还原文件的内容。 为了更好的演示，我们首先在 sample/src 目录下创建一个文件：string.py ，其代码如下所示 - 1234567#!/usr/bin/python3var1 = 'Hello World!'var2 = "Python Programming"print ("var1[0]: ", var1[0])print ("var2[1:5]: ", var2[1:5]) # 切片加索引 并使用以下命令将此文件推送到远程存储库 - 1234567891011121314151617181920212223242526272829303132333435$ pwd/D/worksp/sampleAdministrator@MY-PC /D/worksp/sample (master)$ git add src/Administrator@MY-PC /D/worksp/sample (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: src/string.pyAdministrator@MY-PC /D/worksp/sample (master)$ git add src/string.pyAdministrator@MY-PC /D/worksp/sample (master)$ git commit -m "add new file string.py"[master 44ea8e4] add new file string.py 1 file changed, 7 insertions(+) create mode 100644 src/string.pyAdministrator@MY-PC /D/worksp/sample (master)$ git push origin masterUsername for 'http://git.oschina.net': 769728683@qq.comPassword for 'http://769728683@qq.com@git.oschina.net':Counting objects: 5, done.Delta compression using up to 4 threads.Compressing objects: 100% (3/3), done.Writing objects: 100% (4/4), 443 bytes | 0 bytes/s, done.Total 4 (delta 0), reused 0 (delta 0) 现在，已经将string.py添加到远程存储库中了。 假设我们不小心/或者有心修改了本地存储库中的一个文件。但现在不想要这些修改的内容了，也就是说想要撤销修改。要处理这种情况，那么可以使用git checkout命令。可以使用此命令来还原文件的内容。 12345678910111213141516171819202122232425$ pwd/D/worksp/sampleAdministrator@MY-PC /D/worksp/sample (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: src/string.pyno changes added to commit (use "git add" and/or "git commit -a")Administrator@MY-PC /D/worksp/sample (master)$ git checkout src/string.pyAdministrator@MY-PC /D/worksp/sample (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.nothing to commit, working directory clean 此外，还可以使用git checkout命令从本地存储库获取已删除的文件。假设我们从本地存储库中删除一个文件，我们想要恢复这个文件。那么可以通过使用git checkout命令来实现这一点。 1234567891011121314151617181920212223$ ls -ltotal 1-rw-r--r-- 1 Administ Administ 57 Jul 7 05:37 README.mddrwxr-xr-x 1 Administ Administ 0 Jul 10 21:16 srcAdministrator@MY-PC /D/worksp/sample (master)$ cd src/Administrator@MY-PC /D/worksp/sample/src (master)$ ls -ltotal 1-rwxr-xr-x 1 Administ Administ 156 Jul 10 21:16 string.pyAdministrator@MY-PC /D/worksp/sample/src (master)$ rm string.pyAdministrator@MY-PC /D/worksp/sample/src (master)$ ls -ltotal 0Administrator@MY-PC /D/worksp/sample/src (master)$ git status -s D string.py Git在文件名前显示字母D， 这表示该文件已从本地存储库中删除。 12345678910111213$ git checkout string.pyAdministrator@MY-PC /D/worksp/sample/src (master)$ ls -ltotal 1-rwxr-xr-x 1 Administ Administ 156 Jul 10 21:24 string.pyAdministrator@MY-PC /D/worksp/sample/src (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.nothing to commit, working directory clean 注意：可以在提交操作之前执行这些操作。 用Git复位移动头指针（即回滚）适用场景 当经过更改，并且执行commit后，并且决定删除更改，回退到之前的某个commit。 git reset –hard commitId 当代码提交了之后发现没有提交完整，或者想要重新编辑一下提交的信息 git reset –soft HEAD^。即重置HEAD指针，但不改变文件。 经过少量更改后，可以决定删除这些更改。 git reset命令用于复位或恢复更改。 我们可以执行三种不同类型的复位操作。 下图显示了git reset命令的图示。 git reset命令之前 - git reset命令之后 - —soft选项 每个分支都有一个HEAD指针，它指向最新的提交。 如果用--soft选项后跟提交ID的Git reset命令，那么它将仅重置HEAD指针而不会破坏任何东西。 .git/refs/heads/master文件存储HEAD指针的提交ID。 可使用git log -1命令验证它。 123456$ pwd/D/worksp/sampleAdministrator@MY-PC /D/worksp/sample (master)$ cat .git/refs/heads/master44ea8e47307b47c9a80b44360e09f973e79312b0 现在，查看最新前两个的提交ID，最近一次ID将与上述提交ID一致。 123456789101112$ git log -2commit 44ea8e47307b47c9a80b44360e09f973e79312b0Author: maxsu &lt;your_email@mail.com&gt;Date: Mon Jul 10 21:09:35 2017 +0800 add new file string.pycommit 7d8162db36723b8523c56ad658a07808ae7fb64cAuthor: minsu &lt;minsu@yiibai.com&gt;Date: Mon Jul 10 17:51:11 2017 -0700 remove/delete module.py 下面我们重置HEAD指针。 1git reset -soft 7d8162db36723b8523c56ad658a07808ae7fb64c 现在，只需将HEAD指针重新设置一个位置。现在查看.git/refs/heads/master文件的内容。 123Administrator@MY-PC /D/worksp/sample (master)$ cat .git/refs/heads/master7d8162db36723b8523c56ad658a07808ae7fb64c 来自文件的提交ID已更改，现在通过查看提交消息进行验证。 123456789101112$ git log -2commit 7d8162db36723b8523c56ad658a07808ae7fb64cAuthor: minsu &lt;minsu@yiibai.com&gt;Date: Mon Jul 10 17:51:11 2017 -0700 remove/delete module.pycommit 6bdbf8219c60d8da9ad352c23628600faaefbe13Author: maxsu &lt;your_email@mail.com&gt;Date: Mon Jul 10 20:34:28 2017 +0800 renamed main.py to module.py mixed选项 使用--mixed选项的Git重置将从尚未提交的暂存区域还原这些更改。它仅从暂存区域恢复更改。对文件的工作副本进行的实际更改不受影响。 默认Git复位等效于执行git reset - mixed。 hard选项 如果使用--hard选项与Git重置命令，它将清除分段区域; 它会将HEAD指针重置为特定提交ID的最新提交，并删除本地文件更改。 让我们查看提交ID。 1234567891011Administrator@MY-PC /D/worksp/sample (master)$ pwd/D/worksp/sampleAdministrator@MY-PC /D/worksp/sample (master)$ git log -1commit 7d8162db36723b8523c56ad658a07808ae7fb64cAuthor: minsu &lt;minsu@yiibai.com&gt;Date: Mon Jul 10 17:51:11 2017 -0700 remove/delete module.py 通过在文件开头添加单行注释来修改文件或者往文件里添加其它代码。 123456$ head -2 src/string.py#!/usr/bin/python3Administrator@MY-PC /D/worksp/sample (master)$ git status -s M src/string.py 将修改的文件添加到暂存区域，并使用git status命令进行验证。 12345678910111213$ git add src/string.pyAdministrator@MY-PC /D/worksp/sample (master)$ git statusOn branch masterYour branch and 'origin/master' have diverged,and have 1 and 1 different commit each, respectively. (use "git pull" to merge the remote branch into yours)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: src/string.py Git状态显示该文件存在于暂存区域中。 现在，重置HEAD与--hard选项。 1234$ git reset --hard 7d8162db36723b8523c56ad658a07808ae7fb64cHEAD is now at 7d8162d remove/delete module.pyAdministrator@MY-PC /D/worksp/sample (master) git reset命令成功，这将从分段区域还原文件，并删除对文件所做的任何本地更改。 12Administrator@MY-PC /D/worksp/sample (master)$ git status -s Git状态显示该文件已从暂存区域还原，当前恢复到了删除 moudle.py 时的版本了。 处理冲突 使用idea的处理冲突工具 注意自己的commit要尽量少一些，不然rebase很麻烦 如果自己的commit很多，则先将自己的rebase为一个commit之后在进行拉取 参考 易百教程]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo：理论]]></title>
    <url>%2F2019%2F07%2F08%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2FDubbo%EF%BC%9A%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[Dubbo背景需求 在大规模服务化之前，应用可能只是通过 RMI 或 Hessian 等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过 F5 等硬件进行负载均衡。 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 此时需要一个服务注册中心，动态地注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。 这时，需要自动画出应用间的依赖关系图，以帮助架构师理清理关系。 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？ 为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阈值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 以上是 Dubbo 最基本的几个需求。 架构 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系说明 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性。 连通性 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示。 服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销。 服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销。 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外。 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者。 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。 健壮性 监控中心宕掉不影响使用，只是丢失部分采样数据。 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务。 注册中心对等集群，任意一台宕掉后，将自动切换到另一台。 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯。 服务提供者无状态，任意一台宕掉后，不影响使用。 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复。 伸缩性 注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心。 服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者。 升级性当服务集群规模进一步扩大，带动IT治理结构进一步升级，需要实现动态部署，进行流动计算，现有分布式服务架构不会带来阻力。下图是未来可能的一种架构： 节点角色说明 节点 角色说明 Deployer 自动部署服务的本地代理 Repository 仓库用于存储服务应用发布包 Scheduler 调度中心基于访问压力自动增减服务提供者 Admin 统一管理控制台 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 核心功能 技术结构图： 服务网关 分布式事务 限流算法 微服务API设计 Dubbo SPI扩展实现链接：https://pan.baidu.com/s/1WgHwQO6w4UEXopq75DO5zQ提取码：i5ty复制这段内容后打开百度网盘手机App，操作更方便哦 链接：https://pan.baidu.com/s/16e-O0U0K_f4vSaMueCsMDg提取码：p59a复制这段内容后打开百度网盘手机App，操作更方便哦 链接：https://pan.baidu.com/s/1yDBA-7B4_q9nUZC39PbGHw提取码：ricd复制这段内容后打开百度网盘手机App，操作更方便哦 链接：https://pan.baidu.com/s/1tsbySuJt0o82vUV1pDmHsg提取码：lidy复制这段内容后打开百度网盘手机App，操作更方便哦 参考 dubbo官方文档]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：命令]]></title>
    <url>%2F2019%2F07%2F08%2F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2FGit%EF%BC%9A%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Git resetgit reset命令用于将当前HEAD复位到指定状态。一般用于撤消之前的一些操作(如：git add,git commit等)。 简介 123git reset [-q] [&lt;tree-ish&gt;] [--] &lt;paths&gt;…git reset (--patch | -p) [&lt;tree-ish&gt;] [--] [&lt;paths&gt;…]git reset [--soft | --mixed [-N] | --hard | --merge | --keep] [-q] [&lt;commit&gt;] 描述在第一和第二种形式中，将条目从&lt;tree-ish&gt;复制到索引。 在第三种形式中，将当前分支头(HEAD)设置为&lt;commit&gt;，可选择修改索引和工作树进行匹配。所有形式的&lt;tree-ish&gt;/&lt;commit&gt;默认为 HEAD 。 这里的 HEAD 关键字指的是当前分支最末梢最新的一个提交。也就是版本库中该分支上的最新版本。 示例以下是一些示例 - 在git的一般使用中，如果发现错误的将不想暂存的文件被git add进入索引之后，想回退取消，则可以使用命令：git reset HEAD &lt;file&gt;，同时git add完毕之后，git也会做相应的提示，比如： 1234# Changes to be committed: # (use "git reset HEAD &lt;file&gt;..." to unstage) # # new file: test.py git reset [--hard|soft|mixed|merge|keep] [&lt;commit&gt;或HEAD]：将当前的分支重设(reset)到指定的&lt;commit&gt;或者HEAD(默认，如果不显示指定&lt;commit&gt;，默认是HEAD，即最新的一次提交)，并且根据[mode]有可能更新索引和工作目录。mode的取值可以是hard、soft、mixed、merged、keep。下面来详细说明每种模式的意义和效果。 A). --hard：重设(reset) 索引和工作目录，自从&lt;commit&gt;以来在工作目录中的任何改变都被丢弃，并把HEAD指向&lt;commit&gt;。 下面是具体一个例子，假设有三个commit， 执行 git status结果如下: 123commit3: add test3.ccommit2: add test2.ccommit1: add test1.c 执行git reset --hard HEAD~1命令后，显示：HEAD is now at commit2，运行git log，如下所示 - 12commit2: add test2.ccommit1: add test1.c 应用场景下面列出一些git reset的典型的应用场景： (A) 回滚添加操作 12345$ edit file1.c file2.c # (1) $ git add file1.c file1.c # (1.1) 添加两个文件到暂存$ mailx # (2) $ git reset # (3) $ git pull git://info.example.com/ nitfol # (4) (1). 编辑文件 file1.c, file2.c，做了些更改，并把更改添加到了暂存区。(2). 查看邮件，发现某人要您执行git pull，有一些改变需要合并下来。(3). 然而，您已经把暂存区搞乱了，因为暂存区同HEAD commit不匹配了，但是即将git pull下来的东西不会影响已经修改的file1.c 和 file2.c，因此可以revert这两个文件的改变。在revert后，那些改变应该依旧在工作目录中，因此执行git reset。(4). 然后，执行了git pull之后，自动合并，file1.c 和 file2.c这些改变依然在工作目录中。 (B)回滚最近一次提交 1234$ git commit -a -m "这是提交的备注信息"$ git reset --soft HEAD^ #(1) $ edit code #(2) 编辑代码操作$ git commit -a -c ORIG_HEAD #(3) (1) 当提交了之后，又发现代码没有提交完整，或者想重新编辑一下提交的信息，可执行git reset --soft HEAD^，让工作目录还跟reset之前一样，不作任何改变。HEAD^表示指向HEAD之前最近的一次提交。(2) 对工作目录下的文件做修改，比如：修改文件中的代码等。(3) 然后使用reset之前那次提交的注释、作者、日期等信息重新提交。注意，当执行git reset命令时，git会把老的HEAD拷贝到文件.git/ORIG_HEAD中，在命令中可以使用ORIG_HEAD引用这个提交。git commit 命令中 -a参数的意思是告诉git，自动把所有修改的和删除的文件都放进暂存区，未被git跟踪的新建的文件不受影响。commit命令中-c &lt;commit&gt; 或者 -C &lt;commit&gt;意思是拿已经提交的对象中的信息(作者，提交者，注释，时间戳等)提交，那么这条git commit 命令的意思就非常清晰了，把所有更改的文件加入暂存区，并使用上次的提交信息重新提交。 (C) 回滚最近几次提交，并把这几次提交放到指定分支中 回滚最近几次提交，并把这几次提交放到叫做topic/wip的分支上去。 123$ git branch topic/wip (1) $ git reset --hard HEAD~3 (2) $ git checkout topic/wip (3) (1) 假设已经提交了一些代码，但是此时发现这些提交还不够成熟，不能进入master分支，希望在新的branch上暂存这些改动。因此执行了git branch命令在当前的HEAD上建立了新的叫做 topic/wip 的分支。(2) 然后回滚master分支上的最近三次提交。HEAD~3指向当前HEAD-3个提交，git reset --hard HEAD~3，即删除最近的三个提交(删除HEAD, HEAD^, HEAD~2)，将HEAD指向HEAD~3。 (D) 永久删除最后几个提交 12$ git commit ## 执行一些提交$ git reset --hard HEAD~3 (1) (1) 最后三个提交(即HEAD, HEAD^和HEAD~2)提交有问题，想永久删除这三个提交。 (E) 回滚merge和pull操作 12345678910$ git pull (1) Auto-merging nitfol CONFLICT (content): Merge conflict in nitfol Automatic merge failed; fix conflicts and then commit the result. $ git reset --hard (2) $ git pull . topic/branch (3) Updating from 41223... to 13134... Fast-forward $ git reset --hard ORIG_HEAD (4)` (1) 从origin拉取下来一些更新，但是产生了很多冲突，但您暂时没有这么多时间去解决这些冲突，因此决定稍候有空的时候再重新执行git pull操作。(2) 由于git pull操作产生了冲突，因此所有拉取下来的改变尚未提交，仍然再暂存区中，这种情况下git reset --hard 与 git reset --hard HEAD意思相同，即都是清除索引和工作区中被搞乱的东西。(3) 将topic/branch分支合并到当前的分支，这次没有产生冲突，并且合并后的更改自动提交。(4) 但是此时又发现将topic/branch合并过来为时尚早，因此决定退滚合并，执行git reset --hard ORIG_HEAD回滚刚才的pull/merge操作。说明：前面讲过，执行git reset时，git会把reset之前的HEAD放入.git/ORIG_HEAD文件中，命令行中使用ORIG_HEAD引用这个提交。同样的，执行git pull和git merge操作时，git都会把执行操作前的HEAD放入ORIG_HEAD中，以防回滚操作。 (F) 在污染的工作区中回滚合并或者拉取 123456$ git pull (1) Auto-merging nitfol Merge made by recursive. nitfol | 20 +++++---- ... $ git reset --merge ORIG_HEAD (2) (1) 即便你已经在本地更改了工作区中的一些东西，可安全的执行git pull操作，前提是要知道将要git pull下面的内容不会覆盖工作区中的内容。(2) git pull完后，发现这次拉取下来的修改不满意，想要回滚到git pull之前的状态，从前面的介绍知道，我们可以执行git reset --hard ORIG_HEAD，但是这个命令有个副作用就是清空工作区，即丢弃本地未使用git add的那些改变。为了避免丢弃工作区中的内容，可以使用git reset --merge ORIG_HEAD，注意其中的--hard 换成了 --merge，这样就可以避免在回滚时清除工作区。 (G) 中断的工作流程处理 在实际开发中经常出现这样的情形：你正在开发一个大的新功能(工作在分支：feature 中)，此时来了一个紧急的bug需要修复，但是目前在工作区中的内容还没有成型，还不足以提交，但是又必须切换的另外的分支去修改bug。请看下面的例子 - 123456789$ git checkout feature ;# you were working in "feature" branch and $ work work work ;# got interrupted $ git commit -a -m "snapshot WIP" (1) $ git checkout master $ fix fix fix $ git commit ;# commit with real log $ git checkout feature $ git reset --soft HEAD^ ;# go back to WIP state (2) $ git reset (3) (1) 这次属于临时提交，因此随便添加一个临时注释即可。(2) 这次reset删除了WIP commit，并且把工作区设置成提交WIP快照之前的状态。(3) 此时，在索引中依然遗留着“snapshot WIP”提交时所做的未提交变化，git reset将会清理索引成为尚未提交”snapshot WIP“时的状态便于接下来继续工作。 (H) 重置单独的一个文件 假设你已经添加了一个文件进入索引，但是而后又不打算把这个文件提交，此时可以使用git reset把这个文件从索引中去除。 123$ git reset -- frotz.c (1) $ git commit -m "Commit files in index" (2) $ git add frotz.c (3) (1) 把文件frotz.c从索引中去除，(2) 把索引中的文件提交(3) 再次把frotz.c加入索引 (I) 保留工作区并丢弃一些之前的提交 假设你正在编辑一些文件，并且已经提交，接着继续工作，但是现在你发现当前在工作区中的内容应该属于另一个分支，与之前的提交没有什么关系。此时，可以开启一个新的分支，并且保留着工作区中的内容。 1234567$ git tag start $ git checkout -b branch1 $ edit $ git commit ... (1) $ edit $ git checkout -b branch2 (2) $ git reset --keep start (3) (1) 这次是把在branch1中的改变提交了。(2) 此时发现，之前的提交不属于这个分支，此时新建了branch2分支，并切换到了branch2上。(3) 此时可以用reset --keep把在start之后的提交清除掉，但是保持工作区不变。 Git checkoutgit checkout命令用于切换分支或恢复工作树文件。git checkout是git最常用的命令之一，同时也是一个很危险的命令，因为这条命令会重写工作区。 使用语法 123456git checkout [-q] [-f] [-m] [&lt;branch&gt;]git checkout [-q] [-f] [-m] --detach [&lt;branch&gt;]git checkout [-q] [-f] [-m] [--detach] &lt;commit&gt;git checkout [-q] [-f] [-m] [[-b|-B|--orphan] &lt;new_branch&gt;] [&lt;start_point&gt;]git checkout [-f|--ours|--theirs|-m|--conflict=&lt;style&gt;] [&lt;tree-ish&gt;] [--] &lt;paths&gt;…git checkout [-p|--patch] [&lt;tree-ish&gt;] [--] [&lt;paths&gt;…] 描述更新工作树中的文件以匹配索引或指定树中的版本。如果没有给出路径 - git checkout还会更新HEAD，将指定的分支设置为当前分支。 示例以下是一些示例 - 示例-1 以下顺序检查主分支，将Makefile还原为两个修订版本，错误地删除hello.c，并从索引中取回。 1234$ git checkout master #(1)$ git checkout master~2 Makefile #(2)$ rm -f hello.c$ git checkout hello.c #(3) (1) 切换分支(2) 从另一个提交中取出文件(3)从索引中恢复hello.c 如果想要检出索引中的所有C源文件，可以使用以下命令 - 1$ git checkout -- '*.c' 注意:*.c是使用引号的。 文件hello.c也将被检出，即使它不再在工作树中，因为文件globbing用于匹配索引中的条目(而不是在shell的工作树中)。 如果有一个分支也命名为hello.c，这一步将被混淆为一个指令切换到该分支。应该写： 1$ git checkout -- hello.c 示例-2 在错误的分支工作后，想切换到正确的分支，则使用： 1$ git checkout mytopic 但是，您的“错误”分支和正确的“mytopic”分支可能会在在本地修改的文件中有所不同，在这种情况下，上述检出将会失败： 12$ git checkout mytopicerror: You have local changes to 'frotz'; not switching branches. 可以将-m标志赋给命令，这将尝试三路合并： 12$ git checkout -m mytopicAuto-merging frotz 在这种三路合并之后，本地的修改没有在索引文件中注册，所以git diff会显示从新分支的提示之后所做的更改。 示例-3 当使用-m选项切换分支时发生合并冲突时，会看到如下所示： 1234$ git checkout -m mytopicAuto-merging frotzERROR: Merge conflict in frotzfatal: merge program failed 此时，git diff会显示上一个示例中干净合并的更改以及冲突文件中的更改。 编辑并解决冲突，并用常规方式用git add来标记它： 12$ edit frotz # 编辑 frotz 文件中内容，然后重新添加$ git add frotz 其它示例 git checkout的主要功能就是迁出一个分支的特定版本。默认是迁出分支的HEAD版本一此用法示例： 12345678910111213$ git checkout master #//取出master版本的head。$ git checkout tag_name #//在当前分支上 取出 tag_name 的版本$ git checkout master file_name #//放弃当前对文件file_name的修改$ git checkout commit_id file_name #//取文件file_name的 在commit_id是的版本。commit_id为 git commit 时的sha值。$ git checkout -b dev/1.5.4 origin/dev/1.5.4# 从远程dev/1.5.4分支取得到本地分支/dev/1.5.4$ git checkout -- hello.rb#这条命令把hello.rb从HEAD中签出.$ git checkout .#这条命令把 当前目录所有修改的文件 从HEAD中签出并且把它恢复成未修改时的样子.#注意：在使用 git checkout 时，如果其对应的文件被修改过，那么该修改会被覆盖掉。 Git mergegit merge命令用于将两个或两个以上的开发历史加入(合并)一起。 使用语法 123456git merge [-n] [--stat] [--no-commit] [--squash] [--[no-]edit] [-s &lt;strategy&gt;] [-X &lt;strategy-option&gt;] [-S[&lt;keyid&gt;]] [--[no-]allow-unrelated-histories] [--[no-]rerere-autoupdate] [-m &lt;msg&gt;] [&lt;commit&gt;…]git merge --abortgit merge --continue 描述将来自命名提交的更改(从其历史从当前分支转移到当前分支之后)。 该命令由git pull用于合并来自另一个存储库的更改，可以手动使用将更改从一个分支合并到另一个分支。 示例以下是一些示例 - 示例-1 合并分支fixes和enhancements在当前分支的顶部，使它们合并： 1$ git merge fixes enhancements 示例-2 合并obsolete分支到当前分支，使用ours合并策略： 1$ git merge -s ours obsolete 示例-3 将分支maint合并到当前分支中，但不要自动进行新的提交： 1$ git merge --no-commit maint 当您想要对合并进行进一步更改时，可以使用此选项，或者想要自己编写合并提交消息。应该不要滥用这个选项来潜入到合并提交中。小修补程序，如版本名称将是可以接受的。 示例-4 将分支dev合并到当前分支中，自动进行新的提交： 1$ git merge dev Git fetchGit pullgit pull命令用于从另一个存储库或本地分支获取并集成(整合)。git pull命令的作用是：取回远程主机某个分支的更新，再与本地的指定分支合并，它的完整格式稍稍有点复杂。 使用语法 1git pull [options] [&lt;repository&gt; [&lt;refspec&gt;…]] 描述将远程存储库中的更改合并到当前分支中。在默认模式下，git pull是git fetch后跟git merge FETCH_HEAD的缩写。 更准确地说，git pull使用给定的参数运行git fetch，并调用git merge将检索到的分支头合并到当前分支中。 使用--rebase，它运行git rebase而不是git merge。 示例以下是一些示例 - 1$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如，要取回origin主机的next分支，与本地的master分支合并，需要写成下面这样 - 1$ git pull origin next:master 如果远程分支(next)要与当前分支合并，则冒号后面的部分可以省略。上面命令可以简写为： 1$ git pull origin next 上面命令表示，取回origin/next分支，再与当前分支合并。实质上，这等同于先做git fetch，再执行git merge。 12$ git fetch origin$ git merge origin/next 在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系(tracking)。比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支。 Git也允许手动建立追踪关系。 1$ git branch --set-upstream master origin/next 上面命令指定master分支追踪origin/next分支。 如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名。 1$ git pull origin 上面命令表示，本地的当前分支自动与对应的origin主机”追踪分支”(remote-tracking branch)进行合并。 如果当前分支只有一个追踪分支，连远程主机名都可以省略。 1$ git pull 上面命令表示，当前分支自动与唯一一个追踪分支进行合并。 如果合并需要采用rebase模式，可以使用–rebase选项。 1$ git pull --rebase &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; git fetch和git pull的区别 git fetch：相当于是从远程获取最新版本到本地，不会自动合并。 123$ git fetch origin master$ git log -p master..origin/master$ git merge origin/master 以上命令的含义： 首先从远程的origin的master主分支下载最新的版本到origin/master分支上 然后比较本地的master分支和origin/master分支的差别 最后进行合并 上述过程其实可以用以下更清晰的方式来进行： 123$ git fetch origin master:tmp$ git diff tmp $ git merge tmp git pull：相当于是从远程获取最新版本并merge到本地 1git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。 Git pushgit push命令用于将本地分支的更新，推送到远程主机。它的格式与git pull命令相似。 1$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 使用语法 123456git push [--all | --mirror | --tags] [--follow-tags] [--atomic] [-n | --dry-run] [--receive-pack=&lt;git-receive-pack&gt;] [--repo=&lt;repository&gt;] [-f | --force] [-d | --delete] [--prune] [-v | --verbose] [-u | --set-upstream] [--push-option=&lt;string&gt;] [--[no-]signed|--sign=(true|false|if-asked)] [--force-with-lease[=&lt;refname&gt;[:&lt;expect&gt;]]] [--no-verify] [&lt;repository&gt; [&lt;refspec&gt;…]] 描述使用本地引用更新远程引用，同时发送完成给定引用所需的对象。可以在每次推入存储库时，通过在那里设置挂钩触发一些事件。 当命令行不指定使用&lt;repository&gt;参数推送的位置时，将查询当前分支的branch.*.remote配置以确定要在哪里推送。 如果配置丢失，则默认为origin。 示例以下是一些示例 - 1$ git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果master不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 123$ git push origin :master# 等同于$ git push origin --delete master 上面命令表示删除origin主机的master分支。如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 1$ git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。如果当前分支只有一个追踪分支，那么主机名都可以省略。 1$ git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 1$ git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 123$ git config --global push.default matching# 或者$ git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。 1$ git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。 1$ git push --force origin 上面命令使用-–force选项，结果导致在远程主机产生一个”非直进式”的合并(non-fast-forward merge)。除非你很确定要这样做，否则应该尽量避免使用–-force选项。 最后，git push不会推送标签(tag)，除非使用–tags选项。 1$ git push origin --tags 将当前分支推送到远程的同名的简单方法，如下 - 1$ git push origin HEAD 将当前分支推送到源存储库中的远程引用匹配主机。 这种形式方便推送当前分支，而不考虑其本地名称。如下 - 1$ git push origin HEAD:master 其它示例 1.推送本地分支lbranch-1到新大远程分支rbranch-1： 1$ git push origin lbranch-1:refs/rbranch-1 2.推送lbranch-2到已有的rbranch-1，用于补充rbranch-1： 123$ git checkout lbranch-2$ git rebase rbranch-1$ git push origin lbranch-2:refs/rbranch-1 3.用本地分支lbranch-3覆盖远程分支rbranch-1： 1$ git push -f origin lbranch-2:refs/rbranch-1 或者 - 12$ git push origin :refs/rbranch-1 //删除远程的rbranch-1分支$ git push origin lbranch-1:refs/rbranch-1 4.查看push的结果 1$ gitk rbranch-1 5.推送tag 1$ git push origin tag_name 6.删除远程标签 1$ git push origin :tag_name Git rebasegit rebase命令在另一个分支基础之上重新应用，用于把一个分支的修改合并到当前分支。 使用语法 12345git rebase [-i | --interactive] [options] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt;] [&lt;upstream&gt; [&lt;branch&gt;]]git rebase [-i | --interactive] [options] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt;] --root [&lt;branch&gt;]git rebase --continue | --skip | --abort | --quit | --edit-todo 示例假设你现在基于远程分支”origin“，创建一个叫”mywork“的分支。 1$ git checkout -b mywork origin 结果如下所示 - 现在我们在这个分支(mywork)做一些修改，然后生成两个提交(commit). 12345$ vi file.txt$ git commit$ vi otherfile.txt$ git commit... ... 但是与此同时，有些人也在”origin“分支上做了一些修改并且做了提交了，这就意味着”origin“和”mywork“这两个分支各自”前进”了，它们之间”分叉”了。 在这里，你可以用”pull“命令把”origin“分支上的修改拉下来并且和你的修改合并； 结果看起来就像一个新的”合并的提交”(merge commit): 但是，如果你想让”mywork“分支历史看起来像没有经过任何合并一样，也可以用 git rebase，如下所示: 12$ git checkout mywork$ git rebase origin 这些命令会把你的”mywork“分支里的每个提交(commit)取消掉，并且把它们临时 保存为补丁(patch)(这些补丁放到”.git/rebase“目录中),然后把”mywork“分支更新 到最新的”origin“分支，最后把保存的这些补丁应用到”mywork“分支上。 当’mywork‘分支更新之后，它会指向这些新创建的提交(commit),而那些老的提交会被丢弃。 如果运行垃圾收集命令(pruning garbage collection), 这些被丢弃的提交就会删除. 现在我们可以看一下用合并(merge)和用rebase所产生的历史的区别： 在rebase的过程中，也许会出现冲突(conflict)。在这种情况，Git会停止rebase并会让你去解决冲突；在解决完冲突后，用”git add“命令去更新这些内容的索引(index), 然后，你无需执行 git commit,只要执行: 1$ git rebase --continue 这样git会继续应用(apply)余下的补丁。 撤销操作git rebase –abort在任何时候，可以用--abort参数来终止rebase的操作，并且”mywork“ 分支会回到rebase开始前的状态。 1$ git rebase --abort Git Commitgit commit –amend # 增补提交，会使用与当前提交节点相同的父节点进行一次新的提交，旧的提交将会被取消。 参考 易百教程]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jooq：文档]]></title>
    <url>%2F2019%2F07%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FJooq%2FJooq%EF%BC%9A%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[Jooq提出问题为什么要用（作用）与JPA相比到目前为止，只有少数的数据库抽象框架或者库，真正尊重SQL作为语言的一等公民，而包括JPA、EJB、doubts等许多框架都试图隐藏SQL本身，将其范围最小化。 JOOQ填补了这个空白 与LINQ相比与SQL相比SQL可以作为纯文本编写并通过JDBC API传递，多年来，人们对这种方式保持警惕 没有类型安全 没有语法安全 没有绑定值索引安全性 详细的SQL字符串连接 无聊的绑定值索引技术 JDBC中的详细资源和异常处理 一个非常有“状态”的，不是非常面向对象的jdbc api，很难使用 JOOQ前置了解代码块内容若未给出假设，则假定使用的是Oracle语法 当看到独立函数，则是从org.jooq.impl.DSL导入的静态函数。 123每当您看到BOOK / Book，AUTHOR / Author和类似实体时，假设它们是从生成的模式中导入的（静态的）BOOK.TITLE，AUTHOR.LAST_NAME //对应com.example.generated.Tables.BOOK.TITLE，com.example.generated.Tables.BOOK.TITLEFK_BOOK_AUTHOR //对应com.example.generated.Keys.FK_BOOK_AUTHOR 1234//每当看到Java代码中使用“create”时，假设这是org.jooq.DSLContext的一个实例。//它被称为“创建”的原因是，从DSL对象创建了一个jOOQ QueryPart。//“create”因此是非静态查询DSL的入口点DSLContext create = DSL.using（connection，SQLDialect.ORACLE）; 执行JOOQ无法确定声明是否完整，直到执行fetch或者execute 12create.selectOne().fetch();create.update(T).set(T.V, 1).execute(); 设置jOOQ允许使用org.jooq.conf.Settings覆盖运行时行为。如果未指定任何内容，则假定使用默认运行时设置。 样本数据库jOOQ查询示例针对示例数据库运行。 示例数据库123456789101112131415161718192021222324252627282930313233343536373839CREATE TABLE language ( id NUMBER(7) NOT NULL PRIMARY KEY, cd CHAR(2) NOT NULL, description VARCHAR2(50));CREATE TABLE author ( id NUMBER(7) NOT NULL PRIMARY KEY, first_name VARCHAR2(50), last_name VARCHAR2(50) NOT NULL, date_of_birth DATE, year_of_birth NUMBER(7), distinguished NUMBER(1));CREATE TABLE book ( id NUMBER(7) NOT NULL PRIMARY KEY, author_id NUMBER(7) NOT NULL, title VARCHAR2(400) NOT NULL, published_in NUMBER(7) NOT NULL, language_id NUMBER(7) NOT NULL, CONSTRAINT fk_book_author FOREIGN KEY (author_id) REFERENCES author(id), CONSTRAINT fk_book_language FOREIGN KEY (language_id) REFERENCES language(id));CREATE TABLE book_store ( name VARCHAR2(400) NOT NULL UNIQUE);CREATE TABLE book_to_book_store ( name VARCHAR2(400) NOT NULL, book_id INTEGER NOT NULL, stock INTEGER, PRIMARY KEY(name, book_id), CONSTRAINT fk_b2bs_book_store FOREIGN KEY (name) REFERENCES book_store (name) ON DELETE CASCADE, CONSTRAINT fk_b2bs_book FOREIGN KEY (book_id) REFERENCES book (id) ON DELETE CASCADE); 示例数据1234567891011121314151617181920212223242526272829INSERT INTO language (id, cd, description) VALUES (1, 'en', 'English');INSERT INTO language (id, cd, description) VALUES (2, 'de', 'Deutsch');INSERT INTO language (id, cd, description) VALUES (3, 'fr', 'Français');INSERT INTO language (id, cd, description) VALUES (4, 'pt', 'Português');INSERT INTO author (id, first_name, last_name, date_of_birth , year_of_birth) VALUES (1 , 'George' , 'Orwell' , DATE '1903-06-26', 1903 );INSERT INTO author (id, first_name, last_name, date_of_birth , year_of_birth) VALUES (2 , 'Paulo' , 'Coelho' , DATE '1947-08-24', 1947 );INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (1 , 1 , '1984' , 1948 , 1 );INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (2 , 1 , 'Animal Farm' , 1945 , 1 );INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (3 , 2 , 'O Alquimista', 1988 , 4 );INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (4 , 2 , 'Brida' , 1990 , 2 );INSERT INTO book_store VALUES ('Orell Füssli');INSERT INTO book_store VALUES ('Ex Libris');INSERT INTO book_store VALUES ('Buchhandlung im Volkshaus');INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 1, 10);INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 2, 10);INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 3, 10);INSERT INTO book_to_book_store VALUES ('Ex Libris' , 1, 1 );INSERT INTO book_to_book_store VALUES ('Ex Libris' , 3, 2 );INSERT INTO book_to_book_store VALUES ('Buchhandlung im Volkshaus', 3, 1 ); 不同的使用情况进行JOOQJOOQ作为SQL构建器允许为任何数据库构建有效的SQL，使用JOOQ的查询DSL API将字符串、文字和其他用户定义的对象包装到面向对象、类型安全的AST当中，为SQL建模 12345678// Fetch a SQL string from a jOOQ Query in order to manually execute it with another tool.// For simplicity reasons, we're using the API to construct case-insensitive object references, here.String sql = create.select(field("BOOK.TITLE"), field("AUTHOR.FIRST_NAME"), field("AUTHOR.LAST_NAME")) .from(table("BOOK")) .join(table("AUTHOR")) .on(field("BOOK.AUTHOR_ID").eq(field("AUTHOR.ID"))) .where(field("BOOK.PUBLISHED_IN").eq(1948)) .getSQL(); 之后，该sql语句可以直接使用JDBC进行执行， JOOQ作为具有代码生成的SQL构建器JOOQ作为SQL执行器使用JOOQ直接执行JOOQ生成的SQL语句，通过让JOOQ执行SQL，JOOQ查询DSL成为真正的嵌入式SQL 12345678// Typesafely execute the SQL statement directly with jOOQResult&lt;Record3&lt;String, String, String&gt;&gt; result =create.select(BOOK.TITLE, AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME) .from(BOOK) .join(AUTHOR) .on(BOOK.AUTHOR_ID.eq(AUTHOR.ID)) .where(BOOK.PUBLISHED_IN.eq(1948)) .fetch(); 并且可以使用任何的SQL构建工具构建SQL语句，之后由JOOQ运行SQL语句。 12345678910// Use your favourite tool to construct SQL strings:String sql = "SELECT title, first_name, last_name FROM book JOIN author ON book.author_id = author.id " + "WHERE book.published_in = 1984";// Fetch results using jOOQResult&lt;Record&gt; result = create.fetch(sql);// Or execute that SQL with JDBC, fetching the ResultSet with jOOQ:ResultSet rs = connection.createStatement().executeQuery(sql);Result&lt;Record&gt; result = create.fetch(rs); JOOQ for CURD12345678910111213141516// Fetch an authorAuthorRecord author : create.fetchOne(AUTHOR, AUTHOR.ID.eq(1));// Create a new author, if it doesn't exist yetif (author == null) &#123; author = create.newRecord(AUTHOR); author.setId(1); author.setFirstName("Dan"); author.setLastName("Brown");&#125;// Mark the author as a "distinguished" author and store itauthor.setDistinguished(1);// Executes an update on existing authors, or insert on new onesauthor.store(); PRO的JOOQJOOQ的工具 jOOQ的执行监听器：jOOQ允许您将自定义执行监听器挂钩到jOOQ的SQL语句执行生命周期中，以集中协调对正在执行的SQL执行的任何操作。用于记录，标识生成，SQL跟踪，性能测量等。 记录：jOOQ内置一个标准的DEBUG记录器，用于记录和跟踪所有已执行的SQL语句和获取的结果集 存储过程：jOOQ支持您喜欢的数据库的存储过程和函数。生成所有例程和用户定义类型，并且可以作为函数引用包含在jOOQ的SQL构建API中。 批量执行：执行大量SQL语句时，批量执行很重要。与JDBC相比，jOOQ简化了这些操作 导出和导入：jOOQ附带API，可以轻松导出/导入各种格式的数据 JOOQ教程入门JOOQ简单7个步骤准备JOOQ的maven 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq&lt;/artifactId&gt; &lt;version&gt;3.10.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-meta&lt;/artifactId&gt; &lt;version&gt;3.10.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen&lt;/artifactId&gt; &lt;version&gt;3.10.8&lt;/version&gt;&lt;/dependency&gt; 商业版 数据库创建一个library的数据库以及一个对应的author表 12345678910CREATE DATABASE `library`;USE `library`;CREATE TABLE `author` ( `id` int NOT NULL, `first_name` varchar(255) DEFAULT NULL, `last_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)); 代码生成使用JOOQ的命令行工具生成映射到我们刚创建的Author表的类。详细信息参照：关于设置代码生成器的jOOQ手册页 最简单的方式是将JOOQ的jar文件（3个）以及数据库的connect文件复制到临时目录下，创建一个library.xml 更新用户名、url、driver等数据 database.includes里包含要创建的数据库表，database.excludes包含需要排除的数据库表 generator.target.package - 将其设置为要为生成的类创建的父包。 设置test.generated将导致test.generated.Author和test.generated.AuthorRecord创建 generator.target.directory - 要输出的目录。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;configuration xmlns="http://www.jooq.org/xsd/jooq-codegen-3.10.0.xsd"&gt; &lt;!-- Configure the database connection here --&gt; &lt;jdbc&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;url&gt;jdbc:mysql://localhost:3306/library&lt;/url&gt; &lt;user&gt;root&lt;/user&gt; &lt;password&gt;&lt;/password&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;!-- The default code generator. You can override this one, to generate your own code style. Supported generators: - org.jooq.util.JavaGenerator - org.jooq.util.ScalaGenerator Defaults to org.jooq.util.JavaGenerator Note the classes have been moved to org.jooq.codegen or org.jooq.meta in jOOQ 3.11 --&gt; &lt;name&gt;org.jooq.util.JavaGenerator&lt;/name&gt; &lt;database&gt; &lt;!-- The database type. The format here is: org.jooq.util.[database].[database]Database Note the classes have been moved to org.jooq.codegen or org.jooq.meta in jOOQ 3.11 --&gt; &lt;name&gt;org.jooq.util.mysql.MySQLDatabase&lt;/name&gt; &lt;!-- The database schema (or in the absence of schema support, in your RDBMS this can be the owner, user, database name) to be generated --&gt; &lt;inputSchema&gt;library&lt;/inputSchema&gt; &lt;!-- All elements that are generated from your schema (A Java regular expression. Use the pipe to separate several expressions) Watch out for case-sensitivity. Depending on your database, this might be important! --&gt; &lt;includes&gt;.*&lt;/includes&gt; &lt;!-- All elements that are excluded from your schema (A Java regular expression. Use the pipe to separate several expressions). Excludes match before includes, i.e. excludes have a higher priority --&gt; &lt;excludes&gt;&lt;/excludes&gt; &lt;/database&gt; &lt;target&gt; &lt;!-- The destination package of your generated classes (within the destination directory) --&gt; &lt;packageName&gt;test.generated&lt;/packageName&gt; &lt;!-- The destination directory of your generated classes. Using Maven directory layout here --&gt; &lt;directory&gt;C:/workspace/MySQLTest/src/main/java&lt;/directory&gt; &lt;/target&gt; &lt;/generator&gt;&lt;/configuration&gt; 到达临时目录后，windows键入。记得替换文件名称 12java -classpath jooq-3.10.8.jar; jooq-meta-3.10.8.jar; jooq-codegen-3.10.8.jar; mysql-connector-java-5.1.18-bin.jar;。 org.jooq.util.GenerationTool library.xml mac键入 12java -classpath jooq-3.10.8.jar：jooq-meta-3.10.8.jar：jooq-codegen-3.10.8.jar：mysql-connector-java-5.1.18-bin.jar：。 org.jooq.util.GenerationTool library.xml 成功后的输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556Nov 1, 2011 7:25:06 PM org.jooq.impl.JooqLogger infoINFO: Initialising properties : /library.xmlNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Database parametersNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: ----------------------------------------------------------Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: dialect : MYSQLNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: schema : libraryNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: target dir : C:/workspace/MySQLTest/srcNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: target package : test.generatedNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: ----------------------------------------------------------Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Emptying : C:/workspace/MySQLTest/src/test/generatedNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Generating classes in : C:/workspace/MySQLTest/src/test/generatedNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Generating schema : Library.javaNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Schema generated : Total: 122.18msNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Sequences fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Tables fetched : 5 (5 included, 0 excluded)Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Generating tables : C:/workspace/MySQLTest/src/test/generated/tablesNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: ARRAYs fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Enums fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: UDTs fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Generating table : Author.javaNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Tables generated : Total: 680.464ms, +558.284msNov 1, 2011 7:25:07 PM org.jooq.impl.JooqLogger infoINFO: Generating Keys : C:/workspace/MySQLTest/src/test/generated/tablesNov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Keys generated : Total: 718.621ms, +38.157msNov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Generating records : C:/workspace/MySQLTest/src/test/generated/tables/recordsNov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Generating record : AuthorRecord.javaNov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Table records generated : Total: 782.545ms, +63.924msNov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Routines fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: Packages fetched : 0 (0 included, 0 excluded)Nov 1, 2011 7:25:08 PM org.jooq.impl.JooqLogger infoINFO: GENERATION FINISHED! : Total: 791.688ms, +9.143ms 连接到数据库连接数据库 123456789101112131415161718192021222324// For convenience, always static import your generated tables and jOOQ functions to decrease verbosity:import static test.generated.Tables.*;import static org.jooq.impl.DSL.*;import java.sql.*;public class Main &#123; public static void main(String[] args) &#123; String userName = "root"; String password = ""; String url = "jdbc:mysql://localhost:3306/library"; // Connection is the only JDBC resource that we need // PreparedStatement and ResultSet are handled by jOOQ, internally try (Connection conn = DriverManager.getConnection(url, userName, password)) &#123; // ... &#125; // For the sake of this tutorial, let's keep exception handling simple catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 查询DSL不会自己关闭，需要我们自己去完成 12DSLContext create = DSL.using(conn, SQLDialect.MYSQL);Result&lt;Record&gt; result = create.select().from(AUTHOR).fetch(); 迭代打印结果 1234567for (Record r : result) &#123; Integer id = r.getValue(AUTHOR.ID); String firstName = r.getValue(AUTHOR.FIRST_NAME); String lastName = r.getValue(AUTHOR.LAST_NAME); System.out.println("ID: " + id + " first name: " + firstName + " last name: " + lastName);&#125; 探索数据库版本管理工具FlywayFlyway简介Flyway是独立于数据库的应用、管理、跟踪数据库变更的数据库版本管理工具。Flyway的项目主页是：https://flywaydb.org/ 为什么使用Flyway 不同的开发人员在开发产品特性时，都有可能更新数据库（添加新表，新的约束等）。当开发人员完成工作并提交代码时，代码会被合并到主分支并在测试服务器上执行单元测试与集成测试。我们在哪个环节来执行数据库的更新操作呢？由QA 部门手工执行sql 脚本？或者我们开发一断程序自动执行数据库更新？以什么顺序来执行这些更新脚本？这些问题同样存在于生产环境。 我们的产品部署在不同的客户服务器上，以及很多的测试、联调、实验局、销售环境上。不同的客户和测试环境上都部署着不同版本的产品。当他们需要升级他们的产品到新的版本时，我们不仅需要让他们的管理员可以升级产品到新的版本，同时需要保留他们的已有数据。在升级产品的步骤中，我们清楚地知道客户数据库的当前版本，以及需要在该数据库上执行哪些数据库更新脚本，来更新数据库表结构与数据库中已存在的数据。当升级完成时，数据库表结构及数据应当与升级后的产品版本保持一致。 当升级失败时（比如在升级过程中出现网络连接失败），我们应当支持对失败进行修复。 更多Flyway文章（参考以下文档） 数据库版本管理工具Flyway——基础篇 Flyway学习笔记 官方文档 Maven配置在pom文件当中定义如下属性，以便在插件配置中进行重用 1234&lt;properties&gt; &lt;db.url&gt;jdbc:h2:~/flyway-test&lt;/db.url&gt; &lt;db.username&gt;sa&lt;/db.username&gt;&lt;/properties&gt; maven项目配置依赖 1234567891011121314151617181920212223242526272829303132333435363738&lt;!-- We'll add the latest version of jOOQ and our JDBC driver - in this case H2 --&gt;&lt;dependency&gt; &lt;!-- Use org.jooq for the Open Source Edition org.jooq.pro for commercial editions, org.jooq.pro-java-6 for commercial editions with Java 6 support, org.jooq.trial for the free trial edition Note: Only the Open Source Edition is hosted on Maven Central. Import the others manually from your distribution --&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq&lt;/artifactId&gt; &lt;version&gt;3.10.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;1.4.177&lt;/version&gt;&lt;/dependency&gt;&lt;!-- For improved logging, we'll be using log4j via slf4j to see what's going on during migration and code generation --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- To ensure our code is working, we're using JUnit --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; Flyway插件 12345678910111213141516171819202122232425&lt;plugin&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;!-- Note that we're executing the Flyway plugin in the "generate-sources" phase --&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;migrate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!-- Note that we need to prefix the db/migration path with filesystem: to prevent Flyway from looking for our migration scripts only on the classpath --&gt; &lt;configuration&gt; &lt;url&gt;$&#123;db.url&#125;&lt;/url&gt; &lt;user&gt;$&#123;db.username&#125;&lt;/user&gt; &lt;locations&gt; &lt;location&gt;filesystem:src/main/resources/db/migration&lt;/location&gt; &lt;/locations&gt; &lt;/configuration&gt;&lt;/plugin&gt; jooq的maven配置 12345678910111213141516171819202122232425262728293031323334353637383940&lt;plugin&gt; &lt;!-- Use org.jooq for the Open Source Edition org.jooq.pro for commercial editions, org.jooq.pro-java-6 for commercial editions with Java 6 support, org.jooq.trial for the free trial edition Note: Only the Open Source Edition is hosted on Maven Central. Import the others manually from your distribution --&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen-maven&lt;/artifactId&gt; &lt;version&gt;$&#123;org.jooq.version&#125;&lt;/version&gt; &lt;!-- The jOOQ code generation plugin is also executed in the generate-sources phase, prior to compilation --&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!-- This is a minimal working configuration. See the manual's section about the code generator for more details --&gt; &lt;configuration&gt; &lt;jdbc&gt; &lt;url&gt;$&#123;db.url&#125;&lt;/url&gt; &lt;user&gt;$&#123;db.username&#125;&lt;/user&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;database&gt; &lt;includes&gt;.*&lt;/includes&gt; &lt;inputSchema&gt;FLYWAY_TEST&lt;/inputSchema&gt; &lt;/database&gt; &lt;target&gt; &lt;packageName&gt;org.jooq.example.flyway.db.h2&lt;/packageName&gt; &lt;directory&gt;target/generated-sources/jooq-h2&lt;/directory&gt; &lt;/target&gt; &lt;/generator&gt; &lt;/configuration&gt;&lt;/plugin&gt; 数据库增量当我们开始开发我们的数据库时。为此，我们将创建数据库增量脚本，我们将其放入src/main/resources/db/migration目录中，如之前为Flyway插件配置的那样。我们将添加这些文件： V1__initialise_database.sql V2__create_author_table.sql V3__create_book_table_and_records.sql 这三个脚本模拟我们的模式版本1-3（注意大写V！）。这是脚本的内容 1234-- V1__initialise_database.sqlDROP SCHEMA flyway_test IF EXISTS;CREATE SCHEMA flyway_test; 12345678910111213-- V2__create_author_table.sqlCREATE SEQUENCE flyway_test.s_author_id START WITH 1;CREATE TABLE flyway_test.author ( id INT NOT NULL, first_name VARCHAR(50), last_name VARCHAR(50) NOT NULL, date_of_birth DATE, year_of_birth INT, address VARCHAR(50), CONSTRAINT pk_author PRIMARY KEY (ID)); 123456789101112131415161718-- V3__create_book_table_and_records.sqlCREATE TABLE flyway_test.book ( id INT NOT NULL, author_id INT NOT NULL, title VARCHAR(400) NOT NULL, CONSTRAINT pk_book PRIMARY KEY (id), CONSTRAINT fk_book_author_id FOREIGN KEY (author_id) REFERENCES flyway_test.author(id));INSERT INTO flyway_test.author VALUES (next value for flyway_test.s_author_id, 'George', 'Orwell', '1903-06-25', 1903, null);INSERT INTO flyway_test.author VALUES (next value for flyway_test.s_author_id, 'Paulo', 'Coelho', '1947-08-24', 1947, null);INSERT INTO flyway_test.book VALUES (1, 1, '1984');INSERT INTO flyway_test.book VALUES (2, 1, 'Animal Farm');INSERT INTO flyway_test.book VALUES (3, 2, 'O Alquimista');INSERT INTO flyway_test.book VALUES (4, 2, 'Brida'); 数据库迁移与代码生成以上的三个脚本会由Flyway选取并按照版本顺序执行。执行命令 1mvn clean install 之后观察log from flyway 123456789[INFO] --- flyway-maven-plugin:3.0:migrate (default) @ jooq-flyway-example ---[INFO] Database: jdbc:h2:~/flyway-test (H2 1.4)[INFO] Validated 3 migrations (execution time 00:00.004s)[INFO] Creating Metadata table: "PUBLIC"."schema_version"[INFO] Current version of schema "PUBLIC": &lt;&lt; Empty Schema &gt;&gt;[INFO] Migrating schema "PUBLIC" to version 1[INFO] Migrating schema "PUBLIC" to version 2[INFO] Migrating schema "PUBLIC" to version 3[INFO] Successfully applied 3 migrations to schema "PUBLIC" (execution time 00:00.073s). jooq log 123456789[INFO] --- jooq-codegen-maven:3.10.8:generate (default) @ jooq-flyway-example ---[INFO] --- jooq-codegen-maven:3.10.8:generate (default) @ jooq-flyway-example ---[INFO] Using this configuration:...[INFO] Generating schemata : Total: 1[INFO] Generating schema : FlywayTest.java[INFO] ----------------------------------------------------------[....][INFO] GENERATION FINISHED! : Total: 337.576ms, +4.299ms 发展每当有人向Maven模块添加新的迁移脚本时，所有前面的步骤都会自动执行。例如，团队成员可能已经提交了一个新的迁移脚本，您可以将其检出，重建并获取最新的jOOQ生成的源，以用于您自己的开发或集成测试数据库。 现在，完成这些步骤后，您可以继续编写数据库查询。想象一下以下测试用例 12345678910111213141516171819202122232425262728293031323334import org.jooq.Result;import org.jooq.impl.DSL;import org.junit.Test;import java.sql.DriverManager;import static java.util.Arrays.asList;import static org.jooq.example.flyway.db.h2.Tables.*;import static org.junit.Assert.assertEquals;public class AfterMigrationTest &#123; @Test public void testQueryingAfterMigration() throws Exception &#123; try (Connection c = DriverManager.getConnection("jdbc:h2:~/flyway-test", "sa", "")) &#123; Result&lt;?&gt; result = DSL.using(c) .select( AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME, BOOK.ID, BOOK.TITLE ) .from(AUTHOR) .join(BOOK) .on(AUTHOR.ID.eq(BOOK.AUTHOR_ID)) .orderBy(BOOK.ID.asc()) .fetch(); assertEquals(4, result.size()); assertEquals(asList(1, 2, 3, 4), result.getValues(BOOK.ID)); &#125; &#125;&#125; SQL构建https://www.jooq.org/doc/3.10/manual/sql-building/ 查询DSL类型JOOQ暴露了许多接口，并隐藏了客户端代码的大多数实现，原因是 接口驱动设计，允许最有效地在流畅的API中建模查询 降低客户端代码的复杂性 API保证，只依赖于公开的接口，而不是具体的实现。 1import static org.jooq.impl.DSL.*; DSL子类 每种SQL方言都有自己的方言专用DSL，如只使用MySQL方言，则可以选择引用MySQLDSL而不是标准DSL DSLContext类创建 12345// Create it from a pre-existing configuration，从预先的配置中创建DSLContext create = DSL.using(configuration);// Create it from ad-hoc arguments，从ad-hoc参数创建DSLContext create = DSL.using(connection, dialect); 配置 可以为这些对象提供配置： org.jooq.SQLDialect：数据库的方言。这可能是任何当前支持的数据库类型（有关详细信息，请参阅SQL Dialect） org.jooq.conf.Settings：可选的运行时配置（有关详细信息，请参阅自定义设置） org.jooq.ExecuteListenerProvider：对可以为jOOQ提供执行侦听器的提供程序类的可选引用（有关详细信息，请参阅ExecuteListeners） org.jooq.RecordMapperProvider：对可以为jOOQ提供记录映射器的提供者类的可选引用（有关详细信息，请参阅带有RecordMappers的POJO） 任何这些： java.sql.Connection：可选的JDBC连接，将在配置的整个生命周期中重复使用（有关详细信息，请参阅连接与数据源）。为简单起见，这是本手册中引用的用例，大部分时间都是如此。 java.sql.DataSource：一个可选的JDBC DataSource，它将在Configuration的整个生命周期中重用。如果您更喜欢在Connections上使用DataSources，jOOQ将在内部从您的DataSource获取新的Connections，在查询执行后方便地再次关闭它们。这在J2EE或Spring上下文中特别有用（有关详细信息，请参阅Connection与DataSource） org.jooq.ConnectionProvider：jOOQ用于“获取”和“释放”连接的自定义抽象。jOOQ将在内部“获取”来自ConnectionProvider的新连接，在查询执行后方便地“释放”它们。（有关详细信息，请参阅Connection vs. DataSource） SQL语句（DML）SQL语句（DDL）参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：概述]]></title>
    <url>%2F2019%2F07%2F06%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[概述因特网目前具有着数以亿计的相连的计算机、通信链路和交换机。 面对如此巨大并且具有如此众多不同组件和用户的因特网，是否能够理解其工作原理。其是否存在某些指导原则和结构，能够作为理解规模和复杂程度惊人的系统的基础。 什么是因特网 以因特网的具体构成来描述，即构成因特网的基本硬件和软件组件 根据为分布式应用提供服务的联网基础设施描述因特网 具体构成描述以因特网的角度来看，所有接入网络的设备都称为主机或端系统。 端系统间的通信端系统通过通信链路和分组交换机连接到一起。当一台端系统要向另一台端系统发送数据时，发送端系统将数据分段，并为每段加上首部字节，由此形成的信息包称为分组，分组通过网络发送到目的端系统，在那里装配成初始数据。 分组交换机的工作分组交换机从它的一条入通信链路接受到达的分组，并从它的一条出通信链路转发该分组。 分类 路由器。位于网络层，通常用于网络核心中。 链路层交换机。位于链路层，通常用于接入网中。 网络路径 在发送端到接收端，一个分组所经历的一系列通信链路和分组交换机称为通过该网络的路径。 总结 分组交换网络很类似于承载运输车辆的运输网络，包括着高速公路、公路和立交桥。分组即是卡车，通信链路类似于高速公路与公路，而分组交换机类似于立交桥，端系统就像是建筑物。因此就像卡车寻找目的地意义，分组选取网络中一条路径前行 ISP（接入因特网）端系统通过因特网服务提供商（ISP）接入因特网。包括了住宅区ISP、公司ISP、学校ISP、WIFI接入的ISP。 每个ISP是一个由多个分组交换机和多段通信链路组成的网络。 各ISP为端系统提供了各种不同类型的网络接入。包括有线接入、高速局域网接入、无线接入等等。ISP也为内容提供者提供因特网接入服务，将Web站点直接接入因特网。 ISP互联 因特网就是将端系统彼此关联，因此为端系统提供接入服务的ISP也必须互联。底层的ISP通过国家的高层ISP互联起来，高层ISP由高速的路由器组成。每个ISP都是独立管理，运行着IP协议 。 协议端系统、分组交换机和其他因特网部件都要运行一系列的协议，控制因特网中信息的接受和发送。 IP协议定义了在端系统和路由器之间发送和接收的分组格式。 服务描述从应用程序提供服务的基础设施的角度描述因特网。 分布式应用程序：涉及到多台互相交换数据的端系统。如社交网络等。 为使得运行在一个端系统上的应用程序向因特网上运行在另一个端系统上的软件发送消息。与因特网相连的端系统提供了一个应用程序编程接口API（类似于邮政服务），规定了运行在一个端系统上的软件请求因特网基础设施向运行在另一个端系统上特定目的地软件交付数据的方式。 协议何为协议，协议是做什么的。 网络协议 一个协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及报文发送和/或接收一条报文或其他事件所采取的动作。 交换报文和采取动作的实体是某些设备的硬件或软件组件，是具有网络能力的设备。 在因特网当中，凡是涉及两个或多个远程通信实体的所有活动都受到协议的制约。 在两台物理上连接的计算机中，硬件实现的协议控制了在两块网络接口卡间的“线上”的比特流。在端系统中，拥塞控制协议控制了在发送端和接收方间的传输的分组发送的速率。 网络边缘在此处，进行深入探究计算机网络的部件。从网络边缘开始观察部件。如计算机、手机等，从边缘向核心推进。 主机或者说端系统，可以分为两类： 客户。 服务器。服务器用于存储和发布web页面等。 接入网接入网，即将端系统连接到其边缘路由器的物理链路。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。 家庭接入接入方式有DSL、电缆、FTTH、拨号、卫星。DSL（数字用户线）和电缆是当下最流行的方式。 DSL接入 用户通常从提供电话接入获得DSL接入，使用DSL时，本地电话公司也是它的ISP。每个用户的DSL调制解调器使用现有的电话线（双绞铜线）与位于本地电话公司的本地中心局中的数字用户线接入复用器（DSLAM）来交换数据。家庭的DSL调制解调器得到数字数据后将其转换为高频音，以通过电话线传输给本地中心局。即模拟信号在DSLAM处被转换回数字形式。 家庭电话线同时承载了数据和传统的电话信号，它们编码位不同的频率。这种方式下，单根的DSL线路如同三根线路，使得一个电话与一个因特网连接同时共享DSL链路（频分复用）。 高速下行信道，50KHZ到1MHZ。 中速上行信道，4KHZ到50KHZ。 普通的双向电话信道，0到4KHZ。 在用户侧，分频器将到达家庭的数据信号和电话信号分隔，将数据信号转发给DSL调制解调器。在本地电话公司侧，DSLAM将数据和电话信号分割开，并将数据送往因特网。 电缆接入 利用了有线电视公司现有的有线电视基础设施。在该系统当中应用了光纤和同轴电缆，因此也被称为混合光纤同轴 电缆因特网接入需要特殊的调整解调器，称为电缆调制解调器。通常是一个外部设备，以一个以太网端口接入家庭。 在电缆头部，电缆调制解调器端接系统（CMTS）起到如同DSL网络的DSLAM类似的功能，将来自许多下行家庭中的电缆调制解调器发送的模拟信号转回数字形式。 电缆因特网接入的一个重要特征是共享广播媒体。特别是由头端发送的每个分组向下行经每段链路到每个家庭；每个家庭发送的每个分组经上行信道向头端传输。 因此若几个用户同时经下行信道下载一个视频文件，每个用户接收的实际速率将大大低于电缆总计的下行速率。 若仅仅有很少的用户在web上，则每个用户都可以以下行速率的全部接收web网页。 因为上行信道也是共享的，需要一个分布式多路访问协议来协调传输和避免碰撞。 光纤到户FTTH 从本地中心局直接到家庭提供一条光纤路径。光纤分布体系结构有：主动光纤网络AON和被动光纤网络PON AON基本上就是交换因特网。PON的FTTH结构如下 企业和家庭接入以太网 在公司和大学校园以及家庭当中，通常是使用局域网（LAN）将端用户连接到边缘路由器。以太网是目前为止最为流行的接入技术。以太网用户使用双绞铜线与一台以太网交换机相连，以太网交换机再与更大的因特网相连。 在该接入下，用户通常以100mbps速率接入交换机，而服务器可能具有1Gbps甚至10Gbps WIFI 在智能手机的加入后，若是使用无线LAN接入，用户从一个接入点发送/接收分组，该接入点与企业网相连，该企业网再与有线因特网相连。一个无线LAN用户需要在接入网几十米范围内。 WIFI+宽带 将DSL或电缆调制解调器与WIFI结合起来。组成有：漫游的便携机、有线PC、与无线通信的基站（无线接入点）、提供与因特网宽带接入的电缆调整解调器、互联了基站以及带有电缆调制解调器的固定PC的路由器。 该网络允许家庭成员经过宽带接入因特网，可以在各个位置漫游上网。 广域无线接入3G 应用了与移动电话相同的基础设施，通过蜂窝网提供商运营的基站发送接收分组。一个用户只需要在基站数万米内即可。 物理媒体HFC使用了光缆和同轴电缆相结合的技术；DSL和以太网使用了双绞铜线；移动接入网使用了无线电频谱。 考虑一个比特的短暂历程。 一个比特从一个端系统开始传输，经过一系列链路和路由器，到达另一个端系统。 这个比特被传输许多多此，源端系统首先传输这个比特，之后一台路由器接收、传输该比特，由路由器进行转发传输。 通过一系列的“传输-接收器”，它们通过跨越一种物理媒体传输电磁波或光脉冲来发送该比特。 该物理媒体可以有多重形状和形式。对于传输-接收器也不必具有相同的类型 物理媒体划分为两类：导引型媒体与非导引型媒体。 导引型：电波沿着固体媒体前行，如光缆、双绞铜线或同轴电缆 非导引型媒体：电波在空气或外层空间中传输，如无线局域网或数字卫星频道 双绞铜线同轴电缆光纤陆地无线电信道微信无线电信道网络核心深入研究网络的核心，即由互联网因特网端系统的分组交换机和链路构成的网状网络。 通过网络链路和交换机移动数据有两种基本方式：电路交换和分组交换。 分组交换端系统彼此交换报文。报文能够包含协议设计者需要的任何东西。报文可以执行一种控制功能，也可以包含数据。 为了从源端系统向目的端系统发送一个报文，源将长报文划分为较小的数据块，称为分组，每个分组都通过通信链路和分组交换机（路由器与链路层交换机）传送。分组以等于该链路最大传输速率的速度传输通过通信链路。 存储转发传输多数的分组交换机在链路的输入端使用存储转发传输机制。存储转发机制是指交换机能够开始向输出链路传输该分组的第一个比特前，必须接收到整个分组。 举例 考虑由两个经一台路由器连接的端系统。 路由器将分组从一条输入链路转移到另一条唯一的连接链路。当分组1的前沿到达路由器时，由于路由器使用存储转发机制，此时还不能将传输已经接收的比特，而是必须先缓存该分组的比特。当路由器已经接收完了该分组的所有比特后，才能向出链路转发该分组。 当源在时刻0进行传输，则在时刻L/R秒（L：分组的比特数，R：链路的传输速率，是将所有分组比特推向链路所需要的时间），路由器刚好接收到整个分组，此时可以进行转发。在时刻2L/R秒，路由器已经传输了整个分组，并被目的地接收。因此总时延是2L/R。若交换机不必进行存储转发，则总时延是L/R。实际的发送时延通常在毫秒到微秒级。 端到端时延 端到端的传输时延是d=NL/R（N为链路数目，中间有N-1台路由器） 排队时延和分组丢失每个分组交换机有一个输出缓存（输出队列），用于存储路由器准备发往哪条链路的分组。如果到达的分组需要传输到某条链路，但发现该链路正忙于传输其他分组，该到达分组必须在输出缓存中等待，因此分组还要承受输出缓存的排队时延。 排队时延是变化的，程度取决于网络中的拥塞程度。 分组丢失：由于缓存空间的大小有限，一个到达的分组可能发现该缓存已经被其他等待传输的分组完全充满了，在此情况下会出现丢包。到达的分组或已经排队的分组之一被丢弃 转发表和路由选择协议路由器从与它相连的一条通信链路获得分组，将其向与它相连的另一条通信链路转发。但是路由器如何决定它应该向哪条链路进行转发呢？不同的额计算机网络以不同的方式完成的 因特网中，每个端系统当中具有一个称为IP地址的地址。当源主机向目的端系统发送一个分组时，源在该分组的首部包含了目的地的IP地址。 根据IP地址进行转发 IP地址具有等级结构，当一个分组到达网络中的路由器时，路由器检查该分组的目的地址的一部分，并向一台相邻路由器转发该分组。路由器有一个转发表用于映射目的地址（或目的地址的一部分）到 输出链路。 转发表是如何设置的呢 因特网具有一些特殊的路由选择协议，用于自动地设置这些转发表。 电路交换电路交换网络中，在端系统间通信会话期间，预留了端系统间通信沿路径所需要的资源（缓存、链路传输速率）。会话的报文按需使用这些资源，其后果可能是不得不等待接入通信线路。 传统的电话网络是电路交换网络的实例，当一个人通过电话网向另一个人发送信息时，在发送方能够发送信息前，该网络必须在发送方和接收方建立一条连接，路径上的交换机都会为该连接维护连接状态。该连接被称为一条电路。 当网络创建这种电路时，也在该连接期间在该网络链路上预留了恒定的传输速率，即发送方能够以确保的恒定速率向发送方传送数据。 电路交换网络中的复用频分复用FDM 链路的频谱由跨越链路创建创建的所有连接所共享。在连接期间，链路为每条连接专用一个频段。在电话网络中该频段通常具有4kHZ的带宽，该频段的宽度称为带宽。调频无线电台使用FDM共享88-108kHZ的频谱，每个电台被分配一个特定的频段。 时分复用TDM 时间被划分为固定的帧，每帧被划分为固定的时隙，当网络跨越一条链路创建一条连接时，网络在每个帧内为该连接指定一个时隙。这些时隙专门由该连接单独使用。 分组交换与电路交换对比 分组交换不适合实时服务（电话等），因为它的端到端时延是可变而不可预测的。（排队时延的变动） 分组交换提供了比电路交换更好地带宽共享 分组交换比电路交换更简单、更有效、成本更低。 分组交换为何更加有效 假设 当多个用户共享一条1Mbps的链路，假定用户活跃周期是变化的 某用户以100kps恒定速率产生数据，时而静止。 假定用户有10%时间活跃。 电路交换 对于电路交换，在所有的时间内必须为每个用户预留100kbps。因此该电路交换链路只能支撑10个并发用户。 分组交换 对于分组交换，一个用户的活跃概率为10%，若有35个用户，则存在11个或更多个活跃用户的概率大约是0.0004，当存在10个以下时，到达的聚合数据率小于输出速率1Mbps，因此基本没有时延，与电路交换一致。 当活跃用户超过10人，则输出队列开始变长，直到聚合输入率小于输出率。由于概率较低，因此总是提供了电路交换相同的性能 情境2 有10个用户，每个用户突然产生1000个1000比特的分组，其他用户静默。 在电路交换中，若有10个时隙，则只有一个时隙用来传输数据。而在分组交换下，活跃用户能够连续以1Mbps速度进行发送数据。 总结 因此在相同较少人数的时候，分组交换与电路交换的性能一致；在人数很少时，分组交换的性能远超电路交换；在人数较多时，电路交换只能等待，而分组交换依然可用，只是存在延迟。 网络的网络端系统通过接入ISP与因特网相连，但为端用户和内容提供商提供和接入ISP仅解决了连接难题中的很小一部分，因为因特网是由数以亿计的用户构成的。因此接入ISP自身必须互联。通过创建网络的网络可以做到这一点。 为了能够使得所有端系统都能够彼此发送分组。较为幼稚的做法是接入ISP直接与其他ISP连接，但是成本太高。 网络结构1用单一的全球承载ISP互联所有接入ISP，假象的全球承载ISP是一个由路由器和通信链路构成的网络，该网络至少具有一个路由器靠近数十万接入ISP中的每一个。为了有利可图，接入ISP被认为是客户，全球承载ISP被认为是提供商 网络结构2若某个公司建立并运行了一个可盈利的全球承载ISP，其他公司建立自己的全球承载ISP并与最初的全球承载ISP竞争。即 数十万接入ISP与多个全球承载ISP组成，并且这些全球承载ISP互联。 网络结构3在网络的第一层，有多个竞争的第一层ISP。在一个区域当中，有多个竞争的区域ISP。在某些区域当中，可能有较大的区域ISP（跨越国家），区域中较小的ISP与之相连等。 每个接入ISP向区域ISP支付连接费用，每个区域ISP向第一层ISP付费。 网络结构4为了建造一个与今天因特网更为相似的网络，需要在网络结构3的基础上增加存在点（POP）、多宿、对等和因特网交换点（IXP）。 PoP PoP存在于等级结构中的所有层次，除底层（接入ISP）外，一个PoP只是提供商网络中的一台或多台（在相同位置）路由器群组，其中客户ISP能够与提供商ISP连接。对于要与提供商PoP连接的客户网络，能够从第三方通信提供商租用高速链路直接将它的路由器之一连到位于该PoP的一台路由器。 多宿 任何ISP（除接入ISP）可以选择为多宿，即与两个或更多提供商ISP连接，即使提供商之一出现故障，仍然可以接收和发送分组。 对等 客户ISP向它们的提供商ISP付费已获得全球因特网互联能力，客户ISP支付的费用反映了它的流量。为了减少费用，位于相同等级结构层次的临近一对ISP能够对等。即他们的网络可以直接相连，使得他们间所有流量经直接连接而不是通过上游的中间ISP传输 对等的ISP通常不进行结算，第三方公司创建一个因特网交换点（IXP），多个ISP在这里共同对等。 网络结构5描述2012年的因特网 在网络结构4的顶部增加内容提供商网络构建而成。该网络仅仅承载出入其服务器主机的流量，并且尝试与较低层ISP对等尝试绕过较高层 分组交换网中的时延、丢包和吞吐量因特网能够看成是一种为运行在端系统上的分布式应用提供服务的基础设施。在理想情况下，我们希望因特网服务能够在任意两个端系统间瞬间移动我们想要的大量数据而没有任何数据丢失。但是这是一个极高的目标。 计算机网络必定要限制在端系统间的吞吐量，在端系统间引入时延，而且实际上能够丢失分组。 分组交换网中的时延概述分组从主机出发，经过一系列路由器传输，在目的地结束里程。在沿途每个结点经受了集中不同的时延，最为重要的有 结点处理时延 通常微不足道，但是对一台路由器的最大吞吐量有重要影响，是路由器能够转发分组的最大速率 排队时延 传输时延 对于LAN等可能微不足道，对于低速拨号调制解调器链路发送的长因特网分组而言是主要成分 传播时延 对于位于同一个大学的两台路由器间可能微不足道，但是对于同步卫星互联的来说可能是主要成分 它们的累加即是结点总时延。 时延的类型一个分组从上游结点通过路由器A向路由器B发送，路由器A具有通往路由器B的出链路。该链路前有一个队列。当该分组从上游结点到达路由器A时，路由器A检查该分组的首部以决定该分组的适当出链路，并将该分组导向该链路。 仅当该链路没有其他分组正在传输并且没有其他分组在前面排队时，才能在该链路上进行传输，否则要参与排队。 处理时延 检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。处理时延也包含其他因素，如检查比特级别的差错所需要的时间。 排队时延 在队列中，当分组在链路上等待传输时，经受排队时延。该时延与入流量与出流量有关。 传输(发送)时延 用L比特表示该分组的长度，用Rbps表示从路由器A到B的传输速率。则传输时延是L/R。是一个收费站的概念。 传播时延 一旦一个比特被推向链路，该比特需要向路由器B传播，从该链路的起点到路由器B传播所需要的时间就是传播时延。时延为d/s。是在高速公路上行驶的概念，但是速度非常快。 排队时延和丢包排队时延对于不同的分组时不同的，在一个队列当中，第一个为0，最后一个要承受相对大的排队时延。因此，在表征排队时延时，人们通常使用统计量测度，如平均排队时延、排队时延的方差和排队时延超过某些特定值的概率。 排队时延很大程度上取决于流量到达该队列的速率、链路的传输速率与到达流量的性质（流量是周期性到达还是突发形式到达）。 流量强度令a表示分组到达队列的平均速率（a的单位是分组/s，即pkt/s）。R为传输速率，即从队列中推出比特的速率（b/s），假定所有分组都是L比特，则比特到达队列的平均速率为La bps，假定队列非常大，可以容纳无限数量的比特，速率La/R称为流量强度。 若La/R&gt;1则比特到达队列的平均速率超过从该队列传输出去的速率，此时队列将趋于无界增加。 考虑La/R&lt;=1，则到达流量的性质会影响排队时延。若分组周期到达，如L/R秒到达，则每个分组将到达一个空队列中。若是分组以突发形式到达，则有很大的平均排队时延。 当流量强度接近于1，将存在到达率超过传输能力的时间间隔，在这些时间内将形成队列，随着越接近1，则平均排队长度变得越来越长。即该强度少量的增加将导致时延大得多的增加。 丢包现实当中，从路由器角度看，一条链路的队列只有优先的容量，其极大依赖于路由器设计和成本。随着流量强度接近1，当到达的分组发现一个满的队列，则路由器会丢弃该分组。 从端系统角度看，一个分组已经传输到网络核心，但是它绝不会从网络发送到目的地，分组丢失的份额随着流量强度增加而增加。 因此一个结点的性能可以通过时延来度量，也可以通过分组丢失的概率来度量。 端到端时延考虑从源主机到目的地的总时延，假定源主机和目的主机之间有N-1台路由器，假设网络此时无堵塞（即排队时延忽略），在每台路由器和源主机上的处理时延是Dproc，每台路由器和源主机的输出速率是Rbps，即Dtrans=L(分组长度)/R，每条链路的传播时延是Dprop，累加得到端到端时延。 Dend-end=N（Dproc+Dtrans+Dprop） 该时延忽略了处理时延与传播时延。弱化了排队时延。 TracerouteTraceroute是一个简单的程序，能够在任何因特网主机上运行，当用户制定一个目的主机名字时，源主机的该程序朝着该目的地发送多个特殊的分组。当分组向目的地传送时，通过一系列的路由器，当路由器接收到这些特殊分组之一时，它向源回送一个短报文，包括该路由器的名字和地址。 即Traceroute会向路径上的所有路由器发送分组。它可以重建路径上所采用的路由。 端系统、应用程序和其他时延端系统中还存在一些其他重要时延。 作为它的协议的一部分，希望向共享媒体（如在Wifi或电缆调制解调器情况下）传输分组的端系统可以有意地延迟它的传输以与其他端系统共享媒体。 吞吐量考虑从主机A到主机B跨越计算机网络传送一个大文件。在任何时间瞬间的瞬时吞吐量是主机B接收该文件的速率（bps）。若文件由F比特组成，接收到所有比特用去T秒，则平均吞吐量为F/Tbps。 考虑服务器与客户端的端系统，它们由两条链路和一台路由器相连。考虑从服务器传送一个文件到客户的吞吐量。即令Rs表示服务器与路由器间的链路速率，Rc表示路由器与客户间的链路速率。 则若Rs&gt;Rc，那么路由器将不能以接收比特那样块的速率进行转发比特，即以Rc离开路由器，若依然是Rs的发送速率，那么比特将不断的挤压在路由器中。因此吞吐量是min{Rc,Rs}。即瓶颈链路的传输速率。（近似值，未考虑分组层次与协议）。 在今天因特网当中对吞吐量限制因素通常是接入网。并且吞吐量不仅仅取决于瓶颈路径，还取决于干扰流量（多个人同时下载占用链路） 协议层次及其服务模型进行分层的体系结构，使得实现由层所提供的服务容易改变，只要该层对其上面的层提供相同的服务，并且使用来自下面层次的相同服务，当某层的实现变化时，该系统的其余部分保持不变。 协议分层一个协议层能够用软件、硬件或两者的结合来实现 HTTP与SMTP等应用层协议几乎总是在端系统中用软件实现的，运输层协议也是如此。 因为物理层和数据链路层负责处理跨越特定链路的通信，它们通常是实现在与给定链路相联系的网络接口卡（WiFi接口卡）。 网络层通常是硬件和软件实现的混合体。 一个第n层协议也会分布在构成网络的端系统、分组交换机和其他组件中。 因特网的协议栈由五个层次组成。：物理层、链路层、网络层、运输层、应用层。 优缺点 概念化 结构化 缺点： 一层可能会冗余较低层的功能。 某层的功能可能需要仅在其他某层才出现的信息。违反了层次分离的目标 应用层应用层是网络应用程序以及它们的应用层协议存留的地方。一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息的分组，将这种信息分组称为报文。 运输层接受上一层的数据，并将数据交给网络层，并保证这些数据段有效到达对端。 运输层在应用程序的端点间传送应用层的报文。有TCP与UDP协议。该层的分组称为报文段。 TCP向他的应用程序提供了面向连接的服务，包括了应用层报文向目的地确保传递和流量控制。TCP将长报文划分为短报文，并提供拥塞控制机制，当网络拥塞时，抑制传输速率。 UDP向应用程序提供无连接的服务。 网络层如何找到目标节点，如何选择最佳路径。将网络地址翻译为物理地址，指导数据传输。 该层的分组称为数据报，网络层负责将数据报从一台主机移动到另一台主机。其协议包括IP协议等协议。 IP协议定义了在数据报中的各个字段以及端系统和路由器如何作用于这些字段。IP协议作为粘合剂将因特网连接在一起，因特网的网络层也包括决定路由的路由选择协议。 链路层定义了如何格式化数据以进行传输，如何控制对物理介质的访问，通常提供错误检测和纠正，保证数据正确传输。 链路层将分组从一个结点（主机或路由器）移动到路径上的下一个结点。链路层的分组称为帧 由链路层提供的服务取决于应用于该链路的特定链路层协议。某些协议基于链路提供可靠传递，从传输结点跨越一条链路到接受结点。但是这不同与TCP的可靠，因为TCP是基于端系统的可靠传输，而这个过程中要经过很多的链路。 物理层首先解决两台物理机间的通信需求，即它们之间发送比特流，它们主要定义各种物理设备的标准，例如网线类型、光纤类型等。 其主要功能是传输比特流，物理层将帧一个一个比特从一个结点移动到下一个结点，该层协议仍然是链路相关的，并且与该链路的实际传输媒体相关。 封装 在发送主机端，一个应用层报文被传输给运输层 运输层收到报文并附上附加信息（运输层的首部信息），应用层报文与运输层首部信息构成了运输层报文段 网路层增加网络层首部信息，产生了网络层数据报 链路层增加链路层首部信息，创建链路层帧 因此，每一层都具有两种类型的字段：首部字段和有效载荷字段。 面对攻击的网络能够经因特网将有害程序放入计算机能够攻击服务器和网络基础设施能够嗅探分组能够伪装成你信任的人因特网最新发展 家庭宽带网接入的积极发展 高速公共WiFi和4G蜂窝电话网的中速因特网接入越来越普及 在线服务上如Google在因特网上部署了自己的广泛的专用网络。因此谷歌几乎可以立即提供搜索结果 许多公司在云上运行他们的应用，为应用提供可扩展的计算和存储环境，也为应用提供高性能专用网络的隐含访问。 参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程语法学习]]></title>
    <url>%2F2019%2F07%2F06%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[编程语法学习基本语法由表及里，首先学习基本的词汇与语法。 编码实践每一门编程语言的学习都会涉及到： 运行环境 数据类型（数字、字符串、数组、集合、映射字典等） 表达式 函数 流程控制 类、方法 学习一门新的语言时，要利用以前所学习的语言的功底，但是也要保持开放的心态。（认知心理学） 技近乎道基础语法的学习，能够让你快速上手，应用实践。对技巧和坑的关注会一定程度上拓展知识面。 系统学习，一方面会进一步拓展知识面，另一方面有利于语言知识结构的形成。 任何一门成熟语言，都有其特有的生态。包括框架、扩展包、解决方案、模式、规范等。在时间中可以不断掌握框架等的使用。 在此情况下，还可以继续去学习语言更底层的东西，而不仅仅留在应用层。如Java中的集合类实现的算法与数据结构，JVM如何执行Java代码等。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Kotlin：StudyResources]]></title>
    <url>%2F2019%2F07%2F05%2FKotlin%2FKotlin%EF%BC%9AStudyResources%2F</url>
    <content type="text"><![CDATA[[Kotlin极简教程] 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Kotlin：start]]></title>
    <url>%2F2019%2F07%2F05%2FKotlin%2FKotlin%EF%BC%9Astart%2F</url>
    <content type="text"><![CDATA[待整理Kotlin语言基础包Kotlin沿用了Java的package概念，同时做出了扩展。 包的声明位于源文件顶部。目录与包的结构无需匹配，即源代码可以在文件系统的任意位置。 若不顶用 内部可以定义包函数。包函数可以与类在同一个包的命名空间下，在此情况下， 包函数可以直接调用而不需要import 若不在一个包下，则需要import对应的类与函数 声明变量和值 声明变量和值kotlin当中一切都是对象。变量可分为： var： var是一个可变变量，这是一个可以通过重新分配来更改为另一个值的变量。这种声明变量的方式和Java中声明变量的方式一样。 val： val是一个只读变量，这种声明变量的方式相当于java中的final变量。一个val创建的时候必须初始化，因为以后不能被改变。 变量类型推断省去变量类型Kotlin中大部分情况不需要说明使用对象的类型，由编译器推断出他的类型。当然也可以明确地指出变量的类型。 is进行类型检测is检测一个表达式是否某类型的一个实例 如果一个不可变的局部变量或属性已经判断出为某类型，那么检测后的分支中可以直接当作该类型使用，无需显式转换： 参考 SpringBoot 2.X Kotlin 系列之Hello World]]></content>
      <categories>
        <category>Kotlin</category>
      </categories>
      <tags>
        <tag>Kotlin</tag>
        <tag>start</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计：domain]]></title>
    <url>%2F2019%2F07%2F05%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%9Adomain%2F</url>
    <content type="text"><![CDATA[domain建模示例发布帖子Round-I业务建模在大家的常识中，每个人都有自己的观点，并可以发表自己的观点，在社区中便表现为：发布帖子。那么谁发布帖子呢？ 很明显是帖子作者，于是我们便可以得到如下描述：帖子作者发布帖子。从上述描述中，我们很容易得到如下几个实体及其行为：帖子作者（PostAuthor）、帖子（Post），而PostAuthor拥有‘发布帖子’的业务行为，我们记着：posting()。 我们再细化现有的模型中的实体。作为实体，必须有一个唯一业务标识，我们为PostAuthor添加一个’作者编号’（authorId），为Post添加一个‘帖子编号’（postId）；PostAuthor可能还存在其他一些属性，我们暂且不管，因为对于我们现在的业务场景无关紧要；再看Post实体，很明显帖子有‘帖子标题’（postTitle）、‘帖子正文’（postContent）、‘帖子发布时间’（postingTime）等等。同时，从业务上要求：帖子发帖时间即为帖子发布动作发生的时间点，帖子的作者是不能为空的，帖子的内容不能为空，帖子的标题可以为空。 此外，为了减少垃圾帖对社区的负面影响，对于‘帖子内容’强制要求帖子内容长度必须不少于16个汉字，字母和数字等同于汉字处理。 总结可以得到‘发布帖子’场景的业务模型描述： 帖子作者发布帖子，帖子标题可以为空，帖子内容不能为空，且不少于16个汉字。 鉴于PostAuthor和Post关系紧密，我们姑且将其和Post放到同一个模块，但是Post看上去并不是PostAuthor的根实体，有点怪怪的感觉，暂且不追究。 业务模型综上，于是我们得到如下的业务模型： 代码Post.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 帖子实体 * @author DAOQIDELV * @CreateDate 2017年9月16日 * */public class Post &#123; /** * 帖子id */ private long id; /** *帖子作者 */ private long authorId; /** * 帖子标题 */ private String title; /** * 帖子源内容 */ private String sourceContent; /** * 发帖时间 */ private Timestamp postingTime; public Post(long authorId, String title, String sourceContent) &#123; this.setAuthorId(authorId); this.setTitle(title); this.setSourceContent(sourceContent); this.postingTime = new Timestamp(System.currentTimeMillis()); &#125; /** * @param authorId the authorId to set */ public void setAuthorId(long authorId) &#123; Assert.isTrue(authorId &gt; 0, "Post's authorId must greater than ZERO."); this.authorId = authorId; &#125; /** * @param sourceContent the sourceContent to set */ public void setSourceContent(String sourceContent) &#123; Assert.isTrue(!StringUtils.isEmpty(sourceContent), "Post's sourceContent must NOT be empty."); this.sourceContent = sourceContent; &#125; //ignore some setter/getter &#125; PostAuthor.java1234567891011121314151617181920212223242526272829/** * 帖子作者 * @author DAOQIDELV * @CreateDate 2017年9月16日 * */public class PostAuthor &#123; private long id; public PostAuthor(long id) &#123; this.id = id; &#125; /** * 发布帖子 * @param title * @param sourceContent * @return Post 发布得到的帖子 */ public Post posting(String title, String sourceContent) throws BusinessException &#123; if(sourceContent.length() &lt; 16) &#123; throw new BusinessException(ExceptionCode.POST_SOURCE_CONTENT_AT_LEAST_SIXTEEN_WORDS); &#125; Post post = new Post(this.id, title, sourceContent); return post; &#125; //ignore some setter/getter&#125; 构造方法 在代码示例中，我们为Post实体提供了一个私有的构造函数，其中只完成了postingTime的初始化，我们的目的是为了限制创建一个空内容的帖子，因为这在实际的业务场景中是不存在的，因此模型也不应当提供这样的构造函数； 另外，还提供了一个包含（authorId,title,sourceContent）的public构造函数，从当前的情形来看是够用了，如果后续有业务场景需要更多的属性传入构造函数，则我们可以重载实现，但是通常来讲，构造函数的入参最好不要超过五个，否则不利于代码阅读，当然特殊业务场景下除外； 最后，在构造函数中，我们并没有直接使用“this.title = title;”的写法，而是使用了这种写法：”this.setTitle(title);”，好处在于我们希望Post实体成为一个“自治的实体”，简单来讲就是可以自我检查 / 自我维护的实体，使用setter的方式，让我们可以再setter方法中加入一些规则判定，使得外部传入的参数满足一定的规格，具体可以参考下一节中的解释。这种处理方式被Martin Fowler称之为“自封装性”，参考了《实现领域驱动设计》P184。 setter方法 接上一节中提到的“自治实体”，我们希望setter方法提供一种校验机制，确保外部传入的参数满足实体的一定规格，也就是具体的业务逻辑。比如说Post实体中的setSourceContent(String sourceContent)方法，业务规则要求：帖子的正文不能为空，因此在Post.setSourceContent(sourceContent)中加入了Assert断言，确保这一规则被强制实现。 参考自Eric Evans的《领域驱动设计》P154。 posting方法 PostAuthor实体现在有了一个业务方法：posting()，它接受具体帖子信息属性，最后返回一个Post实体，很明显PostAuthor现在作为一个Post实体的factory存在。 posting方法对外声明会throw出一个BusinessException异常，BusinessException异常是自定义的业务异常大类，该异常会统一交由框架统一异常处理，这样确保domain领域的干净。posting方法中判定“帖子内容小于16个字”时，便会向上层抛出异常码为2000的BusinessException， Round-II业务建模 我们继续往下探寻业务实体。在讨论中，我们发现发布帖子时，通常需要选择关联哪些话题，且一次性可以关联多个话题，最多可以关联五个话题，且话题不能重复加入。我们尝试用一句话将上述模型表述出来： 帖子可以加入不多于五个话题，且话题不能重复加入。 这样就引入了一个新的实体：话题（Topic），话题持有唯一业务标识，话题应当拥有这些常见的属性：话题名称（title）、话题简介（description）、话题创建者（authorId）、话题创建时间（creatingTime）等；其中，话题名称、话题内容和话题创建者均不能为空。由于这些属性和‘创建话题’的case相关，在这里我们不做过多讨论。 那么Post和Topic的关系是什么呢？肯定不是“聚合”的关系，因为即使Topic消失了，但是Post还在；也不会是“组合”关系，Topic并不是由许多的Post组合而成的；正如业务建模中的描述：Post关联多个话题，所以Post和Topic之间是1：N的关联关系。那么我们是否应当让Post持有多个Topic呢？显然太重了，Topic是一个实体，实体的状态/属性值是会发生改变的，Topic状态发生改变就会引起Post实体内容改变，因此，我们可以有如下两种处理方式： 引入一个值对象TopicId，让Post关联多个TopicId，这个值对象只有一个属性值：topicId，表征Topic的唯一标识值；这是《实现领域驱动设计》中的实现方式； 引入一个值对象TopicPost，表征“话题相关的帖子”，这个值对象可以有更多的属性值。 对比下来，方案2扩展性会更好，且表达能力更强，同时TopicPost这个值对象还可以应用到Topic实体中，在Topic相关的业务case中，会有找到一个Topic下关联的帖子列表的场景，这时候会发现TopicPost便大有用处了。 那么TopicPost和Post之间还是关联关系吗？显然不是。一个Post被删除，那么与其相关的TopicPost值对象也就不复存在了，因此Post持有多个TopicPost，他们是组合关系。 那么TopicPost是属于Topic模块（module）还是属于Post模块，很简单，它以“Topic”打头，因此我们将TopicPost放入Topic模块中。 再来看业务行为，我们将“帖子加入话题”这个业务行为命名为joinTopics(String topics)，字面上‘帖子’是主语，显然joinTopics是Post的业务方法，在这个业务方法中，我们实现业务规则：帖子可以加入的话题数不能多于五个。 上述关于TopicPost值对象引入的讨论非常典型，在两个实体存在关联关系时，可以参考建模。 业务模型 综合上面的讨论，我们得到最新的业务模型如下： 代码PostAuthor.java没有变化，更改Post.java，新增Topic.java和TopicPost.java： Post.java(new)1234567891011121314151617181920212223242526272829public class Post &#123; ...... /** * 将帖子关联话题 * @param topicIds 话题集合 */ public void joinTopics(String topicIds) throws BusinessException&#123; if(StringUtils.isEmpty(topicIds)) &#123; return; &#125; String[] topicIdArray = topicIds.split(CommonConstants.COMMA); for(int i=0; i&lt;topicIdArray.length; i++) &#123; TopicPost topicPost = new TopicPost(Long.valueOf(topicIdArray[i]), this.getId()); this.topics.add(topicPost); if(topicSize() &gt; MAX_JOINED_TOPICS_NUM) &#123; throw new BusinessException(ExceptionCode.ONE_POST_MOST_JOIN_INTO_FIVE_TOPICS); &#125; &#125; &#125; /** * 获取本帖子加入的话题数，参考jdk collection的api设计 * @return 本帖子加入的话题数 */ public int topicSize() &#123; return this.topics.size(); &#125; ......&#125; Topic1234567891011121314151617181920212223242526272829/** * @author DAOQIDELV * @CreateDate 2017年9月16日 * */public class Topic &#123; /** * 话题id */ private long id; /** * 话题标题 */ private String title; /** * 话题描述 */ private String description; /** * 话题创建时间 */ private Timestamp createTime; /** * 话题下的帖子列表 */ private Set&lt;TopicPost&gt; posts; ......&#125; TopicPost123456789101112131415161718192021222324252627282930313233343536/** * @author DAOQIDELV * @CreateDate 2017年9月16日 * */public class TopicPost &#123; private long postId; private long topicId; public TopicPost(long topicId, long postId) &#123; this.setPostId(postId); this.setTopicId(topicId); &#125; @Override public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if(anObject instanceof TopicPost) &#123; if(this.postId == ((TopicPost)anObject).getPostId() &amp;&amp; this.topicId == ((TopicPost)anObject).getTopicId()) &#123; return true; &#125; &#125; return false; &#125; @Override public int hashCode() &#123; return Long.hashCode(this.postId+this.topicId); &#125;&#125; 组合关系集合化处理 如前面业务建模分析，Post持有多个TopicPost，他们是组合关系。代码中Post持有一个TopicPost类型的Set，最初这个topics属性没有被初始化，导致在每次用到它的时候都要去判空，代码冗余度高，可读性差，后面参考java集合的api设计，将topics这个Set直接在声明时就完成初始化，后续使用就没有后顾之忧了。这一个模式可以参考Martin Fowler的《重构》P208。 ‘帖子加入话题’的场景只涉及到了topics集合的元素添加，所以，这里暂且定义了两个api：joinTopics(), topicSize()，至于topics的查询、删除操作在后续的建模场景中会逐一涉及到。 改写TopicPost的equals和hashCode方法 一个帖子不能重复加入某个话题，因此我们使用了HashSet这种数据结构，HashSet中的元素是不能重复的，所以在向HashSet中add元素时，HashSet会判定元素是否相等（== || equals），默认的Object方法equals实现既是比较两个对象是否相等（==），这会带来一个问题：两个在业务上表征同一个帖子加入同一个话题的TopicPost对象会被认为是不相等的两个对象，因此我们需要重写TopicPost的equals和hashCode方法，使之和业务模型保持一致。 equals()的实现参考了java.lang.String的写法；hashCode()的重写最佳实践参考了《重构》P185：读取equals()使用的所有字段的hash码，然后对他们进行按位异或操作。hashCode()的目标是保证在对该对象进行集合类api操作时，能保证较好的散列性，因此只要能达到这个目标就行，鉴于TopicPost中equals方法是用到的topicId和postId均为Long型，也可以简单地这么实现：Long.hashCode(this.postId + this.topicId)。 Round-III业务建模 为确保社区帖子的质量，以及满足国家法律法规的要求，我们需要对帖子标题和内容进行敏感词、广告语、色情、暴力等内容过滤，这些内容过滤即需要调用第三方服务完成，又需要经过社区系统自己积累的敏感词和广告词过滤，对于帖子标题和帖子正文，只要其中一项被过滤服务发现异常，则该帖子就需要被列入待审核队列，等待运营人员审核完成后才能对外发布。我们尝试使用一句话来描述上述case： 帖子标题和内容通过内容过滤后方能发布，如果未能通过内容过滤，则需要经过运营审核之后才能发布。 可以看到上面场景中出现了一个新的短语“内容过滤”，它不是一个实体，看上去像是一个业务行为，是对帖子的标题和内容进行内容过滤，那么我们是不是直接放置到Post实体上呢？ 由于这个内容过滤的行为比较复杂，且涉及到第三方过滤服务的调用，且对帖子标题和帖子内容的过滤逻辑类似，因此我们有必要将“内容过滤”从帖子实体中抽离出来，变成一个领域服务，我们将之命名为：ContentFilter。 考虑到存在多场景多规则的过滤，且只要一个命中一个过滤规则，就可以认为该帖子审核不通过，因此可以使用‘责任链模式’来设计。关于责任链模式的实现和优缺点这里不再赘述，可参考网上资料，或直接看代码即可。 另外，我们发现上面的case描述中，还出现了‘内容过滤未通过’的字样，表明Post需要有一个属性来表征内容过滤的结果，考虑到可见case中存在帖子被用户删除等状态，我们记为“帖子状态”（staus），字典定义为：00 – 已发布；01 – 待运营审核；99 – 已删除。 上面虽然已经创建了一个领域服务专门来承担‘内容过滤’的职责，但是这个业务行为仍然应当属于Post实体，因此我们为Post增加一个filt()业务行为，在这个业务行为中，会去调用“过滤标题”（filtTitle()） 和 “过滤正文”（filtMainBody()）l两个业务方法完成。而filtTitle()和filtMainBody()则会将具体的内容过滤工作委托给上面提到的责任链模式实现的领域服务ContentFilter。 由于ContentFilter这一领域服务采用责任链模式实现，类较多，如果放置到post module下面，不利于阅读，且考虑到后续的评论等场景可能使用到这个服务，故将其单独建立module，取名为：domain.service.contentfilter。 业务模型 综上，我们可以得到如下业务模型： 代码Post.java(new) PostStatus.java PostMainBodyContentFilterChain.java PostTitleContentFilterChain.java ContentFilter.java ImageContentFilter.java TextContentFilter.java LocalTextContentFilter.java RemoteTextContentFilter.java Summarize最终模型汇总上面建模过程中对模型的描述，我们得到如下： 帖子作者发布帖子，帖子标题可以为空，帖子内容不能为空，且不少于16个汉字； 帖子可以加入不多于五个话题，且话题不能重复加入； 帖子标题和内容通过内容过滤后方能发布，如果未能通过内容过滤，则需要经过运营审核之后才能发布。 业务模型图可以参考Round-III中的模型图。 建模经验尝试用一句完整的话说描述业务场景 仔细观察，我们发现最终得到的业务模型描述其实和产品经理的PRD契合度非常高，但是产品经理的PRD描述很多适合缺少主语，或者语言分散，需要我们通过建模，将语言重新组织，找到业务实体，找到业务行为，找到业务规则，并反映在模型上。反过来想，我们的业务模型对于产品经理/业务专家来讲也不会陌生，因为我们都是使用统一的业务模型语言进行描述，大家都能懂才对。 小步快走，逐步迭代 ’发布帖子‘这个业务场景我们经历了三轮迭代，最终得到了一个较完整的业务模型，每一轮迭代，我们都将焦点聚集在一个case，落实模型之后，再继续往前推进。文章描述起来比较啰嗦，实际建模过程中，可能很快就能完成三轮迭代，得到较满意的模型，但是实际的建模过程应当是和文章描述一样的。 有用的模式 具有关联关系的实体，可以为这种关联关系引入一个值对象，从而降低实体间的耦合，比如：在Post和Topic之间引入了TopicPost值对象； 实体 / 值对象 之间存在组合 / 聚合关系，在设计对外的api时，可以参考jdk中集合的api设计，达到高内聚的目标，这在《重构》这本书中被称为“封装集合（Encapsulate Collection）”，比如：Post实体中的topics话题集便参考Set对外提供api； 配合第2点的实现，通常需要重写equals()和hashCode()方法，最佳实践可以参考示例代码； 极力推荐使用合适的设计模式，提高代码的扩展性和可维护性，比如：contentFilter领域服务组件便采用了“责任链模式”来实现； 当实体依赖于领域服务时，可以讲领域服务作为实体业务方法的参数传入，尤其是当领域服务被ioc容器管理时。比如：contentFilter领域服务组件作为Post的filt()方法的参数传入。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计：概述]]></title>
    <url>%2F2019%2F07%2F05%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[精要核心 将所有业务逻辑内聚到业务领域（domain）层，将设计和开发的关注点聚焦到业务领域； 建立通用的‘业务领域语言（Ubiquitous Language）’，Ubiquitous Language是工程师和业务领域专家（可以是产品经理、运营、业务相关人员）的桥梁； 战略上，通‘上下文（Bounded Context）’解耦各个业务系统/组件，通过‘防腐层（Anticorruption layer）’确保自有业务领域不受外界污染，通过‘开放主机服务（Open Host Service）’向外界公开服务； 战术上，将业务对象建模为entity和value object，entity有唯一业务标识且在其生命周期中状态可变，value object与之相反；关联性强的entity和value object聚合成一个Aggregate，每个Aggregate有一个root entity，确保Aggregate内容业务规则和行为的一致性；业务行为尽量建模在entity/ value object 上，当业务行为无法建模到任何业务entity/value object时，可以使用领域服务（domain service），使用factory创建复杂的业务entity，使用repository实现实体的重建和持久化操作；领域相关的通知等可以通过domain event发布出去。 概念 Bounded context：边界上下文 划分领域边界，边界内领域模型保持一致，强调内聚，并与边界外的领域模型解耦。 Entity：领域实体 有唯一标识，可变的业务实体对象，它有着自己的生命周期。比如User、帖子等。 Value Object：领域值对象 没有唯一业务标识，通常依附于其他领域实体，值对象的内容不可变，要么被整体替换。如：用户点赞行为等。 Aggregate：聚合 是一组业务关联度很强的实体/值对象集合，每个聚合都有一个根实体（Root Entity），通过根实体可以路由到整个聚合。 Domain Event：领域事件 领域中发生的异步处理事件、异步消息通知等，比如：异步写入的登录历史记录。通常借助消息队列实现。 Domain Service：领域服务 当某些业务行为无法归类到某一个Entity/Value Object时，我们便可以创建领域服务来完成。比如：账户转账场景，涉及到两个不同的Account实体，再比如社区的敏感词过滤场景，帖子可以用，评论亦可以用，因此可以抽离到ContentFilter中完成。 Repository：仓库 严格意义上将仓库是基础设施层的东西，但是为了保持领域模型的整体性，我们将仓库的接口定义放到领域中，这样可以在领域中约束实体/值对象的增删改查接口，同时还可以方便地完成仓库的内存形式实现，使得领域模型弱依赖于持久化层。这一点在书中被成为‘依赖倒置’（参考《实现领域驱动设计》P372）。 Factory：领域对象工厂 用于复杂领域对象的创建/重建。重建是指通过respostory加载持久化对象后，重建领域对象。 优点 业务逻辑内聚到业务领域层，可以更好的保证业务规则的一致性； 软件的可维护性和可扩展性增强，工程师可以聚焦在业务领域层，并致力于业务领域模型的迭代和维护，适应新业务的发展； 软件的可测试性增强，领域层代码不需要借助用户接口层的入口便可以独立测试业务逻辑，通过repository的哑实现可以摆脱对数据持久层的依赖； 软件工程师和业务领域专家（产品经理）使用同一种语言交流，沟通成本降低，提升效率；【这一点在现实中或多或少在使用，但是比较模糊，很多时候大家会用到‘领域’这个词语，但是并不会刻意地坐下来讨论各自领域应当包含哪些实体……这也是大家可以进步的地方。】 缺点 对工程师有较高的业务建模技能要求，期望他们能从复杂的业务上下文中识别出正确的业务模型，并将各个业务行为归入合适的entity/value object/domain service中； 项目前期需要投入更多的时间进行业务建模，不能快速进入开发阶段； 需要资深的业务领域专家参与进来，否则业务模型的频繁重构（重大改动）会带来额外成本；DDD适用场景 业务逻辑复杂的系统；不太复杂的业务系统没有必要使用DDD，比如内容管理系统，只是对内容进行简单的增删改查；再比如渠道接入层系统，只是做请求的转发和翻译，没有核心业务逻辑，就没有必要使用DDD。 有资深的业务领域专家支持，需要有一个很懂业务的人，在业务上提供指导性的意见； 工程师都认可DDD设计思路，并积极主动地探讨和迭代，将业务模型日趋完善； 项目工期压力可以接受。 架构风格针对DDD的架构，《实现领域驱动设计》提到了几种架构风格：六边形架构、REST架构、CQRS、事件驱动等。在实际使用中，落地的架构并非是纯粹其中的一种，而很有可能户将上述几种架构风格结合起来实现。 分层架构 将领域逻辑和展示逻辑及基础设施分离出来 领域逻辑依赖基础设施 代价：领域层到展示层的数据转化 六边形架构（端口和适配器）所谓的六边形架构，其实是分层架构的扩展，原来的分层架构通常是上下分层的，比如常见的MVC模式，上层是对外的服务接口，下层是对接存储层或者是集成第三方服务，中层是业务逻辑层。 我们跳出分层的概念，会发现上面层和下面层其实都是端口+适配器的实现，上面层开放http/tcp端口，采用rest/soap/mq协议等对外提供服务，同时提供对应协议的适配器；下层也是端口+适配器，只不过应用程序这时候变成了调用者，第三方服务或者存储层提供端口和服务，应用程序本身实现适配功能。 基于上述思考，将分层接口中的上层和下层统一起来就变成了六边形架构，基于端口和适配器的实现，示意图如下： *上图来源于《实现领域驱动设计》的P111 我认为六边形架构并非创造一种新的架构风格，只是将原来的分层架构风格重新解读，使得架构更加简洁通用。同时，在DDD的设计思想下，六边形架构风格，让领域模型处于架构的核心区域，让开发人员将焦点聚集到领域。DDD和六边形架构是天然契合的，是DDD的首选架构。 RESTREST——即Representational State Transfer的缩写，翻译过来是”表现层状态转化”。参考至：理解RESTful架构。 RESTful风格的架构将‘资源’放在第一位，每个‘资源’都有一个URI与之对应，可以将‘资源’看着是ddd中的实体；RESTful采用具有自描述功能的消息实现无状态通信，提高系统的可用性；至于‘资源’的哪些属性可以公开出去，针对‘资源’的操作，RESTful使用HTTP协议的已有方法来实现：GET、PUT、POST和DELETE。 在DDD的实现中，我们可以将对外的服务设计为RESTful风格的服务，将实体/值对象/领域服务作为’资源’对外提供增删改查服务。但是并不建议直接将实体暴露在外，一来实体的某些隐私属性并不能对外暴露，二来某些资源获取场景并不是一个实体就能满足的，因此我们在实际实践过程中，在领域模型上增加了dto这样一个角色，dto可以组合多个实体/值对象的资源对外暴露。 CQRSCQRS——Cammand-Query Responsibility Segregation的缩写。翻译过来就是“命令与查询职责分离”。 简而言之，CQRS就是平常大家在讲的读写分离，通常读写分离的目的是为了提高查询性能，同时达到读/写的解耦。让DDD和CQRS结合，我们可以分别对读和写建模，查询模型通常是一种非规范化数据模型，它并不反映领域行为，只是用于数据显示；命令模型执行领域行为，且在领域行为执行完成后，想办法通知到查询模型。 那么命令模型如何通知到查询模型呢？ 如果查询模型和领域模型共享数据源，则可以省却这一步；如果没有共用数据源，则可以借助于‘消息模式’（Messaging Patterns）通知到查询模型，从而达到最终一致性（Eventual Consistency）。 Martin在blog中指出： CQRS适用于极少数复杂的业务领域，如果不是很适合反而会增加复杂度； 另一个适用场景为获取高性能的服务。 图片来源于Martin Fowler的blog，图中表述的查询模型和命令模型共用数据源。 关于CQRS的讨论可以参考Martin大叔的blog：CQRS，以及：CQRS, Task Based UIs, Event Sourcing agh! 事件溯源 将持久化逻辑彻底从领域模型中分离出去 只持久化业务中发生过什么，不持久化当前状态。当前状态通过回溯所有事件计算出来 业务事件顺序存储，不会更新，写入效率极高 代价：更强的针对事件建模能力，事件回溯机制 LMAX architecture 将IO和并发从领域模型中分离出去 单线程，异步IO，全内存操作，性能极高 代价：异步IO，无事务回滚等 总结 端口适配器架构 总是采用，投入很小，却能产出干净的易于测试的领域模型，优于分层架构 CQRS 一般都可以采用，从共享数据库做起，不急着做分离的查询存储 事件溯源 一般都不需要用，写入性能要求高，有重播需求时使用 LMAX架构 一般都不需要用，需要超高性能时采用 设计思路从责任出发去分析设计 DDD从战略设计到战术设计，从子领域、限界上下文到值对象，都是从责任分析出发的，而不是从数据出发的 数据是为了行为服务的，行为是为了完成责任。责任包括 内部功能 协调 持有数据 等 好的责任分配，能够形成好的依赖关系 实例 架构实例结合最近在重构的社区服务系统（COMMUNITY），尝试使用上述的指导思想和架构风格，完成一次架构设计尝试，并详述如下： 架构图 架构详述COMMUNITY系统架构整合了六边形架构、RESTful架构风格、CQRS架构风格三种架构风格，并遵循经典的分层架构思想。 1、在遵循分层架构思想的基础上，引入了六边形架构风格，对内对外均通过适配器+端口的方式呈现： 面向用户侧，提供http端口，并使用SpringMVC框架的RequestMapping、Controller等组件实现对http 请求的解析，转化为Application层可识别的业务dto对象，这里的Controller+RequestMapping便起着适配器的作用； 面向第三方服务，通过httpclient和tcpclient的适配，可以对接多种协议的第三方服务端口； 面向存储层，通过mongoclient的适配，访问mongodb；通过mybatis的适配，访问oracle；通过redisclient的适配，访问redis； 面向消息中间件，通过mqclient的适配，方为rabbitMQ； 2、实现了RESTful架构风格，通过RESTful风格的接口契约对外提供主机开放服务。借助SpringMVC实现。 3、实现了CQRS架构风格： orcale作为命令模型存储存在，并配以Transaction事务管理。主要存储帖子、评论、话题、圈子、关注等实体信息； Mongodb作为查询模型存储存在，存储个人动态、社区动态等非结构化数据； redis同样作为查询模型存储存在，存储用户个人信息、热门评论、热门帖子、热门话题、用户点赞信息等； Application层分为QueryService和CommandService两大类应用服务，分别组合查询模型和命令模型； 使用rabbitMQ作为消息中间件，CommandService在完成命令模型的维护后，生产事件消息写入rabbitMQ，QueryService作为消费者从rabbitMQ读取事件消息，更新查询模型； 查询模型和命令模型极其对应的application service可以独立部署，独立扩展。 4、遵循基本的分层架构风格。 User Interface —— 用户接口层。对外提供各种协议形式的服务，并提供Validation参数校验，authenticate权限认证，业务实体组装器Assembler等。图中标绿组件。 Application —— 应用服务层。组合多个业务实体、基础设施层的各种组件完成业务服务。图中标黄部分。 Domain —— 业务领域层。DDD概念中的核心业务层，封装所有业务逻辑，包含entity、value object、domain service、domain event等。图中标蓝部分。 Infrastructure —— 基础设施层。提供公共组件，如：Logging、Trascation、HttpClient等。图中标灰部分。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jooq：Start]]></title>
    <url>%2F2019%2F07%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FJooq%2FJooq%EF%BC%9AStart%2F</url>
    <content type="text"><![CDATA[Jooq示例创建数据库123456789101112DATABASE `library`; USE `library`; CREATE TABLE `author` ( `id` int NOT NULL, `first_name` varchar(255) DEFAULT NULL, `last_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)); INSERT INTO `author` (`id`, `first_name`, `last_name`) VALUES ('1', '3', 'zhang'), ('2', '4', 'li'); sql语句 12345678910SELECT AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME, COUNT(*) FROM AUTHOR JOIN BOOK ON AUTHOR.ID = BOOK.AUTHOR_ID WHERE BOOK.LANGUAGE = 'DE' AND BOOK.PUBLISHED &gt; DATE '2008-01-01'GROUP BY AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME HAVING COUNT(*) &gt; 5ORDER BY AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1 Java 12345678910create.select(AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME, count()) .from(AUTHOR) .join(BOOK).on(AUTHOR.ID.equal(BOOK.AUTHOR_ID)) .where(BOOK.LANGUAGE.eq("DE")) .and(BOOK.PUBLISHED.gt(date("2008-01-01"))) .groupBy(AUTHOR.FIRST_NAME, AUTHOR.LAST_NAME) .having(count().gt(5)) .orderBy(AUTHOR.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) 映射这里，要使用jOOQ的命令行工具生成映射到author表的Java类。 代码生成的最简单的方法是将jOOQ的3个jar文件和MySQL Connector jar文件复制到一个临时目录（本示例中目录是test-generated）， 然后创建一个如下所示的library.xml（名字随意修改）： 目录结构： library.xml配置文件内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;configuration xmlns="http://www.jooq.org/xsd/jooq-codegen-3.9.2.xsd"&gt; &lt;!-- Configure the database connection here --&gt; &lt;jdbc&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;!-- 数据库url --&gt; &lt;url&gt;jdbc:mysql://localhost:3306/library?useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/url&gt; &lt;!-- 数据库账号 --&gt; &lt;user&gt;root&lt;/user&gt; &lt;!-- 数据库账号密码 --&gt; &lt;password&gt;root&lt;/password&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;!-- The default code generator. You can override this one, to generate your own code style. Supported generators: - org.jooq.util.JavaGenerator - org.jooq.util.ScalaGenerator Defaults to org.jooq.util.JavaGenerator --&gt; &lt;name&gt;org.jooq.util.JavaGenerator&lt;/name&gt; &lt;database&gt; &lt;!-- The database type. The format here is: org.util.[database].[database]Database --&gt; &lt;name&gt;org.jooq.util.mysql.MySQLDatabase&lt;/name&gt; &lt;!-- The database schema (or in the absence of schema support, in your RDBMS this can be the owner, user, database name) to be generated --&gt; &lt;inputSchema&gt;library&lt;/inputSchema&gt; &lt;!-- All elements that are generated from your schema (A Java regular expression. Use the pipe to separate several expressions) Watch out for case-sensitivity. Depending on your database, this might be important! --&gt; &lt;includes&gt;.*&lt;/includes&gt; &lt;!-- All elements that are excluded from your schema (A Java regular expression. Use the pipe to separate several expressions). Excludes match before includes, i.e. excludes have a higher priority --&gt; &lt;excludes&gt;&lt;/excludes&gt; &lt;/database&gt; &lt;target&gt; &lt;!-- The destination package of your generated classes (within the destination directory) --&gt; &lt;!-- 生成的包名，生成的类在此包下 --&gt; &lt;packageName&gt;test.generated&lt;/packageName&gt; &lt;!-- The destination directory of your generated classes. Using Maven directory layout here --&gt; &lt;!-- 输出的目录 --&gt; &lt;directory&gt;J:\IDEA_Work_Space\maven_jooq_demo\src\main\java&lt;/directory&gt; &lt;/target&gt; &lt;/generator&gt;&lt;/configuration&gt; cd到目录下 1java -classpath jooq-3.9.5.jar;jooq-meta-3.9.5.jar;jooq-codegen-3.9.5.jar;mysql-connector-java-5.1.41.jar; org.jooq.util.GenerationTool library.xml 连接数据库123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.jooq.cn; import org.jooq.DSLContext;import org.jooq.Record;import org.jooq.Result;import org.jooq.SQLDialect;import org.jooq.impl.DSL; import java.sql.Connection;import java.sql.DriverManager; import static test.generated.tables.Author.AUTHOR; public class Main &#123; public static void main(String[] args) &#123; //用户名 String userName = "root"; //密码 String password = "root"; //mysql链接url String url = "jdbc:mysql://localhost:3306/library"; Connection conn; try &#123; //这是JDBC Mysql连接 conn = DriverManager.getConnection(url, userName, password); //基于JOOQ实现的简单查询 //传入Connection连接对象、数据方言得到一个DSLContext的实例，然后使用DSL对象查询得到一个Result对象。 DSLContext using = DSL.using(conn, SQLDialect.MYSQL); Result&lt;Record&gt; fetch = using.select().from(AUTHOR).fetch(); //for循环输出结果 for (Record record : fetch) &#123; Integer id = record.getValue(AUTHOR.ID); String firstName = record.getValue(AUTHOR.FIRST_NAME); String lastName = record.getValue(AUTHOR.LAST_NAME); /** * 控制台输出 * ID: 1 first name: 3 last name: zhang * ID: 2 first name: 4 last name: li */ System.out.println("ID:"+id + "firstName"+ firstName + "lastName: " + lastName); &#125; //关闭连接 conn.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 关闭数据库连接DSLContext不会主动关闭连接，需要我们手动关闭。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Jooq：StudyResources]]></title>
    <url>%2F2019%2F07%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FJooq%2FJooq%EF%BC%9AStudyResources%2F</url>
    <content type="text"><![CDATA[参考 初步了解JOOQ并实现简单 - - - CRUD（一）]]></content>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计：骨架]]></title>
    <url>%2F2019%2F07%2F04%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A%E9%AA%A8%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[代码骨架 iface 定义接口iface 响应返回的类要用RpcResult包装 请求的接口的字段类req 请求返回的类res app在该层实现iface层的接口 将请求转换为命令，handle处理command 若是app抛出的face异常就抛出face的异常，若是domain的异常就抛出domain的异常 简介在DDD设计思想中，Application层主要职责为组装domain层各个组件及基础设施层的公共组件，完成具体的业务服务。Application层可以理解为粘合各个组件的胶水，使得零散的组件组合在一起提供完整的业务服务。在复杂的业务场景下，一个业务case通常需要多个domain实体参与进来，所以Application的粘合效用正好有了用武之地。 Application层主要由：service、assembler组成，下面分别对其做讲解。 Serviceservice是组件粘合剂这里的Service区别于domain层的domain service，是应用服务。它是组件的粘合剂，组合domain层的各个组件和 infrastructure层的持久化组件、消息组件等等，完成具体的业务逻辑，提供完整的业务服务。 通过不断的实践，我们发现：通过DDD实现业务服务时，检验业务模型的质量的一个标准便是 —— service方法中不要有if/else。如果存在if/else，要么就是系统用例存在耦合，要么就是业务模型不够友好，导致部分业务逻辑泄漏到service了。 通常意义上，一个业务case在service层便会对应一个service方法，这样确保case实现的独立性。拿社区服务中的“帖子”模块来讲，我们有如下几个明显的case：发帖（posting）、删帖（deletePost）、查询帖子详情（queryPostDetail），这些case在service层都对应独立的业务方法。 思考对于较为复杂的case：查询帖子列表，可能需要根据不同的tag过滤帖子，或者查询不同类型的帖子，或者查询热门帖子，这个时候应当用一个service方法实现呢？还是多个呢？ 考虑这个问题，主要从这两方面入手：domain的一致性，数据存储的一致性；如果两个一致性都满足，那么我们可以在一个业务方法中完成，否则就要在独立的业务方法中完成。 例如：根据帖子运营标签查询帖子 和 查询全部帖子列表 这两个case我们可以放到一个service方法中实现，因为前一个case只是在后一个case的基础上加了一个过滤条件，这个过滤条件完全可以交给dao层的sql where条件处理掉，除此之外，domain和repository都完全一样； 而“查询热门帖子” 这个case就不能和上面的两个case共用一个service方法了，因为热门帖子列表的数据源并不在数据库中，而是存在于缓存中，因此repository的取数逻辑存在很大差异，如果共用一个service方法，势必要在service层出现if/else判定，这是不友好的。 类图 code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899@Servicepublic class PostServiceImpl implements PostService &#123; @Autowired private IPostRepository postRepository; @Autowired private PostAssembler postAssembler; public PostingRespBody posting(RequestDto&lt;PostingReqBody&gt; requestDto) throws BusinessException &#123; PostingReqBody postingReqBody = requestDto.getBody(); /** *NOTE： 请求参数校验交给了validation，这里无需校验userId和postId是否为空 */ String userId = postingReqBody.getUserId(); String title = postingReqBody.getTitle(); String sourceContent = postingReqBody.getSourceContent(); long userIdInLong = Long.valueOf(userId); /** * 组装domain model entity * NOTE：这里的PostAuthor不需要从repository重载，原因在于：deletePost场景需要用户登录后才能操作， * 在进入service之前，已经在controller层完成了用户身份鉴权，故到达这里的userId肯定是合法的用户 */ PostAuthor postAuthor = new PostAuthor(userIdInLong); Post post = postAuthor.posting(title, sourceContent); /** * NOTE：使用repository将model entity 写入存储 */ postRepository.save(post); /** * NOTE：使用postAssembler将Post model组装成dto返回。 */ return postAssembler.assemblePostingRespBody(post); &#125; public DeletePostRespBody delete(RequestDto&lt;DeletePostReqBody&gt; requestDto) throws BusinessException &#123; DeletePostReqBody deletePostReqBody = requestDto.getBody(); /** *NOTE： 请求参数校验交给了validation，这里无需校验userId和postId是否为空 */ String userId = deletePostReqBody.getUserId(); String postId = deletePostReqBody.getPostId(); long userIdInLong = Long.valueOf(userId); long postIdInLong = Long.valueOf(postId); /** * 组装domain model entity * NOTE：这里的PostAuthor不需要从repository重载，原因在于：deletePost场景需要用户登录后才能操作， * 在进入service之前，已经在controller层完成了用户身份鉴权，故到达这里的userId肯定是合法的用户 */ PostAuthor postAuthor = new PostAuthor(userIdInLong); /** * 从repository中重载domain model entity * 借此判断该postId是否真的存在帖子 */ Post post = postRepository.query(postIdInLong); postAuthor.deletePost(post); postRepository.delete(post); return null; &#125; @Override public QueryPostDetailRespBody queryPostDetail(RequestDto&lt;QueryPostDetailReqBody&gt; requestDto) throws BusinessException &#123; QueryPostDetailReqBody queryPostDetailReqBody = requestDto.getBody(); String readerId = queryPostDetailReqBody.getReaderId(); String postId = queryPostDetailReqBody.getPostId(); long readerIdInLong = Long.valueOf(readerId); long postIdInLong = Long.valueOf(postId); //TODO 可能有一些权限校验，比如：判定该读者是否有查看作者帖子的权限等。这里暂且不展开讨论。 PostReader postReader = new PostReader(readerIdInLong); Post post = postRepository.query(postIdInLong); /** * NOTE: 使用postAssembler将domain层的model组装成dto，组装过程： * 1、完成类型转换、数据格式化； * 2、将多个model组合成一个dto，一并返回。 */ return postAssembler.assembleQueryPostDetailRespBody(post); &#125; &#125; AssemblerAssembler是组装器Assembler是组装器，负责完成domain model对象到dto的转换，组装职责包括： 完成类型转换、数据格式化；如日志格式化，状态enum装换为前端认识的string； 将多个domain领域对象组装为需要的dto对象，比如查询帖子列表，需要从Post（帖子）领域对象中获取帖子的详情，还需要从User（用户）领域对象中获取用户的社交信息（昵称、简介、头像等）； 将domain领域对象属性裁剪并组装为dto；某些场景下，可能并不需要所有domain领域对象的属性，比如User领域对象的password属性属于隐私相关属性，在“查询用户信息”case中不需要返回，需要裁剪掉。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Post模块的组装器，完成domain model对象到dto的转换，组装职责包括： * 1、完成类型转换、数据格式化；如日志格式化，状态enum装换为前端认识的string； * 2、将多个model组合成一个dto，一并返回。 * TODO: 不太好的地方每个assemble方法都需要先判断入参对象是否为空。 * @author daoqidelv * @createdate 2017年9月24日 */@Componentpublic class PostAssembler &#123; private final static String POSTING_TIME_STRING_DATE_FORMAT = "yyyy-MM-dd hh:mm:ss"; @Autowired private ApplicationUtil applicationUtil; public PostingRespBody assemblePostingRespBody(Post post) &#123; if(post == null) &#123; return null; &#125; PostingRespBody postingRespBody = new PostingRespBody(); postingRespBody.setPostId(String.valueOf(post.getId())); return postingRespBody; &#125; public QueryPostDetailRespBody assembleQueryPostDetailRespBody(Post post) &#123; /** * NOTE: 判定入参post是否为null */ if(post == null) &#123; return null; &#125; QueryPostDetailRespBody queryPostDetailRespBody = new QueryPostDetailRespBody(); queryPostDetailRespBody.setAuthorId(String.valueOf(post.getAuthorId())); //完成类型转换 queryPostDetailRespBody.setPostId(String.valueOf(post.getId()));//完成类型转换 queryPostDetailRespBody.setPostingTime( applicationUtil.convertTimestampToString(post.getPostingTime(), POSTING_TIME_STRING_DATE_FORMAT));//完成日期格式化 queryPostDetailRespBody.setSourceContent(post.getSourceContent()); queryPostDetailRespBody.setTitle(post.getTitle()); return queryPostDetailRespBody; &#125;&#125; 类图 code1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class PostAssembler &#123; private final static String POSTING_TIME_STRING_DATE_FORMAT = "yyyy-MM-dd hh:mm:ss"; @Autowired private ApplicationUtil applicationUtil; public PostingRespBody assemblePostingRespBody(Post post) &#123; if(post == null) &#123; return null; &#125; PostingRespBody postingRespBody = new PostingRespBody(); postingRespBody.setPostId(String.valueOf(post.getId())); return postingRespBody; &#125; public QueryPostDetailRespBody assembleQueryPostDetailRespBody(Post post) &#123; /** * NOTE: 判定入参post是否为null */ if(post == null) &#123; return null; &#125; QueryPostDetailRespBody queryPostDetailRespBody = new QueryPostDetailRespBody(); //完成类型转换 queryPostDetailRespBody.setAuthorId(String.valueOf(post.getAuthorId())); //完成类型转换 queryPostDetailRespBody.setPostId(String.valueOf(post.getId())); //完成日期格式化 queryPostDetailRespBody.setPostingTime( applicationUtil.convertTimestampToString(post.getPostingTime(), POSTING_TIME_STRING_DATE_FORMAT)); queryPostDetailRespBody.setSourceContent(post.getSourceContent()); queryPostDetailRespBody.setTitle(post.getTitle()); return queryPostDetailRespBody; &#125;&#125; jooq查官网 申请 VPN jooq的模块pom文件 将表名配置在pom文件中 user:power_rent includes是表名 mvn命令，前提是表已经创建了的 jdbc的token是不一致，需要申请 domaindomain层是具体的业务领域层，是发生业务变化最为频繁的地方，是业务系统最核心的一层，是DDD关注的焦点和难点。这一层包含了如下一些domain object：entity、value object、domain event、domain service、factory、repository等。DDD实践的难点其实就在于如何识别这些object。 entity领域实体是domain的核心成员。domain entity具有如下三个特征： 唯一业务标识 持有自己的业务属性和业务行为 属性可变，有着自己的生命周期 在社区这一业务领域中，‘帖子’就是一个业务实体，它需要有一个唯一性业务标识表征，拥有这个业务实体相关的业务属性（作者、标题、内容等）和业务行为（关联话题、删帖等），同时他的状态和内容可以不断发生变化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Post &#123; /** * 帖子id */ private long id; //1、‘帖子’实体有唯一业务标识 /** *帖子作者 */ private long authorId; /** * 帖子标题 */ private String title;//2、‘帖子’实体拥有自己的业务属性 /** * 帖子源内容 */ private String sourceContent; /** * 发帖时间 */ private Timestamp postingTime; /** * 帖子状态 * NOTE：使用enum实现，限定status的字典值 * @see com.dqdl.community.domain.model.post.PostStatus */ private PostStatus status; /** * 帖子作者 */ private PostAuthor postAuthor; /** * 帖子加入的话题 */ private Set&lt;TopicPost&gt; topics = new HashSet&lt;TopicPost&gt;(); private Post() &#123; this.postingTime = new Timestamp(System.currentTimeMillis()); &#125; public Post(long id) &#123; this.setId(id); &#125; public Post(long authorId, String title, String sourceContent) &#123; this(); this.setAuthorId(authorId); this.setTitle(title); this.setSourceContent(sourceContent); this.setPostAuthor(new PostAuthor(authorId)); &#125; /** * 删除帖子 */ public void delete() &#123; this.setStatus(PostStatus.HAS_DELETED);//3、帖子的状态可以改变 &#125; /** * 将帖子关联话题 * @param topicIds 话题集合 */ public void joinTopics(String topicIds) throws BusinessException&#123;//2、‘帖子’实体拥有自己的业务行为 if(StringUtils.isEmpty(topicIds)) &#123; return; &#125; String[] topicIdArray = topicIds.split(CommonConstants.COMMA); for(int i=0; i&lt;topicIdArray.length; i++) &#123; TopicPost topicPost = new TopicPost(Long.valueOf(topicIdArray[i]), this.getId()); this.topics.add(topicPost); if(topicSize() &gt; MAX_JOINED_TOPICS_NUM) &#123; throw new BusinessException(ReturnCode.ONE_POST_MOST_JOIN_INTO_FIVE_TOPICS); &#125; &#125; &#125; //...... value obj(区别于entity)领域值对象。value object是相对于domain entity来讲的，对照起来value object有如下特征： 可以有唯一业务标识 【区别于domain entity】 持有自己的业务属性和业务行为 【同domain entity】 一旦定义，他是不可变的，它通常是短暂的，这和java中的值对象（基本类型和String类型）类似 【区别于domain entity】 比如社区业务领域中，‘帖子的置顶信息’可以理解为是一个值对象，不需要为这一值对象定义独立的业务唯一性标识，直接使用‘帖子id‘便可表征，同时，它只有’置顶状态‘和’置顶位置‘，一旦其中一个属性需要发生变化，则重建值对象并赋值给’帖子‘实体的引用，不会对领域带来任何负面影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 帖子置顶消息，value object * @author daoqidelv * @createdate 2017年10月10日 */public class PostTopInfo &#123; /** * 帖子id */ private long postId; /** * 置顶标志。true -- 置顶， false -- 不置顶。 */ private boolean isTop; /** * 置顶位置，当isTop == true时，该字段有意义。 */ private int topIndex; public PostTopInfo(long postId, boolean isTop, int topIndex) &#123; this.setPostId(postId); this.setTop(isTop); this.setTopIndex(topIndex); &#125; public long getPostId() &#123; return postId; &#125; public void setPostId(long postId) &#123; this.postId = postId; &#125; public boolean isTop() &#123; return isTop; &#125; public void setTop(boolean isTop) &#123; this.isTop = isTop; &#125; public int getTopIndex() &#123; return topIndex; &#125; public void setTopIndex(int topIndex) &#123; this.topIndex = topIndex; &#125;&#125; service领域服务。区别于应用服务，他属于业务领域层。可以认为，如果某种行为无法归类给任何实体/值对象，则就为这些行为建立相应的领域服务即可。传统意义上的util static方法中，涉及到业务逻辑的部分，都可以考虑归入domain service。 比如：‘社区’这一业务领域中的‘内容过滤’这一模块，便是领域服务，他不只属于Post实体，还会被用于评论（Comment）实体中，故我们将他独立成domain service。 即涉及到两个及以上的entity时，就可以将其归类为service factory领域对象工厂。用于复杂领域对象的创建/重建。重建是指通过respostory加载持久化对象后，重建领域对象。 repository仓库。我们将仓库的接口定义归类在domain层，因为他和domain entity联系紧密。仓库接口定义了和基础实施的持久化层交互契约，完成领域对应的增删改查操作。domain层的repository只是定义契约的接口，实际实现仍然由infrastructure完成。 仓库的实际实现根据不同的存储介质而不同，可以是redis、oracle、mongodb等。具体仓库的实现会讲给infrastructure层完成，我们会在下一篇blog中详细阐述repository的实现。 对于repository的接口定义，建议规范接口名命名，比如：查询都叫着query等等，减小沟通成本。 123456789public interface IPostRepository &#123; Post query(long postId); int save(Post post); int delete(Post post);&#125; domain-event领域事件。领域中产生的一些消息事件，可以在性能和解耦层面得到好处。我们通常借助于消息中间件，通过事件通知/订阅的方式落地。 在‘社区’业务领域中，‘发帖’之后，会同时为帖子作者生成一个‘发帖动态’，这个‘生成发帖动态’场景并不同步完成，而是通过领域事件发布异步完成。‘发帖’创建Post实体后，发布一个‘发帖动态’领域事件（PostingDynamic），‘动态’（Dynamic）相关服务消费该领域事件，并生成Dynamic实体。 思考查询式和命令式接口使用的domain需要分离查询式接口domain应当简化，甚至于去掉。通常查询接口的实现逻辑为：入参校验、鉴权、从Repository中获取数据、拼凑不同的数据、数据转换、返回数据。理论上，不应当存在过多的业务逻辑。所以可以淡化domain层。如果仍然按照：entity –&gt; model –&gt;dto的转换路径，实际model的作用没有，反而带来了代码复杂度，不值得。 命令式接口，除去查询式接口的逻辑，还有部分业务相关的，比如“关注”这一业务逻辑，较为复杂，需要收口到domain。 因此，建议如下处理方式： 查询式和命令式接口使用的domain需要分离设计，查询式接口使用的domain可以淡化。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统设计：依赖反转与依赖注入]]></title>
    <url>%2F2019%2F07%2F04%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%EF%BC%9A%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC%E4%B8%8E%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[依赖反转依赖为什么要将依赖反转，因为当存在依赖时，被依赖的模块A会先进行编译，而依赖的模块B会在A编译后才能进行编译。 定义软件设计存在抽象层与是实现层之分，一般情况下，抽象依赖于实现。 但是抽象层稳定，实现层容易变化，抽象层应该有较实现层更高的复用性，它就应该我们设计和考量的核心与重点，而不是具体的实现，这样一来，要求我将依赖关系反转过来，即实现应该依赖于我们的抽象，这样的设计才是灵活和易于扩展的。 因此出现依赖反转的概念，即面向接口编程的。接口不提供任何的实现，可以真正意义上进行抽象层的工作。 依赖注入问题当进行依赖反转时，编程的可能情形是： 123456789101112131415interface IService&#123; public void doSomething();&#125;class ServiceImpl implements IService&#123; public void doSomething()&#123; // do something...... &#125;&#125;class Component&#123; private IService service＝new ServiceImpl(); //这里是基于接口进行编程，但却在构造时与具体的实现发生了耦合 //后继方法中会使用该service&#125; 在此的问题是，当实例化service时，必须要使用到实现类 依赖注入的实现运用spring的依赖注入会完美地解决“抽象在创建时刻对实现产生依赖”的问题，在我们代码里，抽象将永远不需要再被指向他的具体实现了，这个过程会放到sping 的配制文件里，使用依赖注入的方式完成 参考 关于依赖反转（基于接口编程）和依赖注入的一个小问题的领悟]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计：StudyResources]]></title>
    <url>%2F2019%2F07%2F03%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%9AStudyResources%2F</url>
    <content type="text"><![CDATA[书籍 Eric Evans Domain-Driven Design: Tackling Complexity in the Heart of Software”一书（中文名字《领域驱动设计–软件核心复杂性应对之道 》，清华大学出版社出版） 偏向于理论 Vaughn Vernon的《实现领域驱动设计》、 偏向于实践 参考 一个博客：【DDD】使用领域驱动设计思想实现业务系统]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计]]></title>
    <url>%2F2019%2F07%2F03%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[关注精简的业务模型及实现的匹配 如果你了解”模型”的定义是对现实的有选择性的精简，然后用这样的观点去读 DDD 这本书，你就会发现，DDD 其实没有什么太多的新鲜玩意，它更多地是可以看作是面向对象思潮的回归和升华。在一个”万事万物皆对象”的世界里，哪些对象是对我们的系统有用的？哪些是对我们拟建系统没有用处的？我们应该如何保证我们选取的模型对象恰好够用？ 前面的选择性问题只是解决了一个初步框选的问题，对象并不是独立存在的，它们之间有着千丝万缕的联系。这种扯不断理还乱的联系构成了系统的复杂性。一个具体的体现就是，我们修改了一处变更，结果引发了一系列的连锁反应。虽然对象的封装机制可以帮我们解决一部分问题，但那只是有限的一部分。我们应该如何在一个更高点的层次上，通过保留对象之间有用的关系去除无用的关系，并且限定变更影响的范围以来降低系统的复杂度呢？即在抽象的角度做业务。 在 DDD 以及传统 OO 的观点中，业务而不是技术是一个开发团队首先要关注的内容，众多的框架和平台产品也在宣称把开发人员解放出来，让他们有更多的精力去关注业务。但是，当我们真正去看待时，会发现，开发人员大多还是沉溺于技术中，对业务的理解和深入付出的太少太少。其实要解决这个问题，就要先看清楚我们提炼出来的模型,在整个架构和整个开发过程中所处的位置和地位。我们经常听到两个词，一个是 MDD（模型驱动设计），一个是MDA（模型驱动架构）。如果 DDD 特别关注的是”M”(以及其实现)，那么，这个 M 应该如何与架构和开发过程相融合呢？我经常会看到我们辛苦提取出来的领域模型被肢解后，分散到系统的若干角落。这真是一件可怕的事情，因为一旦形成了”人脑拼图”，就很难再有一个人将它们一一复原，除非这个人是个天才。 很多面向对象的教材，都会告诉你若干的技巧，让你去机械化地处理模型和对象实现，但是这些教材通常会忽略一个大的上下文环境，就是应该由哪些具有什么样素质和技能的人来处理模型和对象实现,或者说白了，就是应该用什么样的团队模型来匹配业务模型。不同的模型，需要不同的团队模型的支撑，不同的团队模型也会让一个模型实现更优秀或者更糟糕。 相信很多人读过 ATM 机的例子，你发现自己彻底明白了用例应该怎么编写、模型怎么提取和实现，但是当你信心十足地去开始你自己的项目时，你又会发现你的思路片段化了，所有你明白了的技能在你的新项目中好像用不上。算了，还是老的工作思路和工作方式比较顺手，于是一切都照旧会到了老的套路上。那么，面向对象技术或者说我们提炼出来的模型应该如何在大型项目/团队中使用呢？我们是应该要求一个项目使用统一的模型，还是应该把它们分成不同的模型？我们应该如何抉择？ 领域驱动设计软件开发通常被应用到真实世界中已经存在的自动化流程，或者给真实的业务问题提供解决方案。即软件脱胎于领域，并与领域密切相关。 提出问题以汽车制造为例。参与汽车制造的工人会专门负责汽车的某个部件，但这样做的后果是工人们通常对整体的汽车制造流程缺乏了解。他们可能将汽车视为一大堆需要固定在一起的零件的集合体，但一辆汽车的意义远不只于此。一辆好车起源于一个好的创意，开始于认真制定的规格说明，然后再交付给设计。经历若干道设计工序，（历经岁月），用上几个月甚至几年的时间去设计、修改、精化直至完美，直至它反映出最初的愿景。设计的过程也不全然是在纸上进行的。许多的设计工作包括制模、在极端条件下对它们进行测试，以验证它们是否能工作等。设计会根据测试的结果做出修改。汽车最终被交付到生产线上，在那里，所有的部件已经就绪，然后被组装到一起。 因此，为了创建一个好软件，你必须知道这个软件究竟是什么。在你充分了解金融业务是什么之前，你是做不出一个好的银行业软件系统的，你必须理解银行业的领域。 那么对于软件架构师，他只是在使用银行来保护他的财产安全，以保证他的急时所需；软件分析师吗？也不是，他只精通于如何运用所有能够获得的必要因素去分析一个给定的主题；软件开发人员？别难为他了。 真正明白领域的人是业务人员。银行业务系统被银行的内部人员所熟知，我们称其为专家。他们知道所有的细节，所有的困难、所有可能出现的问题，以及所有的规章等。这些就是我们永远的起始点：领域。 背景目标 在启动一个软件项目时，我们应该关注软件涉及的领域。软件的最终目的是增进一个特定的领域。为了达到这个目的，软件需要跟要它服务的领域和谐相处，否则，它会给领域引入麻烦，产生障碍、灾难甚至导致混乱等。 做什么 让软件成为领域的反射（映射）。软件需要具现领域里重要的核心概念和元素，并精确实现它们之间的关系。软件需要对领域进行建模。 需要建立领域的抽象——在脑海当中建立一个蓝图。这个抽象是一个关于领域的模型，并不是一个图，是那副图要极力传递的思想。 模型是我们对目标领域的内部展现方式，会贯穿设计和开发的全过程。 怎么做 一个领域当中包含着海量的信息。我们需要组织信息，将其系统化，分割成一个小一点的信息块，将这些信息块分类放到逻辑模块当中，每次只处理其中的一个逻辑模块。 我们需要忽略领域中的很多部分，因为信息太多，不能放到一个模型当中，并且也存在一些信息并不需要我们去考虑。这同样是一个挑战。 模型 模型是软件设计中的最基础的部分。我们需要它，是因为能够用它来处理复杂问题。我们对领域的所有的思考过程被汇总到这个模型中。 我们需要用模型与其他人进行交流。常见的一种方式是将模型图形化：图、用例、画和图片等。另一种方式是写，我们会写下我们对领域的愿景。还有一种方式是使用语言，我们能够也应该针对要交流的领域内的特定问题建立一种语言。 软件设计 软件设计类似于构建房子的架构，那是跟一个总图相关的。代码设计是非常细节性的工作，类似于在一面墙上定位一幅油画。 瀑布设计方法 业务专家提出一堆需求同业务分析人员进行交流，分析人员基于那些需求来创建模型并作为结果传递给开发人员 开发人员根据他们收到的内容开始编码 缺陷：业务专家得不到分析人员的反馈信息，分析人员也得不到开发人员的反馈信息。 敏捷方法学 产生背景： 预先很难确定所有的需求，特别是需求经常变化的情况。要想预先创建一个覆盖领域所有方面的完整模型确实很困难 “分析瘫痪”，团队成员会因为害怕做出任何设计决定而无所事事。 使用大量灵活的实现，通过由业务涉众持续参与的迭代开发和许多重构，开发团队更多地学习到了客户的领域知识，从而能够产出满足客户需要的软件。 缺陷： 他们提倡简单，但每个人都对“简单”的意义有着自己的观点。 同时，缺乏了真实可见的设计原则，由开发人员执行地持续重构会导致代码更难理解或者更难改变。 虽然瀑布方法可能会导致过度工程，但对过度工程的担心可能会带来另一种担心：害怕做出深度、彻底的设计 构建领域知识通用语言模型驱动设计软件开发过程的重点，以业务领域为中心。让模型植根于领域，并精确反映出领域中的基础概念是建立模型的一个最重要的基础。 建立模型 在业务层通过接口确立模型，进行模型间的交互？ 将模型实现代码。 在模型确立后，用代码进行实现模型，进行不断的迭代？ 模型驱动设计的基本构成要素模式与模式间的关系 分层架构 当创建一个软件应用时，应用的很大一部分是不能直接与领域相关的，但是它们或时基础设施的一部分，或是为软件服务的。如数据库访问、文件、用户界面等相关代码 为了开发一个每个层内聚的设计，让层仅仅依赖于下面的层。一个统一的架构包含4个概念层 用户界面/展现层。 负责向用户展现信息以及解释用户命令。 应用层 很薄的一层，用来协调应用的活动。它不包含业务逻辑。它不保留业务对象的状态，但它保有应用任务的进度状态。 领域层 本层包含关于领域的信息。这是业务软件的核心所在。在这里保留业务对象的状态，对业务对象和它们状态的持久化被委托给了基础设施层。 基础设施层 本层作为其他层的支撑库存在。它提供了层间的通信，实现对业务对象的持久化，包含对用户界面层的支撑库等作用。 实体定义有一类对象看上去好像拥有标识符，它的标识符在历经软件的各种状态后仍能保持一致。对这些对象来讲这已经不再是它们关心的属性，这意味着能够跨越系统的生命周期甚至能超越软件系统的一系列的延续性和标识符。我们把这样的对象称为实体。 标识符不是说一个对对象的引用。相反一个对象经常会被移出或移入内存，被序列化后在网络上传输，在另一端重新建立，或者都被消除。但是我们依然可以知道这个对象到底是什么。例如传过来一个“账户”的对象，我们还是可以确定这个账户到底是什么。 举例考虑一个银行系统，每一个账户都拥有它自己的数字码，一个账户可以用它的数字码来精确标识。这个数字码会在系统的生命周期中会保持不变，并保持延续性。 账户码可以作为一个对象存在于内存中，也可以被在内存中销毁，发送到数据库中。当这个账户被关闭时，它还可以被归档，只要还有人对它感兴趣，它就依然在某处存在。不论它的表现形式如何，数字码会保持一致。 实现创建实体，即意味着创建标识符。通常标识符或是对象的一个属性（或属性的组合），一个专门为保存和表现标识符而创建的属性，也或是一种行为。 对两个拥有不同标识符的对象来说，能用系统轻易地把它们区分开来。或者两个使用了相同标识符的对象能被系统看成是相同的，这些都是非常重要的 值对象如何界定实体与值对象实体是领域模型中必需的对象。如何去确认一个实体？我们是否应该将所有的对象视为实体？每一个对象都应该有一个标识符吗？ 若是将所有对象看成是一个实体，那么由于实体是可以被跟踪的。创建与跟踪标识符需要很大的成本，需要保证每一个实体具有唯一的标识，并且根据标识符可以唯一去确定实体。同时会带来性能问题，如果Customer 是一个实体对象，那么这个对象的一个实例标识一个特殊的银行客户，不能被对应其他客户的账户操作所复用，造成的结果是必须为每一个客户建立一个这样的实例。这会导致系统在处理成千上万的实例时性能严重下降。 值对象 我们对某个对象是什么不感兴趣，只关心它拥有的属性。用来描述领域的特殊方面、且没有标识符的一个对象，叫做值对象。 实体对象 选择那些符合实体定义的对象作为实体 值对象的使用没有标识符，值对象可以很轻易地被创建和丢弃。 极力推荐值对象是不变的，由一个构造器创建，并且在生命周期内永远不会被修改。这样值对象就可以被共享了，不变的对象可以在重要性能语境下共享，也能表明一致性。 如果值对象是可共享的，那么它们应该是不可变的。值对象应该保持尽量的简单。当其他当事人需要一个值对象时，可以简单地传递值，或者创建一个副本。 服务当分析领域并试图定义构成模型的主要对象时，有些方面的领域很难映射为对象。 对象通常要考虑拥有属性，对象管理它的内部状态并暴露行为。对应的动词可以映射为对象的行为。但是领域中的一些动作，看上去不属于任何的对象，代表着领域中的一个重要行为，通常这种动作会跨越若干个对象。 当识别出这样的动作，最佳实践是将它声明成一个服务。这样的对象不再拥有内置的状态了，它的作用是为了简化所提供的领域功能。服务所能提供的协调作用是非常重要的，一个服务可以将服务于实体和值对象的相关功能进行分组。最好显式声明服务，因为它创建了领域中的一个清晰的特性，它封装了一个概念。把这样的功能放入实体或者值对象都会导致混乱，因为那些对象的立场将变得不清楚。 服务是多个对象的一个链接点 服务的特征 服务执行的操作涉及一个领域概念，这个领域概念通常不属于一个实体或者值对象。 被执行的操作涉及到领域中的其他的对象。 操作是无状态的 服务的设计在使用服务时，需要保持领域层的隔离，不应当弄混属于领域层的服务和属于基础设施层的服务。 决定服务是否属于领域层 如果所执行的操作概念上属于领域层，那么服务就应该放到这个层。如果操作和领域对象相关，而且确实也跟领域有关，能够满足领域的需要，那么它就应该属于领域层。 模块 对于大型的复杂项目，模型较为复杂，为降低复杂性，将模型组织进模块当中 代码应该具有高层次的内聚与低层次的耦合度，将内聚组织到模块当中 聚合 聚合是用来定义对象所有权和边界的领域模式 提出问题一个领域会包含众多的领域对象，我们总会看到许多对象与其他对象发生关联，形成一个复杂的关系网。领域对象间的实际关联在代码中结束，有时甚至却在数据库中。 直到模型中嵌入了对领域的深层理解，否则就要时常对模型中的关系进行消减和简化。 关联关系 对于1对1的关系。会表现为两个对象间的引用，并且在数据库表中隐含一个关联关系。 对于1对多的关联关系。可以被简单转化为一个对象与一组其他对象间的关联，虽然不总是行得通 对于多对多的关联。大部分是双向的，使得对这样的对象的生命周期管理变得困难。关联的数字应该被尽可能地消减。 首先删除模型中非本质的关联关系 增加约束，以消减多重性。如果很多对象满足一种关系，那么在这个关系上加入正确的约束后，很有可能只有一个对象会继续满足这种关系 转换为非双向的关联。 数据一致性问题 当系统完全删除一个客户的信息时，必须保证所有的引用都被删除了。如果许多对象保有这样的引用，则很难保证它们全被删除了。 同时当客户的某些数据发生了变化，系统必须确保在系统中执行了适当的更新。通常在数据库层面进行处理，手段是利用事务。若没有仔细设计模型，则会导致很大程度的数据库争夺导致性能佷差。 不变量 不变量是数据发生变化时必须维护的那些规则。这在许多对象与数据发生变化的对象保持引用时更难实现。 聚合定义聚合是针对数据变化可以考虑成一个单元的一组相关的对象。聚合使用边界将内部和外部的对象划分开来。 每个聚合有一个根。这个根是一个实体，并且它是外部可以访问的唯一的对象。根可以保持对任意聚合对象的引用，并且其他的对象可以持有任意其他的对象，但一个外部对象只能持有根对象的引用。如果边界内有其他的实体，那些实体的标识符是本地化的，只在聚合内有意义。 聚合原理因为其他对象只能持有根对象的引用，意味着它们不能直接变更聚合内的其他的对象，只能对根进行变更，或让根来执行某些活动。 当删除根后，聚合的所有其他对象也都删除了，因为不会有其他对象持有他们当中的任何一个。 根对象可能将内部的临时引用传递给外部对象，作为限制，当操作完成后，外部对象不能再持有这个引用。（传递一个值对象的拷贝） 如果聚合对象被保存到数据库当中，只有根可以通过查询获得。 工厂实体和聚合通常会很大很复杂，根实体的构造函数内的创建逻辑也会很复杂。通过构造器构建一个复杂的聚合与领域本身也会很冲突。 工厂用来封装对象创建所必需的知识，他们对创建聚合十分有效。 注意 工厂破坏了一个对象的封装原则，当对象中发生了某种变化，会对构造规则或者某些不变量造成影响，需要确认工厂也被更新以支持新的条件。 使用构造函数的情况 构造过程不复杂 对象的创建不涉及到其他对象的创建，所有的属性都需要传递给构造函数 客户程序对实现很感兴趣，可能希望选择使用策略模式 类是特定的类型，不涉及继承，所以不用在一系列的具体实现中进行选择 资源库提出问题创建对象的整体是为了能够使用他们。而想要获得这样的引用，客户程序必须创建一个对象或者通过导航已经有的关联关系从另一个对象中获得它。 问题是，客户程序首先要获得对根的引用，对大型应用而言，我们必须保证客户始终对需要的对象保持引用。者会强制要求对象持有一系列他们可能其实并不需要保持的一系列的引用。增加了耦合性，创建了一系列不需要的关联。 若是客户程序从数据库当中访问，获得它所需要的对象，看似简单，但是会对设计产生负面的影响。 数据库是基础设施一部分，客户程序必须要知道访问数据库所需的细节。 访问数据库可能会暴露其内部更细节的信息。 进行数据库访问的代码在整个模型中四散，在领域模型当中处理许多基础设施的细节而不是领域概念。 资源库目的是封装所有获取对象引用所需的逻辑，领域对象不需要处理基础设施，以得到领域中对其他对象的所需的引用，只需要从资源库中获取。 资源库作为一个全局的可访问对象的存储点而存在。资源库会保存对某些对象的引用，当一个对象被创建出来时，可以被保存到资源库中，然后以后使用时可以从资源库中检索。 面向深层理解的重构保持模型一致性参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码设计]]></title>
    <url>%2F2019%2F07%2F01%2FJava%2F%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[代码规范命名规范输入检测代码设计对于coder，面对问题会直觉使用计算机可以理解地逻辑来描述和表达待解决的问题和具体的求解过程。 但是这样的程序只能满足当前的需求，程序不容易维护，不容易扩展，不容易复用。 面向对象封装 业务逻辑与界面逻辑的分离 继承 当系统当中的操作需要增加或者修改，而这些操作拥有一个共性，那么就可以增加一个接口或者父类。在内部定义好操作，在子类当中进行实现 当新的操作加入进来，只需要继承即可。当旧的操作需要改变，只需要修改对应的子类即可 例如计算薪资的问题 多态 工厂模式 经验 面向对象的编程，并不是类越多越好，类的划分是为了封装，但分类的基础是抽象，具有系统属性和功能的对象的抽象集合才是类 原则以活字印刷为例。 可维护：要改，只需要改要改之字 可复用：活字的模板并非用完就无用，可以在之后的印刷重复使用 可扩展：若要加字，只需另刻字 灵活性好：若字要竖排，则移动活字即可。 可维护易扩展易复用灵活性好类设计技巧 一定要保证数据私有 这是最重要的；绝对不要破坏封装性。有时候，需要编写一个访问器方法或更改器方法，但是最好还是保持实例域的私有性。很多惨痛的经验告诉我们，数据的表示形式很可能会改变，但它们的使用方式却不会经常发生变化。当数据保持私有时，它们的表示形式的变化不会对类的使用者产生影响，即使出现 bug 也易于检测。 一定要对数据初始化 Java 不对局部变量进行初始化，但是会对对象的实例域进行初始化。最好不要依赖于系统的默认值 ， 而是应该显式地初始化所有的数据，具体的初始化方式可以是提供默认值，也可以是在所有构造器中设置默认值。 不要在类中使用过多的基本类型 就是说，用其他的类代替多个相关的基本类型的使用。这样会使类更加易于理解且易于修改。例如，用一个称为Address的新的类替换一个Customer类中以下的实例域： 1234private String street ;private String city ;private String state ;private int zip ; 这样，可以很容易处理地址的变化，例如，需要增加对国际地址的处理。 不是所有的域都需要独立的域访问器和域更改器 或许，需要获得或设置雇员的薪金。 而一旦构造了雇员对象，就应该禁止更改雇用日期，并且在对象中，常常包含一些不希望别人获得或设置的实例域，例如，在Address类中，存放州缩写的数组。 将职责过多的类进行分解 这样说似乎有点含糊不清，究竟多少算是“过多”？每个人的看法不同。但是，如果明显地可以将一个复杂的类分解成两个更为简单的类，就应该将其分解（但另一方面，也不要走极端。设计10个类，每个类只有一个方法，显然有些矫枉过正了） 类名和方法名要能够体现它们的职责 与变量应该有一个能够反映其含义的名字一样，类也应该如此 优先使用不可变的类 LocalDate类以及java.time包中的其他类是不可变的—没有方法能修改对象的状态。类似 plusDays 的方法并不是更改对象，而是返回状态已修改的新对象 更改对象的问题在于，如果多个线程试图同时更新一个对象，就会发生并发更改。其结果是不可预料的。如果类是不可变的，就可以安全地在多个线程间共享其对象。 因此，要尽可能让类是不可变的，这是一个很好的想法。对于表示值的类，如一个字符串或一个时间点，这尤其容易。计算会生成新值，而不是更新原来的值。 当然，并不是所有类都应当是不可变的。如果员工加薪时让raiseSalary方法返回一个新的Employee对象，这会很奇怪。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux：概述]]></title>
    <url>%2F2019%2F06%2F27%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2FLinux%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Linux发展史分类 内核版本：内核官网（www.kernel.org） 外核版本 在内核基础上做出改进，即发行版本。 发行版本 redhat：它有一部分收费的售后功能 Centos：是完全免费的，并且与redhat一致 fediro：个人版 Ubuntu：图形界面更优秀 debian： Linux应用领域 开源软件开源软件，即获得程序的源代码，而不是编译后的二进制文件 使用的自由：绝大多数开源软件免费 研究的自由：可以获得软件源代码 散步及改良的自由：可以自由传播、改良甚至销售 在Linux当中，以服务器端的角度看，Linux当中有更多的开源软件，有着更高质量的软件 Apache：网站服务搭建软件 Nginx：占用服务器资源更少，支持更高的并发 MySQL php Samba mongoDB python Ruby Sphinx等 Linux应用领域基于Linux的企业服务器www.netcraft.com 嵌入式应用Linux文件基本属性不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。在Linux中我们可以使用ll或者ls –l命令来显示一个文件的属性以及文件所属的用户和组，如： 1234[root@www /]# ls -ltotal 64dr-xr-xr-x 2 root root 4096 Dec 14 2012 bindr-xr-xr-x 4 root root 4096 Apr 19 2012 boot 第一个字符代表这个文件是目录、文件或链接文件等： d：目录，-：文件，l：链接文档，b：装置文件里面的可供储存的接口设备(可随机存取装置)，c：装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。 接下来的字符3个为一组，且均为rwx的组合。 r：可读，w：可写，x：可执行。若没有权限：-。 1-3位：属主拥有该文件的权限，即该文件的所有者。 4-6位：确定属主，即所有者的同组用户所有该文件的权限。 7-9位：确定其他用户拥有该文件的权限。 文件属主和属组对于文件来说，都有一个特定的所有者，也就是对该文件具有所有权的用户。在Linux系统中用户是按组分类的，一个用户属于一个或多个组。 文件所有者以外的用户又可以分为文件所有者的同组用户和其他用户。因此，Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。 在以上实例中，mysql文件是一个目录文件，属主和属组都为mysql，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。 对于root用户来说，一般情况下，文件的权限对其不起作用。 Linux常见目录作用 /：根目录 /bin，是命令保存目录，任何用户都可以执行 /user/bin /sbin，是保存系统命令目录，只有root用户可以执行 /user/sbin /boot，启动目录，启动相关文件 /dev，设备文件保存目录，保存特殊文件 /etc，配置文件保存目录， /home，普通用户的家目录 /lib，系统库保存目录 /mnt，系统挂载目录 /media，挂载目录 /root，超级用户家目录 /misc，挂载目录 /proc，直接写入内存的，不可以直接操作 /tmp，临时目录 /sys，保存的是内存的过载点，不可以直接操作 /user，系统软件资源目录 /var，系统相关文档内容 参考]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构：分布式架构]]></title>
    <url>%2F2019%2F06%2F22%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[分布式系统概述定义 分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此间仅仅通过消息传递进行通信和协调的系统。 很多台计算机组成一个整体，一个整体一致对外并且处理同一请求，并且在这些计算机上部署了我们的组件，其分布在网络计算机上。 内部的每台计算机仅仅通过消息传递来通信并协调行动（rest/rpc）。 客户端到服务端的一次请求到响应结束会历经多台计算机。 意义 升级单机处理能力的性价比越来越低。CPU、内存、磁盘和网络。 单机处理能力存在瓶颈。 出于稳定性和可用性的考虑。 基础知识从单个计算机角度看一下计算机的组成要素。组成计算机的五要素： 外存。计算机断电时外存的数据不会丢失。 内存。计算机断电时，内存中存储的数据会丢失。 CPU。 输出设备。 输入设备。 阿姆达尔定律程序中的串行部分对于增加CPU核心来提升处理速度存在限制$$S(N)=1/(1-P+P/N)$$P指程序中可并行部分的程序在单核上执行时间的占比。N表示处理器的个数，S(N)指程序在N个处理器相对在单个处理器中的速度提升比。 多线程模式基于共享容器协同的多线程模式 常见的有生产者-消费者模型，这个队列会共享一个容器或数据对象，多个线程会并发地访问这个队列。 通过事件协同的多线程模式 线程间存在协调的需求，例如A、B两个线程，B线程需要等到某个状态后事件发生后才能继续自己的工作，而这个状态改变或者事件产生和A线程相关。这个场景下需要完成线程间协调。 多进程模式 分布式就类似于将单机多线程变为了单机的多进程。 多进程的内存空间是独立的，因此通过内存共享、交换数据的方式与多个线程间的方式就有所不同。 进程间的通信、协调以及通过一些事件通知或等待一些互斥锁的释放方面也会与多线程不一样。 网络通信基础知识组件分布在网络上的多个节点中，通过消息的传递来通信并进行动作的协调，因此网络通信在分布式系统中非常重要。 网络IOBIO、NIO、AIO。 如何从单机扩展到分布式即使是分布式系统，也是绕不开输入、输出、运算、存储、控制的。 输入设备的变化分布式系统由通过网络连接的多个节点组成，那么输入设备可以分为两类： 互相连接的多个节点，在接收其他节点传来的信息时，该节点可以看做是输入设备。 传统意义上的人机交互的输入设备。 输出设备的变化 系统中的节点在向其他节点传递信息时，该节点可以看做是输出设备。 传统意义上的人机交互的输出设备。 控制器的变化分布式系统是由多个节点通过网络连接在一起并通过消息的传递进行协调的系统，控制器主要的作用是协调或控制节点之间的动作和行为。 基于硬件负载均衡的请求调用。所有的请求都要经过这个负载均衡设备来完成请求转发的控制，这就是一种控制的方式： 基于软件负载均衡系统。代价更低，并且可控性较强，可以相对自由地按照自己的需求去增加负载均衡的策略。 该方式一般称为透明代理，在集群当中，这种方式对于发起请求的一方和处理请求的一方来说，都是透明的，发起请求的一方会以为是中间的代理提供了服务，而处理请求的一方会以为是中间的代理请求的服务。因此发起请求的一方不用关心由多少台机器提供服务，只需要知道中间透明代理即可，但是有两个不足： 增加网络的开销，存在流量大与延迟的问题。 如果采用LVS的TUN或DR模式，那么处理的返回结果会之间返回请求服务的机器，适合于请求数据包小，处理数据包大的场景。如果请求的数据包很大，则影响较为明显。 延迟问题实际很小，只是存在。 透明代理处于请求的必经路径上，如果代理出现问题，所有请求都会受到影响。 采用名称服务的直连方式的请求调用。在请求发起方和处理方中间没有代理服务器，而是直接连接。名称服务的作用是收集提供请求处理的服务器的地址信息，提供这些地址信息给请求发送方。即名称服务起到一个地址交换的作用，在发起请求的机器上需要根据从名称服务得到的地址进行负载均衡的工作，即将原来透明代理的工作拆分到名称服务和发起请求的机器。 名称服务不在请求的必经路径上，即如果名称服务出现问题，依然有不少办法可以保证请求处理的正常。 直连方式减少了中间路径与可能的额外带宽消耗。 但是代码的升级较为复杂。 采用规则服务器控制路由的请求直连调用。依然是直连的方式，但是请求发起的一方选择请求处理的机器需要依赖规则服务器给的规则，发起的机器会有对规则进行处理从而选择机器的逻辑，此时规则服务器本身不会和请求处理的机器交互，只负责将规则提供给请求发起的机器。 Master+Worker的方式。使用Master节点管理任务，Master将任务分配给不同的Worker处理，其主要是任务的分配与管理，而不是请求发起与处理。 运算器的变化概念 分布式系统中的运算器是运用多个节点的计算能力来协同完成整体的计算任务。 当依靠多台机器处理用户请求时，首先的问题就是用户应该去访问哪个服务器，有两种解决方式： DNS服务进行调度和控制。用户解析DNS时，就会被给予一个服务器的地址，类似于名称服务或者规则服务器的方式。 负载均衡。DNS返回的永远是负载均衡的地址，而用户的访问都是通过负载均衡到达后面的网站服务器。 即构成运算器的多个节点在控制器的配合下对外提供服务，构成了分布式系统中的运算器。 日志处理 当使用多台服务器收集日志并行处理，此时可以采用Master-Worker的方式进行处理： 存储器的变化在分布式系统中，我们需要把承担存储功能的多个节点组织在一起，使其看起来是一个存储器，我们也需要通过控制器来配合完成工作。 如果要将一台KV存储服务器扩展为两台： 使用代理服务器，根据请求的Key进行划分。 使用规则服务，写明如何对数据做Sharding，并包含对具体目标KV存储服务器的地址。 使用Master-Worker，具体的KV选择在Master上就完成。 如果KV服务器出故障了或新增加了，应用服务器如何感知是一种较复杂的问题，尤其是对需要做持久数据服务的节点。 分布式系统的挑战缺乏全局时钟单机程序中，程序以单机的时钟为准，控制时序比较容易，而在分布式系统中每个节点都有自己的时钟，在通过相互发送消息进行协调时，如果仍然依赖时序，就会相对难处理。 很多时候我们使用时钟，它可以区分两个动作的顺序，而不是一定要知道准确的事件，我们可以将这个工作交给一个单独的集群来完成，通过这个集群来区分多个动作的顺序。 面对故障独立性有可能出现某个节点或某些节点存在问题，而其他节点以及网络设备都没有问题。即一部分故障，而其他服务依然可用，即故障独立性。 处理单点故障如果某个角色或功能只有单台单机在支撑，那么这个节点称为单点，发生的故障称为单点故障，即SPoF。一般将其变为集群实现，或者还要另外两种选择： 给这个单点做好备份，能够在出现问题时进行恢复，并尽量做到自动恢复，降低恢复需要用的事件。 降低单点故障的影响范围。 例如将整个交易信息存放在一个数据库，则通过Sharding进行拆分数据库，此时只有当两台数据库同时故障才会影响全部范围。 事务的挑战（数据一致性）两阶段提交、最终一致性、BASE、CAP、Paxos等 分布式系统的瓶颈服务框架的设计与实现应用从集中式走向分布式所遇到的问题要将单层Web应用的结构改为多层的、有服务层的结构时，大多人都是直接为当前要用的服务做一个RPC的功能，为服务使用者提供相关的客户端。而实际上当提供服务的集群多于一个时，通用的服务框架就非常重要了。 转化为RPC后，最关心的问题时提高易用性以及降低性能损失两方面。 服务调用端的设计与实现要调用远程服务的过程： 获得可用服务地址列表。 确定要调用服务的目标机器。 可进行负载均衡。例如规则服务器、直接连接等。 建立连接。 请求序列化，并发送请求。 接收并解析结果。 服务调用者与服务提供者间通信方式的选择远程通信遇到的问题 当为两台机器时，写死IP与端口就可以解决问题了。 但是在实际应用中，提供某种服务的机器一定是多台的，是一个集群，并且调用服务的机器也是集群，则此时如何解决调用者与服务提供者之间的通信问题。 采用透明代理与调用者、服务提供者直连的解决方案 我们可以通过LVS，即硬件负载均衡或者LVS的中间代理来解决该问题。 而在服务框架的设计中，采用的是基于注册中心的解决方案。 出于效率因素，并不是在每次调用远程服务前都通过这个服务注册中心来查找可用地址，而是将地址缓存在调用者本地，当有变化时主动从服务注册中心发起通知，告诉调用者可用的服务提供者列表的变化。 获得地址后，如何为当次的调用进行选择就是路由要解决的问题了。具体到负载均衡的实现上： 随机、轮询。对服务提供者能力对等的情况下比较合适。 权重。权重以动态形式，基于响应时间来计算。 引入基于接口、方法、参数的路由 一般而言会以接口作为服务的粒度，即一个服务就是指一个接口的远程实现。 一般情况下，集群会提供多个服务，每个服务有多个方法，因此除了基础的负载均衡策略，还有更加细粒度地控制服务路由的需求。 如果接口其中的某个方法A执行很慢，其明显慢于其他方法，但是调用频率与其他方法差不多。则由于线程池当中的线程数目一定，在高负载情况下，可能出现所有线程都被方法A占用的情况。 增加资源保证系统的能力是超出需要的。 隔离资源，从而使得快慢不同、重要级别不同的方法之间互不影响。 从客户端的角度讲，控制同一个集群中不同服务的路由并进行请求的隔离是一种可行方案。 即在调用者方，将调用接口A的请求路由到集群D1，将调用接口B的请求路由到集群D2。 采用将路由规则集中管理的方式进行管理，在具体调用者端的服务框架上先获取规则后进行路由的处理的负载均衡算法。 多机房场景 机房之间的距离和分工决定了我们应该采用什么样的架构与策略。考虑较近的同城机房。 服务注册中心做一些工作，通过它来甄别不同机房的调用者集群，给它们不同服务提供者的地址。 通过路由完成，服务注册查找中心给不同机房的调用者相同的服务提供者列表，我们在服务框架内部进行地址过滤。 服务调用端的流控处理 这里的流控是指加载到调用者的控制功能，是为了控制到服务提供者的请求的流量。 以固定的值表示每s可请求的次数，超过则拒绝请求。 设定0-1开关。 那么基于数目维度来进行控制呢？ 根据服务端自身的接口、方法做控制，根据不同的接口、方法设置不同的阈值，保证服务端的不同接口、方法间的负载不互相影响。 根据来源做控制，对相同的接口、方法，根据不同来源设置不同的限制，一版用在较为基础的服务上。 序列化与反序列化处理 网络通信的实现选择 支持多种异步服务调用方式 使用NIO能够完成连接复用以及对调用者的同步调用的支持。 Oneway。只管请求而不关心结果的方式。 Callback。请求方发送请求后会继续执行自己的操作，等对方有响应时进行一个回调，其执行不是在原请求线程中，而是在新的IO线程中。 Future。一种能够主动控制超时、获取结果的方式，并且它的执行仍然在原请求线程中。 可靠异步。一般通过消息中间件来完成。 使用Future方式对远程服务调用的优化当我们需要在一个请求中调用多个远程服务，例如： 那么由于同步调用，我们可能要消耗很久的时间，为寻求改变： 即当请求发出去，我们统一等待服务A、B、C的执行结果，然后再进行本地的数据处理。这种方式以Future的方式进行并行优化，且底层使用NIO方式，并行没有产生额外的开销。 服务提供端的设计与实现参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构：单体架构]]></title>
    <url>%2F2019%2F06%2F18%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[单体架构 概述一个归档包（如war格式）包含了应用所有功能的应用程序，我们通常称为单体应用。 架构单体应用的方法论，我们称之微单体应用架构 基础优缺优点： 部署简单 容易测试。不需要外部的依赖，直接就可以启动整个系统 缺点： 非常臃肿。修改一个模块需要发布整个应用。并且每次发布可能会遇到不同的问题。 复杂性高 对于一个百万行级别的单体应用为例，整个项目包含的模块非常多，模块的边界模糊，依赖关系不清晰，代码质量参差不齐，混乱地堆砌在一起 整个项目非常复杂，每次修改代码都要心惊胆战，甚至添加一个简单的功能或修改一个bug都会造成隐含的缺陷。因为应用程序的其他模块可能会以意料之外的方式使用它 技术债务 随着时间的推移、需求变更和人员更迭，会逐渐形成应用程序的技术债务，并且越积越多。“不坏不修”的问题会很严重。 部署频率低 随着代码的增多，构建和部署的时间也会增加。在单体应用中，每次功能的变更或缺陷的修复都会导致我们需要重新部署整个应用。 全面部署耗时长，影响范围大、 风险高，使得单体应用项目上线部署的频率低，会使得在两次发布间有大量的功能交替和缺陷修复，出错频率高 扩展能力受限 单体应用只能作为一个整体扩展，无法结合业务模块的特点进行伸缩。如IO密集型、CPU密集型 阻碍技术创新。 要求团队每个成员使用相同的开发语言和框架。难以引入新的框架 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法：目录]]></title>
    <url>%2F2019%2F06%2F17%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[算法HackerRank 思路总结算法与数据结构是相互分离的。 算法是一个接口，底层的数据结构是一个接口，并且使用数据结构接口去实现所需要的算法接口。 解决问题： 解决问题本身是一个相对的概念，是探讨解决一个问题的解决方案。 正确还包含优化、代码规范、封装性、容错性等。 首先思考数据结构本身能否解决问题。 能，则说明问题负荷数据结构的特性，直接使用数据结构解决问题。 不能，则思考哪种数据结构对问题有一些帮助，回想数据结构都能解决哪些类型的问题。并下一步： 思考算法需要应用的业务场景，数据拥有哪些特征。 如果有大量重复数据，则可以选择三路快速排序。 如果都是独特的，则普通的快排就可以。 如果数据量很小，则可以使用插入排序。 如果数据是分数，则有一个限定额，可以使用计数排序。 如果是要求稳定性，则可以使用归并排序。 如果是链表组织的，则可以使用归并排序。 如果数据量很大，则需要使用外排。 思考常用算法是否能够解决问题。 例如排序、查找、递归算法。它们是否符合这些常用算法的特性。 思考算法思想，看能否匹配。 写算法先写接口，设计好算法的抽象接口，在抽象的角度上解决问题。 利用数据结构实现算法，解决问题，只要确定实现了抽象的语义，那么一定是可以解决问题的。 常见问题 注意题目中的条件。 O(nlogn)，则可能是分治。 无需额外的空间，则开一个额外的空间。 规模是10000，则On^2算法。 有序数组，则二分等方法是否有帮助。 测试用例。 暴力解法。 基础数据结构线性 数组、动态数组。 链表、栈、队列。 哈希表。 树 二叉树。 二叉查找树、AVL树、红黑树、B树、B+树、B*树。 Segment Tree。 多叉树： Trie 树。 并查集。 图邻接表、邻接矩阵。 高层数据结构高层数据结构指定义好这种数据结构相应的使用接口，包括其本身维持的一些性质，具体的底层实现可以是多种多样的。 栈与队列底层实现： 数组、链表 概述 优先队列。 适用性 应用场景 集合Set概述 Set：承载元素的容器，每个元素只能存在一次。 分类 有序集合。有序集合中的元素具有顺序性，一般基于搜索树实现。可以轻易查找前一个元素等，存在一些增强功能。 无序集合。哈希表、链表等。 多重集合。可以容纳重复的元素。 适用性 实现元素去重。 应用场景 客户统计、词汇量统计等。 操作： boolean contain(E); void add(E); 底层实现： 数组、链表。 树： 二分搜索树（AVL、红黑树等） 速度次快。 哈希表。 速度最快。 映射Map概述 分类 有序映射。 无序映射。 适用性 应用场景 操作： 底层实现： 数组、链表。 二分搜索树。 算法思想分治 递归。 贪心回溯动态规划分支限定常用算法排序与查找递归Graph深度优先、广度优先。 算法基础时间复杂度常数时间的操作：一个操作如果和数据量没有关系，每次都是固定时间内完成的操作。 时间复杂度为一个算法流程中，常数操作数量的指标。常用O来表示。 在常数操作数量的表达式中，只要高阶项，不要低阶项 也不要高阶项的系数 剩下的部分如果记为f(N)，则时间复杂度为O(f(N)) 如果存在两个变量，在不知道两个变量的样本量的大小时，需要将两个变量留下，如O（MlogM）+O(M+N) 当由于数据情况不一致，而复杂度不同，则依靠最差时间复杂度估计。 评价一个算法流程的好坏，先看时间复杂度的指标，然后再分析不同数据样本下的实际运行时间(指标一致)，即常数项时间 空间复杂度空间复杂度是指在原来的样本量基础上，额外申请的空间。 递归的本质递归行为是一种系统压栈，所以任何递归问题都可以改成非递归，改为人工压栈即可。 一种分治的思想。寻找最大值，数组中左边的最大值和右边的最大值当中的最大值一定是全局的最大值。 时间复杂度master公式T(N)=a*T(N/b)+O(N^d) log(b,a)&gt;d-&gt;复杂度为O(N^log(b,a)) log(b,a)==d-&gt;复杂度为O(N^d*logN) log(b,a)&lt;d-&gt;复杂度为O(N^d) 对数器作用 在online上没有题目，自己验证算法是否正确 在笔试的时候，小样本测试过了。面对大样本报错，找出错误的位置。 验证贪心策略的正确与否 组成 一个随机样本生成器 正确的方法r与最好的方法b 判断两个方法是否正确的方法equals 打印出错特殊case的方法print 步骤 有一个想要测试的方法b 实现一个绝对正确但是复杂度不好的方法r 时间复杂度差的算法很暴力，容易写出。因此绝对正确的算法是可以写出的。 但是在笔试的时候是过不了的。因此需要算法a 若方法b不是绝对正确，则在对比的过程中迭代方法修改 实现随机样本产生器 实现比对的方法 把方法a和方法b比对多次来验证方法a是否正确 如果一个样本使得比对出错，打印样本分析哪个方法出错 当样本数量很多时比对测试依然正确，则可以确定方法a已经正确 示例要测的方法： 12345678910111213public static void bubbleSort(int[] arr)&#123; if (arr==null || arr.length &lt; 2) return; for (int end = arr.length - 1;end&gt;0; end--) &#123; for (int i = 0; i &lt; end; i++) &#123; if (arr[i] &gt; arr[i+1]) swap(arr, i, i+1); &#125; &#125;&#125; 绝对正确的方法 1234// 可以直接用一些库函数来进行测试public static void rightMethod(int[] arr)&#123; Arrays.sort(arr);&#125; 实现一个随机样本发生器 1234567891011121314// 随机数生成器public static int[] generateRandomArray(int size, int value)&#123;//Math.random() -&gt; double [0,1)//(int) ((size + 1) * Math.random()) -&gt; [0,size]整数// 生成长度随机[0, size]的数组int[] arr = new int[(int) ((size+1) * Math.random())];for (int i = 0; i &lt; arr.length; i++)&#123; // 一个随机数减去另一个随机数，生成[-value, value]的随机数 arr[i] = (int) ((value+1) * Math.random()) - (int) (value * Math.random());&#125;return arr;&#125; 实现对比的方法 12345678910111213141516// 判断两个数组是否相等public static boolean isEqual(int[] arr1, int[] arr2)&#123; if ((arr1 == null &amp;&amp; arr2 != null) || (arr1 != null &amp;&amp; arr2 == null)) return false; if (arr1 == null &amp;&amp; arr2 == null) return true; if (arr1.length != arr2.length) return false; for (int i = 0; i &lt; arr1.length; i++) &#123; if (arr1[i] != arr2[i]) return false; &#125; return true;&#125; main方法： 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; int testTime = 500000; int size = 10; int value = 100; boolean succeed = true; for (int i = 0; i &lt; testTime; i++) &#123; int[] arr1 = generateRandomArray(size, value); int[] arr2 = copyArray(arr1); int[] arr3 = copyArray(arr1); bubbleSort(arr1); rightMethod(arr2); if (!isEqual(arr1, arr2)) &#123; succeed = false; printArray(arr3); break; &#125; &#125; System.out.println(succeed ? "Nice!" : "error----"); int[] arr = generateRandomArray(size, value); printArray(arr); bubbleSort(arr); printArray(arr);&#125; 比较器实现Comparable接口 参考]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StudyResources]]></title>
    <url>%2F2019%2F06%2F16%2FStudyResources%2F</url>
    <content type="text"><![CDATA[JavaJVMJava性能调优指南 Java性能优化权威指南 第三章 第四章 入门 基础 进阶 参考 Spring Spring4.x企业 Spring揭秘 SpringBoot 揭秘 源码 看透Spring MVC Spring源码深度解析 DBMySQLMySQL技术内幕 RedisRedis设计与实现 Redis开发与运维 网络自顶向下 图解TCP/IP : 第5版 图解HTTP 算法剑指 程序员代码面试指南：IT名企算法与数据结构题目最优解 架构大型网站技术架构 RPC分布式Java应用 thrift http://blog.csdn.net/column/details/thrift.html dubbo http://blog.csdn.net/u010311445/article/category/2745121 微服务 http://microservices.io/patterns/index.html 分布式原理书籍 分布式系统原理介绍（百度 刘杰 文档） 大型分布式网站架构设计与实践 中间件Netty权威指南 docker入门与实践 参考]]></content>
      <categories>
        <category>Base</category>
      </categories>
      <tags>
        <tag>Base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StudyMethod]]></title>
    <url>%2F2019%2F06%2F16%2FStudyMethod%2F</url>
    <content type="text"><![CDATA[寻找与学习相关的资源，并作用个简介，记录到StudyResources 找课程视频做了解，并同时找书看。 写博客，记录学习其中原理，并再次实践，重温书内容 Java求职经验分享规划：一二线大厂更关注基础知识：数据结构与算法、计算机网络与操作系统 其他公司：语言与框架的实践能力。 Java理论 语言基础 Java编程思想、Effective Java 深入理解Java虚拟机、Java并发编程实战 源码分析 设计模式 结合Java类库当中的实现，或者是Spring当中的实现 框架与中间件 Spring，精通Spring4.x、Spring揭秘（对于IOC与AOP比较好） 缓存与消息队列。 Redis实战、Redis设计与实现。 RabbitMQ实战指南 数据库 MySQL必知必回。刷题 数据库系统概念，MySQL技术内幕、高性能MySQL。Innob、索引、锁、事务、性能优化 数据结构与算法 计算机网络 TcpIP、HTTP、socket 计算机网络自顶向下、TCPIP详解、图解HTTP socket了解IO多路复用（UNIX网络编程） OS 进程线程、死锁、内存管理 现代操作系统、深入理解操作系统 LINUX 系统设计 问题：设计网站架构 大型网站架构 分布式，从Paxos到Zookeeper、大规模分布式存储系统、微服务 项目考察主要目的 对业务的理解程度 对热门技术的掌握程度 项目的着力点 从业务角度分析项目的难点 多用热门技术解决问题，缓存、集群、消息队列 从业务角度分析，说清楚这么做有什么用、为什么不用其他方法 建议做高并发项目 建议 部署到云服务器上，有访问地址 开源到GitHub，写好项目文档 求职经验网申渠道 公司的校招官网。公众号 第三方招聘网站收集信息，之后去看官网 简历简历相当于向公司推销自己的工具，要展现自己能为公司带来的价值。 技能的匹配程度。技术栈 能力证明。工作实习、项目中解决的问题等 笔试 笔试问题应试偏强。 面试题目偏向实际问题。 面试比笔试更为重要，笔试是面试的入场券，但是笔试过线就可以参加面试，占用的比例较低 要是简历非常出色就会被面试官看重 若查出作弊就GG，因为这个资料库是共享的 技术面 考察理论知识掌握与学习能力、分析解决问题的能力 面试是交流，在交流中将面试官引入到熟悉的领域，并体现自己的能力 提问 理论知识掌握情况 深度。除了回答标准答案后，还需要结合场景分析使用什么， 广度，不一定非常熟悉全部的，但是要了解他们的基本原理 回答问题 为什么存在(解决了什么问题) 基本原理 使用场景 和其他相比有什么不同 结构化表达，避免回答零散 先列出核心的知识点，不做出过多的引申。最后再拓展 进行引导， 编码能力 边界情况 测试用例。正常用例，空，，输入错误等 分析解决问题能力 看对理论知识是否有深入的理解 对没有遇到过的问题会怎么分析去解决 在遇到一个问题时，最怕没有在搞清楚问题的情况下就解决问题。需要将问题问清楚。没有思路要和面试官多交流。避免逃避问题 最喜欢问项目当中遇到的问题 学习能力 团队协作能力 交流表达能力 自我介绍中突出自己的亮点，引导到自己的优势 项目经理自己联系表达几个问题 介绍自己的项目（用了什么技术） 遇到什么难题 项目有什么亮点 加入意愿 向面试官提问主要目的是对企业和部门有更深入的了解 部门的业务和技术栈 技术难点怎么解决 公司吸引您的地方有哪些 先去官网渠道收集一些信息。我了解到你们使用了XX技术，这个技术XXX，你们如何处理XXX问题的、 了解面试表现 向面试官征求学习建议。会做出一些点评，哪些不足，哪些得到肯定。 牛客网的Java面试题库https://www.nowcoder.com/tutoril/94 HR面 参考]]></content>
      <categories>
        <category>Base</category>
      </categories>
      <tags>
        <tag>Base</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F06%2F16%2F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2FMaven%2FMaven%EF%BC%9AStart%2F</url>
    <content type="text"><![CDATA[Maven提出问题 当要开发一个新的项目时，需要借助框架如：spring、mybatis，第三方框架。此时需要去各个官网下载各种jar包放到lib目录下 此时项目开发并没有开始，但是lib目标拥有很多jar包，并且不知道是否有用、有关联，并且可能存在版本冲突。 为什么要用（作用）Maven是基于项目对象模型（POM），可以通过一小段描述信息来管理项目的构建、报告和文档的软件项目管理工具。 Maven可以帮助我们更有效地管理项目，也是一套自动化构建工具，覆盖编译、测试、运行、清理、打包、部署。提供了一个仓库的概念，统一帮助我们管理第三方的jar包，避免了在你的电脑上可以运行，在我的电脑上不可以运行。 Maven安装Maven目录maven的文件目录 bin目录。包含mvn的运行脚本，shell当中输入mvn会调用这些脚本 boot目录。包括类加载的框架，maven用来加载自己的类库 conf目录。配置文件 lib目录，maven平时自己会用到的目录 配置用户变量：电脑是多人的话，为不影响他人，在这里配置 系统变量：私人电脑 新建一个变量M2_HOME。值为Maven的安装目录 修改Path，%M2_hOME/bin% 配置验证：mvn -v Maven仓库仓库分类 local: ~/.m2/repository 本地资源库，用来存储所有项目的依赖关系（插件Jar和其他文件）这些被下载到本地文件夹 remote 远程仓库 中央仓库http://repo1.maven.org/maven2/ 私服 http://maven.hellobike.cn/ 第三方 jboss、aliyun…… maven包管理流程当在pom文件中依赖某个包后，如果没有做特殊配置 到本地仓库进行搜索，若本地仓库没有则下一步 到中央仓库进行获取。 在Maven远程仓库中搜索（需要进行定义） Mvaen私服由于中央仓库在国外，因此速度无法保证。 搭建maven私服，保证稳定性。并且可以将一些工具包等放入，提高项目开发的灵活度。 搭建 Nexus 是用来搭建 Maven 私服的可以说是唯一的工具，它的官网上是这样说的：“世界上第一个也是唯一的免费使用的仓库解决方案”。目前的最新版本是 OSS 3.x。提供了针对 Windows、Unix、OS X 三种系统的版本。 配置仓库 123456789101112&lt;mirrors&gt; &lt;mirror&gt; &lt;!-- 唯一标识一个mirror --&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;!-- 代表了一个镜像的替代位置，例如central就表示代替官方的中央库 --&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;!--描述--&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;!--库地址--&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt; ...&lt;/mirrors&gt; 配置文件配置结构： localRepository 本地仓库路径 interactiveMode 值为true/false，true表示mave可以使用用户输入，默认true usePluginRegistry true表示maven使用~/.m2/plugin-registry.xml管理插件版本 Offline true表示构建系统在离线模式下执行 pluginGroups 当你在命令行中没有提供插件的groupid时，将会使用该列表 Servers 账号密码等信息 Mirrors 镜像，通过mirrorOf 规则进行匹配 Proxies 代理服务 Profiles 是pom.xml的profile元素的一个裁剪版本 activeProfiles 激活Profiles 安装外部库到本地需要手动发出Maven命令包括一个 jar 到 Maven 的本地资源库。 要使用的 jar 不存在于 Maven 的中心储存库中。 您创建了一个自定义的 jar ，而另一个 Maven 项目需要使用。 下载 “kaptcha”，将其解压缩并将 kaptcha-version.jar 复制到其他地方，比如：C盘。发出下面的命令： 1mvn install:install-file -Dfile=c:\kaptcha-&#123;version&#125;.jar -DgroupId=com.google.code -DartifactId=kaptcha -Dversion=&#123;version&#125; -Dpackaging=jar 示例： 123456789101112131415161718D:\&gt;mvn install:install-file -Dfile=c:\kaptcha-2.3.jar -DgroupId=com.google.code -DartifactId=kaptcha -Dversion=2.3 -Dpackaging=jar[INFO] Scanning for projects...[INFO] Searching repository for plugin with prefix: 'install'.[INFO] ------------------------------------------------------------------------[INFO] Building Maven Default Project[INFO] task-segment: [install:install-file] (aggregator-style)[INFO] ------------------------------------------------------------------------[INFO] [install:install-file][INFO] Installing c:\kaptcha-2.3.jar to D:\maven_repo\com\google\code\kaptcha\2.3\kaptcha-2.3.jar[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ------------------------------------------------------------------------[INFO] Total time: &lt; 1 second[INFO] Finished at: Tue May 12 13:41:42 SGT 2014[INFO] Final Memory: 3M/6M[INFO] ------------------------------------------------------------------------ 现在，“kaptcha” jar被复制到 Maven 本地存储库。 pom.xml 安装完毕后，就在 pom.xml 中声明 kaptcha 的坐标。 12345&lt;dependency&gt; &lt;groupId&gt;com.google.code&lt;/groupId&gt; &lt;artifactId&gt;kaptcha&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; 构建它，现在 “kaptcha” jar 能够从你的 Maven 本地存储库检索了。 Maven项目Maven项目与实际项目不是一一对应的关系，而是对应一个模块，一个实际的项目往往有很多个模块 项目目录 src：源代码 main java package resources：资源文件 test java package target classes：编译生成的class字节码文件 package maven-status： maven-archiver surefive-reports：生成的测试报告 test-classes jar包：mvn package打包后的jar maven构建maven命令123456mvn -v # maven 查看版本mvn compile # 对项目进行编译，在根目录执行。第一次执行时会下载jar包mvn test # 运行项目的测试mvn package # 打包项目mvn clean # 删除targetmvn install # 安装jar包到软件仓库中 maven引入构建包的流程 通过mvn compile编译源代码。如果程序用到了其他的包，会去查找是否引入该依赖包的坐标，即dependency 如果引入了这些坐标，会去本地仓库查找。如果仓库中有这些jar包。如果没有，则取网上Maven的中央仓库中查找，并下载下来 坐标和仓库构件在Maven中任何一个依赖、插件、项目构建的输出均可以称为构件。 所有构件均通过坐标作为其唯一的标识。 基本的坐标： 123&lt;groupId&gt;&lt;/groupId&gt;&lt;artifactId&gt;&lt;/artifactId&gt;&lt;version&gt;&lt;/version&gt; 仓库仓库用来管理项目的依赖 本地仓库。如果本地的仓库找不到构件，则去远程仓库寻找 远程仓库。默认为全球中央仓库，地址在/bin/maven-model-builder/…./pom.xml当中当中 镜像仓库 /maven/conf/setting.xml，在当中 123456&lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;!--该镜像仓库的ID--&gt;、、 &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;!--为哪个仓库配置镜像，可使用通配符适配--&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt;&lt;/mirror&gt; maven生命周期完整的项目构建过程：清理、编译、测试、打包、 集成测试、验证、部署 maven常见生命周期： clean：清理项目 pre-clean：执行清理前的工作 clean：清理上一次构建生成的所有文件 post-clean：执行清理后的文件 vaidate：验证。验证工程配置是否正确 compile：编译。 test：单元测试 package：打包。根据pom描述的打包配置进行打包 verify：检查。验证工程包有效，并满足质量要求 install：安装。在本地、远程仓库中安装工程包 deploy：发布 default：构建项目 compile test package install site：生成项目站点 pre-site：生成项目站点前要完成的工作 site：生成项目的站点文档 post-site： site-deploy：发布生成的站点到服务器上 PomPom是Maven项目的核心管理文件，用于项目描述、组织管理、依赖管理和组织信息的管理。 pom文件 工程标识 groupId：这是工程组的标识。它在一个组织或者项目中通常是唯一的。若继承parent可不填 artifactId：这是工程的标识。它通常是工程的名称。 version：这是工程的版本号。在artifact 的仓库中，它用来区分不同的版本。一般使用语义化版本X.Y.Z规则 packaging：打包机制，pom、Jar、par、rar、ear、ejb、war、maven-plugin parent：用于在子模块对父模块的pom的继承 modules：子模块 dependency：依赖 dependencyManagement：依赖管理，不会被引入到实际的依赖中，定义在父模块，供子模块继承使用 build：编译、打包 distributionManagement：Deploy地址 properties：自定义参数 profiles：根据环境变量进行配置，使用-P[id]激活，如-Pdev 版本号 版本号不写在项目当中，在dependencyManagement当中写，所有子项目的版本就都与父版本一致 打包结果 项目最终打包为jar后，其名称为：groupId:artifactId:version 实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--pom的根元素，包括一些约束信息--&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--代表当前pom的版本为4.0.0--&gt; &lt;!--坐标信息--&gt; &lt;groupId&gt;com.enet&lt;/groupId&gt; &lt;!--代表项目的包名--&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;!--代表模块名--&gt; &lt;!--第一个0代表大版本号，第2个代表分支版本号，第3个代表小版本号--&gt; &lt;!--snapshot快照、alpha内部测试、beta公测、Release稳定、GA正式发布--&gt; &lt;version&gt;0.0.1SNAPSHOT&lt;/version&gt; &lt;!--代表版本名。--&gt; &lt;name&gt;&lt;/name&gt; &lt;!--项目的描述名--&gt; &lt;url&gt;&lt;/url&gt; &lt;!--项目的地址--&gt; &lt;description&gt;&lt;/description&gt; &lt;!--描述--&gt; &lt;packaging&gt;pom&lt;/packaging&gt;&lt;!-- packaging: 打包的机制，如pom, jar, maven-plugin, ejb, war, ear, rar, par 默认为jar--&gt; &lt;properties&gt; &lt;!--在其他地方可以通过$(junit.version)对值进行引用--&gt; &lt;junit.version&gt;&lt;!--可以声明一个值--&gt;&lt;/junit.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;!--用于在子模块对父模块的pom的继承--&gt; &lt;groupId&gt;com.enet&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;modules&gt;&lt;!--定义多个模块，一起进行编译--&gt; &lt;/modules&gt; &lt;dependencyManagement&gt;&lt;!--依赖的管理，不会被引入到实际的依赖中，定义在父模块，供子模块继承使用--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;type&gt;&lt;/type&gt; &lt;scope&gt;&lt;/scope&gt;&lt;!--依赖范围，如果值为test，则只在测试时该jar包有效--&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt;&lt;!--依赖列表--&gt; &lt;dependency&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;type&gt;&lt;/type&gt; &lt;scope&gt;&lt;/scope&gt;&lt;!--依赖范围--&gt; &lt;optional&gt;&lt;/optional&gt;&lt;!--设置依赖是否可选，默认为false即是继承，true则必须显式引入该依赖--&gt; &lt;exclusions&gt;&lt;!--排除依赖传递列表，如A依赖B，B依赖C，则C传递依赖A，即在导入B包的依赖时，会导入C--&gt; &lt;exclusion&gt;&lt;/exclusion&gt;&lt;!--排除传递依赖的C，避免依赖冲突--&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;!--为构建的行为做支持--&gt; &lt;plugins&gt;&lt;!--导入maven的插件--&gt; &lt;plugin&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;executions&gt;&lt;!--可选--&gt; &lt;execution&gt; &lt;phase&gt;&lt;!--示例值：package--&gt; &lt;!--绑定的生命周期的阶段，即在哪个阶段运行这个插件，如在package阶段，则会在mvn package的时候运行source--&gt;&lt;/phase&gt; &lt;goals&gt;&lt;/goals&gt;&lt;!--运行目标--&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 依赖依赖范围将jar包引入项目的classpath当中，项目就可以使用该jar包当中封装好的方法了 maven提供了三种classpath: 编译 测试 运行 在dependency当中导入jar包时，scope的值代表了jar包存在哪个classpath当中，当值为test时，则该jar包将只存在于测试的classpath当中 依赖传递依赖存在传递性，当依赖于A的时候。导入A的依赖时，就会将A所依赖的jar包也导入进来 当需要清除掉传递依赖所需要的jar包时，就需要使用exclusion 依赖冲突当A和B依赖了同一个不同版本的构件，就存在了依赖冲突 Maven解决： 短路优先 A-&gt;B-&gt;C-&gt;X A-&gt;D-&gt;X（短路，则优先，导入该X的版本） 先声明先优先。如果路径长度相同，则谁先声明，先解析谁 聚合和继承如果我们想要将多个项目进行install，将其安装到本地仓库中，需要对多个项目依次进行install。 聚合 maven当中有种方式可以将其放在一起运行，这种方式称为聚合。 聚合标签 继承 在多个项目当中，存在共同的一些依赖，可以像Java当中进行继承。 父类继承标签 123456789101112&lt;!--在该标签内的依赖，是不会再该项目当中运行，会继承给子类。--&gt;&lt;dependencyManagement&gt;&lt;!--依赖的管理，不会被引入到实际的依赖中，定义在父模块，供子模块继承使用--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;type&gt;&lt;/type&gt; &lt;scope&gt;&lt;/scope&gt;&lt;!--依赖范围，如果值为test，则只在测试时该jar包有效--&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 子类继承 123456&lt;parent&gt; &lt;!--用于在子模块对父模块的pom的继承--&gt; &lt;groupId&gt;com.enet&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 参考 项目管理利器——maven]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>Start</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统设计：UML建模]]></title>
    <url>%2F2019%2F06%2F11%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%EF%BC%9AUML%E5%BB%BA%E6%A8%A1%2F</url>
    <content type="text"><![CDATA[UML静态建模静态建模定义了系统中重要对象的属性和操作以及这些对象间的相互关系。主要包括类图、对象图、包图、构件图、部署图。 UML基础类的表示： 第一行：类的名字，如果是接口&lt;接口名&gt;，如果是抽象方法则是斜体的 第二行：类的属性： [开放程度][属性名称]:[类型] +：public，-：private，#：protected，~：包权限，下划线：static 第三行：类的方法。 [开放程度][方法名称](参数):返回类型 斜体：抽象方法 UML类图只有知道对方信息，箭头才能指向对方。 泛化关系抽象语义： 用来描述继承关系，在Java中使用extends关键字。 代码语义： 继承extends关系。 实现关系抽象语义： 用来实现一个接口，在 Java 中使用implements关键字。或者可以说是接口的一个实现 代码语义： implements 关联关系抽象语义： 表示不同类对象之间有关联，这是一种静态关系，与运行过程的状态无关，在最开始就可以确定。因此也可以用1对1、多对1、多对多这种关联关系来表示。比如学生和学校就是一种关联关系，一个学校可以有很多学生，但是一个学生只属于一个学校，因此这是一种多对一的关系，在运行开始之前就可以确定。 双向关联有两个箭头或者没有箭头。而单向关联有一个箭头，表示关联的方向 代码语义： 关联是实打实的关系，因此是实线，并且其作为一个实例属性存在。 它们存在业务的联系，用来表示无法用聚合和组合表示的关系,因此不是组合或者聚合。 一个类当中，有另外一个类作为属性。用来表示无法用聚合和组合表示的关系。如学生与老师的关系 关联是一种拥有的关系, 它使一个类知道另一个类的属性和方法，其暗示了依赖关系。 例如企鹅与气候，企鹅是需要知道气候的变化，需要了解气候规律的。即一个类知道另一个类。 依赖关系抽象语义： 一个类要借助另一个类来实现功能。 和关联关系不同的是，依赖关系是在运行过程中起作用的，是一种使用的关系, 即一个类的实现需要另一个类的协助, 所以要尽量不使用双向的互相依赖。A 类和 B 类是依赖关系主要有三种形式： 代码语义： 依赖是虚拟的，只在使用时关注，因此是虚线并在方法当中作为变量使用。 A类是B类方法的局部变量。 A类是B类方法当中的一个参数。 依赖通常体现为调用一个其他所依赖类的方法，A类向B类发送消息，从而影响B类发生变化。 聚合关系抽象语义： 聚合：是整体与部分的关系, 且部分可以离开整体而单独存在. 如车和轮胎是整体和部分的关系, 轮胎离开车仍然可以存在. 两者具有独立的生命周期。 成员可独立。班级与学生 聚合(Aggregation)关系表示整体与部分的关系。在聚合关系中，成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。例如：汽车发动机(Engine)是汽车(Car)的组成部分，但是汽车发动机可以独立存在，因此，汽车和发动机是聚合关系，如图6所示： 在代码实现聚合关系时，成员对象通常作为构造方法、Setter方法或业务方法的参数注入到整体对象中，图6对应的Java代码片段如下： 12345678910111213public class Car &#123; private Engine engine; //构造注入 public Car(Engine engine) &#123; this.engine = engine; &#125; //设值注入 public void setEngine(Engine engine) &#123; this.engine = engine; &#125; …… &#125; public class Engine &#123; …… &#125; 代码语义： 一个成员变量。 组合关系抽象语义： 两个对象具有相同的生命周期。 组合：是整体与部分的关系, 但部分不能离开整体而单独存在. 如公司和部门是整体和部分的关系, 没有公司就不存在部门. 成员不可独立。汽车与引擎（必须依赖于整体才有意义） 组合(Composition)关系也表示类之间整体和部分的关系，但是在组合关系中整体对象可以控制成员对象的生命周期，一旦整体对象不存在，成员对象也将不存在，成员对象与整体对象之间具有同生共死的关系。在UML中，组合关系用带实心菱形的直线表示。例如：人的头(Head)与嘴巴(Mouth)，嘴巴是头的组成部分之一，而且如果头没了，嘴巴也就没了，因此头和嘴巴是组合关系，如图7所示： 在代码实现组合关系时，通常在整体类的构造方法中直接实例化成员类，图7对应的Java代码片段如下： 12345678910`public class Head &#123; private Mouth mouth; public Head() &#123; mouth = new Mouth(); //实例化成员类 &#125; …… &#125; public class Mouth &#123; …… &#125; ` 代码语义： 作为成员变量。 实战泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖 下面围绕类Library类分析下这个图，首先library通过组合方式关联到了Catalog类目类，这说明类目不能独立存在要依赖图书馆存在，所以这里没有使用聚合而使用了组合。另外library通过聚合关联到了Book Item 类和Account账号类，这说明图书馆是有0个或者多个图书和账户组成，这里使用聚合而不是用组合是因为书和账号可以独立于图书馆存在，比如我有学号账号，但是图书馆里面不是必然有你的账号。 下面围绕Catalog分析，类目通过双向关联关联到bookitem，说明一个类目里面可能会有0个或者多个书籍，一个书籍对应着一个类目。另外类目有通过realization实现了search类和manage类的接口，让类目有搜索和管理功能。Search类搜索时候会依赖Patron类图书捐赠人的姓名地址或者Libraian类图书管理员的姓名地址，职位。 图书管理类时候会依赖图书管理员类的信息。 而Patron图书捐赠人有可能是一个学生，学生有自己的账号，所以patron类会聚合到Account.bookItem类通过泛化继承Book中书的共性部分信息。有通过关联关联到了account,说明一个账户只能接到0本和最多12本书，最多可以预定3本书。 最后Book类双向关联到Author类，数目一个作者至少写了1本书（严格说应该是0），一本书至少有一个作者编写，Account账户类有依赖一个AccountState的枚举值的类用来存放账号状态。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：复合模式]]></title>
    <url>%2F2019%2F06%2F04%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%A4%8D%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[复合模式提出问题为什么要用（作用）应用场景基础概述是什么模式通常被一起使用，并被组合在同一个设计解决方案中。 复合模式在一个解决方案中结合两个或多个模式，以解决一般或重复发生的问题，如MVC。它与一群模式携手合作并不相同 分类，各个分类是什么 MVC 基础优缺实现实现步骤示例底层原理与其他的区别设计思想MVC模型–视图-控制器 模型：持有所有的数据、状态和程序逻辑。模型没有注意到视图和控制器，虽然它提供了操纵和检索状态的接口，并发送状态改变通知给观察者。 视图：用来呈现模型，通常直接从模型中取得它所需要显式的状态与数据 控制器：取得用户的输入并解读其对模型的意思、 模式 模型：观察者模式。当状态改变时，使用观察者模式，让模型完全独立于视图和控制器。一个模型可以使用不同的视图，甚至可以同时使用多个视图 视图：组合模式。 控制器：策略模式。视图是一个对象，可以被调整使用不同的策略，控制器提供了策略。策略模式让视图与模型间关系解耦 进阶反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MQTT协议]]></title>
    <url>%2F2019%2F05%2F29%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2FMQTT%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[提出问题为什么要用（作用）应用场景基础概述是什么MQTT[1](消息队列遥测传输)是ISO 标准(ISO/IEC PRF 20922)[2]下基于发布/订阅范式的消息协议。它工作在 TCP/IP协议族上，是为硬件性能低下的远程设备以及网络状况糟糕的情况下而设计的发布/订阅型消息协议，为此，它需要一个消息中间件 。 MQTT是一个基于客户端-服务器的消息发布/订阅传输协议。MQTT协议是轻量、简单、开放和易于实现的，这些特点使它适用范围非常广泛。在很多情况下，包括受限的环境中，如：机器与机器（M2M）通信和物联网（IoT）。其在，通过卫星链路通信传感器、偶尔拨号的医疗设备、智能家居、及一些小型化设备中已广泛使用。 分类，各个分类是什么基础优缺优点 可以以极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。作为一种低开销、低带宽占用的即时通讯协议，使其在物联网、小型设备、移动应用等方面有较广泛的应用。 实现实现步骤示例协议原理MQTT协议实现方式实现MQTT协议需要客户端和服务器端通讯完成，在通讯过程中，MQTT协议中有三种身份：发布者（Publish）、代理（Broker）（服务器）、订阅者（Subscribe）。其中，消息的发布者和订阅者都是客户端，消息代理是服务器，消息发布者可以同时是订阅者。 MQTT传输的消息分为：主题（Topic）和负载（payload）两部分： Topic，可以理解为消息的类型，订阅者订阅（Subscribe）后，就会收到该主题的消息内容（payload）； payload，可以理解为消息的内容，是指订阅者具体要使用的内容。 网络传输与应用消息MQTT会构建底层网络传输：它将建立客户端到服务器的连接，提供两者之间的一个有序的、无损的、基于字节流的双向传输。 当应用数据通过MQTT网络发送时，MQTT会把与之相关的服务质量（QoS）和主题名（Topic）相关连。 MQTT客户端一个使用MQTT协议的应用程序或者设备，它总是建立到服务器的网络连接。客户端可以： 发布其他客户端可能会订阅的信息； 订阅其它客户端发布的消息； 退订或删除应用程序的消息； 断开与服务器连接。 MQTT服务器MQTT服务器以称为”消息代理”（Broker），可以是一个应用程序或一台设备。它是位于消息发布者和订阅者之间，它可以： 接受来自客户的网络连接； 接受客户发布的应用信息； 处理来自客户端的订阅和退订请求； 向订阅的客户转发应用程序消息。 MQTT协议中的订阅、主题、会话一、订阅（Subscription） 订阅包含主题筛选器（Topic Filter）和最大服务质量（QoS）。订阅会与一个会话（Session）关联。一个会话可以包含多个订阅。每一个会话中的每个订阅都有一个不同的主题筛选器。 二、会话（Session） 每个客户端与服务器建立连接后就是一个会话，客户端和服务器之间有状态交互。会话存在于一个网络之间，也可能在客户端和服务器之间跨越多个连续的网络连接。 三、主题名（Topic Name） 连接到一个应用程序消息的标签，该标签与服务器的订阅相匹配。服务器会将消息发送给订阅所匹配标签的每个客户端。 四、主题筛选器（Topic Filter） 一个对主题名通配符筛选器，在订阅表达式中使用，表示订阅所匹配到的多个主题。 五、负载（Payload） 消息订阅者所具体接收的内容。 MQTT协议中的方法MQTT协议中定义了一些方法（也被称为动作），来于表示对确定资源所进行操作。这个资源可以代表预先存在的数据或动态生成数据，这取决于服务器的实现。通常来说，资源指服务器上的文件或输出。主要方法有： Connect。等待与服务器建立连接。 Disconnect。等待MQTT客户端完成所做的工作，并与服务器断开TCP/IP会话。 Subscribe。等待完成订阅。 UnSubscribe。等待服务器取消客户端的一个或多个topics订阅。 Publish。MQTT客户端发送消息请求，发送完成后返回应用程序线程。 设计思想MQTT协议工作在低带宽、不可靠的网络的远程传感器和控制设备通讯而设计的协议，它具有以下主要的几项特性： 使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。 这一点很类似于XMPP，但是MQTT的信息冗余远小于XMPP，,因为XMPP使用XML格式文本来传递数据。 对负载内容屏蔽的消息传输。 使用TCP/IP提供网络连接。 主流的MQTT是基于TCP连接进行数据推送的，但是同样有基于UDP的版本，叫做MQTT-SN。这两种版本由于基于不同的连接方式，优缺点自然也就各有不同了。 有三种消息发布服务质量： “至多一次”，消息发布完全依赖底层TCP/IP网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。这一种方式主要普通APP的推送，倘若你的智能设备在消息推送时未联网，推送过去没收到，再次联网也就收不到了。 “至少一次”，确保消息到达，但消息重复可能会发生。 “只有一次”，确保消息到达一次。在一些要求比较严格的计费系统中，可以使用此级别。在计费系统中，消息重复或丢失会导致不正确的结果。这种最高质量的消息发布服务还可以用于即时通讯类的APP的推送，确保用户收到且只会收到一次。 小型传输，开销很小（固定长度的头部是2字节），协议交换最小化，以降低网络流量。 这就是为什么在介绍里说它非常适合”在物联网领域，传感器与服务器的通信，信息的收集”，要知道嵌入式设备的运算能力和带宽都相对薄弱，使用这种协议来传递消息再适合不过了。 使用Last Will和Testament特性通知有关各方客户端异常中断的机制。 Last Will：即遗言机制，用于通知同一主题下的其他设备发送遗言的设备已经断开了连接。 Testament：遗嘱机制，功能类似于Last Will。 进阶反省总结参考 维基百科]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式：解释器模式]]></title>
    <url>%2F2019%2F05%2F14%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：优化]]></title>
    <url>%2F2019%2F05%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9A%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参考 万字总结：学习MySQL优化原理，这一篇就够了！]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：数据库原理]]></title>
    <url>%2F2019%2F05%2F09%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL数据类型串串数据类型存储串。并有定长串与变长串两种类型。串值需要在引号内（单引号最好）。 定长串：接受长度固定的字符串，长度在建表时指定。（处理定长列速度很多）： CHAR：1-255个字符定长串，默认长度为1。 变长串：存储可变长度的文本。有些变长数据类型具有最大的定长，有些完全变长的。（无法对变长列索引）： Varchar：长度可变，最大255。 Text：最大长度64K。 TinyText：最大长度255。 LongText：最大长度4GB。 MediumText：最大长度16K。 ENUM：接受最多64K个串组成应该预定义集合的某个串。 SET：接受最多64个串组成应该预定义集合的零个或某个串。 数值数据数值不使用引号，对于货币一般使用Decimal(8,2)。 除了BIT和Boolean都可以由符号或无符号，默认是有符号，可以使用UNSIGNED取消存储负数。 BIT：1字节，位字段，1~64位。 BigInt：8字节，整数值，-2^63^~2^63^。 Boolean：1字节，0或1。 Decimal：自定义长度，精度可变的浮点值。 Double：8字节，双精度浮点。 Float：4或8字节，单精度浮点。 Int：4字节，整数值-2^31^~2^31^。 MediumInt：3字节。 Real：4字节，浮点值。 SmallInt：2字节。 TinyInt：1字节。 日期与时间数据类型 Date：表示YYYY-MM-DD日期。 DateTime：Date与Time组合。 TimeStamp：与DateTime相同，但范围较小。 Time：格式位HH:MM:SS。 Year：2位数字表示，（19）70（20）69。4位数字表示：19012155。 二进制数据类型可以存储任何数据，如图像、多媒体等： Blob：最大长度64KB。 MediumBlob：最大长度16MB。 LongBlob：最大长度4GB。 TinyBlob：最大长度255字节。 关系数据库设计理论函数依赖记A-&gt;B表示A函数决定B，也可以说B函数依赖于A。 如果{A1，A2，… ，An}是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。 对于A-&gt;B，如果能找到A的真子集A’，使得A’-&gt;B，那么A-&gt;B就是部分函数依赖，否则就是完全函数依赖。 对于A-&gt;B，B-&gt;C，则A-&gt;C是一个传递函数依赖。 异常以下的学生课程关系的函数依赖为 Sno, Cname -&gt; Sname, Sdept, Mname, Grade，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 不符合范式的关系，会产生很多异常，主要有以下四种异常： 冗余数据：例如 学生-2 出现了两次。 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 课程-1 需要删除第一行和第三行，那么 学生-1 的信息就会丢失。 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。 范式范式理论是为了解决以上提到四种异常。 高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。 第一范式 (1NF) 属性不可分。 第二范式 (2NF) 每个非主属性完全函数依赖于键码。 可以通过分解来满足。 分解前 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 以上学生课程关系中，{Sno, Cname} 为键码，有如下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname Sno, Cname-&gt; Grade Grade 完全函数依赖于键码，它没有任何冗余数据，每个学生的每门课都有特定的成绩。 Sname, Sdept 和 Mname 都部分依赖于键码，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。 分解后 关系-1 Sno Sname Sdept Mname 1 学生-1 学院-1 院长-1 2 学生-2 学院-2 院长-2 3 学生-3 学院-2 院长-2 有以下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname 关系-2 Sno Cname Grade 1 课程-1 90 2 课程-2 80 2 课程-1 100 3 课程-2 95 有以下函数依赖： Sno, Cname -&gt; Grade 第三范式 (3NF) 非主属性不传递函数依赖于键码。 上面的 关系-1 中存在以下传递函数依赖： Sno -&gt; Sdept -&gt; Mname 可以进行以下分解： 关系-11 Sno Sname Sdept 1 学生-1 学院-1 2 学生-2 学院-2 3 学生-3 学院-2 关系-12 Sdept Mname 学院-1 院长-1 学院-2 院长-2 ER 图Entity-Relationship，有三个组成部分：实体、属性、联系。 用来进行关系型数据库系统的概念设计。 实体的三种联系 包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 下图的 Course 和 Student 是一对多的关系。 表示出现多次的关系一个实体在联系出现几次，就要用几条线连接。 下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。 联系的多向性虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。 一般只使用二元联系，可以把多元联系转换为二元联系。 表示子类用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 位图Bit Map当表中的字段仅有几种值，那么Bit Map就是很好的选择。关键字的位图会存该行是否是该关键字。例如10000就是第一行的值是该关键字。因此一个位图能存储非常多的信息。 因此每一列当中只有1个1，其适合查询统计场景。不适合高并发，其粒度非常大，会锁住很多的信息，当增删改查时会涉及比较多的一致性约定。 MySQL并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 丢失修改T1和T2两个事务都对一个数据进行修改，T1先修改，T2随后修改，T2的修改覆盖了T1的修改。 在任何隔离级别下都不会发生，但可能出现另一个问题： 事务T1查询一行数据，放入本地内存，显示给一个用户U1。 同时，事务T2查询该记录，显式给用户U2。 U1修改这行记录，更新并提交。 U2修改这行记录，更新并提交。此时没有去读取新的数据。 银行转账场景下会出现问题。 脏读T1修改一个数据，T2随后读取这个数据。如果T1撤销了这次修改，那么T2读取的数据是脏数据。 脏数据：事务对缓冲池中行记录的修改，并且还没有被提交。 如果读到了脏数据，即一个事务读取到另一个事务未提交的数据，违反了数据库的隔离性。 不可重复读在一个事务内多次读取同一数据集合，在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。 T2读取一个数据，T1对该数据做了修改。如果T2再次读取这个数据，由于T1事务的修改，此时读取的结果和第一次读取的结果不同。 与脏读的区别： 脏读读到未提交的数据，不可重复读读取到已经提交的数据。 不可重复读违反了数据库事务一致性的要求。 由于读取到的是已经提交的数据，一般而言不会带来很大问题，因此一些数据库允许该现象。 幻读T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 封锁封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 粒度：database、table、page、row。 封锁类型读写锁 排它锁（Exclusive），简写为X锁，又称写锁。 共享锁（Shared），简写为S锁，又称读锁。 有以下两个规定： 一个事务对数据对象A加了X锁，就可以对A进行读取和更新。加锁期间其它事务不能对A加任何锁。 一个事务对数据对象A加了S锁，可以对A进行读取操作，但是不能进行更新操作。加锁期间其它事务能对A加S锁，但是不能加X锁。 意向锁使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务T想要对表A加X锁，就需要先检测是否有其它事务对表A或者表A中的任意一行加了锁，那么就需要对表A的每一行都检测一次，这是非常耗时的。 意向锁在原来的X/S锁之上引入了IX/IS，IX/IS都是表锁，用来表示一个事务想要在表中的某个数据行上加X锁或S锁。有以下两个规定： 一个事务在获得某个数据行对象的S锁之前，必须先获得表的IS锁或者更强的锁。 一个事务在获得某个数据行对象的X锁之前，必须先获得表的IX锁。 通过引入意向锁，事务T想要对表A加X锁，只需要先检测是否有其它事务对表A加了X/IX/S/IS锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务T加X锁失败。 各种锁的兼容关系如下： - X IX S IS X × × × × IX × √ × √ S × × √ √ IS × √ √ √ 解释如下： 任意IS/IX锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S锁只与S锁和IS锁兼容，也就是说事务T想要对数据行加S锁，其它事务可以已经获得对表或者表中的行的S锁。 封锁协议三级封锁协议一级封锁协议 事务T要修改数据A时必须加X锁，直到T结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 T1 T2 lock-x(A) read A=20 lock-x(A) wait write A=19 . commit . unlock-x(A) . obtain read A=19 write A=21 commit unlock-x(A) 二级封锁协议 在一级的基础上，要求读取数据A时必须加S锁，读取完马上释放S锁。 可以解决读脏数据问题，因为如果一个事务在对数据A进行修改，根据1级封锁协议，会加X锁，那么就不能再加S锁了，也就是不会读入数据。 T1 T2 lock-x(A) read A=20 write A=19 lock-s(A) wait rollback . A=20 . unlock-x(A) . obtain read A=20 unlock-s(A) commit 三级封锁协议 在二级的基础上，要求读取数据A时必须加S锁，直到事务结束了才能释放S锁。 可以解决不可重复读的问题，因为读A时，其它事务不能对A加X锁，从而避免了在读的期间数据发生改变。 T1 T2 lock-s(A) read A=20 lock-x(A) wait read A=20 . commit . unlock-s(A) . obtain read A=20 write A=19 commit unlock-X(A) 两段锁协议两段锁协议是指所有事务必须分两个阶段对数据项加锁和解锁： 在对任何数据进行读、写操作之前，要申请并获得对该数据的封锁。 每个事务中，所有的封锁请求先于所有的解锁请求。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 1lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL隐式与显式锁定MySQL的InnoDB存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB也可以使用特定的语句进行显示锁定： 12SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE; 隔离级别使用隔离级别的开销基本一致。因此即使使用未提交读也不会得到性能的大幅提升： 隔离级别 脏读 不可重复读 幻读 未提交读 Read uncommitted 可能 可能 可能 已提交读 Read committed 可能 可能 可重复读 Repeatable read 不可能 不可能 可能 可串行化Serializable 不可能 不可能 不可能 未提交读(Read Uncommitted)事务中的修改，即使没有提交，对其它事务也是可见的。 允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 提交读(Read Committed)一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。Oracle等多数数据库默认都是该级别 (不重复读)： 不可重复读违反了数据库事务一致性。 由于读取到的是已经提交的数据，一般而言不会带来很大问题，因此一些数据库允许该现象。 可重复读(Repeated Read)保证在同一个事务中多次读取同样数据的结果是一样的。InnoDB默认级别。 采用Next-KeyLock算法避免锁的产生。 串行读(Serializable)强制事务串行执行。每次读都需要获得表级共享锁，读写相互都会阻塞 参考 数据库系统原理]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：应用层]]></title>
    <url>%2F2019%2F04%2F21%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络应用是计算机网络存在的理由 应用层协议原理研发网络应用的核心是写出能够运行在不同端系统和通过网络彼此通信的程序。因此研发新应用程序时，需要编写将在多台端系统上运行的软件，并且即使你要为网络核心设备写应用程序软件，也不需要写在网络核心设备如路由器上运行的软件。网络核心设备并不在应用层上起作用，只在较低层起作用，特别是网络层及下面层次，这种基本设计也即将应用软件限制在了端系统上。帮助了大量的应用程序研发 从宏观的角度来看，两个应用仿佛直接通信一样，而对于应用层只需要考虑如何与运输层进行交互即可。 网络应用程序体系结构从应用程序研发者的角度看，网络体系结构是固定的，并为应用程序提供了特定的服务集合。另一方面，应用程序体系结构由应用程序研发者设计，规定了如何在各种端系统上组织该应用程序，常见的结构有：CS结构与P2P结构 CS结构 CS结构的特征 有一个总是打开的主机称为服务器，服务于来自许多其他称为客户的主机的请求。例如Web应用程序。 服务器具有固定的、周知的地址，并且因为该服务器总是打开的，客户总是能够通过向该服务器的IP地址发送分组来与其联系 对于CS结构，常出现一台单独的服务器主机跟不上它所有客户的请求的情况，为此配备大量主机的数据中心常被用于创建强大的虚拟服务器，如Google搜索引擎。 P2P结构 对位于数据中心的专用服务器有最小的依赖，应用程序在间断连接的主机对之间直接通信，这些主机对被称为对等方，对等方并不为服务提供商所有，而是用户控制的PC所有，大多数对等方驻留在家庭、大学等，其不必通过专门的服务器。常见的有文件共享、因特网电话等。 P2P结构存在自扩展性，在一个P2P文件共享应用中，尽管每个对等方都由于请求文件产生工作量，但每个对等方通过向其他对等方分发文件也为系统增加服务能力。P2P结构不需要庞大的服务器设施与服务器带宽，但面临三个主要挑战。 ISP友好：大多数ISP受限于非对称的带宽应用，因此下载比上传要多得多。P2P结构改变了从服务器到住宅ISP的上传流量，为ISP带来了巨大压力 安全性：高分布性与开放性 激励：说服用户自愿向应用提供带宽、存储和计算资源 进程通信客户与服务器进程 网络应用程序由成对的进程组成，这些进程通过网络相互发送报文，其中一个请求数据的进程为客户，另一个回应请求的进程为服务器。而在P2P的应用中，则一个进程既可以是客户又是服务器，因为它既可以上传数据也可以请求数据。 在给定的一对进程之间的通信会话场景中，发起通信（即在会话开始时发起与其他进程的连续）的进程被标识为客户，在会话开始时等待联系的进程是服务器 进程与计算机网络之间的接口 多数应用程序是由通信进程对组成的，每对中的两个进程互相发送报文。从一个进程向另一个进程发送的报文必须通过下面的网络。 进程通过一个称为套接字的软件接口向网络发送报文和从网络接收报文。套接字类似于房子的门，而进程就是房子，通过套接字走出门外到另一个进程。 套接字是同一台主机内应用层与运输层之间的接口，由于该套接字是建立网络应用程序的可编程接口，因此套接字也被称为应用程序与网络间的应用程序编程接口（API），应用程序开发者可以控制套接字在应用层端的一切， 但对该套接字在运输层端几乎没有控制权。对于运输层的控制权有 选择运输层协议 设定几个运输层参数，如最大缓存和最大报文段长度。 进程寻址为了向特定目的地发送邮件，目的地需要一个地址，在一台主机上的进程为了向另一台主机上运行的进程发送分组，接收进程需要一个地址。为了标识接收进程需要两种信息 主机的地址。即IP地址，是一个32比特的量且能够唯一标识主机 定义在目的主机中的接收进程的标识符。即接收套接字，一般是指端口号 可供应用程序使用的运输服务包括因特网在内的很多网络提供了不止一种的运输层协议，当开发一个应用时，必须选择一个可用的运输层协议。最可能的方式是研究这些可用的运输层协议所提供的服务，选择一个最能为你的应用需求提供恰当服务的协议。 如何界定一个运输层协议能够为调用它的应用程序提供什么样的服务呢，大体从四个角度分类：可靠数据传输、吞吐量、定时、安全性 可靠数据传输 分组在计算机网络中可能丢失。例如分组使得路由器中的缓存溢出，分组中的某些比特损坏后可能丢弃。而数据丢失可能会造成很严重的后果，因此为了支持一些对数据要求十分严格的应用，就需要保证确保数据交付服务，即可靠数据传输。 当一个运输协议能够提供这种服务时，发送进程只要将其数据传输进套接字，就可以完全相信该数据将能够无差错到达接收进程。而对于音频等应用，它们是容忍丢失的应用，即使音频等出现小干扰，也并不是十分关键 吞吐量 在沿着一条网络路径上的两个进程间的通信会话场景中，可用吞吐量即发送进程能够向接收进程交付比特的速率。由于其他会话将共享沿着该网络路径的带宽，并且这些会话将到达和离开，因此可用吞吐量也会随时间波动。当一种服务能够以某种特定速率提供确保的可用吞吐量，即应用程序能够请求r/s的稳定速率，并且运输协议确保可用吞吐量至少为r/s，这样的确保吞吐量的协议将很有作用 例如电话需要对语音以32kbps速率进行编码，那么他必须以这个速率向网络发送数据。具有吞吐量要求的应用称为带宽敏感的应用。弹性应用能够根据请求或多或少地利用吞吐量，例如文件传输应用、web传输应用等。 定时 运输层协议也能提供定时保证。如发送方注入进套接字中的每个比特到达接收方的套接字不迟于100ms，这种服务对于交互式的应用程序有吸引力。即实时应用 安全性 如在发送主机中，运输协议能够加密由发送进程传输的所有数据，接收主机中，运输协议能够在将数据交付前解密数据，并且在进程间提供机密性，以及数据完整性和端口鉴别等。 因特网提供的运输服务因特网为应用层协议提供两个运输层协议，即TCP与UDP。而某些应用程序对运输层协议的要求是： TCP服务 TCP服务模型包括面向连接服务于可靠数据传输服务 面向连接服务： 在应用层数据报文流动前，TCP让客户和服务器互相交换运输层控制信息，这个握手过程提示客户和服务器为大量分组的到来做好准备。 在握手阶段，一个TCP连接就在两个进程的套接字间建立了，这条连接是全双工的，即双方进程可以在此连接上同时进行报文收发。 当结束发送时，必须拆除连接 可靠的数据传输服务 通信进程能够依靠TCP无差错、按适当顺序交付所有发送的数据。 TCP协议提供拥塞控制功能，虽然不能为通信进程提供好处，但是为因特网整体带来好处。 UDP服务 UDP是一种不提供不必要服务的轻量级运输协议，它仅仅提供最小服务，是无连接的，即无需握手。并且UDP提供一种不可靠数据传输服务。UDP不包含拥塞控制。 因特网运输协议不提供的服务 不提供定时与吞吐量的保证，而可以使用SSL（应用层）为TCP提供安全性，TCP提供可靠传输 应用层协议应用层协议定义了运行在不同端系统上的应用程序进程如何相互传递报文，应用层协议定义了 交换的报文类型，例如请求报文和响应报文 各自报文类型的语法，如报文中的各个字段及这些字段是如何描述的 字段的语义，即这些字段中包含的信息的含义 一个进程何时以及如何发送报文，对报文进行响应的规则 Web和HTTPHTTP概况Web的应用层协议是超文本传输协议（HTTP），是Web核心。在RFC文档中定义HTTP由两个程序实现，一个客户端和一个服务器，运行在不同的端系统中，通过交换报文进行会话，HTTP定义了报文的结构以及客户和服务器进行报文交换的方式。 Web术语 Web页面是由对象组成的，一个对象只是一个文件，如HTML文件、一个图形等，它们可以通过一个URL地址寻址，多数Web页面包含一个HTML基本文件以及几个引用对象。HTML基本文件通过对象的URL地址引用页面中的其他对象，每个URL地址由两部分组成：存放对象的服务器主机名与对象的路径名。 Web浏览器实现了HTTP的客户端，Web服务器实现了HTTP的服务器端，用于存储Web对象，每个对象由URL寻址。 HTTP HTTP定义了Web客户向Web服务器请求Web页面的方式，以及服务器向客户传送Web页面的方式。HTTP使用TCP作为运输层层协议。服务器向客户发送被请求的文件，而不存储任何关于该客户的状态信息，假如某个特定的客户在短短几秒内两次请求同一个对象，服务器依然会重新发送该对象。因此HTTP是一个无状态协议 非持续连接与持续连接在许多因特网应用程序中，客户和服务器在一个相当长的时间范围内通信，客户发出一系列请求并且服务器对每个请求进行响应，这一系列请求可以以规则的间隔周期性地或者间断性地一个接一个发出。当这种客户-服务器交互是由TCP进行的，则应用程序研制者就需要考虑每个请求是由一个单独的TCP连接发送还是所有请求及响应由相同的TCP发送。前一种为非持续连接，后一种为持续连接 非持续连接 持续连接 HTTP报文格式套接字编程探讨网络应用程序是如何实际编写的，典型的网络应用是由一对程序组成的，即客户端与服务端。他们位于不同的端系统中，当运行这两个程序时，创建一个客户进程与服务器进程，同时它们通过从套接字读出和写入数据彼此进行通信。 网络应用程序有两种，一类是实现在协议标准（如RFC标准文档）中定义的操作，又称为开放的应用程序。另一类是专用的网络应用程序，应用层协议没有公开，其他的开发者无法开发出与该应用程序交互的代码。 UDP套接字编程TCP套接字编程协议域名系统DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传来保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 DNS优化DNS缓存 DNS存在着多级缓存，从离浏览器的距离排序的话，有以下几种: 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。 DNS负载均衡 不知道大家有没有思考过一个问题: DNS返回的IP地址是否每次都一样？如果每次都一样是否说明你请求的资源都位于同一台机器上面，那么这台机器需要多高的性能和储存才能满足亿万请求呢？ 其实真实的互联网世界背后存在成千上百台服务器，大型的网站甚至更多。但是在用户的眼中，它需要的只是处理他的请求，哪台机器处理请求并不重要。DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。大家耳熟能详的CDN(Content Delivery Network)就是利用DNS的重定向技术，DNS服务器会返回一个跟用户最接近的点的IP地址给用户，CDN节点的服务器负责响应用户的请求，提供所需的内容。 文件传送协议FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。 动态主机配置协议DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 DHCP 工作过程如下： 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 远程登录协议TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTPSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 2. POP3POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 3. IMAPIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 常见问题从输入网址到获取页面的过程（其实这个很不好） DNS解析 TCP HTTP 处理并返回 解析 连接结束。 因为它这种很基础，而实际上的会和Tomcat等一系列内容相关 1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2.ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3.DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。 1.DNS解析 先从浏览器缓存里找IP,因为浏览器会缓存DNS记录一段时间 从操作系统缓存查找，查找存储在系统运行内存中的缓存。 如没找到,再从Hosts文件查找是否有该域名和对应IP，看看其中有没有和这个域名对应的规则 如没找到,再从路由器缓存找，一些路由器有DNS缓存功能 如没好到,再从ISP DNS缓存查找，互联网服务提供商（如中国电信）也会提供DNS服务 如果都没找到,浏览器域名服务器向根域名服务器(baidu.com)查找域名对应IP,还没找到就把请求转发到下一级,直到找到IP dns劫持:黑客攻击根域名服务器的节点,发生在上面第四步,从DNS缓存数据库里找时被恶意改为其他的网址,所以请求到的是其他网址. 最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。 2.TCP连接 3.发送HTTP请求 4.服务器处理请求并返回HTTP报文 后端从在固定的端口接收到TCP报文开始，它会对TCP连接进行处理，对HTTP协议进行解析，并按照报文格式进一步封装成HTTP Request对象，供上层使用。 一些大一点的网站会将你的请求到反向代理服务器中，因为当网站访问量非常大，网站越来越慢，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。此时，客户端不是直接通过HTTP协议访问某网站应用服务器，而是先请求到Nginx，Nginx再请求应用服务器，然后将结果返回给客户端，这里Nginx的作用是反向代理服务器。同时也带来了一个好处，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。 5.浏览器解析渲染页面 6.连接结束 参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring：Beans]]></title>
    <url>%2F2019%2F04%2F20%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpring%EF%BC%9ABeans%2F</url>
    <content type="text"><![CDATA[bean的生命周期 Spring对bean进行实例化； Spring将值和bean的引用注入到bean对应的属性中； 如果bean实现了BeanNameAware接口，Spring将bean的ID传递给setBean-Name()方法； 如果bean实现了BeanFactoryAware接口，Spring将调setBeanFactory()方法，将BeanFactory容器实例传入； 如果bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()方法，将bean所在的应用上下文的引用传入进来； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessBeforeInitialization()方法； 如果bean实现了InitializingBean接口，Spring将调用它们的after-PropertiesSet()方法。类似地，如果bean使用init-method声明了初始化方法，该方法也会被调用； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessAfterInitialization()方法； 此时，bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁； 如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。同样，如果bean使用destroy-method声明了销毁方法，该方法也会被调用。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：组合模式]]></title>
    <url>%2F2019%2F04%2F20%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[组合模式提出问题为什么要用（作用）应用场景基础概述是什么组合模式允许你将对象组合成树形结构来表现“整体/部分”层次结构。组合能够让客户以一致的方式处理个别对象以及对象组合 分类，各个分类是什么基础优缺实现实现步骤示例底层原理与其他的区别设计思想UML类图 进阶反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：装饰者模式]]></title>
    <url>%2F2019%2F04%2F19%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰者模式提出问题 将对象包装起来，赋予他们新的职责 为什么要用（作用） 为对象动态添加功能。 应用场景基础概述是什么装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component），具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 分类，各个分类是什么以饮料为例 装饰者：调料。Decorator 具体组件：饮料。ConcreteCompoent 饮料可以动态添加新的调料，添加新的功能并不需要修改代码。 基础优缺实现实现步骤 设计父类接口Component 有着公有的一个方法 设计装饰者类Decorator实现接口Component 设计具体组件抽象类ConcreteComponet实现接口Component 实现具体组件类继承自抽象类 类可以自由添加Decorator，可通过set或者构造器注入 装饰者即与需要装饰的对象实现同一个接口，并且在装饰者当中留有一个接口的引用用于引用被装饰对象。 示例设计不同种类的饮料，饮料可以添加配料，比如可以添加牛奶，并且支持动态添加新配料。每增加一种配料，该饮料的价格就会增加，要求计算一种饮料的价格。 下图表示在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Whip 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Whip 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 123public interface Beverage &#123; double cost();&#125; 1234567//装饰者public class DarkRoast implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123456public class HouseBlend implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 12345//组件抽象类public abstract class CondimentDecorator implements Beverage &#123; //需要包装的装饰者 protected Beverage beverage;&#125; 1234567891011public class Milk extends CondimentDecorator &#123; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 1234567891011public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; Beverage beverage = new HouseBlend(); beverage = new Mocha(beverage); beverage = new Milk(beverage); System.out.println(beverage.cost()); &#125;&#125;3.0 底层原理与其他的区别设计思想进阶反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：状态模式]]></title>
    <url>%2F2019%2F04%2F17%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[状态模式状态模式与策略模式是双胞胎，在出生时才分开。 提出问题当遇到一个类的行为与他的状态相关联时，如TCP的连接案例，Established、Listening、Closed的状态会使得他对请求产生不同的响应。 若要对有状态的对象进行编程，则需要将所有可能发生的情况全部考虑，然后使用if-else进行判断，当有很多的状态时则程序会非常复杂。在增加新的状态时，需要增加新的if-else语句，不利于扩展。 问题案例应用适用性 一个对象的行为取决于它的状态，并且它必须在运行时刻根据状态改变它的行为 一个操作中含有庞大的多分支的if-else语句，且这些分支依赖于对象的状态。这个状态通常用一个或多个枚举常量表示。通常有多个操作包含这一相同的条件结构。 State将每一个条件分支放入一个独立的类，使你可以根据对象自身的情况将对象的状态作为一个对象，这一对象可不依赖于其他对象而独立变化 案例1考虑一个表示网络连接的类TCPConnection，一个TCPConnection对象的状态处于若干不同状态之一：Established、Listening、Closed。当一个TCPConnection对象收到其他对象的请求时，它根据自身的当前状态作出不同的反应。如一个Open请求的结果依赖于该连接是处于连接已关闭还是连接已建立状态。 State模式描述了TCPConnection如何在每一种状态下表现出不同的行为。即引入一个TCPState的抽象类表示网络的连接状态。TCPState类为各表示不同的操作状态的子类声明了一个公共接口，由子类实现与特定状态相关的行为。 基础概述是什么 状态模式：通过改变对象内部的状态来帮助对象控制自己的行为。对象看起来好像修改了它的类。 分类State管理的实现方式 让Context自身实现 让State指定后继状态以及何时转换，在Context中增加接口，让State对象显式设定Context的当前状态 协作结构UML类图 参与者 Context：环境，定义客户感兴趣的接口 State：状态，定义一个接口以封装与COntext的一个特定状态相关的行为 ConcreteState：具体的状态子类，每个子类实现一个与Context的一个状态相关的行为 协作 类关系 Context持有一个State的引用，在运行时引用一个State的子类，Context将与状态相关的方法交给State执行 State接口定义了状态所带有的方法 CincreteState实现了State接口，负责具体的状态操作 逻辑关系 Context将与状态相关的请求委托给当前的ConcreteState对象处理 Context可将自身作为一个参数传递给处理该请求的状态对象，使得状态对象在必要时可以访问Context Context是客户使用的主要接口，客户可用状态对象来配置一个Context，一旦一个Context配置完毕，客户不需要直接与状态对象打交道 Context或ConcreteState都可以决定哪个状态是另外哪一个的后继者，以及是在和种条件下进行状态转换 权衡 谁定义状态转换 State模式不指定哪一个参与者定义状态转换规则，若该准则是固定的，则完全可以在Context实现。 若让State自身指定后继状态如何进行转换，通常会更灵活更合适，这需要Context增加一个接口，让State显式设定Context当前的状态。可以很容易地定义新的State子类来修改和扩展该逻辑，但是会让一个State至少拥有一个其他子类的信息，使得各子类间产生了实现依赖 创建和销毁State对象。即究竟是(1)仅当需要State时才创建它们并随后销毁它们，(2)还是提取创建他们并且始终不销毁他们 当要进入的状态在运行时不可知，并且上下文不经常改变状态时，选择第一种，即避免创建不会被用到的对象，如果在State对象存储大量信息时很重要 当状态改变频繁时，选择第二种 分类结构TCPConnection维护一个表示TCP连接当前状态的状态对象（TCPState）， 效果（优缺） State模式将与特定状态相关的行为局部化，并且将不同状态的行为分割开来。 将所有与一个特定状态相关的行为都放入一个对象中，因为所有与状态相关的代码都存在于某个State子类中，所以通过定义新的子类可以任意增加新的状态转换 该模式将不同状态的行为分布到了多个State子类，增加了子类的数目，相对于单个类的实现来说不够紧凑。但如果不这样则会使用巨大的条件语句。 使得状态转换显式化 当一个对象仅仅以内部数据值（使用if或switch判断）定义当前状态，则状态表现为对一些变量的赋值，并不明确，为不同的状态引入独立的对象使得转会更加明确 State对象保证Context不会发生内部状态不一致的情况，从Context角度看，状态转换是原子的，只需重新绑定一个变量即可 State状态可被共享 如果State对象没有实例变量，即它们表示的状态完全以它们的类型来编码，那么各Context对象可以共享一个State对象。当状态以这种方式被共享，它们必然是没有内部状态，只有行为的轻量级对象 实现实现步骤 首先定义一个state接口，在这个接口当中，每个动作都有一个对应的方法 为机器的每个状态实现状态类，这些类将负责在对应的状态下进行机器的行为 将动作委托到状态类 案例1角色类 12345678910111213141516public class Context &#123; //持有一个State类型的对象实例 private State state; //可以有多个状态 public void setState(State state) &#123; this.state = state; &#125; /** * 用户感兴趣的接口方法 */ public void request(String sampleParameter) &#123; //转调state来处理 state.handle(sampleParameter); &#125;&#125; 状态接口 123456public interface State &#123; /** * 状态对应的处理 */ public void handle(String sampleParameter);&#125; 具体状态 12345678public class ConcreteStateA implements State &#123; @Override public void handle(String sampleParameter) &#123; System.out.println("ConcreteStateA handle ：" + sampleParameter); &#125;&#125; 客户端 1234567891011121314public class Client &#123; public static void main(String[] args)&#123; //创建状态 State state = new ConcreteStateB(); //创建环境 Context context = new Context(); //将状态设置到环境中 context.setState(state); //请求 context.request("test"); //更改状态，则对象的行为改变 &#125;&#125; 相关模式 Flyweight模式解释了何时以及怎样共享状态对象 状态对象通常Singleton 进阶反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：建造者模式]]></title>
    <url>%2F2019%2F04%2F17%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[建造者模式提出问题问题案例基础概述是什么将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 用户只需要给出指定复杂对象的类型和内容； 建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来) 分类应用适用性 方便用户创建复杂的对象（不需要知道实现过程） 代码复用性 &amp; 封装性（将对象构建过程和细节进行封装 &amp; 复用） 案例1协作结构UML类图 指挥者（Director）直接和客户（Client）进行需求沟通； 沟通后指挥者将客户创建产品的需求划分为各个部件的建造请求（Builder）； 将各个部件的建造请求委派到具体的建造者（ConcreteBuilder）； 各个具体建造者负责进行产品部件的构建； 最终构建成具体产品（Product） 参与者协作 类关系 逻辑关系 权衡优点 易于解耦将产品本身与产品创建过程进行解耦，可以使用相同的创建过程来得到不同的产品。也就说细节依赖抽象。 易于精确控制对象的创建将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰 易于拓展增加新的具体建造者无需修改原有类库的代码，易于拓展，符合“开闭原则“。 每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，用户使用不同的具体建造者即可得到不同的产品对象。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似；如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。 分类结构效果（优缺）实现实现步骤 定义组装过程Builder接口 定义具体的建造者（Builder的实现） 定义产品 定义director进行build，获得产品 示例builder抽象类 1234567891011121314151617public abstract class Builder &#123; //第一步：装CPU//声明为抽象方法，具体由子类实现 public abstract void BuildCPU()；//第二步：装主板//声明为抽象方法，具体由子类实现 public abstract void BuildMainboard（）；//第三步：装硬盘//声明为抽象方法，具体由子类实现 public abstract void BuildHD（）；//返回产品的方法：获得组装好的电脑 public abstract Computer GetComputer（）；&#125; builder实现 123456789101112131415161718192021222324252627//装机人员1 public class ConcreteBuilder extend Builder&#123; //创建产品实例 Computer computer = new Computer(); //组装产品 @Override public void BuildCPU()&#123; computer.Add("组装CPU") &#125; @Override public void BuildMainboard（）&#123; computer.Add("组装主板") &#125; @Override public void BuildHD（）&#123; computer.Add("组装主板") &#125; //返回组装成功的电脑 @Override public Computer GetComputer（）&#123; return computer &#125; &#125; 产品 1234567891011121314151617181920public class Computer&#123; //电脑组件的集合 private List&lt;String&gt; parts = new ArrayList&lt;String&gt;()； //用于将组件组装到电脑里 public void Add(String part)&#123; parts.add(part);&#125; public void Show()&#123; for (int i = 0;i&lt;parts.size();i++)&#123; System.out.println(“组件”+parts.get(i)+“装好了”); &#125; System.out.println(“电脑组装完成，请验收”);&#125;&#125; Director 123456789public class Director&#123; //指挥装机人员组装电脑 public void Construct(Builder builder)&#123; builder. BuildCPU(); builder.BuildMainboard（）; builder. BuildHD（）; &#125; &#125; 客户端 1234567891011121314151617public class Builder Pattern&#123; public static void main(String[] args)&#123; //逛了很久终于发现一家合适的电脑店 //找到该店的老板和装机人员 Director director = new Director(); Builder builder = new ConcreteBuilder(); //沟通需求后，老板叫装机人员去装电脑 director.Construct(builder); //装完后，组装人员搬来组装好的电脑 Computer computer = builder.GetComputer(); //组装人员展示电脑给小成看 computer.Show()； &#125;&#125; 案例1相关模式进阶反省总结参考 建造者模式（Builder Pattern）- 最易懂的设计模式解析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：模板方法模式]]></title>
    <url>%2F2019%2F04%2F17%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模板方法模式提出问题当多个类当中存在共同或相似的算法，因此有一些重复的代码块（方法）时，因此在这些类当中就有着重复的代码。 为什么要用（作用） 封装算法块，使得子类可以在任何时候都可以将自己挂接进运算里。 应用场景基础概述是什么 模板方法模式在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤 模板方法 骨架prepareRecipe()，步骤即是算法内部的方法。 步骤延迟到子类中，即内部的一些抽象方法 1234567891011121314151617181920public abstract class CaffeineBeverage&#123; //prepareRecipe()是一个模板方法 //是用来制作咖啡因饮料的算法 final void prepareRecipe() &#123; boilWater(); brew(); pourInCup(); addConiments(); &#125; void boilWater() &#123; &#125; abstract void brew(); void pourInCup() &#123; &#125; abstract void addConiments();&#125; 模板方法原因： 是一个方法 用做一个算法的模板，在模板当中，算法的每一个步骤都被一个方法代表了。 一些方法由超类处理，即这个类，例如boilWater() 而另一些方法由子类处理，这些方法加上abstract标识，如addConiments() 分类，各个分类是什么基础优缺 算法存在与模板方法类当中，拥有算法并保护算法，并且容易修改。专注于算法本身 模板方法对于子类而言可以将代码的复用最大化。 提供了算法框架，新增添的类型可以容易加入 实现实现步骤12345678910111213141516171819202122232425262728//模板方法的模板类，作为基类，子类必须事先其操作public abstract class AbstractClass &#123; //模板方法，final避免子类改变算法顺序 final void templateMethod() &#123; //定义算法步骤，每个步骤由一个方法代表 primitiveOperation1(); primitiveOperation2(); concreteOperation1(); hook(); //利用钩子做判断影响算法流程 //if(hook())&#123; //&#125; &#125; //子类需要事先的操作 abstract void primitiveOperation1(); abstract void primitiveOperation2(); //由超类进行的实现 //算法的默认流程 final void concreteOperation1() &#123; &#125; //一个空的方法，作为钩子，子类视情况决定是否覆盖。 //子类有能力在算法的不同点进行挂钩 //当然也可以不是空的 void hook() &#123; &#125;&#125; 钩子 钩子可以让子类实现算法中可选的部分 钩子对子类实现并不重要时可以忽略 钩子可以让子类能够有机会对模板方法中某些即将发生的步骤做出反应 示例底层原理与其他的区别设计思想UML类图 进阶使用Lambda反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：命令模式]]></title>
    <url>%2F2019%2F04%2F17%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[命令模式提出问题有时必须向某对象提交请求，但并不知道关于被请求的操作或请求的接收者的任何信息。 问题案例应用适用性 将“发出请求的对象与“接收与执行这些请求的对象”分离开 解耦对象间通过命令对象来沟通，命令对象封装了接受者和一个或一组动作 案例1 当有一个遥控器，它需要控制电灯、车门的开关。它不应该去了解电灯开关的具体细节，只需要控制它打开即可 差的设计： 1234if (slot1 ==light) light.on();else if (slot1 == hottub) hottub.jetsOn(); 命令模式： 遥控器是命令的调用者。而启用电灯、开启车门是一项命令。 对于遥控器来讲，执行命令即可，至于命令是什么，是可以随意更换的。是开启电灯、车门不需要关心 命令对象中绑定着接受者，对于开启电灯来讲，具体传递到哪一个电灯，需要绑定到命令中 以餐厅考虑。 顾客点餐，在中间涉及到了：顾客、餐单、服务员、厨师 服务员只需要知道这是一份餐单即可，即使餐单更换了也没有影响。服务员不会去关心餐单的信息，只需要接受，然后送给柜台即可。 厨师不需要与服务员交互，只需要获取提交过来的餐单即可。 即实现解耦合 基础概述是什么 命令模式：将”请求”封装成对象，以便使用不同的请求、队列或日志来参数化其他对象。命令模式也支持可撤销的操作。 别名：动作、事务 分类协作结构 参与者协作 类关系 逻辑关系 权衡分类结构效果（优缺）为什么接受者一定存在， 命令对象不直接执行execute 尽量设计“傻瓜”命令对象，只懂得调用一个接受者的一个行为。这样解耦程度最高。 可以将接受者作为参数传递给命令。实现多种接受者 实现通过命令对象实现方法，而调用者通过执行命令对象，从而进行动作 实现步骤 定义一个命令对象的接口 定义一个实现类，实现接口 在方法调用类当中，将接口与实现类绑定 需要调用方法时，只需要执行命令接口的方法，则无论是哪一个实现类，都可以实现它的方法。 案例1#### command接口 1234567891011/** * @author Heper * @title Command 命令接口 * @date 2019/4/19 15:33 */public interface Command &#123; public void execute(); public void undo();&#125; Receiver接收者 1234567891011121314/** * @author Heper * @title 接受者 Receiver * @date 2019/4/19 15:34 */public class Light &#123; public void on() &#123; System.out.println("on"); &#125; public void off() &#123; System.out.println("off"); &#125;&#125; 命令对象 123456789101112131415161718192021222324252627/** * 定义了动作与接收者之间的绑定关系 * * @author Heper * @title * @date 2019/4/19 15:34 */public class LightCommand implements Command &#123; Light light; //传入实体，以让命令进行控制 public LightCommand(Light light) &#123; this.light = light; &#125; //发出请求，执行动作 @Override public void execute() &#123; light.on(); &#125; @Override public void undo() &#123; light.off(); &#125;&#125; Invoker调用者 1234567891011121314151617181920/** * @author Heper * @title 调用者 Invoker * @date 2019/4/19 15:36 */public class SimpleRemoteControl &#123; Command command; public SimpleRemoteControl() &#123; &#125; public void setCommand(Command com) &#123; this.command = com; &#125; public void buttonWasPressed() &#123; command.execute(); &#125;&#125; Client 12345678910111213141516171819/** * @author Heper * @title 客户端 * @date 2019/4/19 15:38 */public class RemoteControlTest &#123; public static void main(String[] args) &#123; //遥控器，作为命令的调用者 SimpleRemoteControl simpleRemoteControl = new SimpleRemoteControl(); //创建请求的接受者 Light light = new Light(); //创建命令 LightCommand lightCommand = new LightCommand(light); //命令传递给调用者 simpleRemoteControl.setCommand(lightCommand); //调用者执行 simpleRemoteControl.buttonWasPressed(); &#125;&#125; 相关模式进阶命令模式的更多特性：队列请求 命令可以将运算块打包，然后将它传来传去。命令对象可以在不同的线程中调用。因此衍生了一些应用：日程安排、线程池、工作队列等。 工作队列：一端添加命令，另一端是线程，从队列当中取出命令，然后调用execute方法 日志请求：某些应用需要我们将过去的动作都记录在日志中，并在系统死机后，重新调用这些动作恢复到之前的状态。通过新增两个方法store和load即可实现 反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis：分布式锁]]></title>
    <url>%2F2019%2F04%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[Redis分布式锁简单实现熟悉Redis的同学那么肯定对setNx(set if not exist)方法不陌生，如果不存在则更新，其可以很好的用来实现我们的分布式锁。对于某个资源加锁我们只需要 1setNx resourceName value 这里有个问题，加锁了之后如果机器宕机那么这个锁就不会得到释放所以会加入过期时间，加入过期时间需要和setNx同一个原子操作，在Redis2.8之前我们需要使用Lua脚本达到我们的目的，但是redis2.8之后redis支持nx和ex操作是同一原子操作。 1set resourceName value ex 5 nx RedissionJavaer都知道Jedis，Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持。Redission也是Redis的客户端，相比于Jedis功能简单。Jedis简单使用阻塞的I/O和redis交互，Redission通过Netty支持非阻塞I/O。Jedis最新版本2.9.0是2016年的快3年了没有更新，而Redission最新版本是2018.10月更新。 Redission封装了锁的实现，其继承了java.util.concurrent.locks.Lock的接口，让我们像操作我们的本地Lock一样去操作Redission的Lock，下面介绍一下其如何实现分布式锁。 Redission不仅提供了Java自带的一些方法(lock,tryLock)，还提供了异步加锁，对于异步编程更加方便。 由于内部源码较多，就不贴源码了，这里用文字叙述来分析他是如何加锁的，这里分析一下tryLock方法: 尝试加锁:首先会尝试进行加锁，由于保证操作是原子性，那么就只能使用lua脚本，相关的lua脚本如下： 可以看见他并没有使用我们的sexNx来进行操作，而是使用的hash结构，我们的每一个需要锁定的资源都可以看做是一个HashMap，锁定资源的节点信息是Key,锁定次数是value。通过这种方式可以很好的实现可重入的效果，只需要对value进行加1操作，就能进行可重入锁。当然这里也可以用之前我们说的本地计数进行优化。 如果尝试加锁失败，判断是否超时，如果超时则返回false。 如果加锁失败之后，没有超时，那么需要在名字为redisson_lock__channel+lockName的channel上进行订阅，用于订阅解锁消息，然后一直阻塞直到超时，或者有解锁消息。 重试步骤1，2，3，直到最后获取到锁，或者某一步获取锁超时。 对于我们的unlock方法比较简单也是通过lua脚本进行解锁，如果是可重入锁，只是减1。如果是非加锁线程解锁，那么解锁失败。 Redission还有公平锁的实现，对于公平锁其利用了list结构和hashset结构分别用来保存我们排队的节点，和我们节点的过期时间，用这两个数据结构帮助我们实现公平锁，这里就不展开介绍了，有兴趣可以参考源码。 底层原理 加锁机制现在某个客户端要加锁。如果该客户端面对的是一个redis cluster集群，他首先会根据hash节点选择一台机器。这里注意，仅仅只是选择一台机器！这点很关键！紧接着，就会发送一段lua脚本到redis上，那段lua脚本如下所示： LUA脚本：保证复杂业务逻辑执行的原子性。 KEYS[1]代表的是你加锁的那个key，比如说：RLock lock = redisson.getLock(“myLock”);这里你自己设置了加锁的那个锁key就是“myLock”。 ARGV[1]代表的就是锁key的默认生存时间，默认30秒。ARGV[2]代表的是加锁的客户端的ID，类似于下面这样：8743c9c0-0795-4907-87fd-6c719a6b4586:1 第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个锁key不存在的话，你就进行加锁。如何加锁呢？很简单，用下面的命令：hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1，通过这个命令设置一个hash数据结构，这行命令执行后，会出现一个类似下面的数据结构： 123myLock:&#123; &quot;8743c9c0-0795-4907-87fd-6c719a6b4586:1&quot; : 1;&#125; 代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。接着会执行“pexpire myLock 30000”命令，设置myLock这个锁key的生存时间是30秒。好了，到此为止，ok，加锁完成了。 释放锁机制如果执行lock.unlock()，就可以释放分布式锁，此时的业务逻辑也是非常简单的。其实说白了，就是每次都对myLock数据结构中的那个加锁次数减1。如果发现加锁次数是0了，说明这个客户端已经不再持有锁了，此时就会用：“del myLock”命令，从redis里删除这个key。然后呢，另外的客户端2就可以尝试完成加锁了。这就是所谓的分布式锁的开源Redisson框架的实现机制。 一般我们在生产系统中，可以用Redisson框架提供的这个类库来基于redis进行分布式锁的加锁与释放锁。 锁互斥机制那么在这个时候，如果客户端2来尝试加锁，执行了同样的一段lua脚本，会咋样呢？很简单，第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在了。接着第二个if判断，判断一下，myLock锁key的hash数据结构中，是否包含客户端2的ID，但是明显不是的，因为那里包含的是客户端1的ID。 所以，客户端2会获取到pttl myLock返回的一个数字，这个数字代表了myLock这个锁key的剩余生存时间。比如还剩15000毫秒的生存时间。此时客户端2会进入一个while循环，不停的尝试加锁。 watch dog自动延期机制客户端1加锁的锁key默认生存时间才30秒，如果超过了30秒，客户端1还想一直持有这把锁，怎么办呢？ 简单！只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。 可重入加锁机制那如果客户端1都已经持有了这把锁了，结果可重入的加锁会怎么样呢？ 这时我们来分析一下上面那段lua脚本。第一个if判断肯定不成立，“exists myLock”会显示锁key已经存在了。第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端1的那个ID，也就是“8743c9c0-0795-4907-87fd-6c719a6b4586:1” 此时就会执行可重入加锁的逻辑，他会用： incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1 ，通过这个命令，对客户端1的加锁次数，累加1。此时myLock数据结构变为下面这样： 123myLock:&#123; "8743c9c0-0795-4907-87fd-6c719a6b4586:1" : 2&#125; 大家看到了吧，那个myLock的hash数据结构中的那个客户端ID，就对应着加锁的次数 释放锁机制如果执行lock.unlock()，就可以释放分布式锁，此时的业务逻辑也是非常简单的。其实说白了，就是每次都对myLock数据结构中的那个加锁次数减1。如果发现加锁次数是0了，说明这个客户端已经不再持有锁了，此时就会用：“del myLock”命令，从redis里删除这个key。然后呢，另外的客户端2就可以尝试完成加锁了。这就是所谓的分布式锁的开源Redisson框架的实现机制。 一般我们在生产系统中，可以用Redisson框架提供的这个类库来基于redis进行分布式锁的加锁与释放锁。 上述Redis分布式锁的缺点其实上面那种方案最大的问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。 接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。此时就会导致多个客户端对一个分布式锁完成了加锁。这时系统在业务语义上一定会出现问题，导致各种脏数据的产生。 所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。 RedLock我们想象一个这样的场景当机器A申请到一把锁之后，如果Redis主宕机了，这个时候从机并没有同步到这一把锁，那么机器B再次申请的时候就会再次申请到这把锁，为了解决这个问题Redis作者提出了RedLock红锁的算法,在Redission中也对RedLock进行了实现。 通过上面的代码，我们需要实现多个Redis集群，然后进行红锁的加锁，解锁。具体的步骤如下: 首先生成多个Redis集群的Rlock，并将其构造成RedLock。 依次循环对三个集群进行加锁，加锁的过程和5.2里面一致。 如果循环加锁的过程中加锁失败，那么需要判断加锁失败的次数是否超出了最大值，这里的最大值是根据集群的个数，比如三个那么只允许失败一个，五个的话只允许失败两个，要保证多数成功。 加锁的过程中需要判断是否加锁超时，有可能我们设置加锁只能用3ms，第一个集群加锁已经消耗了3ms了。那么也算加锁失败。 3，4步里面加锁失败的话，那么就会进行解锁操作，解锁会对所有的集群在请求一次解锁。 可以看见RedLock基本原理是利用多个Redis集群，用多数的集群加锁成功，减少Redis某个集群出故障，造成分布式锁出现问题的概率。 Redis小结 优点:对于Redis实现简单，性能对比ZK和Mysql较好。如果不需要特别复杂的要求，那么自己就可以利用setNx进行实现，如果自己需要复杂的需求的话那么可以利用或者借鉴Redission。对于一些要求比较严格的场景来说的话可以使用RedLock。 缺点:需要维护Redis集群，如果要实现RedLock那么需要维护更多的集群。 参考 再有人问你分布式锁，这篇文章扔给他]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式：分布式锁]]></title>
    <url>%2F2019%2F04%2F15%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[分布式锁为什么需要 效率：使用分布式锁可以避免不同节点重复相同的工作，这些工作会浪费资源。比如用户付了钱之后有可能不同节点会发出多封短信。 数据一致性：不同的机器对共享的数据进行访问，会导致数据的不一致性。而分布式锁可以实现数据的最终一致性。 该模型与并发模型一致，但由于在不同的机器上，因此加锁的难度较大。 正确性：加分布式锁同样可以避免破坏正确性的发生，如果两个节点在同一条数据上面操作，比如多个节点机器对同一个订单操作不同的流程有可能会导致该笔订单最后状态出现错误，造成损失。 分布式锁的一些特点当我们确定了在不同节点上需要分布式锁，那么我们需要了解分布式锁到底应该有哪些特点: 互斥性：和我们本地锁一样互斥性是最基本，但是分布式锁需要保证在不同节点的不同线程的互斥。 可重入性：同一个节点上的同一个线程如果获取了锁之后那么也可以再次获取这个锁。 锁超时：和本地锁一样支持锁超时，防止死锁。 高效，高可用：加锁和解锁需要高效，同时也需要保证高可用防止分布式锁失效，可以增加降级。 支持阻塞和非阻塞：和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)。 支持公平锁和非公平锁(可选)：公平锁的意思是按照请求加锁的顺序获得锁，非公平锁就相反是无序的。这个一般来说实现的比较少。 常见分布式锁一般实现分布式锁的方式 MySQL ZK Redis 自研分布式锁，谷歌的Chubby MySQL分布式锁InnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持对分布式事务的实现。 分布式事务：允许多个独立的事务资源参与到一个全局的事务中。 事务资源：通常是关系型数据库系统，页可以是其他类型的资源。 全局事务要求在其中的所有参与的事务要么都提交，要么都回滚。 实现分布式事务，InnoDB存储引擎的事务隔离级别必须为Serializable XA事务允许不同数据库键的分布式事务，如MySQL、oracle数据库，只要参与全局事务中的每个节点都支持XA事务。 XA事务由一个或多个资源管理器、一个事务管理器以及一个应用程序组成。 资源管理器：提供访问事务资源的方法，通常一个数据库就是一个资源管理器 事务管理器：协调参与全局事务中的各个事务，需要和参与全局事务的所有资源管理器进行通信 应用程序：定义事务的边界，指定全局事务中的操作。 分布式事务的实现 采用两段式提交的方式 第一阶段：所有参与全局事务的节点都开始准备，告诉事务管理器它们准备好提交了 第二阶段：事务管理器告诉资源管理器执行ROLLBACK或COMMIT。 与本地事务不同的是，分布式事务要多一次prepare工作，待收到所有节点的同意信息后，再进行commit或者rollback Java实现Java的JTA可以很好的支持MySQL的分布式事务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class MyXid implements Xid&#123; public int formatId; public byte gtrid[]; public byte bqual[]; //get方法 //构造器&#125;public class XaDemo &#123; public static MysqlXADataSource getDataSource(String connStr, String user, String pwd) &#123; try &#123; MysqlXADataSource ds = new MysqlXADataSource(); ds.setUrl(connStr); ds.setUser(user); ds.setPassword(pwd); return ds; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] arg) &#123; String connStr1 = "jdbc:mysql://192.168.0.1:3306/test"; String connStr2 = "jdbc:mysql://192.168.0.2:3306/test"; try &#123; //从不同数据库获取数据库数据源 MysqlXADataSource ds1 = getDataSource(connStr1, "root", "123456"); MysqlXADataSource ds2 = getDataSource(connStr2, "root", "123456"); //数据库1获取连接 XAConnection xaConnection1 = ds1.getXAConnection(); XAResource xaResource1 = xaConnection1.getXAResource(); Connection connection1 = xaConnection1.getConnection(); Statement statement1 = connection1.createStatement(); //数据库2获取连接 XAConnection xaConnection2 = ds2.getXAConnection(); XAResource xaResource2 = xaConnection2.getXAResource(); Connection connection2 = xaConnection2.getConnection(); Statement statement2 = connection2.createStatement(); //创建事务分支的xid Xid xid1 = new MysqlXid(new byte[] &#123; 0x01 &#125;, new byte[] &#123; 0x02 &#125;, 100); Xid xid2 = new MysqlXid(new byte[] &#123; 0x011 &#125;, new byte[] &#123; 0x012 &#125;, 100); try &#123; //事务分支1关联分支事务sql语句 xaResource1.start(xid1, XAResource.TMNOFLAGS); int update1Result = statement1.executeUpdate("update account_from set money=money - 50 where id=1"); xaResource1.end(xid1, XAResource.TMSUCCESS); //事务分支2关联分支事务sql语句 xaResource2.start(xid2, XAResource.TMNOFLAGS); int update2Result = statement2.executeUpdate("update account_to set money= money + 50 where id=1"); xaResource2.end(xid2, XAResource.TMSUCCESS); // 两阶段提交协议第一阶段 int ret1 = xaResource1.prepare(xid1); int ret2 = xaResource2.prepare(xid2); // 两阶段提交协议第二阶段 if (XAResource.XA_OK == ret1 &amp;&amp; XAResource.XA_OK == ret2) &#123; xaResource1.commit(xid1, false); xaResource2.commit(xid2, false); System.out.println("reslut1:" + update1Result + ", result2:" + update2Result); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; 内部XA事务 之前的分布式事务时外部事务，即资源管理器是MySQL数据库本身 另一种分布式事务在存储引擎与插件间，或者存在于存储引擎与存储引擎间，称为内部XA事务。 常见的为binlog与InnoDB存储引擎间。 ZooKeeper流程图： 该锁是一个临时节点。 Redis分布式锁的安全问题上面我们介绍过红锁，但是Martin Kleppmann认为其依然不安全。有关于Martin反驳的几点，我认为其实不仅仅局限于RedLock,前面说的算法基本都有这个问题，下面我们来讨论一下这些问题： 长时间的GC pause:熟悉Java的同学肯定对GC不陌生，在GC的时候会发生STW(stop-the-world),例如CMS垃圾回收器，他会有两个阶段进行STW防止引用继续进行变化。那么有可能会出现下面图(引用至Martin反驳Redlock的文章)中这个情况： client1获取了锁并且设置了锁的超时时间，但是client1之后出现了STW，这个STW时间比较长，导致分布式锁进行了释放，client2获取到了锁，这个时候client1恢复了锁，那么就会出现client1，2同时获取到锁，这个时候分布式锁不安全问题就出现了。这个其实不仅仅局限于RedLock,对于我们的ZK,Mysql一样的有同样的问题。 时钟发生跳跃:对于Redis服务器如果其时间发生了向跳跃，那么肯定会影响我们锁的过期时间，那么我们的锁过期时间就不是我们预期的了，也会出现client1和client2获取到同一把锁，那么也会出现不安全，这个对于Mysql也会出现。但是ZK由于没有设置过期时间，那么发生跳跃也不会受影响。 长时间的网络I/O:这个问题和我们的GC的STW很像，也就是我们这个获取了锁之后我们进行网络调用，其调用时间由可能比我们锁的过期时间都还长，那么也会出现不安全的问题，这个Mysql也会有，ZK也不会出现这个问题。 对于这三个问题，在网上包括Redis作者在内发起了很多讨论。 GC的STW对于这个问题可以看见基本所有的都会出现问题，Martin给出了一个解法，对于ZK这种他会生成一个自增的序列，那么我们真正进行对资源操作的时候，需要判断当前序列是否是最新，有点类似于我们乐观锁。当然这个解法Redis作者进行了反驳，你既然都能生成一个自增的序列了那么你完全不需要加锁了，也就是可以按照类似于Mysql乐观锁的解法去做。 我自己认为这种解法增加了复杂性，当我们对资源操作的时候需要增加判断序列号是否是最新，无论用什么判断方法都会增加复杂度，后面会介绍谷歌的Chubby提出了一个更好的方案。 时钟发生跳跃Martin觉得RedLock不安全很大的原因也是因为时钟的跳跃，因为锁过期强依赖于时间，但是ZK不需要依赖时间，依赖每个节点的Session。Redis作者也给出了解答:对于时间跳跃分为人为调整和NTP自动调整。 人为调整:人为调整影响的那么完全可以人为不调整，这个是处于可控的。 NTP自动调整:这个可以通过一定的优化，把跳跃时间控制的可控范围内，虽然会跳跃，但是是完全可以接受的。 长时间的网络I/O这一块不是他们讨论的重点，我自己觉得，对于这个问题的优化可以控制网络调用的超时时间，把所有网络调用的超时时间相加，那么我们锁过期时间其实应该大于这个时间，当然也可以通过优化网络调用比如串行改成并行，异步化等。可以参考我的两个文章: 并行化-你的高并发大杀器，异步化-你的高并发大杀器 Chubby的一些优化大家搜索ZK的时候，会发现他们都写了ZK是Chubby的开源实现，Chubby内部工作原理和ZK类似。但是Chubby的定位是分布式锁和ZK有点不同。Chubby也是使用上面自增序列的方案用来解决分布式不安全的问题，但是他提供了多种校验方法: CheckSequencer()：调用Chubby的API检查此时这个序列号是否有效。 访问资源服务器检查，判断当前资源服务器最新的序列号和我们的序列号的大小。 lock-delay:为了防止我们校验的逻辑入侵我们的资源服务器，其提供了一种方法当客户端失联的时候，并不会立即释放锁，而是在一定的时间内(默认1min)阻止其他客户端拿去这个锁，那么也就是给予了一定的buffer等待STW恢复，而我们的GC的STW时间如果比1min还长那么你应该检查你的程序，而不是怀疑你的分布式锁了。 参考 再有人问你分布式锁，这篇文章扔给他]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统：死锁]]></title>
    <url>%2F2019%2F04%2F14%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁进程间由于共享资源所导致的一种无限期等待的情况 概念由于竞争资源或者通信关系，两个或者更多线程在执行中出现，永远相互等待只能由其他进程引发的事件 进程访问资源的流程 资源类型 CPU执行时间、内存空间、IO设备等 每类资源R有W个实例 进程访问资源的流程 请求/获取 使用/占用 释放 资源分类 可重用资源 资源不能被删除，且任何时刻只能有一个进程使用 进程释放资源后，其他进程可重用 可重用资源示例 硬件：处理器、IO、主和副存储器、设备等 软件：文件、数据库、信号量等数据结构 可能出现死锁 一个进程占用一部分资源并请求其他资源 消耗资源 资源创建和销毁 销毁资源示例： 在IO缓冲区的中断、信号、消息等 可能出现死锁 进程间相互等待接收对方的消息 资源分配图 描述资源和进程间的分配和占用关系的有向图 两类定点 系统中的所有进程P 系统中的所有资源R 两类有向边 资源请求边P-&gt;R 资源分配边R-&gt;P 存在死锁的分配图： 出现死锁的必要条件 互斥：任何时刻只能有一个进程使用一个资源实例 持有并等待：进程保持至少一个资源，并正在等待获取其他进程持有的资源 非抢占：资源只能再进程使用后自愿释放 循环等待：存在等待进程集合，形成循环 处理方法类似于消防系统 死锁预防 确保系统永远不会进入死锁状态 资源利用效率可能较低 死锁避免 使用前进行判断，只允许不会出现死锁的进程请求资源 死锁检测和恢复 在检测到运行系统进入死锁状态后，进行恢复 由应用进程处理死锁 通常操作系统忽略死锁的存在 死锁预防 预防是采用某种策略，限制并发进程对资源的请求，使系统在任何时刻都不满足死锁的必要条件 互斥：把互斥的共享资源封装成可同时访问 持有并等待： 进程请求资源时，要求它不能持有任何其他资源 仅允许进程在开始执行时，一次请求所有需要的资源 资源利用率低 非抢占： 如进程请求不能立即分配的资源，则释放已占有资源 只有能同时获得所有需要资源时，才执行分配操作 循环等待：对资源排序，要求进程按顺序请求资源 死锁避免 利用额外的先验信息，在分配资源时判断是否会出现死锁，只在不会死锁时分配资源 要求进程声明需要的资源的最大数目 限定提供与分配的资源数量，确保满足进程的最大需求 动态检查资源分配状态，确保不会出现环路等待 系统资源分配的安全状态 进行执行的安全序列 银行家算法一种死锁避免的方法，以银行借贷分配策略为基础，判断并保证系统处于安全状态 问题模型： 数据结构 死锁检测 允许系统进入死锁状态 维护系统的资源分配图 定期调用死锁检测算法来搜索图红是非存在死锁 出现死锁使用死锁恢复机制 死锁检测算法的使用 检测的时间和周期选择依据 死锁多久可能会发生 多少进程需要被回滚 资源图可能有多个循环 难于分辨造成死锁的关键进程 死锁恢复进程终止 终止所有的死锁进程 一次只终止一个进程直到死锁消除 终止进程的顺序应该是 进程的优先级 进程已运行时间以及还需运行时间 进程已占有资源 进程完成需要的资源 终止进程数目 进程是交互还是批处理 资源抢占 选择被抢占进程 最小成本目标 进程回退 返回到一些安全状态，重启进程到安全状态 可能出现饥饿 同一进程可能一直被抢占 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：目录]]></title>
    <url>%2F2019%2F04%2F11%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[目录并发挑战 并发编程的挑战 并发基础概述 如何设计解决并发问题 并发原理 硬件 CPU JMM级别 并发机制的JMM原理 并发思想 线程机制 线程安全性 线程安全 安全发布对象 线程协作、调度 死锁 并发实现 线程池 JUC 并发Start 各种工具的场景与应用 简单的并发类介绍 Java实现(分两个) Java 并发类库的使用 解决一些实际场景的问题 实战案例 并发案例 高并发 并发工具总结类设计 Java并发关注的主要是由于数据共享而导致的不一致问题。可变状态是至关重要的 同步只是保证共享数据在争用时的正确性的手段 所有的并发问题都可以归结为如何协调对并发状态的访问。可变状态越少，越容易确保线程安全性 有些程序出现数据不一致的问题并不重要（个人猜想），要根据业务场景判断 封装有助于管理复杂性 将数据封装在对象中，更易于维持不变性条件，将同步机制封装在对象中，更易于遵循同步策略。 执行复合操作期间要持有锁、当保护同一个不变性条件中的所有变量时要持有锁。 项目设计 并发的设计在于设计任务，即Runnable、Callable、Future 查看JUC-Executor 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>目录</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：JMM]]></title>
    <url>%2F2019%2F04%2F11%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJMM%2F</url>
    <content type="text"><![CDATA[JMM基础内存模型：在特定的操作协议(应该时指缓存一致性协议把)下，对特定内存或高速缓存进行读写访问地过程抽象 Java内存模型(JMM)试图屏蔽各种硬件和OS间的内存访问差异，以实现Java程序在各种平台下都能达到一致的内存访问效果。 Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性而建立的 JMMJMM规范了java虚拟机与计算机内存如何协同工作，规定了一个线程如何和何时能看到其他线程修改过的共享变量的值，以及在必须时如何同步地访问共享变量 在JMM中，堆区域是线程间会共享的数据(实例字段、静态字段、构成数组对象的元素等)，Java内存模型的主要目标时定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 并且为了获得较好的执行性能，JMM没有限制执行引擎使用CPU的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施 内存模型JMM当中，所有变量都必须存储在主内存当中，每条线程还有自己的工作内存，线程中的工作内存保存了被该线程使用到的变量的主内存副本拷贝。当线程中对对象的引用，引用了在堆上的对象，调用了对象的方法，访问了对象的数据，这个时候他们拥有的是对象成员变量的私有拷贝。 而线程对变量的所有修改都必须在工作内存中进行，不能直接读写主内存中的变量，不同的线程间也无法直接访问对方工作内存中的变量，即线程间的变量值传递均需要通过主内存来完成。 Java内存区域的堆栈 工作内存、主内存与Java堆栈不是一个层次的内存划分，即它们没有直接关联。 若非要对应的话，则主内存主要对应与Java堆内的对象实例数据部分，而工作内存主要对应虚拟机栈内的部分区域。 CPU寄存器CPU registers，访问缓存的速度最快，其次是高速缓存。它们都属于线程的本地内存 内存间交互操作关于主内存与工作内存间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节。 Java内存模型定义了8种操作，并且虚拟机实现时必须保证每一种操作都是原子的，不可再分的(long和double的load、store、read、write在某些平台上允许例外) lock锁定：作用于主内存的变量，把一个变量标识为一条线程独占状态 unlock解锁：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read读取：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后load动作使用 load载入：作用于工作内存的变量，把read操作从主内存得到的变量值放入工作内存的变量副本中 use使用：作用于工作内存的变量，把工作内存的一个变量值传递给执行引擎（线程） assign赋值：作用于工作内存的变量，把一个从执行引擎接收到的值赋值给工作内存的变量 store存储：作用于工作内存的变量，把工作内存的一个变量的值传递到主内存中，以便随后的write操作 write写入：作用于主内存的变量，把store操作从工作内存中一个变量的值传送到主内存的变量中 而具体操作间的顺序是有一定的规则的，较为简单的即happens-before原则判断 同步规则 不允许read、load与store、write操作单一出现，但是不必连续执行，中间可以插入其他指令 不允许一个线程丢弃掉它最近的assign操作，必须将变化同步给主内存 不允许一个线程无原因地（没有assign操作）将数据同步给主内存。 一个新的变量只能从主内存中诞生，不允许在工作内存直接使用一个未初始化（load或assign）的变量，即在use与store前，必须先assign 一个变量在同一时刻只允许一个线程进行lock，lock可以被同一线程执行多次。 如果一个变量执行了lock操作，将清空工作内存中次变量的值，在执行引擎使用这个变量前需要重新load或assign操作初始化变量 如果一个变量没有lock，则不允许unlock操作，也不能unlock其他线程lock的变量 对变量unlock前，必须先将变量同步到主内存 long和double型变量的特殊规则 对于64位数据类型，允许虚拟机将没有被volatile修饰的64位数据的读写操作划分位两次32位的操作来进行，允许虚拟机实现选择可以不保证64位数据类型的load、store、read、write这4个操作的原子性。即long和double的非原子性协定 如果多个线程共享一个未声明为volatile的long或double类型的变量并且同时进行读取和修改，那么线程可能读到一个既非原值也非其他线程修改值的代表了半个变量的数值（商用JVM不会出现，因为虚拟机选择将其实现了原子操作）。 happens-beforeJDK5开始，Java使用新的JSR-133内存模型，JSR-133使用happens-before的概念来阐述操作之间的内存可见性 如果两个操作的执行次序无法从happens before推导出来，则JVM可以对它进行随意的重排序。 概述 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 happens-before规则 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 虽然由于指令重排序，即使先行发生也可能再时间上后发生，但是在一个线程中无法感知到这一点，因此并没有关系 衡量并发安全问题时不要受到时间顺序的干扰，一切以先行发生原则为准。 锁定操作：一个unlock操作先行发生于后面对同一个锁的lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对于这个变量的读操作 传递规则；如果操作A先行发生于操作B，而操作B又先行发生于操作C，则操作A先行发生于操作C 线程启动规则：Thread对象的start（）方法先行发生于此线程的每一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测 对象终结规则：一个对象的初始化完成先行发生于它的finalize（）方法的开始 优点 happens-before规则避免Java程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法 JMM的抽象结构 Java中，所有实例域、静态域和数组元素都存放在堆内存中，堆内存在线程间共享。即共享变量 局部变量和异常处理器参数不会在线程间共享，不会有内存可见性问题，不受内存模型影响。 Java线程间通信由JMM控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。JMM定义了线程和主内存间的抽象关系。 JMM通过控制主内存与每个线程的本地内存间的交互，为程序员提供内存可见性保证。 CPU从源代码到指令序列的重排序在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。 编译器重排序：编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 处理器重排序： 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 对于Java源代码到最终执行的指令序列，会经历三种重排序，可能导致内存可见性问题： JMM属于语言级别的内存模型，确保在不同的编译器和处理器平台上，通过禁止特定类型的编译器重排序和处理器重排序，保证一致性的内存可见性。 对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序 对于处理器重排序。JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，禁止特定类型的处理器重排序 并发编程模型的分类现代处理器的写缓冲区： 临时保存向内存写入的数据。 优点：保证指令流水线的持续运行，避免由于处理器停顿下来等待向内存写入数据而产生的延迟。以批处理方式刷新写缓冲区，合并对同一内存地址的多次写，减少对内存总线的占用 缺点：写缓冲区只对其所在处理器可见。对内存操作的执行顺序产生重要影响。导致处理器对内存的读、写操作的执行顺序，不一定与内存实际发生的读、写顺序一致 示例：在并行执行下 现代处理器都会允许对写-读操作重排序 内存屏障指令对于只有一个CPU访问内存时，并不需要内存屏障。但是如果有两个或更多个CPU访问同一块内存，并且其中有一个正在观测另一个，就需要内存屏障保证一致性。 为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序 StoreLoad Barriers 全能型屏障，具有其他3个屏障的效果。现代处理器大多数支持该屏障 开销很高，要把写缓冲区的数据全部刷新到内存中 三个特性原子性数据类型级别：Java内存模型直接保证的原子性变量操作包括read、load、assign、use、store、write。大致可以认为基本数据类型的访问读写时具备原子性的。 synchronized：若应用场景需要一个更大范围的原子性保证，则提供了lock和unlock来满足这种需求，虽然虚拟机未将lock、unlock操作开放给用户使用，但提供了更高层次的字节码指令monitorenter和monitorexit来隐式使用这两个操作，而反映到Java代码中即synchronized，即synchronized块间操作具备原子性 可见性可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 导致共享变量在线程间不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存间及时更新 在没有同步地情况下，编译器、处理器以及运行时等都可能对操作地执行顺序进行一些意想不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得到正确的结论。 JMM是提供在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式实现可见性的。 volatile的特殊规则保证了新值能够立即同步到主内存，并且每次使用前立即从主内存刷新 synchronized是由“对一个变量执行unlock操作前，必须先把此变量同步回主内存中”这条规则获得的 final字段在构造器中一旦初始化完成，并且构造器没有将this引用传递出去(this引用逃逸可能让其他线程访问到初始化了一半的对象)，那再其他线程中就能看到final字段的值。 示例 1234567891011121314151617public class NoVisibility&#123; private static boolean ready; private static int number; private static class ReaderThread extends Thread&#123; publi void run()&#123; while(!ready)&#123; Thread.yield(); &#125; println(number); &#125; &#125; public static void main(String[] args)&#123; new ReadThread().start(); number = 42; ready = true; &#125;&#125; 由于线程交叉执行，在创建单例对象时可能创建两个对象 由于重排序，可能先执行了ready=true导致此时依然number=0，因此ReadThread输出0。 由于共享变量没有及时更新，ReadThread可能永远执行下去。 失效数据失效数据时指当读线程查看ready变量时，可能得到一个已经失效的值。除非每次访问变量时都使用同步，否则很可能得到该变量的一个失效值。而且失效值可能不会同时出现：一个线程可能获得某个变量的最新值，而获得另一个变量的失效值。 非原子的64位操作当线程在没有同步的情况下读取该变量时可能会得到一个失效值，但至少这个值时由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性 最低安全性适用于大多数变量，但是long和double不属于该类型，因此读取该变量时可能读取到某个值的高32位与另一个值的低32位。 加锁与可见性加锁可以确保某个线程以一种可预测的方式来查看另一个线程的执行结果。在同步代码块M上调用unlock之前的所有操作结果，对于在M上调用lock之后的线程都是可见的。 即为什么要求在访问某个共享且可变的变量时要求所有线程在同一个锁上同步，是为了确保某个线程写入该变量的值对于其他线程来说都是可见的。 volatilevolatile是一种稍弱的同步机制，用来确保将变量的更新操作通知到其他线程，当变量声明为volatile后，编译器与运行时都会注意到这个变量是共享的，因此不会讲该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或其他处理器不可见的地方，因此读取volatile变量总会返回最新的值。 仅当volatile变量能够简化代码的实现以及对同步策略的验证时，才应该使用它们。如果在验证正确性时需要对可见性进行复杂的判断，那么就不要使用volatile变量。 volatile的正确使用方式： 确保它们自身状态的可见性。确保它所引用对象的状态的可见性 标识一些重要的程序生命周期事件的发生。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性 当且仅当满足以下所有条件时才应该使用volatile变量 对变量的写入操作不依赖变量的当前值，或者你能够确保只有单个线程更新变量的值 该变量不会与其他状态变量一起纳入不变性条件中 在访问变量时不需要加锁。 有序性线程内表现为串行的语义：如果在本线程内观察，所有的操作都是有序的。 指令重排序与工作内存与主内存同步延迟：如果在一个线程中观察另一个线程，所有操作都是无序的。 Java提供volatile与synchronized保证线程间操作的有序性 volatile本身禁止指令重排序的语义 synchronized是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的。这决定了持有同一个锁的两个同步块只能串行进入。 顺序一致性顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。 数据竞争与顺序一致性当程序未正确同步时，就可能存在数据竞争。 数据竞争：在一个线程中写一个变量，在另一个线程中读一个编程，而且写和读没有通过同步来排序。 JMM对正确同步的多线程程序的内存一致性做了如下保证 如果程序是正确同步的，程序的执行将具有顺序一致性（Sequentially Consistent）——即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性。 一个线程中的所有操作必须按照程序的顺序来执行 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见 而在JMM当中是没有这个保证的 未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。 比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见； 从其他线程的角度来观察，会认为这个写操作根本没有被当前线程执行。 只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其他线程看到的操作执行顺序将不一致。 同步程序的顺序一致性效果示例代码： 123456789101112class SynchronizedExample&#123; int a = 0; boolean flag = false; public synchronized void writer()&#123; a = 1; flag = true; &#125; public synchronized void reader()&#123; if(flag) int i = a; &#125;&#125; 根据JMM规范，该程序的执行结果将与程序在顺序一致性模型中的执行结果相同。 JMM中，临界区内的代码可以重排序（但是临界区的代码不能逸出到临界区外，那样会破坏监视器的语义），JMM会在退出、进入临界区这两个时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图 虽然线程A在临界区做了重排序，但由于监视器互斥执行的特性。线程B无法观察到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取到的值不会无中生有（Out Of Thin Air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在已清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了。 JMM综述总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构：大型网站架构演化]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%2F</url>
    <content type="text"><![CDATA[概述如何打造一个高性能、高可用、易扩展、可伸缩且安全的网站。 如何让网站随应用所需灵活变动。 随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。 架构单一应用架构当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 当用户访问量提高时。 垂直应用架构当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 分布式服务架构当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 流动计算架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。 常见问题雪崩由于一个节点的原因导致资源一直被占用，如果这部分资源没有被释放，就会导致其他节点的崩溃。 大型网站软件系统的特点对大型网站而言，访问量于数据量缺一不可。 与传统企业应用系统相比，大型网站软件系统的特点有： 高并发、大流量 需要面对高并发用户，大流量访问 高可用 系统7*24小时不间断服务，大型网站的宕机事件会成为新闻焦点 海量数据 需要存储、管理海量数据，需要使用大量服务器 用户分布广泛，网络情况复杂 需要为全球用户提供服务，各地网络情况千差万别 国内，各个运营商网络互通难的问题 中美光缆的数次故障，需要一些对国外用户依赖大的网站考虑建立海外数据中心 安全环境恶劣 互联网的开放型，容易受到攻击 需求快速变更，发布频繁 渐进式发展 从一个小网站渐进的发展过来 大型网站架构演化发展历程任何简单的业务一旦需要处理数以P计的数据和面对数以亿计的用户，问题就会很棘手。大型网站架构主要解决这类问题 初始阶段的网站架构 一台服务器即可 应用程序、数据库、文件等所有资源都在一台服务器上。 应用服务与数据服务分离问题 一台服务逐渐不能满足需求，越来越多的用户导致性能越来越差，越来越多的数据导致存储空间不足 解决方案：将数据和应用分离 三台服务器： 应用服务器：需要处理大量业务逻辑，需要更强CPU 数据库服务器：快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存 文件服务器：存储大量用户上传的文件，需要更大的硬盘 不同的服务器承担不同的服务角色，网站的并发处理能力、数据存储空间得到很大改善 使用缓存改善网站性能问题 数据库压力太大导致访问延迟，进而影响整个系统的性能。 解决方案： 网站的访问特点：二八定律，80%的业务访问集中在20%的数据上。 将频繁访问的数据缓存在内存当中。 缓存分类： 本地缓存，缓存在应用服务器上。 速度更快。 受内存限制，并与应用程序争夺内存。 远程缓存，缓存在专门的分布式缓存服务器上。 理论上不受内存限制。 使用应用服务器集群改善网站的并发处理能力问题 单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为瓶颈 解决方案： 增加服务器分担压力，并可以以此方式不断提升系统性能。实现系统的可伸缩性。 负载均衡调度服务器：将来自用户的访问请求分发到应用服务器集群的任何一台服务器中，若有更多的用户，则在集群中增加更多的服务器，使应用服务器的负载压力不再成为整个网站的瓶颈 解决集群后的Session问题当使用集群后，当第一次访问在服务器A上，则Session就建立在了服务器A上，如果不做处理，则无法保证接下来的请求每次都落在服务器A上，则存在Session问题，会话数据无法保存在单机上。 解决方案有： Session Sticky。较好。 Session Replication。 Session数据集中存储。较好。 Cookie Based。 Session Sticky 如果保证同一个会话的请求都在同一个Web服务器上处理，那么对这个会话的个体来说，与之前单机的情况是一样的。则需要负载均衡器能够根据每次请求的会话的标识来进行请求转发。 该方案只是在负载均衡器上做处理，使得同样Session的请求每次都发送到同一个服务器端处理，非常利于针对Session进行服务器端本地的缓存。不过存在以下问题： 如果有一台Web服务器宕机或重启，那么这台机器上的会话数据会丢失，此时用户需要重新登录了。 会话标识是应用层的信息，那么负载均衡器要将同一个会话的请求都保存到同一个Web服务器上的话，就需要进行应用层的解析，开销大。 负载均衡器变为了一个有状态的节点，要将会话保存到具体Web服务器的映射，与无状态节点相比，内存消耗会更大，容灾方面会更麻烦。 举例讲即会话数据是我们的碗筷，要保证每次吃饭都用自己的碗筷，就讲碗筷存在某一家，每次都去这家吃。 Session Replication 如果我们在每个店都存放一套自己的餐具，就可以更自由地选择饭店了。 由Web服务器间保证不同服务器间的Session数据的一致。一般的应用容器都支持该方式。 存在的问题： 同步Session数据带来了网络带宽的开销，只要Session数据有变化，就需要将数据同步到所有其他机器上，机器数越多，同步带来的网络带宽开销就越大。 每台Web服务器都要保存所有的Session数据，如果整个集群的Session数很大的话，则占用大量的空间。 即不适合集群机器数很大的场景。 Session数据集中存储 将Session数据集中存储起来，不同的Web服务器从同样的地方来获取Session。 存在的问题： 读写Session引入了网络操作，相对于本机的数据读取来说，问题在于时延和不稳定性，但一般内网问题很小。 如果集中存储的Session的机器或集群存在问题就会影响应用。 在Web服务器数量较大时，优势很明显。 Cookie Based 该方案通过Cookie传递Session数据，我们将Session数据存放于Cookie中，在Web服务器上从Cookie生成Session数据，就好比每次将自己的碗筷都带在身上。 存在的问题： Cookie长度的限制。 安全性。 带宽消耗。 性能影响。 数据库读写分离问题： 数据库负载压力过高 即使使用缓存后，绝大部分数据访问都可以不通过数据库就能完成 但依然有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作需要访问数据库。会导致数据库负载压力过高 解决方案： 配置数据库的主从关系，将一台数据库服务器上的数据更新同步到另一台服务器上，实现读写分离。 应用服务器在写数据时，访问主数据库，主数据库通过主从复制将数据更新同步到从数据库，当应用服务器读数据时，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常使用专门的数据访问模块，使数据库读写分离对应用透明 使用反向代理和CDN加速网站响应问题： 复杂的网络环境，导致不同地区的用户访问网站速度差别极大 解决方案： 加快网络响应速度，提高用户体验 反向代理与CDN加速 原理为：利用缓存 CDN：部署在网络提供商的机房，使得用户在请求网站服务时，可以从距离自己最近的网络提供方机房获得数据 反向代理：部署在网站的中心机房，当用户请求到达中心时，首先访问反向代理服务器，如果反向代理服务器缓存着用户请求的数据，就直接返回给用户 通过缓存数据，也减轻了后端服务器的负载压力 使用分布式存储系统和分布式数据库系统问题： 任何强大的单一服务器都无法满足持续增长的业务需求。 数据库服务器与文件服务器无法支持。 解决方案： 分布式数据库： 分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大时才使用。 常见手段为业务分库，不同业务的数据库部署在不同服务器上。 分布式存储系统： 包含分布式文件系统、分布式Key-Value系统和分布式数据库。 分布式文件系统解决小文件和大文件的存储问题，分布式Key-Value提供高性能的半结构化的支持，分布式数据库提供一个支持大数据、高并发的数据库系统。 通过集群提供高容量、高并发访问、数据冗余容灾的支持。 使用NoSQL和搜索引擎问题： 网站业务复杂，对数据存储和检索的需求越来越复杂，需要采用一些非关系数据库（NoSQL）以及非数据库查询技术（搜索）。 解决方案： NoSQL与搜索引擎都是源自互联网的技术手段，对于可伸缩的分布式特性有更好地支持。 搜索引擎可作为一个读库，降低数据库压力。 应用服务器通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 分库分表问题： 数据库的压力依然在不断上升。 垂直拆分： 分而治之，将整个网站业务分为不同的产品线。将不同的表拆分到不同的数据库。 将一个网站拆分为许多不同的应用，每个应用独立部署维护。 应用间通过超链接建立关系。 也可以通过消息队列进行数据分发。 最多的是通过访问同一个数据存储系统来构成一个关联的完整系统 水平拆分： 水平拆分即将同一个表的数据拆分到两个数据库中，其原因是某个业务的数据量或更新量到达的单个数据库的瓶颈。 即使一个订单表，也可以拆分为家电订单、图书订单。 也可以依据时间拆分，即2018年的订单，2019年的订单。 此时自增字段等不可用。 分布式服务问题： 随着业务拆分越来越小，存储系统越来越大，应用系统的复杂性指数级增大，部署维护越来越困难 所有应用都要与数据库系统相连接，数万台服务器中，连接的数目是服务器^2，导致数据库资源不足，拒绝服务 解决方案： 将每一个应用系统需要执行的相同业务操作提取出来独立部署 由这些可复用的业务连接数据库，提供公共的业务服务。 应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作 云计算平台当大型网站架构解决了海量数据管理和高并发事务的处理，就可以将这些解决方案应用到网站自身以外的业务上，即建设云计算平台，将计算作为一种基础资源出售。 总结 大型网站架构演化的价值观网站的价值在于它能够为用户提供什么样的价值，在于能做什么，而不是怎么做的 因此在小网站上追求架构是舍本逐末的，需要做的就是为用户提供更好的服务创造价值 核心价值观：随网站所需灵活应对 核心价值是随着小型网站业务的逐步发展，慢慢演化为一个大型网站 驱动大型网站技术发展的主要力量：网站的业务发展 创新的业务发展模式对网站架构逐步提出了更高的要求，才使得创新的网站架构得以发展成熟。 业务成就了技术，后努力提高技术回馈业务 网站架构设计的误区一味追求大公司的解决方案 为了技术而技术 网站技术是为业务而存在的，除此毫无意义。 在技术选型和架构设计中，脱离网站业务发展的实际，一味追求技术，会使得架构之路越走越难 企图用技术解决所有问题 12306的故障问题 真正的问题是在于业务架构 在几亿中国人一票难求的情况下进行窗口售票模式在网上售票（0点后出售若干天后的车票） 是一种促销秒杀 进行分时段售票、排队机制等，控制并发访问的量 技术是解决业务问题，业务手段也可以解决业务问题 大型网站架构模式高并发下的方案选择需要依靠业务场景，进行方案的组合。 跨越JVM的一致性问题强一致性：指分布式事务 最终一致性：通过补偿和记录的方式实现，在做所有不确定的事情前，先将事情记录下来，再去做不确定的事情。其结果有： 成功：清除记录。 失败：依靠定时任务补偿性不断重试，直到成功。并需要做好幂等。 不确定：视为失败。 分层分层是最常见的一种架构模式，将系统在横向维度上切分成几个部分，每个部分负责一部分相对比较单一的职责，然后通过上层对下层的依赖和调用组成一个完整的系统。 应用层 负责具体业务和视图展示，如网站首页以及搜索输入和结果展示 服务层 为应用层提供服务支持，如用户管理服务、购物车服务等 数据层 提供数据存储访问服务，如数据库、缓存、文件等 各层之间具有一定的独立性，只要维持调用接口不变，各层可以根据具体问题独立发展演化，而不需要其它层做出调整 扩容占用内存大小取决于工作内存内变量的多少与大小。 单个线程占用的内存不会很大，但是很多线程占用内存就会很多。 垂直扩容：提高系统部件能力（加内存）。 内存的价格，以及当前的内存性能瓶颈等问题。 水平扩容：增加更多系统成员来实现（加服务器），即服务器集群。 共享的资源与系统间的协调性是一种约束条件。例如网络IO、数据库资源。 扩容-数据库读操作扩展： 垂直扩容。 memcache。 redis。 CDN等缓存。 写操作扩展： 水平扩容。而垂直扩容存在硬盘与CPU的平衡，因此不如水平扩容有效。 Cassandra。 Hbase等。 缓存缓存可以使用在APP端、网络转发端、服务端、存储端等位置，而不仅仅是在服务端。 消息队列开始流程A-&gt;发送消息A1到队列-&gt;消息A1被处理-&gt;处理消息A1。 特性 业务无关，只做消息分发。 FIFO，先投递先到达。 容灾，节点的动态增删和消息的持久化。 性能：吞吐量提示，系统内部通信效率提高。 为什么需要 生产和消费的速度或稳定性等因素不一致。 优势 业务解耦。 最终一致性。两个系统的状态保持一致，其存在一个时间限制。 A成功，B失败 A成功，B成功，但是没有获得B成功的消息，网络异常。 A成功，B失败，A想回滚，但是此时A宕机了。 广播。如果没有消息队列，每有一个新的接口都需要联调一次，而消息队列只需要将其投放到消息队列即可。 错峰、流控。将短板效应进行一定的弥补，针对延迟不敏感的服务可以实现错峰。 举例 Kafka RabbitMQ 应用拆分从整体将一个应用拆分为多个应用。 原则 业务优先。业务存在边界，根据业务的不同进行拆分。 循序渐进。拆分与测试缺一不可，保证系统测试与功能要完整。 兼顾重构与分层。不能为了分布式而分布式，分层进行提高代码的可重用性。 可靠测试。 思考 应用间通信：RPC（dubbo）、消息队列。 RPC框架实时性更高；消息队列传输数据包小，但数据量大，对实时性要求不是很高。 应用间数据库设计，每个应用都有独立的数据库。 避免事务操作跨应用。分布式事务非常消耗资源。 限流限流：限制一段时间内某段代码执行的频率。 如果直接将大量数据直接插入到master库，则很可能导致master库崩溃。并且master库还要同步到slave库，slave库的延迟也会很大，导致slave的查询也会错误。 如果使用限流，则可以以恒定速率写入到master库，并以正常同步的速度同步到slave库。 限流算法计数器法： 设置一个计数器，对于A接口，每当一个请求到达，Counter++，如果在时间到达1分钟，则重置Counter。 但是存在临界问题：在重置节点附近瞬间发出大量请求。 滑动窗口： 每过一定时间窗口向右滑动一格，每一格都有对应的Counter。窗口越多越平滑。 漏桶： 请求到达之后存放在一个桶当中，桶中的请求以一个恒定的速率做处理。 令牌桶： 一个固定容量的令牌桶。 系统的守护线程一直在向令牌桶内部丢令牌。 当请求到达时，桶内存在令牌，则执行业务。如果没有令牌则根据处理策略处理请求，但一定不会让你执行。 对业务峰值有一定承担能力 服务降级与熔断服务降级流量对一些服务和页面做有策略的降级，以此缓解保证部分或大部分的客户得到正确的响应。 如果当前服务处理不了或请求出错了，则给出一个默认的返回。 服务降级可以根据不同的接口做不同的或默认的定级。 分类 自动降级：超时、失败次数、故障、限流。 超时：超时时间和超时次数。定时用异步机制探测回复情况。 失败：不稳定的API一定的失败次数。使用异步机制探测回复情况。 故障：调用的远程服务挂掉了，可能是DNS、网络故障等。 限流。限流后后续的服务会自动降级。 人工降级： 秒杀、双11等。 考虑： 核心服务、非核心服务。 是否支持降级，降级策略。 业务放通场景，策略。 服务熔断当服务过载，为防止整个系统崩溃，则停止额外的服务。 服务降级与服务熔断 共性： 目的：从可用性、可靠性着想，防止系统整体缓慢或崩溃。 最终表现：某些用户感觉服务不可达或不可用。 粒度：一般是服务级别。 自治性：要求自动处理。 区别： 降级：从整体负荷考虑而引起。降级有层级，一般从最外围开始。 熔断：某个服务或下游服务故障而引起。熔断是框架级处理，每个服务都需要。 实现不同。 数据库分库分表数据库瓶颈： 单个库数据量太大（1-2T）：多个库。 单个数据库服务器压力太大、读写瓶颈：多个库。 单表数据量过大：分表。 切库： 实际应用：读写分离。 分表： 什么时候考虑分表： 当表数据量很大，即使SQL和索引优化后，操作时延还是影响使用。 高可用手段 任务调度系统分布式：elastic-job + zookeeper。 主备切换：apache curator + zookeeper分布式锁实现。 监控报警机制。 总结 利用云计算资源，便可以对所需要的一切技术资源：计算、存储、网络都可以按需购买，线性伸缩。 因此亲身经历架构演化之路的人会越来越少。架构师更应该对这个过程深刻了解，理解成熟的网站架构技术方案的来龙去脉和历史渊源，才能在技术选型和架构决策时有的放矢，直击要害。 参考]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：并发机制的底层原理]]></title>
    <url>%2F2019%2F04%2F11%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[并发机制的底层原理Java代码在编译后会变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制依赖于JVM的实现和CPU的指令。 Volatile概述定义 Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 特性 轻量级synchronized 在使用恰当情况下，比synchronized的使用和执行成本更低。它不会引起线程的上下文切换与调度 保证共享变量的可见性 可见性：当一个线程修改一个共享变量的值，另外一个线程能读到这个修改的值 实现原理CPU术语 volatile如何保证可见性在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时，CPU会做什么事情。 12345//Java代码：volatile instance = new Singleton();//汇编代码0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp);//由于volatile而多出 Lock前缀的指令在多核处理器下会引发了两件事情 将当前处理器缓存行的数据写回到系统内存。 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 JMM内存模型 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。 如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以， 在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 volatile的两条实现原则处理器缓存回写到内存。 Lock前缀指令会引起处理器缓存回写到内存。 Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。但是，在最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。 处理器可以独占任何共享内存 ：因为它会锁住总线，导致其他CPU不能访问总线，不能访问总线就意味着不能访问系统内存。 在8.1.4节有详细说明锁定操作对处理器缓存的影响，对于Intel486和Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。 缓存无效。 一个处理器的缓存回写到内存会导致其他处理器的缓存无效。 IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。 处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。 嗅探技术这是一个跟踪每个缓存行的状态的缓存子系统。该系统使用一个称为 “总线动态监视” 或者称为“总线嗅探” 的技术来监视在系统总线上发生的所有事务，以检测缓存中的某个地址上何时发生了读取或写入操作。 当这个缓存子系统在系统总线上检测到对缓存中加载的内存区域进行的读取操作时，它会将该缓存行的状态更改为 “shared”。如果它检测到对该地址的写入操作时，会将缓存行的状态更改为 “invalid”。 该缓存子系统想知道，当该系统在监视系统总线时，系统是否在其缓存中包含数据的惟一副本。如果数据由它自己的 CPU 进行了更新，那么这个缓存子系统会将缓存行的状态从 “exclusive” 更改为 “modified”。如果该缓存子系统检测到另一个处理器对该地址的读取，它会阻止访问，更新系统内存中的数据，然后允许该处理的访问继续进行。它还允许将该缓存行的状态标记为 shared。 volatile使用优化追加字节著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类Linked-TransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。LinkedTransferQueue的代码如下。 123456789101112131415/** 队列中的头部节点 */private transient final PaddedAtomicReference&lt;QNode&gt; head;/** 队列中的尾部节点 */private transient final PaddedAtomicReference&lt;QNode&gt; tail;static final class PaddedAtomicReference &lt;T&gt; extends AtomicReference T&gt; &#123;// 使用很多4个字节的引用追加到64个字节 Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe; PaddedAtomicReference(T r) &#123; super(r); &#125;&#125;public class AtomicReference &lt;V&gt; implements java.io.Serializable &#123; private volatile V value;// 省略其他代码｝ 追加字节能优化性能？ 这种方式看起来很神奇，但如果深入理解处理器架构就能理解其中的奥秘。让我们先来看看LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个字节。 为什么追加64字节能够提高并发编程的效率呢？ 因为对于英特尔酷睿i7、酷睿、Atom和NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行。 这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。 Doug lea使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。 那么是不是在使用volatile变量时都应该追加到64字节呢？ 不是的。在两种场景下不应该使用这种方式。 缓存行非64字节宽的处理器。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。 共享变量不会被频繁地写。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定。 Java7下可能不生效 不过这种追加字节的方式在Java 7下可能不生效，因为Java 7变得更加智慧，它会淘汰或重新排列无用字段，需要使用其他追加字节的方式。除了volatile，Java并发编程中应用较多的是synchronized，下面一起来看一下。 性能某些情况下，volatile的同步机制的性能确实要优于锁(synchronized、JUC)等，但是虚拟机对锁实行了许多消除和优化，使得我们很难量化认为volatile比synchronized快多少。 如果volatile与自己比较，则volatile读操作的性能消耗与普通变量几乎没有什么差别。而写操作会慢一些，因为它需要在本地代码中插入很多内存屏障指令保证不会乱序执行。 选择在volatile与锁之间选择的唯一依据仅仅是volatile的语义能否满足场景的需求 synchronized概述重量级锁，在Java SE1.6后进行了各种优化，显得并没有那么重了。 Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 实现原理与应用synchronized实现同步的基础：Java中的每一个对象都可以作为锁 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁到底存在哪里呢？锁里面会存储什么信息呢？ 锁存放在Java对象头当中 synchronized在JVM当中的实现原理JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。 代码块同步是使用monitorenter和monitorexit指令实现的 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。 任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。 Java对象头如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。 Java对象头 Mark Word32位机默认存储结构 结构随着锁标志位变化而变化 Mark Word 64位机，大小64bit 锁升级Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁” 锁的四种状态：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。随着竞争情况逐渐升级。 锁只可升级不可降级 偏向锁概念HotSpot [1] 的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。 如果测试成功，表示线程已经获得了锁。 如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）： 如果没有设置，则使用CAS竞争锁； 如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。 它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着。 如果线程不处于活动状态，则将对象头设置成无锁状态； 如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 关闭偏向锁偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活。 如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。 如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 轻量级锁加锁 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。 然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。 如果成功，当前线程获得锁 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 解锁 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头， 如果成功，则表示没有竞争发生。 如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。 图中是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 锁优缺点对比 原子操作原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。 让我们一起来聊一聊在Intel处理器和Java里是如何实现原子操作的。 概述CPU术语定义 CPU如何实现原子操作32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 首先处理器会自动保证基本的内存操作的原子性。 处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的 但是复杂的内存操作处理器是不能自动保证其原子性的 比如跨总线宽度、跨多个缓存行和跨页表的访问。 总线锁所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。 保证了CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 缺陷： 但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 缓存锁在同一时刻，我们只需保证对某个内存地址的操作是原子性即可 概述 所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。 有两种情况下处理器不会使用缓存锁定 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。 有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 Java原子操作锁锁机制有：偏向锁、轻量级锁和互斥锁 除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。 CAS基于处理器提供的CMPXCHG指令实现的 Atomic包下的很多类支持原子操作 问题 ABA问题 使用版本号解决 AtomicStampedReference可解决 循环时间长开销大 自旋的执行开销 如果JVM支持pause指令，会有一定的效率提升 它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零 它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作 AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：并发编程的挑战]]></title>
    <url>%2F2019%2F04%2F11%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E6%8C%91%E6%88%98%2F</url>
    <content type="text"><![CDATA[问题并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。如果希望通过多线程执行任务让程序运行得更快，会面临非常多的挑战。 性能与可伸缩性 上下文切换的问题、锁的竞争 活跃性危险 死锁、饥饿、糟糕的响应性、活锁 受限于硬件和软件的资源限制问题 概述 性能与可伸缩性首先要保证程序能正常运行，然后仅当程序的性能需求和测试结果要求程序执行的更快时，才应该设法提高它的运行速度。 对性能的思考提升性能意味着用更少的资源做更多的事情。资源指CPU时钟周期、内存、网络带宽、IO带宽、数据库请求、磁盘空间以及其他资源。 当操作性能由于某种特定的资源而受限时，通常称为资源密集型操作，例如CPU密集型、数据库密集型。 使用多个线程相比于单个线程总会引入一些额外的性能开销 线程间的协调，例如加锁、触发信号以及内存同步等 上下文切换、线程的创建和销毁 线程的调度等。 因此想要通过并发获得更好的性能，就需要努力做好两件事情：更有效地利用现有处理资源、在出现新的处理资源时使程序尽可能利用这些新资源。 性能与可伸缩性应用程序的性能可以使用多个指标来衡量：服务时间、延迟时间、吞吐率、效率、可伸缩性、容量等 运行速度：某个指定的任务单元需要多块才能处理完成，用于衡量程序的运行速度。例如服务时间、等待时间 处理能力：计算资源一定的情况下，能完成多少工作。例如生产量、吞吐量。 可伸缩性：当增加计算资源时(CPU、内存、存储或IO带宽)，程序的吞吐量或者处理能力能相应地增加 性能调优 通常目的时用更小的代价完成相同的工作，例如通过缓存重用之前的结果，或更换算法。 可伸缩性调优 目的是将问题的计算并行化，从而能利用更多的计算资源完成更多的工作。 对于多快与多少两个指标，是完全独立的，有时候甚至是相互矛盾的。要实现更高的可伸缩性或硬件利用率，通常会增加各个人物所要处理的工作量。 评估各种性能权衡因素大多数优化措施不成熟的原因之一：它们通常无法获得一组明确的需求。 避免不成熟的优化。首先使程序正确，然后再提高运行速度——如果它还运行地不够快。 当进行决策时，有时候通过增加某种形式的成本来降低另一种形式的开销。大多数性能决策都包含多个变量，并且非常依赖于运行环境。在使得某个方案比其他方案更快前，首先要明确： 更快的含义时什么 该方法在什么条件下运行地更快？低负载还是高负载？大数据集还是小数据集？能否通过测试结果验证答案 这些条件在运行环境中的发生频率？能否通过测试结果验证答案 在其他不同条件的环境中能否使用这些代码 在实现这种性能提升时需要付出哪些隐含的代价，例如增加开发风险或维护开销？这种权衡是否合适？ 对于并发，开发人员对于哪些地方存在性能问题，哪种方法的运行速度更快，以及哪种方法的可伸缩性更高，往往会存在错误的直觉。因此在性能调优时一定要有明确的性能需求(什么时候需要调优，什么时候应该停止)。并且需要应该测试环境进行测试是否达到了预期目标。 以测试为基准，不要猜测。 Amdahl定律大多数并发程序都是由一系列的并行工作和串行工作组成的。Amdahl定律描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。假设F是必须被串行执行的部分，则在包含N个处理器的机器中，最高加速比为：$$Speedup&lt;1/(F+(1-F)/N)$$即如果程序有50%的计算需要串行执行，那么最高加速比只能是2。该理论还量化了串行化的效率 应用当代多核CPU成为主流，系统可能拥有数百个处理器，一些在4路系统中看似具有可伸缩性的算法，可能存在一些隐含的可伸缩瓶颈。 线程引入的开销上下文切换如果可运行的线程大于CPU的数量，那么OS最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU，这将导致一次上下文切换。 上下文切换概念 CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。 损耗： 保存上一个任务状态、再加载下一个任务状态所消耗的时间。并且新的线程数据可能不在缓存中，将导致一些缓存丢失，使得线程在首次调度运行时更加缓慢。因此线程有一个最小执行时间。 应用程序、OS、JVM使用一组相同的CPU，在JVM和OS的代码中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越少。 单核处理器实现多线程执行代码： CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。 多线程未必很快并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁还有受限于硬件和软件的资源闲置问题。 多线程就是几乎同时执行多个线程（一个处理器在某一个时间点上永远都只能是一个线程！即使这个处理器是多核的，除非有多个处理器才能实现多个线程同时运行）。CPU通过给每个线程分配CPU时间片来实现伪同时运行，因为CPU时间片一般很短很短，所以给人一种同时运行的感觉。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ConcurrencyTest &#123;/** 执行次数 */private static final long count = 10000l;public static void main(String[] args) throws InterruptedException &#123; //并发计算 concurrency(); //单线程计算 serial();&#125;private static void concurrency() throws InterruptedException &#123; long start = System.currentTimeMillis(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; int a = 0; for (long i = 0; i &lt; count; i++) &#123; a += 5; &#125; System.out.println(a); &#125; &#125;); thread.start(); int b = 0; for (long i = 0; i &lt; count; i++) &#123; b--; &#125; thread.join(); long time = System.currentTimeMillis() - start; System.out.println("concurrency :" + time + "ms,b=" + b);&#125;private static void serial() &#123; long start = System.currentTimeMillis(); int a = 0; for (long i = 0; i &lt; count; i++) &#123; a += 5; &#125; int b = 0; for (long i = 0; i &lt; count; i++) &#123; b--; &#125; long time = System.currentTimeMillis() - start; System.out.println("serial:" + time + "ms,b=" + b + ",a=" + a);&#125;&#125; 测试上下文切换 使用Lmbench3（性能分析工具）可以测量上下文切换的时长。 一般相当于5000~10000个时钟周期，即几微秒。 使用vmstat可以测量上下文切换的次数。 一般一秒1000多次，如果内核占有率很高(10%以上)，那么通常表示调度活动发生很频繁，可能由IO或竞争锁导致的。 如何减少上下文切换上下文切换又分为2种：让步式上下文切换和抢占式上下文切换。前者是指执行线程主动释放CPU，与锁竞争严重程度成正比，可通过减少锁竞争和使用CAS算法来避免；后者是指线程因分配的时间片用尽而被迫放弃CPU或者被其他优先级更高的线程所抢占，一般由于线程数大于CPU可用核心数引起，可通过适当减少线程数和使用协程来避免。 如果线程频繁发生阻塞，它们将无法使用完整的调度时间片。在程序上发生越多的阻塞，与CPU密集型的程序就会发生越多的上下文切换，从而增加调度开销，因此降低吞吐量 方法 无锁并发编程 避免使用锁，如将数据ID按照HASH算法取模分段，不同线程处理不同段的数据 CAS算法 使用最少线程 避免创造太多的线程，使得大量线程处于等待 使用协程 单线程当中实现多任务的调度，并在单个线程里维持多个任务的切换 实战通过减少大量waiting线程来减少上下文切换 内存同步内存操作的性能开销包括多个方面，例如volatile提供的可见性会使用到一些特殊指令，即内存栅栏(Memory Barrier)内存栅栏可以刷新缓存，使得缓存无效，刷新硬件写缓存，以及停止执行管道。并且会对性能带来间接影响，因为将抑制一些优化操作。 评估同步带来的性能影响，要区分有竞争的同步和无竞争的同步(volatile通常是非竞争的)。synchrnized对无竞争的同步进行了优化，非竞争的同步对整体性能影响微乎其微。 阻塞竞争的同步可能需要OS介入，从而增加开销。当在锁上发生竞争时，竞争失败的线程肯定会则是，JVM在实现阻塞行为时可以采用自旋等待，或OS挂起被阻塞的线程。具体的效率高低要取决于上下文切换的开销以及在成功获得锁之前等待的时间。 减少锁竞争串行操作会降低并行性，上下文切换也会降低性能，在锁上发生竞争将同时导致这两种问题。 在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。 减少锁发生竞争的可能性有: 锁的请求频率。 每次持有该锁的时间。 即缩小锁的范围 降低线程请求锁的频率，可以通过锁分解和锁分段等技术实现，使得不同线程在不同的数据或一个数据的不同部分上操作。 锁分段一定要表现出在锁上的竞争频率高于在锁保护的数据上发生的频率。 也可以使用带有协调机制的独占锁，这些机制允许更高的并发性。 当每个请求都请求多个变量时，锁的粒度将很难降低， 监测CPU的利用率当测试可伸缩性时，通常要确保处理器得到充分利用。UNIX上的vmstat可以查看CPU的忙碌状态。如果所有的CPU利用率并不均匀，那么首要目标就是进一步找出程序中的并行性，不均匀的利用率表明大多数计算都是由一小组线程完成的。通常有以下几种原因: 负载不充足。测试的程序中可能没有足够多的负载，因而可以在测试时增加负载，并检查利用率、响应时间、服务时间等指标的变化。 IO密集。可以通过iostat或perfmon判断某个程序是否磁盘IO密集的，或通过监测网络的通信流量判断是否需要高带宽 外部限制。如果应用程序依赖于外部服务，可能性能瓶颈是在外部服务中 锁竞争。使用分析工具可以找到程序中存在何种程度的锁竞争，以及在哪些锁上存在激烈的竞争。如果因为激烈的竞争，则在线程转储中会频繁出现 资源限制概念资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。所以在进行并发编程时，要考虑这些资源的限制。 服务器的带宽只有2Mb/s，某个资源的下载速度是1Mb/s每秒，系统启动10个线程下载资源，下载速度不会变成10Mb/s 硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。 软件资源限制有数据库的连接数和socket连接数等。 引发的问题本来是并发编程，但由于资源限制，导致并行退化为串行。在此情况下，由于上下文切换与资源调度，导致执行速度更慢。 在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。例如，之前看到一段程序使用多线程在办公网并发地下载和处理数据时，导致CPU利用率达到100%，几个小时都不能运行完成任务，后来修改成单线程，一个小时就执行完成了。 解决资源限制 对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多机上运行。比如使用ODPS、Hadoop或者自己搭建服务器集群，不同的机器处理不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。 对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。 在资源限制情况下进行并发编程如何在资源限制的情况下，让程序执行得更快呢？ 方法就是，根据不同的资源限制调整程序的并发度 比如下载文件程序依赖于两个资源——带宽和硬盘读写速度。 有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞，等待数据库连接。 活跃性危险在安全性与活跃性间通常存在某种制衡，我们使用加锁确保线程安全，但如果过度使用加锁，则可能导致锁顺序死锁。 如果使用线程池和信号量来限制对资源的使用，可能导致资源死锁。Java程序无法从死锁中恢复过来，因此设计时一定要排除可能导致死锁的条件。 死锁是什么死锁的必要条件 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 解决锁 持有锁一定时间，依然在等待的话，则释放持有的所有锁。 死锁示例 A、B锁互相等待 12345678910111213141516171819202122232425262728293031323334353637383940414243public class DeadLockDemo &#123; /** A锁 */ private static String A = "A"; /** B锁 */ private static String B = "B"; public static void main(String[] args) &#123; new DeadLockDemo().deadLock(); &#125; private void deadLock() &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (A) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (B) &#123; System.out.println("1"); &#125; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (B) &#123; synchronized (A) &#123; System.out.println("2"); &#125; &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125; 出现的场景 t1拿到锁之后，因为一些异常情况没有释放锁（死循环）。 t1拿到一个数据库锁，释放锁的时候抛出了异常，没释放掉。 锁顺序死锁 两个线程试图以不同的顺序来获得相同的锁。如果按照相同的顺序来请求锁就不会出现循环的加锁依赖性。 如果所有线程都以固定的顺序来获得锁，那么程序中就不会出现锁顺序死锁的问题。 动态的锁顺序死锁 有时候并不能清楚地知道是否在锁顺序上有足够的控制权来避免死锁的发生。 假设一个转账的场景，需要获得转账的账户A以及被转账的账户B的锁，那么假设同时发生A-&gt;B转账与B-&gt;A转账。则会产生死锁。 可以通过定义锁的顺序，并在整个应用程序中都按照这个顺序来获取锁。 在协作对象间发生的死锁 在协作对象间，很容易出现锁的获取顺序不同的问题，因为作为两个不同的业务场景，它们最开始需要的锁很可能是不同的 如果在持有锁时调用某个外部方法，那么将出现活跃性问题。在这个外部方法中可能或获取其他锁(可能产生死锁)，或者阻塞时间过长，导致其他线程无法及时获得当前被持有的锁。 开放调用 如果在调用某个方法时不需要持有锁，那么这种调用被称为开放调用。 在程序中应尽量使用开放调用，与那些在持有锁时调用外部方法的程序相比，更易于对依赖于开放调用的程序进行死锁分析。 资源死锁 在相同的资源集合上等待时也会出现死锁，例如等待数据库连接。 另一种形式就是线程饥饿死锁，例如单线程的线程池中一个任务提交另一个任务，则第一个任务永远等待，另一个任务永远在队列中等待。 死锁检测在使用细粒度锁的程序中，可以通过使用一种两阶段策略来检查代码中的死锁：首先找出在什么地方将获取多个锁(使这个集合尽量小)，然后对所有这些示例进行全局分析，从而确保它们在整个程序中获取锁的顺序都保持一致。 利用dump线程查看到底哪个线程出现了问题，可见是42行、31行出现死锁 死锁避免当必须获取多个锁，那么在设计时必须考虑锁的顺序，尽量减少潜在的加锁交互数量，将获取锁需要遵守的协议写入文档。 常见方法： 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 超时后释放锁，并在一段时间后重新尝试。但是对于嵌套的多个锁效果很差。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 饥饿当线程由于无法访问它所需要的资源而不能继续执行时就发生了饥饿。 最常见的资源时CPU时钟周期。例如线程优先级（OS相关，增加平台依赖性）使用不当，或者持有锁时进行一些无法结束的结构，也会导致饥饿。 丢失信号糟糕的响应性如果某个线程长时间占有一个锁，而其他想要访问整个容器的线程就需要等待很长时间 活锁活锁是另一种活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操，而且总会失败。 例如处理事务消息的程序，如果不能成功处理某个消息，则回滚整个事务，并将其重新放到队列的开头，如果消息处理器处理某种特定类型的消息存在错误并导致事务失败，那么由于消息在队列开头，处理器将反复调用并一直失败。 并发编程模型的两个关键问题 线程间如何通信。通信指线程间以何种机制交换信息 线程间如何同步 在命令式编程中，线程通信机制有两种： 共享内存。 线程间共享程序的公共状态，通过读写内存中的公共状态进行隐式通信 同步是显式进行的，程序员必须显式指定某个方法或某段代码需要在线程间互斥执行 消息传递。 线程间没有公共状态，必须通过发送消息来显式进行通信 同步是隐式进行的，消息的发送必须在消息的接受前 Java并发采用的是共享内存模型 Java线程间通信总是隐式进行，整个通信过程对程序员完全透明 多线程开发良好的实践 给线程起个有意义的名字，这样可以方便找 Bug。 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。 多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。 使用 BlockingQueue 实现生产者消费者问题。 多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。 使用本地变量和不可变类来保证线程安全。 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。 总结建议多使用JDK并发包提供的并发容器和工具类来解决并发问题，因为这些类都已经通过了充分的测试和优化，均可解决了本章提到的几个挑战。 参考 Java多线程学习（七）并发编程中一些问题]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：网络层]]></title>
    <url>%2F2019%2F04%2F08%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络层概述实现主机到主机的通信服务，在每一台路由器与主机上都有一个网络层部分 三个重要组件：IP协议、路由选择、ICMP协议（报告数据报中的差错和对某些网络层的请求做响应的设施） 分组交换机：一台通用的分组交换设备，根据分组首部字段的值，从输入链路接口到输出链路接口转移分组。基于链路层字段做转发决定的为链路层交换机，其他的叫路由器，基于网络层字段做转发决定。 网络层功能与服务功能：转发、路由选择、连接建立（要求从源到目的地沿着所选择的路径彼此握手） 网络服务模型：定义了分组在发送与接收端之间端到端的运输特性。 网络层（ATM CBR,ATM ABR等提供恒定比特率与可用比特率的服务）可以提供某些特定服务，但是因特网的网络层只提供尽力而为的服务 确保交付 具有时延上限的确保交付 有序分组交付 确保最小带宽 确保最大时延抖动 安全性服务 虚电路与数据报网络在当下的计算机网络体系结构当中，只提供两种服务之一，而不同时提供两种服务 虚电路网络： 仅在网络层提供连接服务的计算机网络。使用在ATM、帧中断的体系结构中 组成： 源和目的主机间的路径 VC号，沿着该路径每段链路的一个号码 沿着该路径的每台路由器中的转发表表项 过程： 虚电路建立 数据传输 虚电路拆除 数据报网络： 仅在网络层提供无连接服务的计算机网络。 因为因特网对网络层有最小限度的需求，使得互联网使用不同的链路层技术更加容易，而且具有不同的传输速率。并且使得web等服务可以在互联网上很快地部署 每当一个端系统要发送分组，就为该分组加上目的端系统的地址，然后将分组推入网络当中。 路由器转发：分组在单一的路由器由一条入链路到一条出链路的传送 转发表：每台路由器有一张转发表，通过检查分组首部字段的值来转发分组，利用值在转发表查询索引。其值由路由选择算法插入 转发表当中不可能对每一个地址都存放一个表项，因此使用了前缀匹配，即将目的地址的比特与转发表的前缀进行匹配，如果前缀匹配成功，则转发向对应的端口，如果有多个匹配，则转发向最长前缀所对应的端口（最长前缀匹配原则），如果没有匹配则转发向其他端口 路由器的结构路由器从功能上可以划分为：路由选择和分组转发。（硬件实现，速度更快） 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。类似于高速公路的收费站 因为路由器可能在同一时间处理数量巨大的流，因此设计尽量简单，并且采用数据报网络层，使用一种流水线和固定长度的首部（IPv6），取消分片（IPv6），和提供唯一的尽力而为服务 输入端口：查询转发表，找到对应的输出端口 交换结构：将分组转换到对应的输出端口 路由选择处理机：执行路由选择协议，维护路由选择表与连接的链路状态信息，并计算转发表，执行网络管理功能 排队：输入与输出端口的序列，如果排队过长将耗尽路由器的缓存空间，出现丢包。 路由器分组转发流程 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。 可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 内部网关协议 RIPRIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 内部网关协议 OSPF开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 外部网关协议 BGPBGP（Border Gateway Protocol，边界网关协议） AS 之间的路由选择很困难，主要是由于： 互联网规模很大； 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量； AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。 IP协议​ IP的服务模型是尽力而为地交付服务，即尽最大的努力，不确保报文段的交付，不保证报文段的按序交付，不保证报文段中数据的完整性。即IP是不可靠的服务。 ​ IPv4、IPv6 概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为首部固定长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP数据报分片 当链路层帧能承载的最大数据量（最大传送单元MTU）小于IP数据报长度，将数据报中的数据分片，然后用单独的链路层帧封装（在端系统重新组装，路由器不会组装），分片需要在全部接受（依据标识，标志与片偏移量进行分辨，最后一片的标识比特为0，其余为1）后才能进行组装为原本的数据，因此有时候会被用于dos攻击。 IP 地址编址方式IPv4 在因特网的每台主机与路由器的每个接口都必须有唯一IP地址（NAT后接口除外） 在该图当中，IP地址左侧3个数字相同，即左侧24位比特的值是相同的。这4个接口（3主机+路由）也通过一个不包含路由器的网络互联起来，如以太网LAN等。互联这三个主机接口与1个路由器接口的网路构成1个子网，IP编址为这个子网分配一个地址，223.1.1.0/24，/24即子网掩码，指示最左侧的24字节定义了子网地址。 任何要连接到该子网的主机都要求其地址为223.1.1.xxx 因特网的地址分配策略称为无类别域间路由选择CIDR，a.b.c.d/x，x的最高比特构成了IP地址的网络部分，也是该网络地址的前缀​ IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 无分类无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 DHCP获取地址P239 230地址解析协议 ARP网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 路由选择路由选择：涉及一个网络的所有路由器，它们经由路由选择协议共同交互，以决定分组从源到目的地节点所采用的路径。计算路径的算法为路由选择算法 广播路由选择：网络层提供了从一种源节点到网络中其他节点交付分组的服务 通过N次单播来实现，但是效率低下（在链路上拥挤，可以通过在网络上的节点复制来解决），并且需要知道广播到达的目的地址 无控制洪泛方法，源节点向其所有的邻居发送分组副本，当某节点接受一个分组副本，则复制向该节点邻居继续发送。但是会产生广播风暴，无休止的进行分组复制 受控洪泛：避免广播风暴，明智选择何时洪泛分组 序号控制洪泛：源节点将其地址以及广播序号放入广播分组，每个节点维护它已经收到、复制、和转发的源地址和每个广播分组的序号列表 反向路径转发：当路由器收到具有给定定源地址的广播分组时，仅当分组到达的链路正好是位于它自己的返回其源的最短单播路径上，才向所有出链路传输。否则丢弃。 RPF只需要知道在它到发送方的单播最短路径的下一个邻居，仅依这个邻居的身份决定是否发送 生成树广播，以上方法避免了广播风暴，但是没有避免冗余广播分组的传输。 首先对网络节点构成一颗最小生成树，向所有属于该生成树的所有邻居转发分组 多播路由选择：​ 使单个源节点能够向其他网络节点的一个子集发送分组的副本。与广播交给所有节点不同。适用于：软件更新、交互游戏、直播等 怎样标识多播分组的接收方 怎样为发送到这些接收方的分组编址 由于目的地很多，因此分组无法携带所有接收方的IP地址。因此在因特网中对多播数据报使用间接地址编址。即用一个标识标识一组接收方。因特网中表示一组接收方的单一标识就是一个D类多播分组，与一个D类地址相关联的接收方小组称为一个多播组。多播组与主机的IP地址是完全独立的。 一个多播组如何形成，如何终结？如何选择组地址 新主机如何加入某个组，任何主机都能加入一个组吗，组成员资格是否会限制，如果限制，由谁限制 一个组成员是否知道其他组成员的地址，相互如何交互，以向所有组成员交付一个多播数据报。 上述问题均与IGMP（因特网组管理协议有关） IGMP协议IGMP协议运行在一台主机与其直接相连的路由器中间，IGMP为主机提供了手段，让它通知与其相连的路由器：在本机上运行的一个应用程序想加入一个特定的多播组。即IGMP的交互范围限制在主机与其直接相连的路由器之间。 三种报文类型，IGMP报文也是封装在一个IP数据报当中，IP协议号为2 member_query member_report level_group 多播路由选择算法协调因特网的多播路由器，以便多播数据报能够路由到最终目的地。 在该例子当中，C、D不需要接受多播组流量。多播路由的目标是发现一颗链路的树，连接了所有具有属于该多播组的相连主机的路由器 多播路由选择树的建立 单一的组共享树来为组中所有发送方分发流量。 为每个独立的发送方构建一颗特定源的路由选择器。 路由选择协议 距离向量多播路由选择协议（第一个） 协议无关的多播路由选择协议（使用最广泛） 网际控制报文协议 ICMP​ ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议，从体系结构上讲，ICMP（类UDP，TCP）位于IP之上。 ​ 报告数据报中的差错（目的网络不可达等）和对某些网络层的请求做响应的设施，ICMP被主机和路由器用来彼此沟通网络层的信息。 ICMP 报文分为差错报告报文和询问报文。 PingPing 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 TracerouteTraceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。 下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。 网络地址转换 NAT专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。 在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。 IPv6 P238 247参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：运输层]]></title>
    <url>%2F2019%2F04%2F08%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[运输层概述与运输层服务目的 两个实体怎么样才能在一种会丢失或损坏数据的媒体上建立可靠的通信 控制运输层实体的传输速率以避免网络拥塞，或从拥塞中恢复 运输层与网络层的关系 网络层提供了主机之间逻辑通信，运输层为运行在不同主机上的进程之间提供了逻辑通信。运输层协议只工作在端系统中，将来自应用进程的报文移动到网络边缘 网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。 服务模型最基本的责任是将两个端系统间IP的交付服务扩展到运行在端系统上的两个进程的交付服务，被称为是运输层的多路复用与多路分解 多路复用与多路分解进程拥有一个或多个套接字socket，相当于从网络向进程传递数据和进程向网络传递信息的门户，运输层与进程通信，是运输层将数据传递给socket。 多路分解：将运输层报文段中的数据交付到正确的套接字的工作。运输层检查达运输层的报文，标识出接收套接字，将报文段定向到该套接字。 多路复用：在源主机从不同的套接字收集数据块，并未每个数据块装上首部信息，生成报文段传递到网络层。 分解与复用依据：源IP，源端口，目的IP，目的端口 UDP套接字：目的IP,目的端口。但是报文依然有着源IP与端口，两个不同源的报文会被定向到同一进程 TCP：源IP，源端口，目的IP，目的端口。两个不同源的报文会被定向到不同进程 UDP提供的运输层服务 最低限度的运输层服务 检查报文段首部差错字段而提供完整性检查 数据交付 即 用户数据报协议 属于 传输层通信协议 基于UDP的应用层协议有 TFTP、SNMP 与 DNS 特点 UDP 是无连接的； UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数），因此可以支持更多的用户； UDP 是面向报文的；（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部） 因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。这也就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。 UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）； UDP 支持一对一、一对多、多对一和多对多的交互通信； UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 为什么使用UDP UDP关于何时、发送什么数据控制更为精细。UDP的效率更高，速度更快。而TCP还有拥堵 UDP不引入连接握手，不引入时延 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 UDP的差错检验 ​ 由UDP检验和提供，即对报文段的所有16位比特字的和进行反码运算，求和时候遇到的溢出进行回卷，即结果。在接受方的正确结果应该是1111111111111111，如果有一个0，则出现了差错。 ​ 设计原因：端到端原则，某种功能必须基于端到端实现，在低级别设置功能可能是冗余的甚至完全没有价值的。即使网络中间进行了检测，但依然无法确保链路与路由器内存的可靠性。 TCP即 传输控制协议 属于 传输层通信协议 基于TCP的应用层协议有HTTP、SMTP、FTP、Telnet 和 POP3 特点 TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）； TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达； TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。 进程将数据发送到缓存当中，TCP在方便时候取出缓存数据发送 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设A为客户端，B为服务器端。 首先B处于LISTEN（监听）状态，等待客户的连接请求。 A向B发送连接请求报文，SYN = 1，ACK = 0，选择一个初始的序号seq = x。 B收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN = 1，ACK = 1，确认号为x + 1，同时也选择一个初始的序号y。 A收到B的连接确认报文后，还要向B发出确认，确认号为y + 1，序号为x + 1。 B收到A的确认后，连接建立。 三次握手的原因 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 为什么要传回 SYN 接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。 传了 SYN,为啥还要传 ACK 双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。 握手的核心目的 握手的核心目的是告知对方seq，对方回复ack（收到的seq+包的大小），这样发送端就知道有没有丢包了。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 因此，如果没有还未传送完的数据，syn+fin一起发送，那就三次了 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 可靠传输包含确认、定时器、重传、序号机制来保证可靠传输 底层通信是一个不靠谱的点对点通信 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 其中，0 ≤ α ＜ 1，RTTs 随着 α 的增加更容易受到 RTT 的影响。 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差的加权平均值。 TCP协议如何来保证传输的可靠性TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。 对于可靠性，TCP通过以下方式进行保证： 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据； 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；对于失序且缺失前面序号的数据，TCP将问题交给编程人员，可以保留（对于带宽而言更有效），也可以丢弃 丢弃重复数据：对于重复数据，能够丢弃重复数据； 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒； 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段； 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。 累积确认：在收到失序的报文段，返回确认号字段为第一个失序号 TCP 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，提示接受方还有多少可用的缓存空间，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 拥塞状态：链路容量有限，在较高的拥堵下，排队时延将呈现指数上升，并且可能陷入无限排队，爆掉缓存，吞吐量接近0 路由器可以向发送方提供关于网络中拥塞状态的显式反馈信息（ATM ABR） UDP连接（恒定速率，不会降速）与web的并行TCP连接会使得网络拥塞，对于其他连接不公平 判断拥塞的原则 一个丢失的报文段意味着拥塞 一个确认报文段指示网络正在接受，即可增加速率 带宽探测，给定ACK指示无拥塞，丢包则指示有拥塞 TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd，对一个TCP发送方能向网络中发送流量的速率做了限制）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免（必然）发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。 平均吞吐量：0.75W/RTT 2. 快重传与快恢复（推荐部分）在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。 # 参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：适配器模式]]></title>
    <url>%2F2019%2F04%2F07%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式提出问题 将类的接口转换为想要的接口，以便实现不同的接口。两个对象因为接口不兼容而不能一起工作，这时需要第三方适配。 适配器：我拥有一个三角插头，而只有一个二角的插座，则我需要一个适配器，让我能够重新充电 为什么要用（作用） 将一个类的接口转换为客户希望的另外一个接口，Adapter模式使得原本由于接口不兼容而不能一起工作的类可以一起工作。 为复用而设计的工具箱类不能够被复用的原因仅仅是因为它的接口与专业应用领域所需要的接口不匹配。 应用适用性 你想使用一个已经存在的类，而它的接口不符合你的需求 你想创建一个可以复用的类，该类可以与其他不想关的类或不可预见的类（即那些接口可能不一定兼容的类）协同工作 （仅适用于对象Adapter）你想使用一些已经存在的子类，但是不可能对每一个都进行子类化以匹配他们的接口。对象适配器可以适配它的父类接口（什么意思） 案例 已有一个软件系统，希望能够与新厂商类库搭配，但是新厂商的接口不同于旧厂的接口 写一个类，将新厂商的接口转换为期望的接口 一个应用可能会具有一些类具有不同的接口，并且这些接口互不兼容，像TextView这样已经存在并且不相关的类如何协同工作呢？ 即是我们得到了源代码，修改textView意义也不大，因为不应该仅仅为了实现一个应用，工具箱就不得不采用一些与特定领域相关的接口 因此我们可以定义一个新的类，进行适配接口，从而实现最终目标 基础概述是什么适配器模式将一个类的接口转换成客户期望的另一个接口，让原本接口不兼容的类可以合作无间。 作为适配器，它还可以提供原系统接口所没有的功能，在原接口的基础上进行拓展 分类优缺 如果需要实现一个很大的目标接口，要有很多的工作要做 实现一个适配器所需要进行的工作与目标接口的大小成正比 但如果不适用适配器，则需要花更多的力气进行改写工作。即复用了现存的类。 客户端通过适配器可以透明地调用目标接口。 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题。 一个适配器可以封装一个或多个类 协作参与者 Client。与符合target接口的对象协同 Target。是客户需要使用的接口，定义客户使用的与特定领域相关的接口 Adapter。是对Target接口的实现，并且它将原有接口Adaptee转换到了所需要的接口Target Adaptee。系统当中原有的功能接口，这个接口需要被适配 协作Client在Adapter实例上调用一些操作，接着适配器调用Adapter的操作实现这个请求 权衡考虑Adapter的匹配程度对Adaptee的接口与Target接口进行匹配的工作量各个Adapter可能不一样。可能是从简单的接口转换到支持完全不同的操作集合，其取决于Target接口与Adaptee接口的相似程度。 可插入的Adapter 当其他的类使用一个类时，如果所需要的假定条件越少，这个类就更具可复用性。如果将接口匹配构建一个类，就不需要假定对其他的类可见的是相同的一个接口。即接口匹配使得我们可以将自己的类加入到一些现有的系统中去，而这些系统对这个类的接口可能会有不同 使用双向适配器提供透明操作适配器并不对所有的客户都透明；被适配的对象不再兼容Adaptee的接口，因此并不是所有Adaptee对象都可以被使用的地方它都可以使用。即客户可以使用Adaptee对象的接口，但是Adaptee不能使用Target的接口 双向适配器提供了这样的透明性。在两个不同的客户需要用不同的方式查看同一个对象时，尤其有用 类适配器结构使多重继承对一个接口与另外一个接口进行匹配 效果 用一个具体的Adapter类对Adaptee和Target进行匹配。结果是当我们想要匹配一个类以及它所有子类时，类Adapter不能胜任 Adapter可以重定义Adaptee的部分行为，因为是它的一个子类 仅仅引入了一个对象，并不需要额外的指针以间接得到adaptee 实现实现步骤 继承原有接口进行扩展 客户通过目标接口调用适配器的方法对适配器发出请求 适配器使用被适配接口把请求转换为被适配者的一个或多个调用接口 客户接受到调用的结果，但并未察觉到这一切是适配器再起转换作用 示例1首先是Target接口，该接口有一个方法是request方法。但是有一个类Adaptee已经实现了request方法，因此可以去复用该方法 123public interface Target &#123; public void request();&#125; 类Adaptee实现了Tagret类所希望实现的内容，但是Adaptee是没有实现Target接口的，因此Target无法做复用。 12345public class Adaptee &#123; public void specificRequest() &#123; System.out.println("适配者中的业务代码被调用！"); &#125;&#125; 因此，这两个接口并不匹配。需要进行适配操作，即产生了Adapter。类适配器继承自Adaptee因此可以调用它的Adaptee方法。而同时也实现了Target接口，因此Target也可以使用request方法 123456public class ClassAdapter extends Adaptee implements Target &#123; @Override public void request() &#123; specificRequest(); &#125;&#125; 让Target进行调用，即让Target引用ClassAdapter，此时调用request时，也调用了specificRequest方法，因此实现了复用，即实现了适配器Adapter。 1234567public class ClassAdapterTest &#123; public static void main(String[] args) &#123; System.out.println("类适配器模式测试："); Target target = new ClassAdapter(); target.request(); &#125;&#125; 对象适配器结构依赖于对象组合 效果 允许一个Adapter与多个Adaptee——即本身以及它的所有子类同时工作。Adapter也可以一次给所有的Adaptee添加功能 使得重定义Adaptee的行为比较困难，需要生成Adaptee的子类并且使得Adapter引用这个子类而不是Adaptee本身。 实现实现步骤 将原有接口的实例作为组成部分，进行组合 示例1在对象适配器当中更多的是依赖于组合实现适配器。因此在该适配器当中有一个Adaptee成员，而初始化操作即为它分配一个Adaptee 123456789101112public class ObjectAdapter implements Target &#123; private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); &#125;&#125; 进行对象适配器的测试 12345678public class ObjectAdapterTest &#123; public static void main(String[] args) &#123; System.out.println("对象适配器模式测试："); Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request(); &#125;&#125; 示例2鸭子与火鸡： Duck 是作为系统当中原有的的功能接口 123456public interface Duck &#123; public void quack(); public void fly();&#125; 123456789101112public class MallerdDuck implements Duck &#123; @Override public void quack() &#123; System.out.println("Quack"); &#125; @Override public void fly() &#123; System.out.println("Flying"); &#125;&#125; Turkey 是系统当中新生的需求和实体 123456public interface Turkey &#123; public void gobble(); public void fly();&#125; 1234567891011public class WildTurkey implements Turkey &#123; @Override public void gobble() &#123; System.out.println("Gobble"); &#125; @Override public void fly() &#123; System.out.println("Fly short time"); &#125;&#125; 适配器 新生的需求需要使用到原有的系统设计的功能，却接口不统一。通过适配器实现 12345678910111213141516171819//实现了Duck接口public class TurkeyAdapter implements Duck &#123; //内部还是turkey Turkey turkey; public TurkeyAdapter(Turkey turkey) &#123; this.turkey = turkey; &#125; //以turkey的方法转换到Duck的方法 @Override public void quack() &#123; turkey.gobble(); &#125; @Override public void fly() &#123; turkey.fly(); &#125;&#125; 双向适配器结构效果实现实现步骤示例1target接口，即客户 123public interface TwoWayTarget &#123; public void request();&#125; adaptee接口，即被适配者 123public interface TwoWayAdaptee &#123; public void specificRequest();&#125; 构建双向适配器，即适配器实现Target接口与Adaptee接口。因此被适配者与客户都可以去引用该适配器 12345678910111213141516171819202122class TwoWayAdapter implements TwoWayTarget, TwoWayAdaptee &#123; private TwoWayTarget target; private TwoWayAdaptee adaptee; public TwoWayAdapter(TwoWayTarget target) &#123; this.target = target; &#125; public TwoWayAdapter(TwoWayAdaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); &#125; @Override public void specificRequest() &#123; target.request(); &#125;&#125; 进行测试 123456789101112public class TwoWayAdapterTest &#123; public static void main(String[] args) &#123; System.out.println("目标通过双向适配器访问适配者："); TwoWayAdaptee adaptee = new AdapteeRealize(); TwoWayTarget target = new TwoWayAdapter(adaptee); target.request(); System.out.println("适配者通过双向适配器访问目标："); target = new TargetRealize(); adaptee = new TwoWayAdapter(target); adaptee.specificRequest(); &#125;&#125; 相关模式 Bridge的结构与对象适配器类似，但是Bridge模式的出发点不同。Bridge目的是将接口部分与实现部分分离，从而对它们可以较为容易也相对独立的加以改变。而Adapter意味着改变一个已有对象的接口 Decorator模式增强了其他对象的功能而同时又不改变它的接口。因此Decorator对应用程序的透明性比适配器好。结果是Decorator支持递归组合，而纯粹使用适配器无法实现 Proxy在不改变它的接口的条件下，为另一个对象定义了一个代理 进阶反省总结 在工作的时候，其实很多接口因为版本迭代原因都会出现各种各样的版本，因为新接口、功能迁移，很有可能出现说新接口不兼容旧的接口，而新旧都有各自的引用，重构是十分困难的。 使用适配器模式，你可以在不改变它的实现情况下，进行兼容扩展 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：迭代器模式]]></title>
    <url>%2F2019%2F04%2F07%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[迭代器模式提出问题 有许多种方法可以将对象堆起来成为一个集合。客户想要遍历的时候，如果让客户看到集合的实现，就有些不优雅。 针对不同的需要，可能需要以不同的方式遍历整个列表，即使可以预见到所需要的遍历操作，也不希望列表（指集合对象）的接口中充斥着各种不同遍历的操作。有时可能需要在同一个列表上同时进行多个遍历。 例如可能需要进行过滤列表迭代器，只访问那些满足特定过滤约束条件的元素。 问题案例应用迭代器模式将对列表的访问和遍历从列表对象中分离出来并放入一个迭代器对象中，迭代器定义了一个访问该列表元素的接口，迭代器对象负责跟踪当前的元素，即它知道哪些元素已经遍历过了。 适用性 让客户遍历对象，而又无法窥视存储对象的方式。 支持对集合对象的多种遍历方式 为遍历不同的集合结构提供一个统一的接口（支持多态迭代） 案例1 当有一个ArrayList和一个数组要合并，但是数组对象、ArrayList有很多依赖它的对象和方法。因此不能简单地将数组转换为ArrayList。如果转换，则需要更改它本身的实现 此时，对他们遍历就需要写两个循环 对于不同的集合，遍历是变化的部分，则将变化的部分封装起来。即迭代器 基础概述是什么 迭代器模式：迭代器模式提供一种方法顺序访问一集合对象中的各个元素，而又不暴露其内部的表示 在实例化列表迭代器前，必须提供待遍历的列表，一旦有了该列表迭代器的实例就可以顺序地访问该列表的各个元素。 将遍历机制与列表对象分离可以让我们定义不同的迭代器来实现不同的遍历策略，而不需要在列表接口中列举它们。 迭代器是与集合耦合在一起的，而且客户对象必须知道遍历的是一个列表而不是其他集合结构。则最好能够有一种办法使得不需要改变客户代码即可改变该集合类，则通过将迭代器的概念推广到多态迭代器来达到目标。 因此我们需要定义一个抽象类AbstrcatList，提供操作列表的公共接口，也需要一个抽象的迭代器类Iterator，然后为每个不同的列表实现定义具体的Iterator子类，此时迭代机制就与具体的集合类无关了。 迭代器的类方案确定后，就是如何创建迭代器，既然使代码不依赖于具体的列表子类，则不能仅仅简单地实例化一个特定的类，而需要让列表对象负责创建相应的迭代器，需要列表对象提供CreateIterator的操作。 创建迭代器是一个Factory Method的例子，用它来使得一个客户可以向一个列表对象请求合适的迭代器。 分类协作结构 参与者 Iterator：迭代器，定义访问和遍历元素的接口 ConcreteIterator：具体迭代器。 实现迭代器接口，集合遍历时跟踪当前位置 Aggregate：集合，定义创建相应迭代器对象的接口 ConcreteIterator：具体集合，实现相应迭代器接口，该操作返回一个ConcreteIterator的适当实例 协作 类关系 见参与者 逻辑关系 ConcreIterator跟踪集合中的当前对象，并能够计算出待遍历的后继对象 权衡 谁控制该迭代 谁定义遍历算法 迭代器的健壮程度 分类结构效果（优缺） 支持以不同的方式遍历一个集合 复杂的集合可用多种方式进行遍历，如代码生成和语义检查要遍历语法分析树，代码生成可以按中序或者前序来遍历语法分析树。迭代器模式使得改变遍历算法变得很容易，仅需要用一个不同的迭代器实例即可。 简化了集合的接口 有了迭代器的遍历接口，集合本身就不再需要类似的遍历接口了，即简化了集合的接口 在同一个集合上可以有多个遍历 每个迭代器保持它自己的遍历状态，因此可以同时进行多个遍历 附加的迭代器操作 可以为迭代器做一些增强性的功能，例如previous操作等 用于复合对象的迭代器 在Composite模式中的那些递归聚合结构上，外部迭代器可能难以实现，因为在该结构中不同对象处于嵌套集合的多个不同层次。因此一个外部迭代器为跟踪当前对象必须存储一条纵贯该Composite的路径 有时使用一个内部迭代器更容易一些，仅需要递归调用自己即可，隐式将路径存储在调用栈当中，无需显式维护当前对象位置 空迭代器 是退化的迭代器，有助于处理边界条件。根据定义一个空迭代器总是已经完成了遍历，即永远是True 实现实现步骤依赖于一个名为迭代器的接口 案例1迭代器接口 123456public interface Iterator&#123; //判断是否还有更多的元素 boolean hasNext(); //返回下一个元素 Object next();&#125; 数组实现迭代器 实现接口方法 实现迭代器 让对象实现返回迭代器的方法 12345678910111213141516171819202122232425//迭代器的实现public class MenuIterator implements Iterator &#123; MenuItem[] items; //标记目前遍历到达的位置 int position; public MenuIterator(MenuItem[] menuItem) &#123; this.items = menuItem; &#125; @Override public boolean hasNext() &#123; if (position &gt;= items.length || items[position] == null) return false; else return true; &#125; @Override public Object next() &#123; MenuItem menuItem = items[position]; position++; return menuItem; &#125;&#125; 1234567891011//对象返回迭代器public class DinerMenu &#123; static final int MAX_ITEMS = 6; int numberOfItems = 0; MenuItem[] menuItems; //返回迭代器接口，客户只需要使用迭代器遍历即可 public Iterator createIterator() &#123; return new MenuIterator(menuItems); &#125;&#125; 相关模式 Composite：迭代器常被应用到像符合这样的递归结构上 Factory Method：多态迭代器靠Factory Method来实例适当的迭代器子类 Memento:常与迭代器模式一起使用，迭代器使用一个memento来捕获一个迭代的状态，迭代器在其内部存储memento 进阶反省总结### 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：基础数据类型]]></title>
    <url>%2F2019%2F04%2F03%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[String12345678910111213141516171819202122232425262728293031323334353637383940414243444546char charAt(int index);//返回指定索引处的 char 值。int compareTo(Object o);//把这个字符串和另一个对象比较。int compareTo(String anotherString);//按字典顺序比较两个字符串。int compareToIgnoreCase(String str);//按字典顺序比较两个字符串，不考虑大小写。String concat(String str);//将指定字符串连接到此字符串的结尾。boolean contentEquals(StringBuffer sb);//当且仅当字符串与指定的StringBuffer有相同顺序的字符时候返回真。static String copyValueOf(char[] data);//返回指定数组中表示该字符序列的 String。static String copyValueOf(char[] data, int offset, int count);//返回指定数组中表示该字符序列的 String。boolean endsWith(String suffix);//测试此字符串是否以指定的后缀结束。boolean equals(Object anObject);//将此字符串与指定的对象比较。boolean equalsIgnoreCase(String anotherString);//将此 String 与另一个 String 比较，不考虑大小写。byte[] getBytes();//使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。byte[] getBytes(String charsetName);//使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin);//将字符从此字符串复制到目标字符数组。int hashCode();//返回此字符串的哈希码。int indexOf(int ch);//返回指定字符在此字符串中第一次出现处的索引。int indexOf(int ch, int fromIndex);//返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。int indexOf(String str);//返回指定子字符串在此字符串中第一次出现处的索引。int indexOf(String str, int fromIndex);//返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。String intern();//返回字符串对象的规范化表示形式。int lastIndexOf(int ch);//返回指定字符在此字符串中最后一次出现处的索引。int lastIndexOf(int ch, int fromIndex);//返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。int lastIndexOf(String str);//返回指定子字符串在此字符串中最右边出现处的索引。int lastIndexOf(String str, int fromIndex);//返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索。int length();//返回此字符串的长度。boolean matches(String regex);//告知此字符串是否匹配给定的正则表达式。boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len);//测试两个字符串区域是否相等。boolean regionMatches(int toffset, String other, int ooffset, int len);//测试两个字符串区域是否相等。String replace(char oldChar, char newChar);//返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。String replaceAll(String regex, String replacement);//使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。String replaceFirst(String regex, String replacement);//使用给定的 replacement 替换此字符串匹配给定的正则表达式的第一个子字符串。String[] split(String regex);//根据给定正则表达式的匹配拆分此字符串。String[] split(String regex, int limit);//根据匹配给定的正则表达式来拆分此字符串。boolean startsWith(String prefix);//测试此字符串是否以指定的前缀开始。boolean startsWith(String prefix, int toffset);//测试此字符串从指定索引开始的子字符串是否以指定前缀开始。CharSequence subSequence(int beginIndex, int endIndex);//返回一个新的字符序列，它是此序列的一个子序列。String substring(int beginIndex);//返回一个新的字符串，它是此字符串的一个子字符串。String substring(int beginIndex, int endIndex);//返回一个新字符串，它是此字符串的一个子字符串。char[] toCharArray();//将此字符串转换为一个新的字符数组。String toLowerCase();//使用默认语言环境的规则将此 String 中的所有字符都转换为小写。String toLowerCase(Locale locale);//使用给定 Locale 的规则将此 String 中的所有字符都转换为小写。String toString();//返回此对象本身（它已经是一个字符串！）。String toUpperCase();//使用默认语言环境的规则将此 String 中的所有字符都转换为大写。String toUpperCase(Locale locale);//使用给定 Locale 的规则将此 String 中的所有字符都转换为大写。String trim();//返回字符串的副本，忽略前导空白和尾部空白。static String valueOf(primitive data type x);//返回给定data type类型x参数的字符串表示形式。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：IO]]></title>
    <url>%2F2019%2F04%2F01%2FJava%2Fbase%2FJavaBase%EF%BC%9AIO%2F</url>
    <content type="text"><![CDATA[IOI/O或者输入/输出 指的是计算机与外部世界或者一个程序与计算机的其余部分的之间的接口。它对于任何计算机系统都非常关键，因而所有I/O的主体实际上是内置在操作系统中的。 针对不同的操作对象，可以划分为磁盘I/O模型，网络I/O模型，内存映射I/O, Direct I/O、数据库I/O等，只要具有输入输出类型的交互系统都可以认为是I/O系统，也可以说I/O是整个操作系统数据交换与人机交互的通道，这个概念与选用的开发语言没有关系，是一个通用的概念。 在如今的系统中I/O却拥有很重要的位置，现在系统都有可能处理大量文件，大量数据库操作，而这些操作都依赖于系统的I/O性能，也就造成了现在系统的瓶颈往往都是由于I/O性能造成的。因此，为了解决磁盘I/O性能慢的问题，系统架构中添加了缓存来提高响应速度；或者有些高端服务器从硬件级入手，使用了固态硬盘（SSD）来替换传统机械硬盘；在大数据方面，Spark越来越多的承担了实时性计算任务，而传统的Hadoop体系则大多应用在了离线计算与大量数据存储的场景，这也是由于磁盘I/O性能远不如内存I/O性能而造成的格局（Spark更多的使用了内存，而MapReduece更多的使用了磁盘）。 因此，一个系统的优化空间，往往都在低效率的I/O环节上，很少看到一个系统CPU、内存的性能是其整个系统的瓶颈。 IO分类同步与异步 同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。 异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。 同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。 阻塞与非阻塞 阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。 IO分类 BIO （Blocking I/O）：同步阻塞I/O模式。它是基于流模型实现的，交互的方式是同步、阻塞方式，也就是说在读入输入流或者输出流时，在读写动作完成之前，线程会一直阻塞在那里，它们之间的调用是可靠的线性顺序。 这里使用那个经典的烧开水例子，这里假设一个烧开水的场景，有一排水壶在烧开水，BIO的工作模式就是， 叫一个线程停留在一个水壶那，直到这个水壶烧开，才去处理下一个水壶。但是实际上线程在等待水壶烧开的时间段什么都没有做。 NIO （New I/O）：同时支持阻塞与非阻塞模式，在Java 1.4引入。提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层高性能的数据操作方式。 那么什么叫做同步非阻塞？如果还拿烧开水来说，NIO的做法是叫一个线程不断的轮询每个水壶的状态，看看是否有水壶的状态发生了改变，从而进行下一步的操作。 AIO （Asynchronous I/O）：异步非阻塞I/O模型，在Java1.7引入，是NIO的升级。异步非阻塞与同步非阻塞的区别在哪里？异步非阻塞无需一个线程去轮询所有IO操作的状态改变，在相应的状态改变后，系统会通知对应的线程来处理。 对应到烧开水中就是，为每个水壶上面装了一个开关，水烧开之后，水壶会自动通知我水烧开了。 IO调用步骤进程中的IO调用步骤大致可以分为以下四步： 进程向操作系统请求数据 ; 操作系统把外部数据加载到内核的缓冲区中; 操作系统把内核的缓冲区拷贝到进程的缓冲区 ; 进程获得数据完成自己的功能 ; 当操作系统在把外部数据放到进程缓冲区的这段时间（即上述的第二，三步），如果应用进程是挂起等待的，那么就是同步IO，反之，就是异步IO，也就是AIO 。 Java IO单独的程序一般是让系统为它们完成大部分的工作。 在Java编程中，直到最近一直使用流的方式完成I/O。所有I/O都被视为单个的字节的移动，通过一个称为Stream的对象一次移动一个字节。流I/O用于与外部世界接触。它也在内部使用，用于将对象转换为字节，然后再转换回对象。 Java在I/O上也一直在做持续的优化，从JDK 1.4开始便引入了NIO模型，大大的提高了以往BIO模型下的操作效率。 BIO 同步阻塞概述是什么这是最基本与简单的I/O操作方式，其根本特性是做完一件事再去做另一件事，一件事一定要等前一件事做完，这很符合程序员传统的顺序来开发思想，因此BIO模型程序开发起来较为简单，易于把握。 BIO可以通过多线程实现伪异步IO，但是当连接数极具上升也会带来性能瓶颈，原因是线程的上线文切换开销会在高并发的时候体现的很明显。 特性 面向流的 在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区。 阻塞 分类传统的 IO 大致可以分为4种类型： InputStream、OutputStream 基于字节操作的 IO Writer、Reader 基于字符操作的 IO File 基于磁盘操作的 IO Socket 基于网络操作的 IO 优缺优点: 使用简单，将底层的机制都抽象成流. 缺点 性能不足。而且IO的各种流是阻塞的，这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 但是BIO如果需要同时做很多事情（例如同时读很多文件，处理很多tcp请求等），就需要系统创建很多线程来完成对应的工作，因为BIO模型下一个线程同时只能做一个工作，如果线程在执行过程中依赖于需要等待的资源，那么该线程会长期处于阻塞状态，我们知道在整个操作系统中，线程是系统执行的基本单位，在BIO模型下的线程阻塞就会导致系统线程的切换，从而对整个系统性能造成一定的影响。 应用适用性 如果我们只需要创建少量可控的线程，那么采用BIO模型也是很好的选择 但如果在需要考虑高并发的web或者tcp服务器中采用BIO模型就无法应对了，如果系统开辟成千上万的线程，那么CPU的执行时机都会浪费在线程的切换中，使得线程的执行效率大大降低。 实现流程主要面向使用BIO通信模型的服务端。 首先通常有一个独立的Accepter线程负责监听客户端的连接，一般通过while(true)的方式调用accept()方法等待接收客户端的连接方式监听请求。请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成。 示例1234567891011121314151617181920212223242526272829303132333435363738int port = 4343; //端口号// Socket 服务器端（简单的发送信息）Thread sThread = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; ServerSocket serverSocket = new ServerSocket(port); while (true) &#123; // 等待连接 Socket socket = serverSocket.accept(); Thread sHandlerThread = new Thread(new Runnable() &#123; @Override public void run() &#123; try (PrintWriter printWriter = new PrintWriter(socket.getOutputStream())) &#123; printWriter.println("hello world！"); printWriter.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); sHandlerThread.start(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;);sThread.start();// Socket 客户端（接收信息并打印）try (Socket cSocket = new Socket(InetAddress.getLocalHost(), port)) &#123; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(cSocket.getInputStream())); bufferedReader.lines().forEach(s -&gt; System.out.println("客户端：" + s));&#125; catch (UnknownHostException e) &#123; e.printStackTrace();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; NIO 同步非阻塞为什么要用NIO本身是基于事件驱动的思想来实现的，采用Reactor模式，其目的就是解决BIO的大并发问题，而在BIO模型中，如果需要并发处理多个I/O请求，那就需要多线程来支持。 NIO不需要位每个Socket套接字分配一个线程，而可以在一个线程当中处理多个Socket套接字相关的工作。 NIO的创建目的是为了让Java程序员可以实现高速I/O而无需编写自定义的本机代码。NIO将最耗时的I/O操作(即填充和提取缓冲区)转移回操作系统，因而可以极大地提高速度。 基础概述是什么NIO中提供了Channel，Selector，Buffer等抽象。支持面向缓冲的，基于通道的IO操作方法。 NIO提供了与传统BIO模型中的Socket和ServerSocket相对应的SocketChannel和ServerSocketChannel两种不同的套接字通道实现，两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。 NIO的特性： Non-blocking IO 非阻塞读：单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据 非阻塞写：一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 Buffer 在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。 最常用的缓冲区是ByteBuffer，一个ByteBuffer提供了一组功能用于操作byte数组。除了ByteBuffer，还有其他的一些缓冲区 Channel NIO 通过Channel（通道）进行读写。通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为Buffer，通道可以异步地读写。 Selectors NIO有选择器，而IO没有。选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。 核心组件 Channel(通道) Buffer(缓冲区) Selector(选择器) 优缺 非阻塞 buffer机制 流替代块 缺陷 JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100% 项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高。 NIO的块机制原来的 I/O 库(在 java.io.*中) 与 NIO 最重要的区别是数据打包和传输的方式。正如前面提到的，原来的 I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I/O 系统一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。为流式数据创建过滤器非常容易。链接几个过滤器，以便每个过滤器只负责单个复杂处理机制的一部分，这样也是相对简单的。 不利的一面是，面向流的 I/O 通常相当慢。 一个 面向块 的 I/O 系统以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。 按块处理数据比按(流式的)字节处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 NIO的buffer机制NIO性能的优势就来源于缓冲的机制，不管是读或者写都需要以块的形式写入到缓冲区中。NIO实际上让我们对IO的操作更接近于操作系统的实际过程。 所有的系统I/O都分为两个阶段：等待就绪和操作。 举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。 以socket为例： 先从应用层获取数据到内核的缓冲区，然后再从内核的缓冲区复制到进程的缓冲区。所以实际上底层的机制也是不断利用缓冲区来读写数据的。即使传统IO抽象成了从流直接读取数据，但本质上也依然是利用缓冲区来读取和写入数据。 所以，为了更好的理解nio，我们就需要知道IO的底层机制，这样对我们将来理解channel和buffer就打下了基础。这里简单提一下，我们可以把bufffer就理解为内核缓冲区，所以不论读写，自然都要经过这个区域，读的话，先从设备读取数据到内核，再读到进程缓冲区，写的话，先从进程缓冲区写到内核，再从内核写回设备。 NIO的非阻塞机制NIO抽象出了新的通道（Channel）作为输入输出的通道，并且提供了缓存（Buffer）的支持 在进行读操作时 需要使用Buffer分配空间 然后将数据从Channel中读入Buffer中 对于Channel的写操作 也需要现将数据写入Buffer 然后将Buffer写入Channel中。 NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 应用适用性实现流程读取数据与写数据 通常来说NIO中的所有IO都是从 Channel（通道） 开始的。 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。 数据读取和写入操作图示： NIO使用了多路复用器(selector)机制，以socket使用来说，多路复用器通过不断轮询各个连接的状态，只有在socket有流可读或者可写时，应用程序才需要去处理它，在线程的使用上，就不需要一个连接就必须使用一个处理线程了，而是只是有效请求时（确实需要进行I/O处理时），才会使用一个线程去处理，这样就避免了BIO模型下大量线程处于阻塞等待状态的情景。 示例如下是NIO方式进行文件拷贝操作的示例，见下图： 通过比较New IO的使用方式我们可以发现，新的IO操作不再面向 Stream来进行操作了，改为了通道Channel，并且使用了更加灵活的缓存区类Buffer，Buffer只是缓存区定义接口， 根据需要，我们可以选择对应类型的缓存区实现类。在java NIO编程中，我们需要理解以下3个对象Channel、Buffer和Selector。 Channel 首先说一下Channel，国内大多翻译成“通道”。Channel和IO中的Stream(流)是差不多一个等级的。只不过Stream是单向的，譬如：InputStream，OutputStream。而Channel是双向的，既可以用来进行读操作，又可以用来进行写操作，NIO中的Channel的主要实现有：FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel；通过看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。 Buffer NIO中的关键Buffer实现有：ByteBuffer、CharBuffer、DoubleBuffer、 FloatBuffer、IntBuffer、 LongBuffer,、ShortBuffer，分别对应基本数据类型: byte、char、double、 float、int、 long、 short。当然NIO中还有MappedByteBuffer, HeapByteBuffer, DirectByteBuffer等这里先不具体陈述其用法细节。 说一下DirectByteBuffer与HeapByteBuffer的区别？ 它们 ByteBuffer 分配内存的两种方式。HeapByteBuffer 顾名思义其内存空间在 JVM 的 heap（堆）上分配，可以看做是 JDK 对于 byte[] 数组的封装；而 DirectByteBuffer 则直接利用了系统接口进行内存申请，其内存分配在c heap 中，这样就减少了内存之间的拷贝操作，如此一来，在使用 DirectByteBuffer 时，系统就可以直接从内存将数据写入到 Channel 中，而无需进行 Java 堆的内存申请，复制等操作，提高了性能。既然如此，为什么不直接使用 DirectByteBuffer，还要来个 HeapByteBuffer？原因在于， DirectByteBuffer 是通过full gc来回收内存的，DirectByteBuffer会自己检测情况而调用System.gc()，但是如果参数中使用了DisableExplicitGC那么就无法回收该快内存了，-XX:+DisableExplicitGC标志自动将System.gc()调用转换成一个空操作，就是应用中调用 System.gc() 会变成一个空操作，那么如果设置了就需要我们手动来回收内存了，所以DirectByteBuffer使用起来相对于完全托管于 java 内存管理的Heap ByteBuffer 来说更复杂一些，如果用不好可能会引起OOM。Direct ByteBuffer 的内存大小受-XX:MaxDirectMemorySizeJVM 参数控制（默认大小64M），在 DirectByteBuffer 申请内存空间达到该设置大小后，会触发 Full GC。 Selector Selector 是NIO相对于BIO实现多路复用的基础，Selector 运行单线程处理多个 Channel，如果你的应用打开了多个通道，但每个连接的流量都很低，使用 Selector 就会很方便。例如在一个聊天服务器中。要使用 Selector , 得向 Selector 注册 Channel，然后调用它的 select() 方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新的连接进来、数据接收等。 这里我们再来看一个NIO模型下的TCP服务器的实现，我们可以看到Selector 正是NIO模型下 TCP Server 实现IO复用的关键，请仔细理解下段代码while循环中的逻辑，见下图： nettyJava NIO存在一些问题： JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100% 项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高，上面这一坨代码我都不能保证没有 bug Netty 的出现很大程度上改善了 JDK 原生 NIO 所存在的一些让人难以忍受的问题。 AIO 异步非阻塞Java AIO就是Java作为对异步IO提供支持的NIO.2 ，Java NIO2 (JSR 203)定义了更多的 New I/O APIs， 提案2003提出，直到2011年才发布， 最终在JDK 7中才实现。JSR 203除了提供更多的文件系统操作API(包括可插拔的自定义的文件系统)， 还提供了对socket和文件的异步 I/O操作。 同时实现了JSR-51提案中的socket channel全部功能,包括对绑定， option配置的支持以及多播multicast的实现。 概述是什么AIO的异步IO是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 AIO采用Proactor模式，在读写时，只需要调用相应的read/write方法，并且需要传入CompletionHandler，动作完成后会调用CompetionHandler。 AIO是异步IO的缩写，虽然NIO在网络操作中，提供了非阻塞的方法，但是NIO的IO行为还是同步的。对于 NIO 来说，我们的业务线程是在IO操作准备好时，得到通知，接着就由这个线程自行进行IO操作，IO操作本身是同步的。 从编程模式上来看AIO相对于NIO的区别在于，NIO需要使用者线程不停的轮询IO对象，来确定是否有数据准备好可以读了，而AIO则是在数据准备好之后，才会通知数据使用者，这样使用者就不需要不停地轮询了。当然AIO的异步特性并不是Java实现的伪异步，而是使用了系统底层API的支持，在Unix系统下，采用了epoll IO模型，而windows便是使用了IOCP模型。关于Java AIO，本篇只做一个抛砖引玉的介绍，如果你在实际工作中用到了，那么可以参考Netty在高并发下使用AIO的相关技术。 总结IO实质上与线程没有太多的关系，但是不同的IO模型改变了应用程序使用线程的方式，NIO与AIO的出现解决了很多BIO无法解决的并发问题，当然任何技术抛开适用场景都是耍流氓，复杂的技术往往是为了解决简单技术无法解决的问题而设计的，在系统开发中能用常规技术解决的问题，绝不用复杂技术，否则大大增加系统代码的维护难度，学习IT技术不是为了炫技，而是要实实在在解决问题。 参考 以Java的视角来聊聊BIO、NIO与AIO的区别？ Snailclimb BIO-NIO-AIO]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：InnoDB]]></title>
    <url>%2F2019%2F04%2F01%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9AInnoDB%2F</url>
    <content type="text"><![CDATA[MySQL体系结构和存储引擎尽管各平台在底层实现方面都各有不同，但是MySQL基本上能保证在各平台上的物理体系结构的一致性。 定义数据库和实例 数据库： 物理操作系统文件或其他形式文件类型的集合。 在MySQL数据库中，文件可以是frm、MYD、MYI等结尾的文件。 NDB引擎时，可能是存放于内存当中的文件。 是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合。 实例： MySQL数据库由后台线程以及一个共享内存区组成。可以被运行的后台线程所共享。 是真正用于操作数据库文件的。 是程序，是位于用户与OS间的一层数据管理软件，程序只有通过实例才能和数据库打交道。 MySQL是一个单进程多线程架构的数据库。 MySQL体系结构 MySQL组成 连接池组件 管理服务和工具组件 SQL接口组件 查询分析器组件 优化器组件 缓冲组件 插件式存储引擎。基于表而不是数据库 物理文件 MySQL存储引擎用户应该根据具体的应用选择合适的存储引擎 InnoDB 支持事务，设计目标主要面向在线事务处理的应用 特点 行锁设计 支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁 通过使用多版本并发控制（MVCC）来获得高并发性，并实现了SQL标准的4种隔离级别 默认为Repeatable read 使用一种被称为next-keylocking的策略避免幻读 提供插入缓冲、二次写、自适应哈希索引、预读等高性能功能。 对于表中数据的存储，采用了聚集的方式，因此每张表存储都是按照主键的顺序进行存放，如果没有显式定义逐渐，InnoDB将为每一行生成一个6字节的ROWID InnoDB存储引擎将数据放在一个逻辑的表空间，这个表空间像一个黑盒一样由InnoDB管理，可以将表单独存放到一个独立的idb文件中 MyISAM 不支持事务、表锁设计 支持全文索引 主要面向一些OLAP数据库应用。适合报表查询系统，因为这些系统并不需要事务。 只缓存索引文件，不缓冲数据文件 锁的粒度为表级 相对简单，在效率上更优，小型应用更为适合 表是保存成文件形式，在跨平台的数据转移中会省去不少麻烦 NDB 一个集群存储引擎。结构为share nothing的集群架构，能够提供更高的可用性 特点 数据全部放在内存中，因此主键查找速度极快 可通过添加NDB数据存储结点，线性提高数据库性能 从MySQL5.1开始，可以将非索引数据放在磁盘上。 缺陷 NDB存储引擎的连接操作是在MySQL数据库层完成的，而不是存储引擎层。因此复杂的连接操作需要巨大的网络开销，查询速度很慢 Memory 适用于存储临时数据的临时表，以及数据仓库中的维度表 特点 将表中数据放在内存中，如果数据库重启或崩溃，表中数据都将消失。 默认使用哈希索引 速度非常快。 只支持表锁，并发性能较差，不支持TEXT和BLOB列类型。存储变长字段时是按照定常字段的方式进行，会浪费内存。 当作为临时表存放中间结果集，如果中间结果集大于Memory存储引擎表的容量设置，或含有TEXT列类型，则会转换为MyISAM存储引擎 Archive 只支持Insert和select操作 从MySQL5.1支持索引 适合存储归档数据，如日志。使用zlib算法将数据行压缩存储，压缩比一般可达到1：10。 使用行锁实现高并发的插入操作，但本身不是事务安全的，设计目标是提供高速的插入和压缩功能 Federated 不存放数据，只是指向一台远程MySQL数据库服务器上的表 Maria 新开发的引擎，设计目标是取代原有的MyISAM，从而成为MySQL的默认存储引擎 支持缓存数据和索引文件 应用行锁设计，提供MVCC功能，支持事务和非事务安全的选项，以及更好地blob字符类型的处理性能 连接MySQL管道、命名管道、命名字、TCP/IP套接字、UNIX域套接字 InnoDB存储引擎是事务安全的存储引擎。在InnoDB 1.2x增加了全文索引支持。 概述 第一个完整支持ACID事务的存储引擎 原子性（atomicity，或称不可分割性）。一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 一致性（consistency）。在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 隔离性（isolation，又称独立性）。数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（durability）。事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 特点 行锁设计、支持MVCC、支持外键、提供一致性非锁定读 被设计用来最有效地以及使用内存和CPU InnoDB体系架构 InnoDB存储引擎有多个内存块，可以认为他们组成一个大内存池，负责： 维护所有进程/线程需要访问的多个内部数据结构。 缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改前在这里缓存。 重做日志(redo log)缓冲。 。。。 数据存储Innodb存储引擎可将所有数据存放于ibdata*的共享表空间，也可将每张表存放于独立的.ibd文件的独立表空间。共享表空间以及独立表空间都是针对数据的存储方式而言的。 独立表空间： 每一个表都将会生成以独立的文件方式来进行存储，每一个表都有一个.frm表描述文件，还有一个.ibd文件。 其中这个文件包括了单独一个表的数据内容以及索引内容，默认情况下它的存储位置也是在表的位置之中。 优点： 每个表都有自已独立的表空间，每个表的数据和索引都会存在自已的表空间中，可以实现单表在不同的数据库中移动。 空间可以回收（除drop table操作处，表空不能自已回收） Drop table操作自动回收表空间，如果对于统计分析或是日值表，删除大量数据后可以通过:alter table TableName engine=innodb;回缩不用的空间。 对于使innodb-plugin的Innodb使用turncate table也会使空间收缩。 对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。 缺点： 单表增加过大，当单表占用空间过大时，存储空间不足，只能从操作系统层面思考解决方法； 共享表空间： 即idbdata*，又称为系统表空间。某一个数据库的所有的表数据，索引文件全部放在一个单独的表空间中，而这个表空间可以由很多个文件组成，一个表可以跨多个文件存在，所以其大小限制不再是文件大小的限制，而是其自身的限制。默认这个共享表空间的文件路径在data目录下。 默认的文件名为:ibdata1 初始化为10M。 优点： 表空间可以分成多个文件存放到各个磁盘，所以表也就可以分成多个文件存放在磁盘上，表的大小不受磁盘大小的限制。数据和文件放在一起方便管理。 缺点： 所有的数据和索引存放到一个文件，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，当数据量非常大的时候，表做了大量删除操作后表空间中将会有大量的空隙，特别是对于统计分析，对于经常删除操作的这类应用最不适合用共享表空间。 共享表空间分配后不能回缩：当出现临时建索引或是创建一个临时表的操作表空间扩大后，就是删除相关的表也没办法回缩那部分空间了（可以理解为oracle的表空间10G，但是才使用10M，但是操作系统显示mysql的表空间为10G），进行数据库的冷备很慢； 后台线程负责 刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。 将已经修改的数据文件刷新到磁盘文件。 保证数据库在发生异常的情况下InnoDB能恢复到正常运行状态。 MasterThread 负责将缓冲池中的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓冲、UNDO页的回收 IO Thread InnoDB大量使用AIO处理写请求，可以极大提高数据库的性能 负责将IO请求的回调处理。 Linux下有4个，为write、read、insert buffer、log IO thread Windows可以自行设定，write与read增大到了4个，通过参数innodb_read(write)_io_threads设定 Purge Thread 事务提交后，其使用的undo log可能不再需要，使用该线程回收已经使用并分配的undo页 Page Cleaner Thread 将之前版本中脏页的刷新操作放入到单独的线程。 内存缓冲池InnoDB存储引擎基于磁盘存储的，并将其中的记录按照页的方式进行管理。即可认为是基于磁盘的数据库系统。 考虑CPU与磁盘速度，则使用缓冲池技术提高数据库整体性能。缓冲池是一块内存区域，通过内存的速度来弥补磁盘的速度较慢。 数据库读取页的操作： 首先将从磁盘读到的页存放到缓冲池中。 下一次读取相同的页，判断该页是否在缓冲池中。若在，则该页被命中，直接读取。否则读取磁盘。 数据库页修改操作： 首先修改在缓冲池中的页，再以一定频率刷新到磁盘（Checkpoint机制）。 缓冲池大小配置：innodb_buffer_pool_size。 数据页类型 缓冲池当中的数据页类型有：索引页、数据页、undo页、插入缓冲、自适应哈希索引、InnoDB存储的锁信息、数据字典信息等。 多缓冲池 InnoDB 1.0.x后允许有多个缓冲池实例。每个页根据哈希值平均分配到不同的缓冲池实例中。 减少了数据库内部的资源竞争，增加数据库的并发处理能力 配置：innodb_buffer_pool_instances LRU List、Free List和Flush List对缓冲池这么大的内存区域进行管理。 InnoDB使用LRU管理页，缓冲池中页的默认大小是16KB。使用innodb_old_blocks_time表示页读取到mid位置后需要等待多久才会被加入到LRU列表的热端。 在数据库当启动时，LRU列表是空的，此时页都存放在Free列表中，当需要从缓冲区中分页时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中，否则根据LRU算法淘汰LRU列表末尾的列，将该内存空间分配给新的页。 压缩页 从1.0.x开始支持压缩页的概念，可将原本16KB的页压缩为1KB、2KB、4KB、8KB，因此LRU列表页存在变化，对于压缩过的页是通过unzip_LRU列表进行管理的。 Flush List 该列表当中的页为脏页列表，脏页既存在于LRU列表，也存在FLUSH列表中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘。 重做日志缓冲InnoDB存储引擎的内存区域除了有缓冲池，还有重做日志缓冲(redo log buffer)。 InnoDB首先将重做日志信息放入到该缓冲区，然后按一定频率将其刷新到重做日志文件。一般不需要很大，一般每s会将日志缓冲刷新到日志文件，用户只需要保证每s产生的事务量在这个缓冲范围内即可。 在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存。 记录的是物理数据页面的修改的信息。 可通过innodb_log_buffer_size控制，默认为8MB。 刷新日志缓冲到外部磁盘的redo log buffer Master Thread每秒将重做日志缓冲刷新到重做日志文件。 每个事务提交时会将重做日志缓冲刷新到重做日志文件中 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。 额外的内存池在InnoDB存储引擎中，对内存的管理是通过一种称为内存堆的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。 分配了缓冲池，但是每个缓冲池的帧缓冲和对应的缓冲控制对象（这些对象记录LRU、锁、等待等信息）的内存需要从缓冲控制块申请。因此申请了很大的缓冲池，也要考虑相应增加额外内存池。 Checkpoint技术页的操作首先是在缓冲池中完成的。如果一条DML语句，则此时页是脏的，缓冲池中的页版本比磁盘当中新，数据库需要将新版本的页刷新到磁盘。 倘若每次一个页发生变化，就刷新到磁盘，则开销极大。 倘若在刷新到磁盘的过程中，服务器宕机，则数据无法恢复。 为了避免数据丢失问题，普遍采用Write Ahead Log策略 当事务提交时，先写redo log，再修改页。 当宕机导致数据丢失时，通过重做日志来完成数据的恢复，实现持久性的要求。 是否不需要将缓冲池中页刷新到磁盘。 缓冲池无法缓存数据库所有的数据。 重做日志无法无限增大，即使可以，运维难度大、成本高。 日志文件太大，恢复数据库需要时间太久。 Checkpoint技术 解决的问题： 缩短数据库的恢复时间。只需对Checkpoint后的重做日志进行恢复。 缓冲池不够用时，将脏页刷新到磁盘。采用LRU算法溢出页面，如果为脏页则强制执行Checkpoint，刷新页面。 重做日志不可用时，刷新脏页。数据库对重做日志进行循环使用，覆盖重用。 重做日志不可用是指当repo log已经满了，而repo log不可增大，此时必须将脏页刷新回磁盘。 Checkpoint发生的时间、条件以及脏页的选择等都非常复杂。Innodb中有两种Checkpoint： Sharp Checkpoint。 默认的工作方式，发生在数据库关闭时，将所有的脏页都刷新回磁盘。即参数innodb_fast_shutdown=1 若数据库运行时页使用该技术，则数据库可用性会受到很大限制。 Fuzzy Checkpoint。 只刷新一部分脏页，而不是刷新所有脏页回磁盘。 Fuzzy Checkpoint InnoDB存储引擎中可能发生的几种请求的Fuzzy Checkpoint。 Master Thread Checkpoint。每s或每10s刷新，是异步操作。 FLUSH_LRU_LIST Checkpoint。为保证LRU列表有100个空闲页可用。若没有，则移除尾端页，若这些页有脏页，则需要进行Checkpoint。 Async/Sync Flush Checkpoint。为了保证重做日志的循环使用的可用性。重做日志文件不可用的情况下（写满了），需要强制将一些页刷新会磁盘。 Dirty Page too much Checkpoint。脏页数量太多，目的是为了保证缓冲池当中有足够可用的页。 Master Thread工作方式InnoDB的主要工作都是在一个单独的后台线程Master Thread中完成的，其具有最高的线程优先级别。内部由多个循环组成：主循环、后台循环、刷新循环、暂停循环。Master Thread会根据数据库运行的状态在四个循环间切换。 主循环通过thread sleep实现，因此其计时并不精确，可能延迟。其包含每s或每10s的操作 每s的操作： 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）。 合并插入缓冲（可能，会根据当前1s内IO次数是否小于5次，如果是则可以执行该操作）。 至多刷新100个InnoDB的缓冲池中脏页到磁盘（可能，会去判断脏页比例是否超标）。 如果当前没有用户活动，则切换大background loop（可能）。 每10s的操作 刷新100个脏页到磁盘（可能，判断10s内IO是否小于200次，如果是则执行）。 合并至多5个插入缓冲（总是）。 将日志缓冲刷新到磁盘（总是）。 删除无用的undo页（总是）。 数显100个或10个脏页到磁盘（总是）。 后台循环，若当前没有用户活动，或数据库关闭就会切换到该循环 删除无用的undo页（总是）。 合并20个插入缓冲（总是）。 跳回主循环（总是）。 不断刷新100个页直到符合条件（可能或跳转到flush loop中完成）。 刷新循环。 暂停循环。若flush loop无事可做，则切换到该循环，将Master Thread挂起。 在InnoDB1.1.x时 合并插入缓冲时，数量未innodb_io_capacity的5% 从缓冲区刷新脏页时，数量为innodb_io_capacity 脏页阈值调整到75% 可以动态设置full purge回收undo页的数量 InnoDB1.2.x在InnoDB1.2.x时，将Master Thread中的刷新脏页操作分离到了一个单独的Page Cleaner Thread当中，进一步提高了系统的并发现。 InnoDB关键特性插入缓冲Insert Buffer并不是缓冲区，而是与数据页一样，都是物理页的一个组成部分。 在InnoDB存储引擎中，主键是行唯一标识符。通常应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的。因此插入聚集索引一般是顺序的，不需要磁盘的随机读取。 对于主键自增长的列，在页当中，行记录是按照聚集索引的值进行顺序存放的，一般不需要随机读取另一个页中的记录，因此对于此类插入操作，速度非常快。 并不是所有的主键插入都是顺序的，若主键类为UUID这样，那么插入和辅助索引一样，同样随机 但是一张表上同样有多个非聚集的辅助索引，则此时会产生非聚集且不是唯一的索引 进行插入操作时，数据页的存放还是按主键进行顺序存放 对于非聚集索引叶子结点的插入不再是顺序的了，需要离散地访问非聚集索引的页，由于随机读取的存在而导致了插入操作性能下降 B+树的特性决定了非聚集索引插入的离散性 Insert Buffer 对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页当中 判断插入的非聚集索引页是否在缓冲池内，若在，直接插入 若不在，则先放入一个Insert Buffer对象中，假装已经插入到叶子结点 以一定频率和情况进行Insert Buffer和辅助索引页子节点的合并操作。将多次插入合并到一次操作（因为在一个索引页当中），这样就大大提高了对于非聚集索引插入的性能。 需要满足的条件 索引是辅助索引。 索引不唯一。插入缓冲时，数据库就不必去查找索引页判断记录的唯一性。否则为了判断唯一性一定要去磁盘当中查找该页面，此时Insert Buffer就没有了意义。 缺陷 宕机时，可能有很多Insert Buffer没有合并，导致恢复需要较长时间。 在写密集情况下，Insert Buffer会占用过多的缓冲池内存，默认最大可用占用1/2的缓冲池内存。 内部实现 Insert Buffer的数据结构是B+树，在当前版本全局一颗Insert Buffer B+树。 负责对所有的表的辅助索引进行Insert Buffer。 存放在共享表空间，默认是idbata1中。 试图通过独立表空间idb文件恢复表数据，往往导致Check table失败，因为辅助索引还在Insert Buffer中。 通过idb恢复后，还需要进行repair table进行重建辅助索引。 B+树非叶子结点存放的是查询的search key键值： 当一个辅助索引要插入到页，且页不在缓冲池，则需要先构造一个search key，并插入到叶子结点当中。 第5列开始即实际插入记录的各个字段。 Change Buffer Insert Buffer的升级，1.0.x。对DML操作都进行缓冲，即Insert Buffer、Delete Buffer、Purge buffer。 对一条记录进行update操作： 将记录标记为已删除，Delete Buffer 真正将记录删除，Purge buffer Insert Buffer Bitmap 启用Insert Buffer后，辅助索引页中的记录可能被插入到Insert Buffer B+树中，为了保证每次的Merge Insert Buffer成功，hi需要有一个特殊的页来标记每个辅助索引页的可用空间，即Insert Buffer Bitmap。 每个Insert Buffer Bitmap用来追踪16384个辅助索引页，即256个区。 Merge Insert Buffer 将Insert Buffer合并到真正的辅助索引中，合并辅助索引可能发生在以下几种情况： 辅助索引页被读取到缓冲池时 Insert Buffer Bitmap页追踪到该辅助索引页已经没有可用空间时 至少需要有1/32页的空间 Master Thread 每s或每10s进行一次操作，不同之处在于每次进行merge的页数量不同 两次写提供数据页的可靠性： 部分写失效：当服务器宕机，可能InnoDB存储引擎正在写入某个页到表中，但只写了一部分就宕机。面对部分写失效，重做日志可能没有效果 重做日志中记录的是对页的物理操作，如偏移量800，写’aaaa’记录，如果页本身发生损坏，则进行重做无意义。 在应用重做日志前，用户需要一个页的副本，当写入失效发生时，写通过页的副本来还原该页，再进行重做，即doublewrite。 doublewrite 在对缓冲池的脏页进行刷新时： 并不直接写磁盘，而是通过memcpy函数将脏页先赋值到内存的doublewrite buffer。 通过doublewrite buffer分两次，每次1MB顺序写入共享表空间的物理磁盘。double write页是连续的，顺序写，开销小。 调用fsync函数，同步磁盘，避免缓冲写带来的问题。表空间是不连续的，写入是离散的。 解决部分写失效： InnoDB存储引擎可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件。 应用redo log 自适应哈希索引在生产环境下B+树的高度一般为3-4层。 自适应哈希索引（AHI）：InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引。 AHI通过缓冲池的B+树页构造，速度很快，而且不需要对整张表构建哈希索引。 会自动根据访问的频率和模式来自动为某些热点页建立哈希索引 要求对这个页的连续访问模式必须是一样的，如where a= ？与where a=? and b=?是两种访问模式 以该模式访问了100次，或页通过该模式访问了N次，N=页中记录/16 异步IO（AIO）提高磁盘操作性能。在InnoDB1.1.X提供了内核级别的AIO支持。 Sync IO：与AIO对应，每进行一次IO操作，需要等待此次操作结束才能继续接下来的操作。 AIO可以进行IO Merge操作，将对多个连续页的IO合并为一个操作，提高IOPS的性能。 刷新临近页当刷新一个脏页时，InnoDB存储引擎会检测该页所在区的所有页，如果是脏页，那么一起进行刷新。通过AIO可以将多个IO写入操作合并为1个操作。 存在的问题： 是不是可能将不怎么脏的页进行了写入，而该页又很快变成了脏页。 固态硬盘有较高的IOPS，是否还需要这个特性。 因此提供参数innodb_flush_neighbos来控制是否启用该特性,对于固态硬盘具有较高的IOPS建议关闭。 索引与算法若索引太多，程序的性能可能受到影响；索引太少，对查询性能又会产生影响。 如果知道数据的使用，则一开始就应该在需要处添加索引 InnoDB存储引擎索引概述 B+树索引（传统意义上的索引）。 不能找到一个给定键值的具体行，能找到的只是被查找数据行所在的页。然后数据库将页读入到内存，在内存中进行查找，最后得到所要查找的数据。 高度一般在2-4层，即查找某一键值的行记录最多需要2-4次IO，当前一般机械硬盘100IO/s，即需要0.02-0.04s 全文索引。 哈希索引（自适应的，不能人为干预）。 索引特点： 可以加快数据库的检索速度。 降低数据库插入、修改、删除等维护的速度。 只能创建在表上，不能创建到视图上。 既可以直接创建又可以间接创建。 可以优化隐藏中使用索引。 使用查询处理器执行SQL语句，在一个在表上，一次只能使用一个索引。 优点： 创建唯一性索引，保证数据库表中每一行数据的唯一性。 大大加快数据的检索速度，这是创建索引的最主要原因。 加速数据库表间连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询中使用优化隐藏器，提高系统的性能。 缺点： 创建索引和维护索引需要时间，随着数据量的增加而增加。 索引需要占用物理空间，除了数据表占用数据空间外，每一个索引需要占用一定的物理空间，如果建立聚簇索引，需要的空间更大。 当队表中数据进行增加、删除和修改时，索引也需要维护，降低数据维护的速度。 分类： 直接创建索引和间接创建索引。 普通索引与唯一性索引。 单个索引和复合索引。 聚簇索引和非聚簇索引。 索引失效： 如果条件中有Or，即使其中有条件带索引也不会使用。 对于多列索引，不是使用的第一部分，则不会使用索引。 like查询时以%开头。 如果列类型是字符串，那一定要在条件中使用引号引起来，否则不会使用索引。 如果MySQL估计全表扫描比索引块，则不使用索引。 什么情况下适合建立索引： 在经常出现关键字order by、group by、distinct后面的字段，建立索引。 在union等集合操作的结果集字段上，建立索引。 为经常用作查询选择的字段，建立索引。 在经常用作表连接的属性上，建立索引。 考虑使用索引覆盖，对数据很少被更新的表，如果用户经常只查询其中的几个字段，可以考虑在这几个字段上建立索引，从而将表的扫描改变为索引的扫描。 密集索引与稀疏索引密集索引：文件中每个索引码值都对应一个索引值。叶子节点保存的不仅仅是键值，而且保存位于同一行的其他列信息。 稀疏索引：文件只为索引码的某些值建立索引项。仅保存键信息以及地址。 索引调优索引调优如何定位并优化慢查询SQL 最左匹配原则索引建立索引不是建立越多越好。 数据量小的表不需要建立索引，建立会增加额外的开销。 数据变更需要维护索引，意味更多的维护成本与更大的空间 B+树索引B+树索引可以分为聚集索引和辅助索引。 聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息。 聚集索引InnoDB存储引擎表是索引组织表，即表中数据按照主键顺序存放。而聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页，每个数据页都通过一个双向链表来进行连接。 数据页上存放的是完整的每行的记录，在非数据页的索引页中，存放的仅仅是键值以及指向数据页的偏移量，不是一个完整的行记录。 对于主键的排序查找和范围查找非常快 叶子节点的数据就是用户查询的数据，若需要表最后的10位用户，由于是索引是双向链表，则用户可以快速地找到最后一个数据页。 对于范围查询，通过叶子节点的上层中间节点就可以得到页的范围，然后直接读取数据页即可。 对于排序，由于聚集索引默认有序，则不需要进行filesort 辅助索引叶子节点不包含行记录的全部数据，除了包含键值外，还包含一个书签（告诉InnoDB可以在哪里找到与索引对应的行数据）。 若辅助索引与聚集索引的高度均为3，则一共需要6次IO以得到最终的数据页。 B+树索引的分裂与一般B+树的分裂不同，需要涉及到并发 当自增的主键插入时，如 1，2，3，4，5（中间值），6，7，8，9 此时插入10需要分裂，则： 1，2，3，4 5（大于等于键值的在右），6，7，8，9，10 因为自增，则P1这个页不会再插入，从而导致浪费 InnoDB存储引擎的Page Header有以下几个部分用来保存插入的顺序信息 Page_Last_Insert Page_Direction Page_N_Direction 通过这些决定向左还是向右进行分裂，同时决定将分裂点记录为哪一个 若插入是随机的，则取中间记录分裂 若往同一方向进行插入的记录数量为5，并且目前已经定位到的记录之后还有3条记录。 则分裂点的记录为定位到的记录后的第三条记录 否则分裂点记录就是待插入的记录（自增插入中普遍存在） 定位：在插入时，首先需要定位，定位到的记录为待插入记录的前一条记录 B+树索引的管理Fast Index Creation MySQL5.5前，对于索引的DDL操作操作为： 首先创建一张新的临时表，表结构为通过Alter table定义的新结构。 将原表中的数据导入临时表，并删除原表，将临时表重命名为原来的表名。 因此DDL操作需要很久的时间，则使用了FIC的索引创建方式 对于辅助索引的创建，会为创建索引的表加上应该S锁。 对于辅助索引的删除，只需要更新内部视图，并将辅助索引空间标记为可用，同时删除索引定义即可。 但是对于主键，依然需要重建一张表。 Cardinality值什么是Cardinality低选择性：对于性别字段、类型字段、地区字段，他们可选择的范围很小。 高选择性：某个字段的取值范围很广，几乎没有重复。这时使用B+树索引才是最合适的。 通过Show Index结果中的列Cardinality来观察索引是否高选择性。 Cardinality：表示索引中不重复记录数量的预估值，Cardinality/n_rows_in_table应尽可能接近1，如果非常小，则需要考虑是否还必要创建这个索引。 InnobDB存储引擎的Cardinality统计数据库对于Cardinality的统计是通过采样的方法完成。 Cardinality统计信息的更新发生在两个操作中：insert与update。更新Cardinality信息的策略为： 表中1/16的数据已经发生变化 stat_modified_counter（某一行数据频繁地变化，每变化一次+1）&gt;2000000000 采样的过程，默认对8个叶子结点采用： 取得B+树索引中叶子结点的数量，记为A 随机取得B+树索引中的8个叶子结点。统计每个页不同记录的个数，记为P1，P2，P8 根据采样信息给出Cardinality的预估值，即SUM（P）*A/8 B+树索引的使用不同应用中B+树索引的使用数据库存在两种类型的应用：OLTP、OLAP。 在OLTP当中，查询操作只是从数据库中取得一小部分数据，例如根据订单号获得订单的详情。这种情况下，B+树索引建立后，对该索引的使用也只是通过该索引取得表中少部分的数据，此时建立B+树索引才是有意义的。否则即使建立了，优化器也可能选择不使用索引。 对于OLAP应用，情况比较复杂。但是大部分都需要访问表中大量的数据，根据这些数据产生查询的结果，其多是面向分析的查询，例如月每个用户的消费情况。因此OLAP中索引的添加根据的是宏观的信息，而不是用户ID，但是如果存在复杂查询、多表联结，则索引依然有意义。 联合索引联合索引是指对表上的多个列进行索引，例如key idx_a_b(a,b)。联合索引也是一颗B+树，不过其键值的数量&gt;=2. 当执行select * from table where a = xx and b = xx则会利用到联合索引。如果只是单独查询一个字段，如果该字段存在单个键值的索引，则不会使用到，因为单个键值则理论上一个页能存放的记录更多。 同时如果使用select * from table where a = xx order by b也会用到联合索引。 使用联合索引后，键值是有序的，通过叶子结点但可用逻辑上顺序读出所有数据。其排序会首先根据第一个字段，然后根据第二个字段。 使用联合索引避免了第二次的排序。因为索引本身在叶子结点已经排序了。 对于联合索引(a,b,c)而言，下面语句同样可用通过联合索引得到结果，因为对于优化器而言，联合索引已经排好序了，因此会用到： select * from table where a = xxx order by b select * from table where a = xxx and b=xxx order by c 但是对于下面的语句，依然需要filesort排序，因为索引(a,c)未排序： select * from table where a = xxx order by c 覆盖索引覆盖索引即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。由于辅助索引不包含整行记录的所有信息，其大小远小于聚集索引。 辅助索引中的信息包含主键信息，因此下面的语句可用使用一次辅助联合索引来完成查询： select key2 from table where key1 = xxx 对于统计问题，例如select count(*) from buy_log也会使用辅助索引，因为辅助索引远小于聚集索引，可用减少IO操作。 优化器选择不使用索引的情况 当查询需要整行信息时，索引不能覆盖到我们需要的信息，因此还需要一次书签访问，虽然索引查询到数据有序，但是书签访问是无序的，带来很多的IO操作。 如果访问数据量很小，小于表20%时，会使用辅助索引。 如果很大，则会优先通过聚集索引。如果对于硬盘很自信的话，可用强制使用force index来使用辅助索引 索引提示Index hint显式地告诉优化器使用索引，其应用场景有： MySQL数据库的优化器错误地选择了某个索引，导致SQL语句运行的很慢。 某SQL语句可用选择的索引非常的多，这时优化器选择执行计划时间的开销可能会大于SQL语句本身。优化器分析Range查询本身就是耗时的操作。 Multi-Range-Read优化MySQL5.6的MRR优化，其目的是为了减少磁盘的随机访问，并将随机访问转化未较为顺序的数据访问，对于IO-bound类型的SQL查询语句可用带来性能极大的提升。MRR适用于range、ref、eq_ref类型的查询。 优势： MRR使数据访问变得较为顺序，在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签查找。 减少缓冲池内页被替换的次数 批量处理对键值的查询操作。 对于范围查询和Join查询： 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的。 将缓存中的键值根据RowId排序。 根据RowId的排序顺序来访问实际的数据文件。 ICP优化MySQL5.6支持的根据索引进行查询的优化方式，支持range、ref、eq_ref、ref_or_null类型的查询。 之前的索引查询是首先根据索引来查找记录，然后再根据where来过滤记录。ICP之后，MySQL会在取出索引的同时判断是否可以进行where条件的过滤。 哈希算法InnoDB哈希算法冲突机制采用链表方式。对于缓冲池页的哈希表，都有一个chain指针指向相同哈希函数值的页。 哈希函数采用除法散列方式。m的取值为略大于2倍的缓冲池页数量的质数。 自适应哈希索引只能用来搜索等值查找。 全文检索概述全文检索是将存储于数据库中的整本书或整篇文章中的任意内容信息查找处理的技术。可以根据需要获得全文中有关章、节、句、词等信息，也可以进行各种统计和分析。 InnoDB 1.2.x开始，支持全文检索，支持MyISAM的全部功能，以及一些其他特性。 倒排索引全文检索通常使用倒排索引实现。在辅助表中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。通常使用关联数组实现，有两种表现形式： inverted file index，表现为｛单词，单词所在文档的ID｝ full inverted index，表现为｛单词，（单词所在文档的ID，在文档的具体位置）｝ InnoDB全文检索使用full inverted index，将（单词所在文档的ID，在文档的具体位置）视为一个ilist。拥有两个列：word、ilist，并且在word上设有索引。 倒排索引需要将word存放在一张辅助表当中，在InnoDB存储引擎中，为了提高全文检索的并行性能，共有6张辅助表Auxiliary Table，每张表根据word的Latin编码进行分区。辅助表是持久的表，存放于磁盘上。 为了提高全文索引性能，使用了FTS Index Cache（全文检索索引缓存）。是一个红黑树结构，根据（word,ilist）排序，由于是缓存，其刷新类似于Insert Buffer。 全文检索参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：单例模式]]></title>
    <url>%2F2019%2F03%2F31%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式提出问题 有些对象其实我们只需要一个。如果制造出多个，就会导致许多问题的产生。 如线程池、缓存、对话框、处理偏好设置和注册表的对象、日志对象，充当打印机、显卡设备的驱动程序的对象 使用全局变量存在缺陷 如果使用全局变量，则必须在程序一开始就创建好对象。如果对象非常消耗资源，而程序在这次执行中又没有使用到它，则形成浪费 概述是什么 单例模式：确保一个类只有一个实例，并提供一个全局访问点 分类应用适用性 当类只能有一个实例，而且客户可以从一个众所周知的访问点访问它 当这个唯一实例应该是通过子类化可扩展的，并且客户应该无需更改代码就能使用一个扩展的实例 案例协作结构 参与者协作 类关系 逻辑关系 效果 对唯一实例的受控访问。因为Singleton类封装它的唯一实例，所以可以严格控制客户怎样以及何时访问它 缩小名空间。Singleton是对全局变量的一种改进，避免了那些存储唯一实例的全局变量污染名空间 允许对操作和表示的精化。Singleton可以有子类，而且用这个扩展类的 允许可变数目的实例 比类操作更为灵活 权衡基础优缺 为什么全局变量比单例差 急切实例化VS延迟实例化 全局变量可以提供全局访问，但是不能保证只有一个实例。而且全局变量指向很多小对象会造成命名空间的污染。 为什么不创建一个类，把所有的方法和变量定义为静态，将类当做一个单例 如果类自给自足，而且不依赖于复杂的初始化，那么OK的 但静态初始化的控制权是在Java手上，并且当很多类牵扯其中时，就可能有一些与初始化次序有关的bug 实现懒汉式线程不安全法1234567891011121314151617181920212223242526/** * 懒汉模式 * 单例实例在第一次使用时候进行创建 */@NotRecommendpublic class SingletonExample1 &#123; //私有的构造函数 //即其他途径无法创建这个类的对象 private SingletonExample1()&#123; //包含对资源的处理等等 &#125; //单例对象 private static SingletonExample1 instance = null; //静态的工厂方法 //public public static SingletonExample1 getInstance()&#123; //多线程环境很容易出现问题 if (instance == null)&#123; instance = new SingletonExample1(); &#125; return instance; &#125;&#125; 双重检测机制(线程不安全) 12345678910111213141516171819202122232425262728293031323334353637/** * 懒汉模式 --&gt; 双重同步锁单例模式 * 单例实例在第一次使用时候进行创建 */@NotRecommendpublic class SingletonExample4 &#123; //私有的构造函数 private SingletonExample4()&#123;&#125; // 1.memory = allocate() 分配对象的内存空间 // 2.ctorInstance() 初始化对象 // 3. instance = memory 设置instance 指向刚分配的内存 //JVM和CPU优化，发生了指令重排 // 1.memory = allocate() 分配对象的内存空间 // 3. instance = memory 设置instance 指向刚分配的内存 // 2.ctorInstance() 初始化对象 //在第三步的时候,instance!=null //而此时在指令重排下,另一个线程就会获得一个没有初始化对象的引用,并将其返回 //单例对象 private static SingletonExample4 instance = null; //静态的工厂方法 private static SingletonExample4 getInstance()&#123; if (instance == null)&#123; //双重检测机制 //B synchronized (SingletonExample4.class)&#123; //同步锁 if (instance == null)&#123; instance = new SingletonExample4(); //A - 3 &#125; &#125; &#125; return instance; &#125; 线程安全法不推荐法 1234567891011121314151617public class SingletonExample3 &#123; //私有的构造函数 private SingletonExample3()&#123;&#125; //单例对象 private static SingletonExample3 instance = null; //静态的工厂方法 //synchronized限制,而存在性能开销 private static synchronized SingletonExample3 getInstance()&#123; if (instance == null)&#123; instance = new SingletonExample3(); &#125; return instance; &#125;&#125; 双重同步锁 基于volatile 1234567891011121314151617181920212223242526272829/** * 懒汉模式 --&gt; 双重同步锁单例模式 * 单例实例在第一次使用时候进行创建 */@ThreadSafepublic class SingletonExample5 &#123; //私有的构造函数 private SingletonExample5()&#123;&#125; // 1.memory = allocate() 分配对象的内存空间 // 2.ctorInstance() 初始化对象 // 3. instance = memory 设置instance 指向刚分配的内存 //单例对象 volatitle+ 双重检测机制 -&gt; 禁止指令重排序 private volatile static SingletonExample5 instance = null; //静态的工厂方法 private static SingletonExample5 getInstance()&#123; if (instance == null)&#123; //双重检测机制 //B synchronized (SingletonExample5.class)&#123; //同步锁 if (instance == null)&#123; instance = new SingletonExample5(); //A - 3 &#125; &#125; &#125; return instance; &#125;&#125; 饿汉模式通过静态域实现 123456789101112131415161718192021/** * 饿汉模式 * 单例实例在装载使用时候进行创建 */@ThreadSafepublic class SingletonExample2 &#123; //私有的构造函数 private SingletonExample2()&#123; //如果构造方法中存在过多的功能,则在加载时会过慢,存在性能问题 //只进行资源加载而没有实际调用,则会导致资源浪费 &#125; //单例对象 private static SingletonExample2 instance = new SingletonExample2(); //静态的工厂方法 private static SingletonExample2 getInstance()&#123; return instance; &#125;&#125; 通过静态块实现 123456789101112131415161718192021222324@ThreadSafepublic class SingletonExample6 &#123; //私有的构造函数 private SingletonExample6()&#123;&#125; //静态资源是顺序执行的 //单例对象 private static SingletonExample6 instance = null; //必须写在后面,如果写在前面,则会被上一句赋值为null static &#123; instance = new SingletonExample6(); &#125; //静态的工厂方法 private static SingletonExample6 getInstance()&#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance().hashCode()); System.out.println(getInstance().hashCode()); &#125;&#125; 枚举模式12345678910111213141516171819202122232425262728/** * 枚举模式：最安全 */@ThreadSafe@Recommendpublic class SingletonExample7 &#123; //私有的构造函数 private SingletonExample7()&#123;&#125; public static SingletonExample7 getInstance()&#123; //在实际使用的时候才会初始化 return Singleton.INSTANCE.getSingleton(); &#125; private enum Singleton&#123; INSTANCE; private SingletonExample7 singleton; //JVM保证这个方法绝对只调用一次 Singleton()&#123; singleton = new SingletonExample7(); &#125; public SingletonExample7 getSingleton()&#123; return singleton; &#125; &#125;&#125; 底层原理与其他的区别设计思想进阶 为什么不直接使用synchronized同步getInstance()，简单有效 因为同步一个方法可能导致程序的执行效率下降100倍，如果这个getInstance()在一个频繁运行的地方，那性能将很差了。 两个类加载器有机会各自创建自己的单例 自行指定类加载器，指定同一个类加载器 总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构：解析微服务架构]]></title>
    <url>%2F2019%2F03%2F31%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[什么是微服务简而言之，微服务架构风格这种开发方法，是以开发一组小型服务的方式来开发一个独立的应用系统的。其中每个小型服务都运行在自己的进程中，并经常采用HTTP资源API这样轻量的机制来相互通信。这些服务围绕业务功能进行构建，并能通过全自动的部署机制来进行独立部署。这些微服务可以使用不同的语言来编写，并且可以使用不同的数据存储技术。对这些微服务我们仅做最低限度的集中管理。 微服务是一种将业务系统进一步拆分的架构风格。 强调每个单一业务都独立运行。 每个单一服务都应该更轻量的机制保持通信。 服务不强调环境，可以用不同语言或数据源。 为什么需要微服务架构“微服务”架构是近期软件应用领域非常热门的概念。让我们先来看看传统IT架构面临的一些问题： 使用传统的整体式架构(Monolithic Architecture)应用开发系统，如CRM、ERP等大型应用，随着新需求的不断增加，企业更新和修复大型整体式应用变得越来越困难； 随着移动互联网的发展，企业被迫将其应用迁移至现代化UI界面架构以便能兼容移动设备，这要求企业能实现应用功能的快速上线； 许多企业在SOA投资中得到的回报有限，SOA可以通过标准化服务接口实现能力的重用，但对于快速变化的需求，受到整体式应用的限制，有时候显得力不从心； 随着应用云化的日益普及，生于云端的应用具有与传统IT不同的技术基因和开发运维模式。 此外，从技术方面看，云计算及互联网公司大量开源轻量级技术不停涌现并日渐成熟： 互联网/内联网/网络更加成熟； 轻量级运行时技术的出现(node.js, WAS Liberty等)； 新的方法与工具(Agile, DevOps, TDD, CI, XP, Puppet, Chef…)； 新的轻量级协议(RESTful API接口, 轻量级消息机制)； 简化的基础设施：操作系统虚拟化(hypervisors), 容器化(e.g. Docker), 基础设施即服务 (IaaS), 工作负载虚拟化(Kubernetes,Spark…)等； 服务平台化(PaaS)： 云服务平台上具有自动缩放、工作负载管理、SLA 管理、消息机制、缓存、构建管理等各种按需使用的服务； 新的可替代数据持久化模型：如NoSQL, MapReduce, BASE, CQRS等； 标准化代码管理：如Github等。 这一切都催生了新的架构设计风格 – 微服务架构的出现。 什么是微服务什么是微服务 微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 微服务的概念源于2014年3月Martin Fowler所写的一篇文章Microservices。 尽管“微服务”这种架构风格没有精确的定义，但其具有一些共同的特性，如围绕业务能力组织服务、自动化部署、智能端点、对语言及数据的“去集中化”控制等等。 微服务架构的思考是从与整体应用对比而产生的。 其中，对应用组件封装的方式是整体架构与微服务架构的主要差异，微服务架构将相关联的业务逻辑及数据放在一起形成独立的边界，其目的是能在不影响其他应用组件(微服务)的情况下更快地交付并推出市场。 微服务架构的一些通用特性根据MartinFowler的分析，微服务架构有以下的一些通用特性，但并非所有微服务架构应用都必须具备所有这些特性： 每个微服务可以独立运行在自己的进程里。通过服务实现应用的组件化(Componentizationvia Services)：微服务架构中将组件定义为可被独立替换和升级的软件单元，在应用架构设计中通过将整体应用切分成可独立部署及升级的微服务方式进行组件化设计。 一系列独立运行的微服务共同构建起整个系统 围绕业务能力组织服务(Organizedaround Business Capabilities)，每个服务为独立的业务开发，一个服务只关注一个功能。如订单管理、用户管理 ：微服务架构采取以业务能力为出发点组织服务的策略，因此微服务团队的组织结构必须是跨功能的（如：既管应用，也管数据库）、强搭配的DevOps开发运维一体化团队，通常这些团队不会太大（如：亚马逊的“Two pizzateam”- 不超过12人）。 微服务间通过一些轻量级的通信机制进行通信，如通过rest api 可以使用不同的语言和数据存储技术 全自动的部署机制 产品而非项目模式(Productsnot Projects)：传统的应用模式是一个团队以项目模式开发完整的应用，开发完成后就交付给运维团队负责维护；微服务架构则倡导一个团队应该如开发产品般负责一个“微服务”完整的生命周期，倡导“谁开发，谁运营”的开发运维一体化方法。 智能端点与管道扁平化(Smartendpoints and dumb pipes)：微服务架构主张将组件间通讯的相关业务逻辑/智能放在组件端点侧而非放在通讯组件中，通讯机制或组件应该尽量简单及松耦合。RESTful HTTP协议和仅提供消息路由功能的轻量级异步机制是微服务架构中最常用的通讯机制。 “去中心化”治理(DecentralizedGovernance)：整体式应用往往倾向于采用单一技术平台，微服务架构则鼓励使用合适的工具完成各自的任务，每个微服务可以考虑选用最佳工具完成(如不同的编程语言)。微服务的技术标准倾向于寻找其他开发者已成功验证解决类似问题的技术。 “去中心化”数据管理(DecentralizedData Management)：微服务架构倡导采用多样性持久化(PolyglotPersistence)的方法，让每个微服务管理其自有数据库，并允许不同微服务采用不同的数据持久化技术。 基础设施自动化(InfrastructureAutomation)：云化及自动化部署等技术极大地降低了微服务构建、部署和运维的难度，通过应用持续集成和持续交付等方法有助于达到加速推出市场的目的。 故障处理设计(Designfor failure)：微服务架构所带来的一个后果是必须考虑每个服务的失败容错机制。因此，微服务非常重视建立架构及业务相关指标的实时监控和日志机制。 演进式的设计(EvolutionaryDesign)：微服务应用更注重快速更新，因此系统的计会随时间不断变化及演进。微服务的设计受业务功能的生命周期等因素影响。如某应用是整体式应用，但逐渐朝微应用架构方向演进，整体式应用仍是核心，但新功能将使用应用所提供的API构建。再如在某微服务应用中，可替代性模块化设计的基本原则，在实施后发现某两个微服务经常必须同时更新，则这很可能意味着应将其合并为一个微服务。 微服务的一些常见误解 关于一些比较概念的澄清： 在同一范畴内比较才有意义： 微服务架构 vs. SOA – 两者都是架构风格范畴，但其关注领域与涉及范围不同。SOA更关注企业规模范围，微服务架构则更关注应用规模范围。 微服务组件 vs. 服务组件 – 两者都是描述业务功能的具体实现，其区别在于粒度不同，此外还有在可管理性、灵活性上的差异。 概念混淆的不恰当比较 微服务 vs. SOA – 不恰当的比较。微服务是组件范畴，而SOA是一种架构设计风格。因此应该比较的是微服务架构与SOA。 微服务 vs. API – 不恰当的比较。 API是接口，是业务功能暴露的一种机制。微服务架构是用于实施业务功能的组件架构。因此直接比较它们是没有意义的。 微服务 vs. 服务– 不恰当的比较。“服务”在不同的场景下有不同的含义，需要进一步澄清其描述的语境，是指服务实施、服务暴露、服务定义还是其他？微服务亦是如此，需要有特定语境才可判断比较是否有意义。 微服务架构与SOA架构的比较 一个简单的微服务应用例子：航班预订应用 将航班预订应用划分为预订航班、时间表查询、计算票价、分配座位、管理奖励、更新客户、调整库存七个微服务实施。 概述基本概念 Provider：服务提供者。 Consumer：服务调用者。 同一个服务可以既是Provider又是Consumer。 哪些应用会从微服务收益 ？ 记录型系统(System of Record)将从微服务方法中获益最多。例如可将大型应用按相对独立的业务功能分解成若干个微服务实现。 交互型系统(System of Engagement)也将受益于微服务方法，例如渠道应用可以应用“后端服务前端”的模式实现。 分析型系统(System of Insight)则可能对微服务受益不多。其他架构模式如管道及过滤模式可能更适用于分析型系统。 基础优缺优点 每个服务都比较简单，只关注于一个业务功能。易于开发与维护 微服务架构方式是松耦合的，可以提供更高的灵活性。 技术栈不受限制。微服务可通过最佳及最合适的不同的编程语言与工具进行开发，能够做到有的放矢地解决针对性问题。 每个微服务可由不同团队独立开发，互不影响，加快推出市场的速度。 微服务架构是持续交付(CD)的巨大推动力，允许在频繁发布不同服务的同时保持系统其他部分的可用性和稳定性。 单个微服务启动较快 局部修改容易部署。只需要重新部署这个服务。 可以针对不同类型的业务，如IO密集型，CPU密集型进行定向的增强 缺点： 微服务的一些想法在实践上是好的，但当整体实现时也会呈现出其复杂性。 运维开销及成本增加：整体应用可能只需部署至一小片应用服务区集群，而微服务架构可能变成需要构建/测试/部署/运行数十个独立的服务，并可能需要支持多种语言和环境。这导致一个整体式系统如果由20个微服务组成，可能需要40~60个进程。 必须有坚实的DevOps开发运维一体化技能：开发人员需要熟知运维与投产环境，开发人员也需要掌握必要的数据存储技术如NoSQL，具有较强DevOps技能的人员比较稀缺，会带来招聘人才方面的挑战。 隐式接口及接口匹配问题：把系统分为多个协作组件后会产生新的接口，这意味着简单的交叉变化可能需要改变许多组件，并需协调一起发布。在实际环境中，一个新品发布可能被迫同时发布大量服务，由于集成点的大量增加，微服务架构会有更高的发布风险。 代码重复：某些底层功能需要被多个服务所用，为了避免将“同步耦合引入到系统中”，有时需要向不同服务添加一些代码，这就会导致代码重复。 分布式系统的复杂性：作为一种分布式系统，微服务引入了复杂性和其他若干问题，例如网络延迟、容错性、消息序列化、不可靠的网络、异步机制、版本化、差异化的工作负载等，开发人员需要考虑以上的分布式系统问题。 异步机制：微服务往往使用异步编程、消息与并行机制，如果应用存在跨微服务的事务性处理，其实现机制会变得复杂化。 可测性的挑战：在动态环境下服务间的交互会产生非常微妙的行为，难以可视化及全面测试。经典微服务往往不太重视测试，更多的是通过监控发现生产环境的异常，进而快速回滚或采取其他必要的行动。但对于特别在意风险规避监管或投产环境错误会产生显著影响的场景下需要特别注意。 设计原则 服务自治原则 每个微服务必须具备独立的业务能力、依赖于运行环境 单一职责原则 轻量级通信原则 接口明确原则 每个服务的对外接口都应该明确，并尽量保持不变 微服务功能 服务的注册与发现。 服务的调用。 服务的负载均衡。 服务的容错。 服务网关。 服务配置的统一管理。 链路追踪。 实时日志。 关于微服务架构的取舍 在合适的项目，合适的团队，采用微服务架构收益会大于成本。 微服务架构有很多吸引人的地方，但在拥抱微服务之前，也需要认清它所带来的挑战。 需要避免为了“微服务”而“微服务”。 微服务架构引入策略 – 对传统企业而言，开始时可以考虑引入部分合适的微服务架构原则对已有系统进行改造或新建微服务应用，逐步探索及积累微服务架构经验，而非全盘实施微服务架构。 微服务架构简单的微服务架构 基础框架/组件 服务注册发现 后台内部的服务信息交流 服务网关。是连接内外的大门 将服务暴露给前端。涉及到服务的前端路由 对外屏蔽内部的细节 可以将web的请求反向路由到内部某个微服务中 限流与容错，监控与日志。所有的请求都要经过网关 可以对web请求进行控制。是判断微服务做的好不好的关键 后端通用服务（中间层服务） 启动时将信息注册到注册表 前端服务（边缘服务） 查询注册表，发现调用后端服务。主要做对后端服务必要的聚合和裁剪，后暴露给外部不同的设备 聚合：对多个API调用逻辑进行聚合，从而减少客户端的请求数。如客户端要请求两个接口，请求客户的个人信息、请求收货地址。前端服务将这两个接口聚合起来，只需要调用一个接口即可 裁剪：根据不同的需求返回不同的数据。如果PC端获取数据，尽量详细一些，手机端的话，就信息少 一些。 实现手段 阿里系 Dubbo Zookeeper Spring MVC与Spring Boot Spring Cloud 服务注册与发现创建调用关系的微服务创建存在调用关系的微服务，调用关系如下 服务消费者：调用别的微服务 服务提供者：提供API的微服务 使用Eureka实现服务注册与发现 服务发现组件：包含服务注册表（核心组件） 服务注册表：存放服务的IP和端口。 心跳机制：每间隔一段时间向服务发现组件renew，保证服务没有死掉。如果服务没有发送renew，则在服务发现组件中将其踢掉。 客户端负载均衡ribbon客户端的负载均衡器。 与服务器端的负载均衡的区别 客户端的负载均衡，去知道服务提供者有几个实例，提供负载均衡的方案 服务器端的负载均衡，在服务注册侧做负载均衡 ribbon原理： 在eureka查询当前可用的提供者结点。获得提供者的IP、端口等的列表。 进行负载均衡算法，命中某个结点 声明式的HTTP Client Feign微服务容错雪崩效应C-&gt;D-&gt;A，当A宕机，则C调用B的服务，B调用A的服务的线程会堵塞，导致C调用B的服务的线程也会阻塞。最后整个系统宕机 实现容错的方案 为请求设置超时 一般一个远程调用一般在几十毫秒就可以得到响应了，如果依赖的服务不可用，则时间就会很长。 而一个请求对应一个线程，如果响应太慢，则线程无法释放，因此为每个请求设置超时，使得资源尽快释放 使用断路器 当依赖的服务有大量超时，再让新的请求进行访问就没有太大的意义。如果超时间内有大量的请求在时间内都得不到响应，则往往意味着异常。就没有必要让更多的请求访问这个依赖 此时使用断路器避免资源浪费。断路器实现快速失败，如果在一段时间内侦测到许多类似错误，就会强迫之后的多个调用快速失败，不再请求所依赖的服务。 断路器状态图： 半开状态：当断路器打开一段时间，断路器猜测，失败的服务是否已经修好，则让一小部分流量通过，如果结果达到预期值，即服务已经被修复，则关闭断路器，否则继续打开断路器。 API网关统一配置中心微服务Dubbo仅仅是一个微服务框架。 Spring Cloud是一个微服务的集合，包含各种微服务治理的方案，例如API网关、服务降级和回退、负载均衡。 微服务选择Dubbo Dubbo基于RPC通信协议，速度更快，底层可以使用二进制传输。 Dubbo的多中心配置更灵活，可以使用Zookeeper和Redis。 Dubbo可以按需集成其他组件，完成微服务生态环境构建。 Dubbo底层是TCP协议，数据包最大100KB。 SpringCloud HTTP协议，因此速度慢于Dubbo。 融入微服务的企业集成架构将介绍融入微服务的企业集成架构的演进，并描述交互式系统的微服务模式及相关技术决策，然后给出了一个具体的微服务架构业务应用的例子。 交互型系统与记录型系统随着移动互联网的快速发展，企业除了需要提供传统核心IT系统能力之外，还需提供客户与合作伙伴友好型的以交互为重点的创新及交互式系统。这两类系统的特性与禀赋完全不同，因此企业IT的支撑迈入了双速IT时代。 企业微服务架构的引入主要集中在以下两类系统： 记录型系统：是指传统的应用系统，对应用所关注领域的信息进行增删改查作为应用的核心能力。如CRM、ERP、OA等系统。记录型系统使用的往往是一些传统的经典IT技术构建，往往更难改变，其集成难度也较高。 交互型系统：是指以与用户交互为主要目的而开发的应用系统。如各种移动应用、微信、微博等等。交互型系统更多地会采用现代的各种新技术语言及运行时部署，具体高度的敏捷性，通过简单的现代化连接即可实现集成。 融入微服务的企业集成架构不同的企业背景应该采用不同的微服务架构引入策略： 对大型的成熟企业而言，由于本身已有大量在建的企业IT系统，因此决定了微服务架构仅是其多种应用架构风格之一，大型企业在服务总线与能力开放网关的集成架构下，可以首先从交互型系统入手引入基于微服务架构的应用，逐步积累面向微服务的开发运维经验。另外，对于部分新建的记录型系统，也可以考虑采用微服务架构进行构建，并通过服务总线等SOA集成技术实现与企业遗留系统的信息交互。 对于初创企业而言，由于其没有任何历史包袱，因此可以考虑将企业范围的整体架构以(微)服务架构为基础进行搭建。 大型成熟企业在企业集成架构及不同应用(整体式应用与微服务应用)架构风格中使用的技术及中间件也各有不同。例如：在整体式应用中往往更强调应用的交易完整性、安全性、数据的一致性等高标准特性，而微服务应用则更强调系统功能的快速上线。因此，这导致了这两类系统所偏好的技术及中间件产品会有差异。下图是在一个企业集成架构中，不同应用及集成所对应的IBM软件产品的示例： 整体式应用使用WAS ND集群化企业级应用服务器和DB2数据库。 微服务应用使用轻量级的WAS Liberty、Node.js，以及NoSQL数据库。 甚至可以考虑将其部署至公有云PaaS平台(如IBM Bluemix)上以充分利用PaaS平台上众多的服务能力。 集成组件使用企业级的IBM Integration Bus服务总线以及API Connect能力开放网关解决方案。 在系统云化方面，整体式应用与微服务应用也具有不同的偏好。因此，未来的企业必然朝着混合型部署架构演进： 企业级整体式应用部署偏好于系统专用资源模式，也可根据各个应用特性评估是否可迁移至企业**私有云**之上以实现企业IT资源优化部署。 微服务应用则偏好于生于云端的PaaS平台，使其可方便地使用各种就绪的底层服务，并采用多样化的编程语言和持久化技术。 交互式系统的微服务模式交互式系统微服务模式包括多渠道交互层与业务逻辑层： 多渠道交互层通常采用“后端服务前端”的设计模式。 业务逻辑层则采用微服务架构，通过垂直服务而非水平分层实现对不同业务功能的解耦。 各业务服务微服务的依赖关系是微服务架构设计的一个考虑重点，一个业务服务可以委托给其他业务服务，但需尽量避免循环依赖。需要注意的是每个微服务仍然实现了一个完整的任务，而不是传统的水平分层模式。 交互式系统微服务架构应用的技术决策 1、编程语言的考虑： Java：鉴于Java有广大的受众以及其商业软件的企业级保障能力，以及在市场上能够非常容易找到优秀的开发人员，并且Java已开始加速增加最新和最现代的语言特性如Lambda等，Java仍然是实现**业务逻辑层**的不二之选。其他语言技术虽然层出不穷，各有优点，但并没出现新的统治级编程语言。 Node.js：在交互层，Node.js是JavaScript服务端的解决方案，结合其他技术组成的MEAN全堆栈javascript开发框架（Mongo DB – 简单的NoSQL数据库，使用JSON风格存储文档；ExpressJS – 是一个Web应用框架，提供有帮助的组件和模块帮助建立一个网站应用； AngularJS – 是一个前端MVC框架；Node.js -是一个并发异步事件驱动的Javascript服务器后端开发平台。），使Node.js正成为REST服务实施和构建交互式系统方面实上的解决方案。 2、多样性持久化考虑：使用合适的NoSQL技术存储持久化数据。 交互式系统基于PaaS云端部署方式：随着PaaS云技术的日益成熟，企业可以考虑将交互式系统部署于云端，以充分利用PaaS平台上的各种服务。可将应用的Web/移动层迁移到云端，交互模型存储到云端，将记录型系统能力以API形式开放出来实现与交互式系统的连接。 交互式系统微服务架构例子 航班预订应用微服务架构设计 航班预订应用采用多样化技术满足不同的业务技术特性。 以上内容介绍了融入微服务的企业集成架构的演进，并描述交互式系统微服务模式及相关技术决策，然后给出了一个具体微服务架构业务应用的例子。 微服务重构应用及IBM解决方案将介绍已有IT应用如何进行微服务重构的转型，以及IBM微服务相关解决方案的介绍。 微服务转型采用微服务架构意味着以更复杂的运维环境为代价，实现更高速的应用交付及更快推出市场。因此企业需要在更快的交付与更复杂的运维之间进行权衡。 大部分企业都有大量遗留的应用系统，因此对需要更快更好地满足业务需求成为迫切任务时，大部分情况下企业不会全新构建一个完整的应用，通常情况下是企业对已有应用进行重构或希望能尽量重用已有代码。 向微服务架构演进通常包括以下几个阶段： 1.传统的SOA服务化改造； \2. 开始引入某些微服务原则，进行针对性重构，如“一个任务一个服务”； \3. 引入整套完整的微服务原则； \4. 实现微服务的规模化 – 添加服务发现、服务缩放能力等增强特性。 并非所有应用都需要完成上述的各个阶段，一个基本原则是重构解决针对性业务问题，需要避免为了“微服务”而“微服务”化。 需要注意的是并非所有应用都可以转变为微服务架构: 部分系统无法重构为微服务架构：例如非常老旧又缺乏维护的系统，对此类系统可以采用“如果应用无法被打破，就不要试图解决它”的策略，其中SOA资产重用化应该是更佳的解决方案。 原有应用无法改变数据存储方式：对这种情况，需要考虑如果数据仍然保持烟囱式或集中式存储，那对应用进行微服务化是否具有业务价值；需要考虑切分数据库是否会导致事务性保障的缺失并进而影响系统的稳定性；同时也可以考虑应用能否采用如BASE、CQRS等模式解决数据的一致性问题。 原有系统如何融入微服务架构：在原有系统中剥离部分功能并重构为微服务时，如何实现微服务与原有系统在高可用性上的隔离，如果原有系统与微服务的扩展性不匹配又如何处理？这些问题也许要在进行微服务重构前考虑清楚。 微服务重构在重构应用方面，可通过以下方法梳理微服务：(1)每个REST服务是一个潜在的微服务；(2)每个SOAP web服务或EJB是一个潜在的微服务,特别是无状态的session bean,需要将面向功能的接口重新设计为面向资产的接口，并使接口转变为RESTful形式；(3)使用领域驱动设计(domain-driven design)发现企业资产，这些资产可能是微服务。 在重构数据方面，需要考虑以下几个方面： 寻找与其他数据关联不大的数据孤岛，检查系统的实体-关系图；如果有与其他数据断开的数据，就是一个潜在的数据重构点； 数据表非规范化，对高规范化数据库中非规范化一些数据表以将数据重组为更大的逻辑块，其目的是增加数据冗余度使其更容易被打破； 反向批数据更新，对数据重构时需要考虑数据重构失败时可批量地将新数据反向导回旧的数据模式； 使用主数据管理，对被广泛使用的数据实体组成一个单一的一致性视图，并开发相应的微服务与主数据一起工作； 在SQL数据库中寻找存储在BLOB(二进制大对象)字段类型中的代码，转而将这些对象存储在NoSQL数据库中，例如以键值(Key-value)存储方式存储； 寻找活跃的记录模式，与其他无关的Flat对象，使用文档模式数据库进行存储，例如Cloudant或Mongo等。 微服务重构后还需要重新打包应用，包括： 分割应用的EAR文件并打包成独立的WAR文件； 应用“一个容器一个服务”，分别部署每个WAR文件至其自有的WebSphereLiberty实例运行时或Docker容器中； 分别构建、部署和管理**,为每个WAR文件使用独立的DevOps管线,每个WAR文件独立伸缩和管理。 微服务IBM解决方案 API Connect - 创建、运行、管理及保护API能力开放和微服务应用的企业级平台。 企业为了加速应用开发以满足不断增长的需求，需要开放内部的业务和数据能力并吸引合作伙伴及开发者基于其能力快速创新，IBM API Connect为企业提供了一个统一完整的API能力开放平台解决方案，实现API的创建、运行、管理、安全保证和微服务运行环境以满足企业参与API经济的需求。 IBM API Connect平台为数字化应用提供基础能力： 创建微服务并将为其提供对外的API接口； 管理、控制及保护REST和SOAP API； 为企业内外的应用开发者提供自服务的API门户； 将API接口发布到多个开发者门户； 分析API用量和性能指标。 WAS Liberty+WXS - 基于OSGi内核，高模块化，高动态性的轻量级WebSphere应用服务器，以及具备企业级高可用性的缓存服务，助力快速交付的微服务应用 微服务应用要求与各微服务有独立的运行环境，因此传统的应用服务器容器显得过于笨重，因此企业需要使用轻量级的应用服务器容器，但同时还需要考虑完善的技术服务支持。 IBM WAS Liberty是IBM开发的基于Java的轻量级WebSphere应用服务器，既满足了创新型应用轻量级的要求，又为企业提供了有效的商业技术支持，避免企业由于使用开源软件而有可能出现的技术支持风险。 WXS(WebSphere eXtreme Scale)则提供高性能、可扩展的高速缓存框架和网格技术，通过多样化数据存储加速微服务应用访问效率。 PureApp+ICO+UCD**组成的混合云框架为企业提供私有云自动化部署的完整解决方案** 微服务应用需要IT基础设施提供多种自动化能力以实现应用的快速上线和自动伸缩。IBM UrbanCode Deploy、IBM CloudOrchestrator和IBM PureApplication是三种可供企业客户组合搭配提供包括企业自动化部署加速应用持续交付、企业私有云自动化弹性伸缩环境和软硬一体化的私有云解决方案。 IBM Bluemix 创新应用开发平台 微服务架构提倡使用多样化的编程语言和多样化的存储，以最适合的技术解决业务需求并实现快速上线和自动伸缩。IBM Bluemix平台能够很好地满足此类需求。 Bluemix 是一个基于开放标准和云的平台，可以用于应用的快速构建、运行及管理。Bluemix 由三大关键的开放计算技术支撑：Cloud Foundry, Docker, 以及 OpenStack。在其上进行了大量服务（目前超过100多种，并且服务数量还在不断增长）的扩展，健壮的 DevOps 工具，集成能力，以及无缝的开发人员体验。 Bluemix四大核心能力提升创新应用交付速度和价值：(1)Bluemix提供一体化运行环境，保证创新应用秒级上线；(2) Bluemix提供百余种流行的服务模块，构建应用简单快速;(3) Bluemix提供高效管理手段DevOps，保证应用强健稳定;(4) Bluemix可以放在本地，又可以无缝连接其公有云，具有多种部署模式，让企业具有更大的灵活性，形成更大的创新生态圈。 参考 解析微服务架构(一)：什么是微服务]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：反射]]></title>
    <url>%2F2019%2F03%2F28%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[反射提出问题如果不知道某个对象的确切类型，RTTI可以告知，但是有一个限制，这个类型在编译时必须已知。 那么假设获取了一个指向某个并不在你的程序空间中的对象的引用，实际上在编译时根部无法获知这个对象所属的类。例如从磁盘文件、网络连接中获取了一串字节， 并被告知这些字节代表了一个类，那么此时该怎样使用这样的类。 应用适用性 反射提供了一种机制：用来检查可用的方法，并返回方法名。Java通过JavaBeans提供了基于构件的编程架构 希望提供在跨网络的远程平台上创建和运行对象的能力，即远程方法调用RMI 反射在你需要创建更加动态的代码时会很有用，反射在Java当中是用来支持其他特性的，例如对象序列化与JavaBean. 应用场景反射的主要应用场景有： 开发通用框架 - 反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 JavaBean、Filter 等），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。 动态代理 - 在切面编程（AOP）中，需要拦截特定的方法，通常，会选择动态代理方式。这时，就需要反射技术来实现了。 注解 - 注解本身仅仅是起到标记作用，它需要利用反射机制，根据注解标记去调用注解解释器，执行行为。如果没有反射机制，注解并不比注释更有用。 可扩展性功能 - 应用程序可以通过使用完全限定名称创建可扩展性对象实例来使用外部的用户定义类。 反射的缺点 性能开销 - 由于反射涉及动态解析的类型，因此无法执行某些 Java 虚拟机优化。因此，反射操作的性能要比非反射操作的性能要差，应该在性能敏感的应用程序中频繁调用的代码段中避免。 破坏封装性 - 反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。 内部曝光 - 由于反射允许代码执行在非反射代码中非法的操作，例如访问私有字段和方法，所以反射的使用可能会导致意想不到的副作用，这可能会导致代码功能失常并可能破坏可移植性。反射代码打破了抽象，因此可能会随着平台的升级而改变行为。 概述什么是反射反射(Reflection)是Java程序开发语言的特征之一，它允许运行中的Java程序获取自身的信息，并且可以操作类或对象的内部属性。 Java 反射机制在程序运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。这种 动态的获取信息 以及 动态调用对象的方法 的功能称为 java 的反射机制。 反射机制很重要的一点就是“运行时”，其使得我们可以在程序运行时加载、探索以及使用编译期间完全未知的.class文件。换句话说，Java 程序可以加载一个运行时才得知名称的.class文件，然后获悉其完整构造，并生成其对象实体、或对其 fields（变量）设值、或调用其 methods（方法）。 通过反射机制，可以在运行时访问 Java 对象的属性，方法，构造方法等。 分类有两个类库为反射的概念提供了支持。 Java.lang.reflect库 Class类 类库中包含了Field、Method、Constructor类（每个类都实现了Member接口），这些类型的对象是由JVM在运行时创建的，用以表示类里对应的成员。 反射机制类加载过程 类加载的完整过程如下： 在编译时，Java 编译器编译好 .java 文件之后，在磁盘中产生 .class 文件。.class 文件是二进制文件，内容是只有 JVM 能够识别的机器码。 JVM 中的类加载器读取字节码文件，取出二进制数据，加载到内存中，解析.class文件内的信息。类加载器会根据类的全限定名来获取此类的二进制字节流；然后，将字节流所代表的静态存储结构转化为方法区的运行时数据结构；接着，在内存中生成代表这个类的java.lang.Class对象。 加载结束后，JVM开始进行连接阶段（包含验证、准备、初始化）。经过这一系列操作，类的变量会被初始化。 Class 对象要想使用反射，首先需要获得待操作的类所对应的 Class 对象。Java 中，无论生成某个类的多少个对象，这些对象都会对应于同一个 Class 对象。这个 Class 对象是由 JVM 生成的，通过它能够获悉整个类的结构。所以，java.lang.Class可以视为所有反射 API 的入口点。 反射的本质就是：在运行时，把 Java 类中的各种成分映射成一个个的 Java 对象。 举例来说，假如定义了以下代码： 1User user = new User(); 步骤说明： JVM 加载方法的时候，遇到new User()，JVM 会根据User的全限定名去加载 User.class 。 JVM 会去本地磁盘查找User.class文件并加载 JVM 内存中。 JVM 通过调用类加载器自动创建这个类对应的Class对象，并且存储在 JVM 的方法区。注意：一个类有且只有一个 Class 对象。 反射机制当通过反射与一个未知类型的对象打交道时，JVM只是简单地检查这个对象，看它属于哪个特定的类（如同RTTI），在用它做其他事情前必须先加载那个类的Class对象，因此该.class文件对于JVM必须是可获取的，要么在本地机器，要么通过网络取得。 RTTI，编译器在编译时打开和检查.class文件 反射，.class文件在编译期不可获取，所以是在运行时打开和检查.class文件 使用反射java.lang.reflect 包Java 中的 java.lang.reflect 包提供了反射功能。java.lang.reflect 包中的类都没有 public 构造方法。 java.lang.reflect 包的核心接口和类如下： Member 接口 - 反映关于单个成员(字段或方法)或构造函数的标识信息。 Field 类 - 提供一个类的域的信息以及访问类的域的接口。 Method 类 - 提供一个类的方法的信息以及访问类的方法的接口。 Constructor 类 - 提供一个类的构造函数的信息以及访问类的构造函数的接口。 Array 类 - 该类提供动态地生成和访问 JAVA 数组的方法。 Modifier 类 - 提供了 static 方法和常量，对类和成员访问修饰符进行解码。 Proxy 类 - 提供动态地生成代理类和类实例的静态方法。 可以使用Constructors创建新对象，用get/set方法读取和修改与Field对象关联的字段。用invoke方法调用与Method对象关联的方法。还可以调用getFields、getMethods等方法，以返回表示字段、方法的对象的数组。这样匿名的类信息就能在运行时完全确定下来，而在编译时不需要知道任何事情。 获得 Class 对象获得 Class 的三种方法： （1）使用 Class 类的 forName 静态方法 示例： 123456789101112131415161718package io.github.dunwu.javacore.reflect;public class ReflectClassDemo01 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class c1 = Class.forName("io.github.dunwu.javacore.reflect.ReflectClassDemo01"); System.out.println(c1.getCanonicalName()); Class c2 = Class.forName("[D"); System.out.println(c2.getCanonicalName()); Class c3 = Class.forName("[[Ljava.lang.String;"); System.out.println(c3.getCanonicalName()); &#125;&#125;//Output://io.github.dunwu.javacore.reflect.ReflectClassDemo01//double[]//java.lang.String[][] 使用类的完全限定名来反射对象的类。常见的应用场景为：在 JDBC 开发中常用此方法加载数据库驱动。 （2）直接获取某一个对象的 class 示例： 123456789101112131415161718public class ReflectClassDemo02 &#123; public static void main(String[] args) &#123; boolean b; // Class c = b.getClass(); // 编译错误 Class c1 = boolean.class; System.out.println(c1.getCanonicalName()); Class c2 = java.io.PrintStream.class; System.out.println(c2.getCanonicalName()); Class c3 = int[][][].class; System.out.println(c3.getCanonicalName()); &#125;&#125;//Output://boolean//java.io.PrintStream//int[][][] （3）调用 Object 的 getClass 方法，示例： Object 类中有 getClass 方法，因为所有类都继承 Object 类。从而调用 Object 类来获取 示例： 1234567891011121314151617181920212223242526272829package io.github.dunwu.javacore.reflect;import java.util.HashSet;import java.util.Set;public class ReflectClassDemo03 &#123; enum E &#123;A, B&#125; public static void main(String[] args) &#123; Class c = "foo".getClass(); System.out.println(c.getCanonicalName()); Class c2 = ReflectClassDemo03.E.A.getClass(); System.out.println(c2.getCanonicalName()); byte[] bytes = new byte[1024]; Class c3 = bytes.getClass(); System.out.println(c3.getCanonicalName()); Set&lt;String&gt; set = new HashSet&lt;&gt;(); Class c4 = set.getClass(); System.out.println(c4.getCanonicalName()); &#125;&#125;//Output://java.lang.String//io.github.dunwu.javacore.reflect.ReflectClassDemo.E//byte[]//java.util.HashSet 判断是否为某个类的实例判断是否为某个类的实例有两种方式： 用 instanceof 关键字 用 Class 对象的 isInstance 方法（它是一个 Native 方法） 示例： 1234567891011121314public class InstanceofDemo &#123; public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); if (arrayList instanceof List) &#123; System.out.println("ArrayList is List"); &#125; if (List.class.isInstance(arrayList)) &#123; System.out.println("ArrayList is List"); &#125; &#125;&#125;//Output://ArrayList is List//ArrayList is List 创建实例通过反射来创建实例对象主要有两种方式： 用 Class 对象的 newInstance 方法。 用 Constructor 对象的 newInstance 方法。 示例： 1234567891011121314151617181920public class NewInstanceDemo &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; c1 = StringBuilder.class; StringBuilder sb = (StringBuilder) c1.newInstance(); sb.append("aaa"); System.out.println(sb.toString()); //获取String所对应的Class对象 Class&lt;?&gt; c2 = String.class; //获取String类带一个String参数的构造器 Constructor constructor = c2.getConstructor(String.class); //根据构造器创建实例 String str2 = (String) constructor.newInstance("bbb"); System.out.println(str2); &#125;&#125;//Output://aaa//bbb FieldClass 对象提供以下方法获取对象的成员（Field）： getFiled - 根据名称获取公有的（public）类成员。 getDeclaredField - 根据名称获取已声明的类成员。但不能得到其父类的类成员。 getFields - 获取所有公有的（public）类成员。 getDeclaredFields - 获取所有已声明的类成员。 示例如下： 123456789101112131415161718192021222324252627public class ReflectFieldDemo &#123; class FieldSpy&lt;T&gt; &#123; public boolean[][] b = &#123;&#123;false, false&#125;, &#123;true, true&#125;&#125;; public String name = "Alice"; public List&lt;Integer&gt; list; public T val; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; Field f1 = FieldSpy.class.getField("b"); System.out.format("Type: %s%n", f1.getType()); Field f2 = FieldSpy.class.getField("name"); System.out.format("Type: %s%n", f2.getType()); Field f3 = FieldSpy.class.getField("list"); System.out.format("Type: %s%n", f3.getType()); Field f4 = FieldSpy.class.getField("val"); System.out.format("Type: %s%n", f4.getType()); &#125;&#125;//Output://Type: class [[Z//Type: class java.lang.String//Type: interface java.util.List//Type: class java.lang.Object MethodClass 对象提供以下方法获取对象的方法（Method）： getMethod - 返回类或接口的特定方法。其中第一个参数为方法名称，后面的参数为方法参数对应 Class 的对象。 getDeclaredMethod - 返回类或接口的特定声明方法。其中第一个参数为方法名称，后面的参数为方法参数对应 Class 的对象。 getMethods - 返回类或接口的所有 public 方法，包括其父类的 public 方法。 getDeclaredMethods - 返回类或接口声明的所有方法，包括 public、protected、默认（包）访问和 private 方法，但不包括继承的方法。 获取一个 Method 对象后，可以用 invoke 方法来调用这个方法。 invoke 方法的原型为: 123public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException 示例： 123456789101112131415161718192021222324public class ReflectMethodDemo &#123; public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; // 返回所有方法 Method[] methods1 = System.class.getDeclaredMethods(); System.out.println("System getDeclaredMethods 清单（数量 = " + methods1.length + "）："); for (Method m : methods1) &#123; System.out.println(m); &#125; // 返回所有 public 方法 Method[] methods2 = System.class.getMethods(); System.out.println("System getMethods 清单（数量 = " + methods2.length + "）："); for (Method m : methods2) &#123; System.out.println(m); &#125; // 利用 Method 的 invoke 方法调用 System.currentTimeMillis() Method method = System.class.getMethod("currentTimeMillis"); System.out.println(method); System.out.println(method.invoke(null)); &#125;&#125; ConstructorClass 对象提供以下方法获取对象的构造方法（Constructor）： getConstructor - 返回类的特定 public 构造方法。参数为方法参数对应 Class 的对象。 getDeclaredConstructor - 返回类的特定构造方法。参数为方法参数对应 Class 的对象。 getConstructors - 返回类的所有 public 构造方法。 getDeclaredConstructors - 返回类的所有构造方法。 获取一个 Constructor 对象后，可以用 newInstance 方法来创建类实例。 示例： 12345678910111213141516171819202122public class ReflectMethodConstructorDemo &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; Constructor&lt;?&gt;[] constructors1 = String.class.getDeclaredConstructors(); System.out.println("String getDeclaredConstructors 清单（数量 = " + constructors1.length + "）："); for (Constructor c : constructors1) &#123; System.out.println(c); &#125; Constructor&lt;?&gt;[] constructors2 = String.class.getConstructors(); System.out.println("String getConstructors 清单（数量 = " + constructors2.length + "）："); for (Constructor c : constructors2) &#123; System.out.println(c); &#125; System.out.println("===================="); Constructor constructor = String.class.getConstructor(String.class); System.out.println(constructor); String str = (String) constructor.newInstance("bbb"); System.out.println(str); &#125;&#125; Array数组在 Java 里是比较特殊的一种类型，它可以赋值给一个对象引用。下面我们看一看利用反射创建数组的例子： 12345678910111213141516public class ReflectArrayDemo &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class&lt;?&gt; cls = Class.forName("java.lang.String"); Object array = Array.newInstance(cls, 25); //往数组里添加内容 Array.set(array, 0, "Scala"); Array.set(array, 1, "Java"); Array.set(array, 2, "Groovy"); Array.set(array, 3, "Scala"); Array.set(array, 4, "Clojure"); //获取某一项的内容 System.out.println(Array.get(array, 3)); &#125;&#125;//Output://Scala 其中的 Array 类为 java.lang.reflect.Array 类。我们通过 Array.newInstance 创建数组对象，它的原型是： 1234public static Object newInstance(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException &#123; return newArray(componentType, length);&#125; 动态代理动态代理是反射的一个非常重要的应用场景。动态代理常被用于一些 Java 框架中。例如 Spring 的 AOP ，Dubbo 的 SPI 接口，就是基于 Java 动态代理实现的。 静态代理 静态代理其实就是指设计模式中的代理模式。 代理模式为其他对象提供一种代理以控制对这个对象的访问。 Subject 定义了 RealSubject 和 Proxy 的公共接口，这样就在任何使用 RealSubject 的地方都可以使用 Proxy 。 123abstract class Subject &#123; public abstract void Request();&#125; RealSubject 定义 Proxy 所代表的真实实体。 123456class RealSubject extends Subject &#123; @Override public void Request() &#123; System.out.println("真实的请求"); &#125;&#125; Proxy 保存一个引用使得代理可以访问实体，并提供一个与 Subject 的接口相同的接口，这样代理就可以用来替代实体。 1234567891011class Proxy extends Subject &#123; private RealSubject real; @Override public void Request() &#123; if (null == real) &#123; real = new RealSubject(); &#125; real.Request(); &#125;&#125; 说明： 静态代理模式固然在访问无法访问的资源，增强现有的接口业务功能方面有很大的优点，但是大量使用这种静态代理，会使我们系统内的类的规模增大，并且不易维护；并且由于 Proxy 和 RealSubject 的功能本质上是相同的，Proxy 只是起到了中介的作用，这种代理在系统中的存在，导致系统结构比较臃肿和松散。 动态代理为了解决静态代理的问题，就有了创建动态代理的想法： 在运行状态中，需要代理的地方，根据 Subject 和 RealSubject，动态地创建一个 Proxy，用完之后，就会销毁，这样就可以避免了 Proxy 角色的 class 在系统中冗杂的问题了。 Java 动态代理基于经典代理模式，引入了一个 InvocationHandler，InvocationHandler 负责统一管理所有的方法调用。 动态代理步骤： 获取 RealSubject 上的所有接口列表； 确定要生成的代理类的类名，默认为：com.sun.proxy.$ProxyXXXX； 根据需要实现的接口信息，在代码中动态创建 该 Proxy 类的字节码； 将对应的字节码转换为对应的 class 对象； 创建 InvocationHandler 实例 handler，用来处理 Proxy 所有方法调用； Proxy 的 class 对象 以创建的 handler 对象为参数，实例化一个 proxy 对象。 从上面可以看出，JDK 动态代理的实现是基于实现接口的方式，使得 Proxy 和 RealSubject 具有相同的功能。 但其实还有一种思路：通过继承。即：让 Proxy 继承 RealSubject，这样二者同样具有相同的功能，Proxy 还可以通过重写 RealSubject 中的方法，来实现多态。CGLIB 就是基于这种思路设计的。 在 Java 的动态代理机制中，有两个重要的类（接口），一个是 InvocationHandler 接口、另一个则是 Proxy 类，这一个类和一个接口是实现我们动态代理所必须用到的。 InvocationHandler 接口InvocationHandler 接口定义： 1234public interface InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 每一个动态代理类都必须要实现 InvocationHandler 这个接口，并且每个代理类的实例都关联到了一个 Handler，当我们通过代理对象调用一个方法的时候，这个方法的调用就会被转发为由 InvocationHandler 这个接口的 invoke 方法来进行调用。 我们来看看 InvocationHandler 这个接口的唯一一个方法 invoke 方法： 1Object invoke(Object proxy, Method method, Object[] args) throws Throwable 参数说明： proxy - 代理的真实对象。 method - 所要调用真实对象的某个方法的 Method 对象 args - 所要调用真实对象某个方法时接受的参数 如果不是很明白，等下通过一个实例会对这几个参数进行更深的讲解。 Proxy 类Proxy 这个类的作用就是用来动态创建一个代理对象的类，它提供了许多的方法，但是我们用的最多的就是 newProxyInstance 这个方法： 1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 这个方法的作用就是得到一个动态的代理对象。 参数说明： loader - 一个ClassLoader对象，定义了由哪个ClassLoader对象来对生成的代理对象进行加载。 interfaces - 一个 Interface 对象的数组，表示的是我将要给我需要代理的对象提供一组什么接口，如果我提供了一组接口给它，那么这个代理对象就宣称实现了该接口(多态)，这样我就能调用这组接口中的方法了 h - 一个 InvocationHandler 对象，表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个 InvocationHandler 对象上 动态代理实例上面的内容介绍完这两个接口(类)以后，我们来通过一个实例来看看我们的动态代理模式是什么样的： 首先我们定义了一个 Subject 类型的接口，为其声明了两个方法： 123456public interface Subject &#123; void hello(String str); String bye();&#125; 接着，定义了一个类来实现这个接口，这个类就是我们的真实对象，RealSubject 类： 12345678910111213public class RealSubject implements Subject &#123; @Override public void hello(String str) &#123; System.out.println("Hello " + str); &#125; @Override public String bye() &#123; System.out.println("Goodbye"); return "Over"; &#125;&#125; 下一步，我们就要定义一个动态代理类了，前面说个，每一个动态代理类都必须要实现 InvocationHandler 这个接口，因此我们这个动态代理类也不例外： 123456789101112131415161718192021222324252627public class InvocationHandlerDemo implements InvocationHandler &#123; // 这个就是我们要代理的真实对象 private Object subject; // 构造方法，给我们要代理的真实对象赋初值 public InvocationHandlerDemo(Object subject) &#123; this.subject = subject; &#125; @Override public Object invoke(Object object, Method method, Object[] args) throws Throwable &#123; // 在代理真实对象前我们可以添加一些自己的操作 System.out.println("Before method"); System.out.println("Call Method: " + method); // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用 Object obj = method.invoke(subject, args); // 在代理真实对象后我们也可以添加一些自己的操作 System.out.println("After method"); System.out.println(); return obj; &#125;&#125; 最后，来看看我们的 Client 类： 1234567891011121314151617181920212223public class Client &#123; public static void main(String[] args) &#123; // 我们要代理的真实对象 Subject realSubject = new RealSubject(); // 我们要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的 InvocationHandler handler = new InvocationHandlerDemo(realSubject); /* * 通过Proxy的newProxyInstance方法来创建我们的代理对象，我们来看看其三个参数 * 第一个参数 handler.getClass().getClassLoader() ，我们这里使用handler这个类的ClassLoader对象来加载我们的代理对象 * 第二个参数realSubject.getClass().getInterfaces()，我们这里为代理对象提供的接口是真实对象所实行的接口，表示我要代理的是该真实对象，这样我就能调用这组接口中的方法了 * 第三个参数handler， 我们这里将这个代理对象关联到了上方的 InvocationHandler 这个对象上 */ Subject subject = (Subject)Proxy.newProxyInstance(handler.getClass().getClassLoader(), realSubject .getClass().getInterfaces(), handler); System.out.println(subject.getClass().getName()); subject.hello("World"); String result = subject.bye(); System.out.println("Result is: " + result); &#125;&#125; 我们先来看看控制台的输出： 123456789101112com.sun.proxy.$Proxy0Before methodCall Method: public abstract void io.github.dunwu.javacore.reflect.InvocationHandlerDemo$Subject.hello(java.lang.String)Hello WorldAfter methodBefore methodCall Method: public abstract java.lang.String io.github.dunwu.javacore.reflect.InvocationHandlerDemo$Subject.bye()GoodbyeAfter methodResult is: Over 我们首先来看看 com.sun.proxy.$Proxy0 这东西，我们看到，这个东西是由 System.out.println(subject.getClass().getName()); 这条语句打印出来的，那么为什么我们返回的这个代理对象的类名是这样的呢？ 12Subject subject = (Subject)Proxy.newProxyInstance(handler.getClass().getClassLoader(), realSubject .getClass().getInterfaces(), handler); 可能我以为返回的这个代理对象会是 Subject 类型的对象，或者是 InvocationHandler 的对象，结果却不是，首先我们解释一下为什么我们这里可以将其转化为 Subject 类型的对象？ 原因就是：在 newProxyInstance 这个方法的第二个参数上，我们给这个代理对象提供了一组什么接口，那么我这个代理对象就会实现了这组接口，这个时候我们当然可以将这个代理对象强制类型转化为这组接口中的任意一个，因为这里的接口是 Subject 类型，所以就可以将其转化为 Subject 类型了。 同时我们一定要记住，通过 Proxy.newProxyInstance 创建的代理对象是在 jvm 运行时动态生成的一个对象，它并不是我们的 InvocationHandler 类型，也不是我们定义的那组接口的类型，而是在运行是动态生成的一个对象，并且命名方式都是这样的形式，以$开头，proxy 为中，最后一个数字表示对象的标号。 接着我们来看看这两句 12subject.hello("World");String result = subject.bye(); 这里是通过代理对象来调用实现的那种接口中的方法，这个时候程序就会跳转到由这个代理对象关联到的 handler 中的 invoke 方法去执行，而我们的这个 handler 对象又接受了一个 RealSubject 类型的参数，表示我要代理的就是这个真实对象，所以此时就会调用 handler 中的 invoke 方法去执行。 我们看到，在真正通过代理对象来调用真实对象的方法的时候，我们可以在该方法前后添加自己的一些操作，同时我们看到我们的这个 method 对象是这样的： 12public abstract void io.github.dunwu.javacore.reflect.InvocationHandlerDemo$Subject.hello(java.lang.String)public abstract java.lang.String io.github.dunwu.javacore.reflect.InvocationHandlerDemo$Subject.bye() 正好就是我们的 Subject 接口中的两个方法，这也就证明了当我通过代理对象来调用方法的时候，起实际就是委托由其关联到的 handler 对象的 invoke 方法中来调用，并不是自己来真实调用，而是通过代理的方式来调用的。 小结反射应用 空对象接口与类型信息附录Class信息 动态代理 参考 深入理解 Java 反射和动态代理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：代理模式]]></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式提出问题 为了只有在我们确实需要这个对象时才对它进行初始化 我们在写一个功能函数时，经常需要在其中写入与功能不是直接相关但很有必要的代码 问题案例1考虑一个数据库查询场景，需要将公司的所有员工显示出来，而且不要翻页，在显示全部员工时，只需要显示名称即可，但是必要时也可以查看某位员工的具体信息。 该查询查询的数据条很多，并且每条数据的数据量也很大，则会消耗很大的内存。从用户角度看，y用户可能访问一条数据，也可能不访问等等。而从程序角度则应该减少内存的消耗 问题案例2如日志记录，信息发送，安全和事务支持等，这些枝节性代码虽然是必要的，但它会带来以下麻烦： 枝节性代码游离在功能性代码之外，它不是函数的目的，这是对OO是一种破坏 枝节性代码会造成功能性代码对其它类的依赖，加深类之间的耦合，可重用性降低 从法理上说，枝节性代码应该监视着功能性代码，然后采取行动，而不是功能性代码通知枝节性代码采取行动，这好比吟游诗人应该是主动记录骑士的功绩而不是骑士主动要求诗人记录自己的功绩 问题案例3考虑一个场景，即去买演唱会的票，如果直接去现场买，则很难买，而且很浪费时间，如果通过代理买，我们只需要交钱就可以了。但是要额外承担一笔代理的费用。 基础概述是什么 代理(Proxy)是一种设计模式,定义：为其他对象提供一个代理以控制对某个对象的访问，即通过代理对象访问目标对象. 这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能. 这里使用到编程中的一个思想: 不要随意去修改别人已经写好的代码或者方法,如果需改修改,可以通过代理的方式来扩展该方法 所以说代理模式就是：当前对象不愿意干的，没法干的东西委托给别的对象来做，我只要做好本分的东西就好了！ 分类根据实现方式分类 静态代理 动态代理 根据目的分类 远程代理。隐藏一个对象存在于不同地址空间的事实，一般用于RMI等 虚代理。可以进行最优化，根据要求创建对象。即根据需要创建开销很大的对象， 该对象只有在真正需要的时候才会被创建。 保护代理。提供不同的访问权限，允许在访问一个对象时有一些附加处理 智能指引。允许在访问一个对象时有一些附加处理 区别很明显的是： 静态代理需要自己写代理类–&gt;代理类需要实现与目标对象相同的接口 而动态代理不需要自己编写代理类—&gt;(是动态生成的) 使用静态代理时： 如果目标对象的接口有很多方法的话，那我们还是得一一实现，这样就会比较麻烦 使用动态代理时： 代理对象的生成，是利用JDK API，动态地在内存中构建代理对象(需要我们指定创建 代理对象/目标对象 实现的接口的类型)，并且会默认实现接口的全部方法。 应用适用性 远程代理，为一个对象在不同的地址空间提供局部代表 虚代理，根据需要创建开销很大的对象 保护代理，控制对原始对象的访问，用于对象应该有不同的访问权限的时候 智能指引，取代了简单的指针，在访问对象时执行一些附加操作 对指向实际对象的引用计数，当对象没有用时，可以自动释放 在访问一个对象时，对它进行事务、日志等操作 案例1CopyOnWrite的优化方式，拷贝是一个开销很大的操作，如果拷贝没有被修改，则代理延迟这一拷贝过程，保证只有在这个对象被修改时才进行拷贝 协作结构 参与者 Proxy 保护一个引用使得代理可以访问实体，如果RealSubject与Subject的接口相同，Proxy会引用Subject 提供一个与Subject的接口相同的接口，这样代理就可以用来替代实体 控制对实体的存取，并可能负责创建和删除它 其他功能依赖于代理的类型 Remote Proxy负责对请求及其参数进行编码，并向不同地址空间的实体发送已编码的请求 Virtual Proxy可以缓存实体的附加信息，以便延迟对它的访问 Protection Proxy检查调用者是否具有实现一个请求所必须的访问权限 Subject 定义RealSubject与Proxy的公共接口，可以在任何使用RealSubject的地方都可以使用Proxy RealSubject 定义Proxy所代表的实体 协作 类关系 逻辑关系 代理根据其种类，在适当的时候向RealSubject转发请求。 权衡静态代理结构效果（优缺）实现实现步骤案例1这里有一个Subject接口 123public interface Subject &#123; void coding();&#125; 实现RealSubject 1234567public class RealSubject implements Subject &#123; @Override public void coding() &#123; System.out.println("Im Real"); &#125;&#125; 实现Proxy扩展原有的RealSubject的功能 12345678910111213141516public class SubjectProxy implements Subject &#123; private Subject realSubject ; public RealSubjectProxy(Subject real) &#123; this.realSubject = real; &#125; public void upvote() &#123; System.out.println("扩展RealSubject无法做的功能"); &#125; @Override public void coding() &#123; realSubject.coding();//将操作转发给原有对象 upvote();//扩展功能 &#125;&#125; 接口功能还是由RealSubject来实现，但每次实现后会有一些扩展功能 1234567public class Main &#123; public static void main(String[] args) &#123; RealSubject real = new RealSubject(); SubjectProxy programmer = new RealSubjectProxy(real); programmer.coding(); &#125; &#125; 问题案例1实现一个代理对象，持有用户对象，并拥有查询用户姓名等基础信息的方法，当要查询某一个具体的用户全部信息时，进行reload加载该用户的信息。 透明代理(普通代理)让真实对象(RealSubject)对外界来说是透明的 1234567891011121314151617181920public class RealSubjectProxy implements Subject &#123; // 指定具体的代理对象 private RealSubject realSubject ; // 只做针对单个的目标 public RealSubjectProxy() &#123; this.realSubject = new RealSubect(); &#125; public void upvote() &#123; System.out.println("扩展"); &#125; @Override public void coding() &#123; realSubject.coding(); upvote(); &#125;&#125; 于是乎，实现代理 123456789public class Main &#123; public static void main(String[] args) &#123; // 受委托代理 RealSubjectProxy programmer = new RealSubjectProxy(); programmer.coding(); &#125;&#125; 动态代理结构效果（优缺）实现实现步骤案例1利用动态代理自动生成代理对象 123456789101112131415161718192021public class Main &#123; public static void main(String[] args1) &#123; RealSubject real = new RealSubject(); Programmer proxy = (Programmer) Proxy.newProxyInstance(real.getClass().getClassLoader(), real.getClass().getInterfaces(), (proxy, method, args) -&gt; &#123; // 如果是调用coding方法，那么执行代理 if (method.getName().equals("coding")) &#123; method.invoke(real, args); System.out.println("扩展"); &#125; else &#123; // 如果不是调用coding方法，那么调用原对象的方法 return method.invoke(real, args); &#125; return null; &#125;); proxy.coding(); &#125;&#125; Java动态代理Proxy调用过程1`//简化上述(2)(3)(4)步骤Object o = Proxy.newProxyInstance(Stub.class.getClassLoader(), new Class&lt;?&gt;[] &#123;Subject.class&#125;, client.handler);` 整体的过程可以拆解为以下过程 12345678910111213141516171819202122232425public class StubClient &#123; public static void main(String[] args) throws Exception &#123; //(2)通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类 Class&lt;?&gt; proxyClass = Proxy.getProxyClass(RealSubject.class.getClassLoader(), new Class&lt;?&gt;[]&#123;Subject.class&#125;); //(3)通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型 Constructor&lt;?&gt; proxyClassConstructor = proxyClass.getConstructor(new Class&lt;?&gt;[]&#123;InvocationHandler.class&#125;); //(4)通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入 Object o = proxyClassConstructor.newInstance(new StubClient().handler); //(5)通过动态代理对象调用 Subject subject = (Subject) o; //(6)输出委托类的结果 subject.doSomething(); &#125; //(1)通过实现 InvocationHandler 接口创建自己的调用处理器 private InvocationHandler handler = new InvocationHandler() &#123; //创建委托类对象实例 private RealSubject real = new RealSubject(); @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return method.invoke(real, args);//调用委托类的方法 &#125; &#125;;&#125; 动态代理类的属性 如果所有的代理接口都是public的，那么代理类就是public、final的，切不是abstract的 动态代理类的名称以”$ProxyN”开头,N是代理类的唯一编号. 动态代理类都继承于java.lang.reflect.Proxy 动态代理类实现了其创建时指定的接口，且保持接口指定的顺序 如果动态代理类实现了一个非public接口，那么它将定义和接口相同的包名；否则代理类的包是不确定的，默认是com.sun.proxy,运行时，包密封性不防止特定包成功定义代理类；如果都不是，动态代理类将由同一个类加载器和相同的包与特定签名定义. 动态代理类实现了其创建时指定的所有接口，调用代理类Class对象的getInterfaces将返回和创建时指定接口顺序相同的列表，调用 getMethods方法返回所有接口方法的数组对象，调用getMethod会返回代理类接口中期望的method. 调用Proxy.isProxyClass方法时,传入Proxy.getProxyClass返回的Class或者Proxy.newProxyInstance返回对象的Class，都会返回true，否则返回false. 代理类的java.security.ProtectionDomain是由系统根类加载器加载的，代理类的代码也是系统信任的代码生成的，此保护域通常被授予java.security.AllPermission 每一个代理类都有一个public的，含有一个InvocationHandler实现为参数的构造方法，设置了调用处理器接口，就不必使用反射api访问构造方法，通过Proxy.newProxyInstance可以产生和Proxy.getProxyClass和调用句柄相同的调用构造函数行为. 动态代理实例的属性 给定一个代理实例proxy，Foo实现的接口之一，表达式 proxy instanceof Foo 返回true,(Foo) proxy能成功转换. 每个代理实例都关联一个InvocationHandler， 通过Proxy.getInvocationHandler方法，将返回代理类关联的InvocationHandler. 代理类实例调用其代理接口中所声明的方法时，这些方法将被编码，并最终由调用处理器(InvocationHandler)的invoke方法执行. 代理类根类java.lang.Object中的hashCode,equals和toString方法，也会被分派到调用处理其的invoke方法执行；可能的原因有：一是因为这些方法为 public 且非 final 类型，能够被代理类覆盖；二是因为这些方法往往呈现出一个类的某种特征属性，具有一定的区分度，所以为了保证代理类与委托类对外的一致性，这三个方法也应该被分派到委托类执行。 当代理的一组接口有重复声明的方法且该方法被调用时，代理类总是从排在最前面的接口中获取方法对象并分派给调用处理器，而无论代理类实例是否正在以该接口（或继承于该接口的某子接口）的形式被外部引用，因为在代理类内部无法区分其当前的被引用类型。 获取动态代理类时需要注意哪些？1public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces) 通过指定的ClassLoader loader和有序的interfaces，ClassLoader将动态生成实现有序interfaces的代理类，如果这个ClassLoader已经定义过相同有序接口实现的代理类，那么将不在重复定义. 所有interfaces中的对象必须都是接口，否则会抛出异常 interfaces中的接口不能重复 所有接口相对指定的ClassLoader必须是可见的 所有的非public接口必须在同一个包中，否这不能成功生成实现所有接口的代理类. 代理类的接口数目不能超过65535，这个是JVM所限定的 当不满足上述限定中的一条或多条时，将会抛出IllegalArgumentException异常，如果interfaces中的接口对象一个或多个是null，也将抛出NullPointerException.注意：代理类指定的接口的顺序是很重要的，否则不通顺序的相同接口数组将会导致生成不同的代理类 从源码中理解动态代理类的生成上面我们讲述了动态代理的使用，动态代理类的属性，动态代理实例的属性，以及获取动态代理类时需要注意的事项，下面我们从源码角度去观察这些东西 Proxy的重要变量123456//构造器参数类型private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;;//代理类缓存 private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());//关联的调用处理器protected InvocationHandler h; Proxy的构造方法1234567//私有构造函数，禁止外部调用private Proxy() &#123;&#125;// 通过子类指定一个调用处理器接口protected Proxy(InvocationHandler h) &#123; doNewInstanceCheck(); this.h = h;&#125; Proxy.newProxyInstance函数分析12345678910111213public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)throws IllegalArgumentException &#123; .... //(1)权限检查和校验 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); .... //(2)查找已经存在的或动态生成生成代理类 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); ... //(3)通过反射调用含有调用处理器参数的构造函数生成动态代理类的实例对象并返回 return newInstance(cons, ih);&#125; Proxy.getProxyClass函数分析123456789public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces)throws IllegalArgumentException &#123; ... //(1)权限检查和校验 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); ... //(2)返回查找已经存在的或动态生成生成代理类 return getProxyClass0(loader, intfs);&#125; Proxy.checkProxyAccess函数分析123456789101112131415161718192021222324/*caller 调用Proxy.getProxyClass或Proxy.newProxyInstance接口的类loader 调用接口时传入的ClassLoaderinterfaces 调用接口时传入的接口列表*/private static void checkProxyAccess(Class&lt;?&gt; caller, ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader ccl = caller.getClassLoader(); if (loader == null &amp;&amp; ccl != null) &#123; if (!ProxyAccessHelper.allowNullLoader) &#123; //如果传入的ClassLoader是null，则要检查"getClassLoader"权限 sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; &#125; /* 如果接口列表中有一个接口不是public的，那么代理类应该由该接口的ClassLoader加载定义，如果caller的ClassLoader和接口的ClassLoader不相同，那么虚拟机将在 生成代理类的defineClass0方法(参见java虚拟机类加载机制)中抛出IllegalAccessError */ ReflectUtil.checkProxyPackageAccess(ccl, interfaces); &#125; &#125; Proxy.getProxyClass0函数分析1234567891011/*该函数作用是返回代理类的Class对象，在调用这个方法之前必须要调用checkProxyAccess方法来检查相应的权限*/private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; //接口列表大小的限制 throw new IllegalArgumentException("interface limit exceeded"); &#125; //如果通过指定的loader定义实现有序接口列表的代理类已经存在于缓存，那么返回缓存中的拷贝，否则通过ProxyClassFactory创建代理类 return proxyClassCache.get(loader, interfaces); &#125; 接下来就是代理类从缓存中获取代理类，jdk1.7中的缓存机制略显复杂，没有去深入研究，后期如有可能再补上跳过如下流程代码分析 通过WeakCache的get方法获得代理类的Class对象 删除无效缓存，弱key和强subkey的缓存等（略过…） 通过WeakCache的内部类Factory的get方法调用Proxy.ProxyClassFactory的apply方法得到代理类的Class对象 ProxyClassFactory分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // 所有代理类的前缀 private static final String proxyClassNamePrefix = "$Proxy"; // 生成代理类名称下一个唯一的编号，如$ProxyN private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * 校验代理接口对指定的ClassLoader是否可见，不可见抛出异常 */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + " is not visible from class loader"); &#125; /* * 校验interface Class是否是接口，不是则抛出异常. */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + " is not an interface"); &#125; /* * 校验接口类是否重复，如果重复则抛出异常. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( "repeated interface: " + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // 声明代理类的包名 /* * 记录是否所有的非public接口是否在相同的包下，如果是则代理类的包名是非public接口的包名，否则抛出异常. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? "" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( "non-public interfaces from different packages"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // 如果没有非public的代理接口，包名就用com.sun.proxy proxyPkg = ReflectUtil.PROXY_PACKAGE + "."; &#125; /* * 生成选定的代理类名称,如$ProxyN. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* *通过ProxyGenerator类生成指定的代理类字节数组. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces); try &#123; //通过指定ClassLoader生成代理类的Class对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * 一些其他参数方面影响了代理类的创建异常. */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; 至此，动态代理的Class对象生成进入结尾，Proxy的isProxyClass方法和getInvocationHandler方法就比较清晰明显了，请读者自行分析. 动态代理类生成事物往往不像其看起来的复杂，需要的是我们能够化繁为简，这样也许就能有更多拨云见日的机会. 代理类中方法调用的分派转发推演实现 123456789101112131415161718192021222324252627282930313233343536public final class Proxy$0 extends java.lang.reflect.Proxy implements com.thinkdevos.java.dynamicproxy.Subject &#123; private static Method m0; //为了代理调用高效，这里缓存了接口方法的实例 ..... private static Method mN; //同上还需要缓存hashCode,toString,equals方法实例 .... static &#123;//给静态变量mN赋值 try &#123; Class&lt;?&gt; subClass = Class.forName("com.thinkdevos.java.dynamicproxy.Subject"); Method m0 = subClass.getMethod("doSomething"); .... &#125; catch (Exception e) &#123; ... &#125; &#125; public Proxy$0(java.lang.reflect.InvocationHandler handler) &#123; super(handler); &#125; public final void doSomething() &#123; try &#123; //通过调用处理器调用 handler.invode(this, mN, new Object[] &#123;...&#125;); &#125; catch(Exception e) &#123; .... &#125; &#125; public final int hashCode() &#123; try &#123; handler.invode(this, mN, new Object[] &#123;...&#125;); &#125; catch(Exception e) &#123; .... &#125; &#125;&#125; 用调用处理器调用方法时，在捕获方法本身抛出的异常后，还有可能有未知异常抛出，对于不支持的异常，必须抛 UndeclaredThrowableException 运行时异常. 代理类中方法调用的分派转发推演实现 12345678910public final void doSomething() &#123; try &#123; //通过调用处理器调用 handler.invode(this, mN, new Object[] &#123;...&#125;); &#125; catch(Exception e) &#123; .... &#125; catch(Throwable thr) &#123; throw new UndeclaredThrowableException(e); &#125;&#125; 这样我们就完成了对动态代理类的推演实现。下面我们就实例验证一番，通过如下代码生成字节码文件工具类： 通过ProxyGenerator.generateProxyClass生成代理类字节数组并保存到文件中 1234567891011121314151617181920212223242526272829303132333435public class ProxyUtils &#123; /** * Save proxy class to path * * @param path path to save proxy class * @param proxyClassName name of proxy class * @param interfaces interfaces of proxy class * @return */ public static boolean saveProxyClass(String path, String proxyClassName, Class[] interfaces) &#123; if (proxyClassName == null || path == null) &#123; return false; &#125; // get byte of proxy class byte[] classFile = ProxyGenerator.generateProxyClass(proxyClassName, interfaces); FileOutputStream out = null; try &#123; out = new FileOutputStream(path); out.write(classFile); out.flush(); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return false; &#125;&#125; 运行生成Proxy$0.class 123456public class ProxyClass &#123; public static void main(String[] args) &#123; ProxyUtils.saveProxyClass("/home/borney/tmp/Proxy$0.class", "Proxy$0", new Class&lt;?&gt;[]&#123;Subject.class&#125;); &#125;&#125; 通过 javap -p Proxy$0 查看字节码文件基本信息 1234567891011public final class Proxy$0 extends java.lang.reflect.Proxy implements com.thinkdevos.java.dynamicproxy.Subject &#123; private static java.lang.reflect.Method m1; private static java.lang.reflect.Method m0; ... public Proxy$0(java.lang.reflect.InvocationHandler) throws ; ... public final int hashCode() throws ; public final void doSomething() throws ; ... static &#123;&#125; throws ;&#125; 通过 javap -v Proxy$0 查看详细信息，我们主要看下调用处理器对doSomething调用和异常捕获处理(注释是自己加的，字节码文件中没有注释) 123456789101112131415161718192021222324252627282930313233public final void doSomething() throws ; descriptor: ()V flags: ACC_PUBLIC, ACC_FINAL Code: stack=10, locals=2, args_size=1 0: aload_0 1: getfield #16 // Field java/lang/reflect/Proxy.h:Ljava/lang/reflect/InvocationHandler; 4: aload_0 5: getstatic #60 // Field m3:Ljava/lang/reflect/Method; 8: aconst_null /* 通过调用处理器调用方法 */ 9: invokeinterface #28, 4 // InterfaceMethod java/lang/reflect/InvocationHandler.invoke:(Ljava/lang/Object;Ljava/lang/reflect/Method;[Ljava/lang/Object;)Ljava/lang/Object; 14: pop 15: return 16: athrow 17: astore_1 /* 抛出UndeclaredThrowableException异常 */ 18: new #42 // class java/lang/reflect/UndeclaredThrowableException 21: dup 22: aload_1 23: invokespecial #45 // Method java/lang/reflect/UndeclaredThrowableException.&quot;&lt;init&gt;&quot;:(Ljava/lang/Throwable;)V 26: athrow Exception table: from to target type 0 16 16 Class java/lang/Error 0 16 16 Class java/lang/RuntimeException 0 16 17 Class java/lang/Throwable Exceptions: throws 动态代理的不足之处动态代理只能支持接口的代理，这也是因为java的继承性本质所限制的，因为所有的动态代理类都继承了Proxy类，所以再也无法同时继承其他类.然而，我们不可否认动态代理设计的伟大之处，世上所有的事物都不可能完美. 动态代理调用过程我们来看看究竟是怎么请水军的： Java提供了一个Proxy类，调用它的newInstance方法可以生成某个对象的代理对象,该方法需要三个参数： 参数一：生成代理对象使用哪个类装载器【一般我们使用的是被代理类的装载器】 参数二：生成哪个对象的代理对象，通过接口指定【指定要被代理类的接口】 参数三：生成的代理对象的方法里干什么事【实现handler接口，我们想怎么实现就怎么实现】 在编写动态代理之前，要明确几个概念： 代理对象拥有目标对象相同的方法【因为参数二指定了对象的接口，代理对象会实现接口的所有方法 用户调用代理对象的什么方法，都是在调用处理器的invoke方法。【被拦截】 使用JDK动态代理必须要有接口【参数二需要接口】 上面也说了：代理对象会实现接口的所有方法，这些实现的方法交由我们的handler来处理！ 所有通过动态代理实现的方法全部通过invoke()调用 所以动态代理调用过程是这样子的： 相关模式 Adapter适配器为它所适配的对象提供了一个不同的接口，代理提供了与它的实体相同的接口。然而用于访问保护的代理可能会拒绝执行实体会执行的操作，因此它的接口可能只是实体的一个自己 Decorator，他们的实现类似，但是目的不同，Decorator是为对象添加一个或多个功能，而代理是控制对对象的访问。 进阶反省总结典型应用我们之前写中文过滤器的时候，需要使用包装设计模式来设计一个request类。如果不是Servlet提供了实现类给我们，我们使用包装设计模式会比较麻烦。 现在我们学习了动态代理了，动态代理就是拦截直接访问对象，可以给对象进行增强的一项技能 中文过滤器123456789101112131415161718192021222324252627282930313233343536public void doFilter(final ServletRequest req, ServletResponse resp, FilterChain chain) throws ServletException, IOException &#123; final HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) resp; response.setContentType("text/html;charset=UTF-8"); request.setCharacterEncoding("UTF-8"); //放出去的是代理对象 chain.doFilter((ServletRequest) Proxy.newProxyInstance(CharacterEncodingFilter.class.getClassLoader(), request.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //判断是不是getParameter方法 if (!method.getName().equals("getParameter")) &#123; //不是就使用request调用 return method.invoke(request, args); &#125; //判断是否是get类型的 if (!request.getMethod().equalsIgnoreCase("get")) &#123; return method.invoke(request, args); &#125; //执行到这里，只能是get类型的getParameter方法了。 String value = (String) method.invoke(request, args); if (value == null) &#123; return null; &#125; return new String(value.getBytes("ISO8859-1"), "UTF-8"); &#125; &#125;), response);&#125; 总结本文主要讲解了代理模式的几个要点，其实还有一些细节的：比如“强制代理”(只能通过被代理对象找到代理对象，不能绕过代理对象直接访问被代理对象)。只是用得比较少，我就不说了~~ 要实现动态代理必须要有接口的，动态代理是基于接口来代理的(实现接口的所有方法)，如果没有接口的话我们可以考虑cglib代理。 cglib代理也叫子类代理，从内存中构建出一个子类来扩展目标对象的功能！ 这里我就不再贴出代码来了，因为cglib的代理教程也很多，与动态代理实现差不多~ 总的来说：代理模式是我们写代码中用得很多的一种模式了，Spring的AOP底层其实就是动态代理来实现的–&gt;面向切面编程。具体可参考我之前写的那篇文章： 其实只要记住一点：原有的对象需要额外的功能，想想动态代理这项技术！ Java ProxynewProxyInstance参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring：MVC]]></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpring%EF%BC%9AMVC%2F</url>
    <content type="text"><![CDATA[Spring MVC原理 客户端的所有请求都交给前端控制器DispatcherServlet处理，它会负责调用系统的其他模块来真正处理用户的请求 DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler） 在这个地方，spring会通过HandlerAdapter对该处理进行封装 HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用 Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView包含了数据模型以及相应的视图的信息 ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作 当得到真正的视图对象后，DispatcherServlet会利用对象对模型数据进行渲染 客户端得到响应，可能是一个HTML或json或图片 参考1.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring：AOP]]></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpring%EF%BC%9AAOP%2F</url>
    <content type="text"><![CDATA[AOP产生的背景为了能够更好地将系统级别的代码抽离出来，去掉与对象的耦合，就产生了面向AOP（面向切面）。如上图所示，OOP属于一种横向扩展，AOP是一种纵向扩展。AOP依托于OOP，进一步将系统级别的代码抽象出来，进行纵向排列，实现低耦合。 应用场景 日志、安全性、事务等 AOP 的家庭成员PointCut即在哪个地方进行切入,它可以指定某一个点，也可以指定多个点。 比如类A的methord函数，当然一般的AOP与语言（AOL）会采用多用方式来定义PointCut,比如说利用正则表达式，可以同时指定多个类的多个函数。 Advice在切入点干什么，指定在PointCut地方做什么事情（增强），打日志、执行缓存、处理异常等等。 Advisor/AspectPointCut + Advice 形成了切面Aspect，这个概念本身即代表切面的所有元素。但到这一地步并不是完整的，因为还不知道如何将切面植入到代码中，解决此问题的技术就是PROXY ProxyProxy 即代理，其不能算做AOP的家庭成员，更相当于一个管理部门，它管理 了AOP的如何融入OOP。之所以将其放在这里，是因为Aspect虽然是面向切面核心思想的重要组成部分，但其思想的践行者却是Proxy,也是实现AOP的难点与核心据在。 AOP的技术实现AOP仅仅是一种思想，那为了让这种思想发光，必然脱离语言本身的技术支持，Java在实现该技术时就是采用的代理Proxy,那我们就去了解一下，如何通过代理实现面向切面。 由于静态代理需要实现目标对象的相同接口，那么可能会导致代理类会非常非常多….不好维护—-&gt;因此出现了动态代理 动态代理也有个约束：目标对象一定是要有接口的，没有接口就不能实现动态代理…..—–&gt;因此出现了cglib代理 cglib代理也叫子类代理，从内存中构建出一个子类来扩展目标对象的功能！ CGLIB是一个强大的高性能的代码生成包，它可以在运行期扩展Java类与实现Java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和dynaop，为他们提供方法的interception（拦截）。 静态代理就像我们去买二手房要经过中介一样，房主将房源委托给中介，中介将房源推荐给买方。中间的任何手续的承办都由中介来处理，不需要我们和房主直接打交道。无论对买方还是卖房都都省了很多事情，但同时也要付出代价，对于买房当然是中介费，对于代码的话就是性能。下面我们来介绍实现AOP的三种代理方式。 下面我就以买房的过程中需要打日志为例介绍三种代理方式 静态和动态是由代理产生的时间段来决定的。静态代理产生于代码编译阶段，即一旦代码运行就不可变了。下面我们来看一个例子 123public interface IPerson &#123; public void doSomething();&#125; 12345public class Person implements IPerson &#123; public void doSomething()&#123; System.out.println("I want wo sell this house"); &#125;&#125; 1234567891011121314151617181920public class PersonProxy &#123; private IPerson iPerson; private final static Logger logger = LoggerFactory.getLogger(PersonProxy.class);public PersonProxy(IPerson iPerson) &#123; this.iPerson = iPerson;&#125;public void doSomething() &#123; logger.info("Before Proxy"); iPerson.doSomething(); logger.info("After Proxy");&#125;public static void main(String[] args) &#123; PersonProxy personProxy = new PersonProxy(new Person()); personProxy.doSomething();&#125;&#125; 通过代理类我们实现了将日志代码集成到了目标类，但从上面我们可以看出它具有很大的局限性：需要固定的类编写接口（或许还可以接受，毕竟有提倡面向接口编程），需要实现接口的每一个函数（不可接受），同样会造成代码的大量重复，将会使代码更加混乱。 动态代理那能否通过实现一次代码即可将logger织入到所有函数中呢，答案当然是可以的，此时就要用到java中的反射机制 1234567891011121314151617181920212223242526public class PersonProxy implements InvocationHandler&#123; private Object delegate; private final Logger logger = LoggerFactory.getLogger(this.getClass(); public Object bind(Object delegate) &#123; this.delegate = delegate; return Proxy.newProxyInstance(delegate.getClass().getClassLoader(), delegate.getClass().getInterfaces(), this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; try &#123; logger.info("Before Proxy"); result = method.invoke(delegate, args); logger.info("After Proxy"); &#125; catch (Exception e) &#123; throw e; &#125; return result; &#125; public static void main(String[] args) &#123; PersonProxy personProxy = new PersonProxy(); IPerson iperson = (IPerson) personProxy.bind(new Person()); iperson.doSomething(); &#125;&#125; 它的好处理时可以为我们生成任何一个接口的代理类，并将需要增强的方法织入到任意目标函数。但它仍然具有一个局限性，就是只有实现了接口的类，才能为其实现代理。 CGLIBCGLIB解决了动态代理的难题，它通过生成目标类子类的方式来实现来实现代理，而不是接口，规避了接口的局限性。CGLIB是一个强大的高性能代码生成包，其在运行时期（非编译时期）生成被 代理对象的子类，并重写了被代理对象的所有方法，从而作为代理对象。 12345678910111213141516171819public class PersonProxy implements MethodInterceptor &#123; private Object delegate; private final Logger logger = LoggerFactory.getLogger(this.getClass()); public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; logger.info("Before Proxy"); Object result = methodProxy.invokeSuper(method, args); logger.info("After Proxy"); return result; &#125; public static Person getProxyInstance() &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Person.class); enhancer.setCallback(new PersonProxy()); return (Person) enhancer.create(); &#125;&#125;复制代码 当然CGLIB也具有局限性，对于无法生成子类的类（final类），肯定是没有办法生成代理子类的。 以上就是三种代理的实现方式，但千成别被迷惑了，在Spring AOP中这些东西已经被封装了，不需要我们自己实现。要不然得累死，但了解AOP的实现原理（即基于代理）还是很有必要的。 Spring AOP全面认知AOP概述AOP称为面向切面编程，那我们怎么理解面向切面编程？？ 我们可以先看看下面这段代码： 我们学Java面向对象的时候，如果代码重复了怎么办啊？？可以分成下面几个步骤： 1：抽取成方法 2：抽取类 抽取成类的方式我们称之为：纵向抽取 通过继承的方式实现纵向抽取 但是，我们现在的办法不行：即使抽取成类还是会出现重复的代码，因为这些逻辑(开始、结束、提交事务)依附在我们业务类的方法逻辑中！ 现在纵向抽取的方式不行了，AOP的理念：就是将分散在各个业务逻辑代码中相同的代码通过横向切割的方式抽取到一个独立的模块中！ 上面的图也很清晰了，将重复性的逻辑代码横切出来其实很容易(我们简单可认为就是封装成一个类就好了)，但我们要将这些被我们横切出来的逻辑代码融合到业务逻辑中，来完成和之前(没抽取前)一样的功能！这就是AOP首要解决的问题了！ Spring AOP原理 被我们横切出来的逻辑代码融合到业务逻辑中，来完成和之前(没抽取前)一样的功能 没有学Spring AOP之前，我们就可以使用代理来完成。 代理能干嘛？代理可以帮我们增强对象的行为！ 使用动态代理实质上就是调用时拦截对象方法，对方法进行改造、增强！ 其实Spring AOP的底层原理就是动态代理！ 来源《精通Spring4.x 企业应用开发实战》一段话： Spring AOP使用纯Java实现，它不需要专门的编译过程，也不需要特殊的类装载器，它在运行期通过代理方式向目标类织入增强代码。在Spring中可以无缝地将Spring AOP、IoC和AspectJ整合在一起。 来源《Spring 实战 (第4版)》一句话： Spring AOP构建在动态代理基础之上，因此，Spring对AOP的支持局限于方法拦截。 在Java中动态代理有两种方式： JDK动态代理 CGLib动态代理 JDK动态代理是需要实现某个接口了，而我们类未必全部会有接口，于是CGLib代理就有了~~ CGLib代理其生成的动态代理对象是目标类的子类 Spring AOP默认是使用JDK动态代理，如果代理的类没有接口则会使用CGLib代理。 那么JDK代理和CGLib代理我们该用哪个呢？？在《精通Spring4.x 企业应用开发实战》给出了建议： 如果是单例的我们最好使用CGLib代理，如果是多例的我们最好使用JDK代理 原因： JDK在创建代理对象时的性能要高于CGLib代理，而生成代理对象的运行性能却比CGLib的低。 如果是单例的代理，推荐使用CGLib 看到这里我们就应该知道什么是Spring AOP(面向切面编程)了：将相同逻辑的重复代码横向抽取出来，使用动态代理技术将这些重复代码织入到目标对象方法中，实现和原来一样的功能。 这样一来，我们就在写业务时只关心业务代码，而不用关心与业务无关的代码 AOP的实现者AOP除了有Spring AOP实现外，还有著名的AOP实现者：AspectJ，也有可能大家没听说过的实现者：JBoss AOP~~ 我们下面来说说AspectJ扩展一下知识面： AspectJ是语言级别的AOP实现，扩展了Java语言，定义了AOP语法，能够在编译期提供横切代码的织入，所以它有专门的编译器用来生成遵守Java字节码规范的Class文件。 而Spring借鉴了AspectJ很多非常有用的做法，融合了AspectJ实现AOP的功能。但Spring AOP本质上底层还是动态代理，所以Spring AOP是不需要有专门的编辑器的~ AOP的术语嗯，AOP搞了好几个术语出来~~两本书都有讲解这些术语，我会尽量让大家看得明白的： 连接点(Join point)： 能够被拦截的地方：Spring AOP是基于动态代理的，所以是方法拦截的。每个成员方法都可以称之为连接点~ 切点(Poincut)： 具体定位的连接点：上面也说了，每个方法都可以称之为连接点，我们具体定位到某一个方法就成为切点。 增强/通知(Advice)： 表示添加到切点的一段逻辑代码，并定位连接点的方位信息。 简单来说就定义了是干什么的，具体是在哪干 Spring AOP提供了5种Advice类型给我们：前置、后置、返回、异常、环绕给我们使用！ 织入(Weaving)： 将增强/通知添加到目标类的具体连接点上的过程。 引入/引介(Introduction)： 引入/引介允许我们向现有的类添加新方法或属性。是一种特殊的增强！ 切面(Aspect)： 切面由切点和增强/通知组成，它既包括了横切逻辑的定义、也包括了连接点的定义。 在《Spring 实战 (第4版)》给出的总结是这样子的： 通知/增强包含了需要用于多个应用对象的横切行为；连接点是程序执行过程中能够应用通知的所有点；切点定义了通知/增强被应用的具体位置。其中关键的是切点定义了哪些连接点会得到通知/增强。 总的来说： 这些术语可能翻译过来不太好理解，但对我们正常使用AOP的话影响并没有那么大~~看多了就知道它是什么意思了。 Spring对AOP的支持Spring提供了3种类型的AOP支持： 基于代理的经典SpringAOP 需要实现接口，手动创建代理 纯POJO切面 使用XML配置，aop命名空间 @AspectJ 注解驱动的切面 使用注解的方式，这是最简洁和最方便的！ 基于代理的经典SpringAOP这部分配置比较麻烦，用起来也很麻烦，这里我就主要整理一下书上的内容，大家看看了解一下吧，我们实际上使用Spring AOP基本不用这种方式了！ 首先，我们来看一下增强接口的继承关系图： 可以分成五类增强的方式： Spring提供了六种的切点类型： 切面类型主要分成了三种： 一般切面 切点切面 引介/引入切面 一般切面，切点切面，引介/引入切面介绍： 对于切点切面我们一般都是直接用就好了，我们来看看引介/引入切面是怎么一回事： 引介/引入切面是引介/引入增强的封装器，通过引介/引入切面，可以更容易地为现有对象添加任何接口的实现！ 继承关系图： 引介/引入切面有两个实现类： DefaultIntroductionAdvisor：常用的实现类 DeclareParentsAdvisor：用于实现AspectJ语言的DeclareParent注解表示的引介/引入切面 实际上，我们使用AOP往往是Spring内部使用BeanPostProcessor帮我们创建代理。 这些代理的创建器可以分成三类： 基于Bean配置名规则的自动代理创建器：BeanNameAutoProxyCreator 基于Advisor匹配机制的自动代理创建器：它会对容器所有的Advisor进行扫描，实现类为DefaultAdvisorAutoProxyCreator 基于Bean中的AspectJ注解标签的自动代理创建器：AnnotationAwareAspectJAutoProxyCreator 对应的类继承图： 嗯，基于代理的经典SpringAOP就讲到这里吧，其实我是不太愿意去写这个的，因为已经几乎不用了，在《Spring 实战 第4版》也没有这部分的知识点了。 但是通过这部分的知识点可以更加全面地认识Spring AOP的各种接口吧~ 拥抱基于注解和命名空的AOP编程Spring在新版本中对AOP功能进行了增强，体现在这么几个方面： 在XML配置文件中为AOP提供了aop命名空间 增加了AspectJ切点表达式语言的支持 可以无缝地集成AspectJ 那我们使用@AspectJ来玩AOP的话，学什么？？其实也就是上面的内容，学如何设置切点、创建切面、增强的内容是什么… 具体的切点表达式使用还是前往：Spring【AOP模块】就这么简单看吧~~ 对应的增强注解： 使用引介/引入功能实现为Bean引入新方法其实前置啊、后置啊这些很容易就理解了，整篇文章看下来就只有这个引介/引入切面有点搞头。于是我们就来玩玩吧~ 我们来看一下具体的用法吧，现在我有个服务员的接口： 12345678public interface Waiter &#123; // 向客人打招呼 void greetTo(String clientName); // 服务 void serveTo(String clientName);&#125; 一位年轻服务员实现类： 1234567891011public class NaiveWaiter implements Waiter &#123; public void greetTo(String clientName) &#123; System.out.println("NaiveWaiter:greet to " + clientName + "..."); &#125; @NeedTest public void serveTo(String clientName) &#123; System.out.println("NaiveWaiter:serving " + clientName + "..."); &#125;&#125; 现在我想做的就是：想这个服务员可以充当售货员的角色，可以卖东西！当然了，我肯定不会加一个卖东西的方法到Waiter接口上啦，因为这个是暂时的~ 所以，我搞了一个售货员接口： 12345public interface Seller &#123; // 卖东西 int sell(String goods, String clientName);&#125; 一个售货员实现类： 123456789public class SmartSeller implements Seller &#123; // 卖东西 public int sell(String goods,String clientName) &#123; System.out.println("SmartSeller: sell "+goods +" to "+clientName+"..."); return 100; &#125; &#125; 此时，我们的类图是这样子的： 现在我想干的就是：借助AOP的引入/引介切面，来让我们的服务员也可以卖东西！ 我们的引入/引介切面具体是这样干的： 12345678@Aspectpublic class EnableSellerAspect &#123; @DeclareParents(value = "com.smart.NaiveWaiter", // 指定服务员具体的实现 defaultImpl = SmartSeller.class) // 售货员具体的实现 public Seller seller; // 要实现的目标接口 &#125; 写了这个切面类会发生什么？？ 切面技术将SmartSeller融合到NaiveWaiter中，这样NaiveWaiter就实现了Seller接口！！！！ 是不是很神奇？？我也觉得很神奇啊，我们来测试一下： 我们的bean.xml文件很简单： 12345678910&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd"&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;bean id="waiter" class="com.smart.NaiveWaiter"/&gt; &lt;bean class="com.smart.aspectj.basic.EnableSellerAspect"/&gt;&lt;/beans&gt; 测试一下： 1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext("com/smart/aspectj/basic/beans.xml"); Waiter waiter = (Waiter) ctx.getBean("waiter"); // 调用服务员原有的方法 waiter.greetTo("Java3y"); waiter.serveTo("Java3y"); // 通过引介/引入切面已经将waiter服务员实现了Seller接口，所以可以强制转换 Seller seller = (Seller) waiter; seller.sell("水军", "Java3y"); &#125;&#125; 具体的调用过程是这样子的： 当引入接口方法被调用时，代理对象会把此调用委托给实现了新接口的某个其他对象。实际上，一个Bean的实现被拆分到多个类中 总结看起来AOP有很多很多的知识点，其实我们只要记住AOP的核心概念就行啦。 下面是我的简要总结AOP： AOP的底层实际上是动态代理，动态代理分成了JDK动态代理和CGLib动态代理。如果被代理对象没有接口，那么就使用的是CGLIB代理(也可以直接配置使用CBLib代理) 如果是单例的话，那我们最好使用CGLib代理，因为CGLib代理对象运行速度要比JDK的代理对象要快 AOP既然是基于动态代理的，那么它只能对方法进行拦截，它的层面上是方法级别的 无论经典的方式、注解方式还是XML配置方式使用Spring AOP的原理都是一样的，只不过形式变了而已。一般我们使用注解的方式使用AOP就好了。 注解的方式使用Spring AOP就了解几个切点表达式，几个增强/通知的注解就完事了，是不是贼简单…使用XML的方式和注解其实没有很大的区别，很快就可以上手啦。 引介/引入切面也算是一个比较亮的地方，可以用代理的方式为某个对象实现接口，从而能够使用借口下的方法。这种方式是非侵入式的~ 要增强的方法还可以接收与被代理方法一样的参数、绑定被代理方法的返回值这些功能… 最后，将我们上一次IOC的思维导图补充AOP的知识点上去吧~ 参考 Spring【AOP模块】就是这么简单]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpring%EF%BC%9AIOC%2F</url>
    <content type="text"><![CDATA[什么是IOC提出问题IOC的理论背景 我们知道在面向对象设计的软件系统中，它的底层都是由N个对象构成的，各个对象之间通过相互合作，最终实现系统地业务逻辑。 图1 软件系统中耦合的对象 如果我们打开机械式手表的后盖，就会看到与上面类似的情形，各个齿轮分别带动时针、分针和秒针顺时针旋转，从而在表盘上产生正确的时间。图1中描述的就是这样的一个齿轮组，它拥有多个独立的齿轮，这些齿轮相互啮合在一起，协同工作，共同完成某项任务。我们可以看到，在这样的齿轮组中，如果有一个齿轮出了问题，就可能会影响到整个齿轮组的正常运转。 齿轮组中齿轮之间的啮合关系,与软件系统中对象之间的耦合关系非常相似。对象之间的耦合关系是无法避免的，也是必要的，这是协同工作的基础。现在，伴随着工业级应用的规模越来越庞大，对象之间的依赖关系也越来越复杂，经常会出现对象之间的多重依赖性关系，因此，架构师和设计师对于系统的分析和设计，将面临更大的挑战。对象之间耦合度过高的系统，必然会出现牵一发而动全身的情形。 图2 对象之间的依赖关系 耦合关系不仅会出现在对象与对象之间，也会出现在软件系统的各模块之间，以及软件系统和硬件系统之间。如何降低系统之间、模块之间和对象之间的耦合度，是软件工程永远追求的目标之一。为了解决对象之间的耦合度过高的问题，软件专家Michael Mattson 1996年提出了IOC理论，用来实现对象之间的“解耦”，目前这个理论已经被成功地应用到实践当中。 为什么要用（作用）IOC使得对象只需要发挥自己的特长即可 让你脱离对依赖对象的维护，只需要随用随取，不需要关心依赖对象的任何过程。（是不是感觉特别简单） 应用场景基础概述什么是IOCIOC是Inversion of Control的缩写，多数书籍翻译成“控制反转”。 1996年，Michael Mattson在一篇有关探讨面向对象框架的文章中，首先提出了IOC 这个概念。对于面向对象设计及编程的基本思想，前面我们已经讲了很多了，不再赘述，简单来说就是把复杂系统分解成相互合作的对象，这些对象类通过封装以后，内部实现对外部是透明的，从而降低了解决问题的复杂度，而且可以灵活地被重用和扩展。 IOC理论提出的观点大体是这样的：借助于“第三方”实现具有依赖关系的对象之间的解耦。如下图： ​ 图3 IOC解耦过程 大家看到了吧，由于引进了中间位置的“第三方”，也就是IOC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了，全部对象的控制权全部上缴给“第三方”IOC容器，所以，IOC容器成了整个系统的关键核心，它起到了一种类似“粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个“粘合剂”，对象与对象之间会彼此失去联系，这就是有人把IOC容器比喻成“粘合剂”的由来。 我们再来做个试验：把上图中间的IOC容器拿掉，然后再来看看这套系统： ​ 图4 拿掉IOC容器后的系统 我们现在看到的画面，就是我们要实现整个系统所需要完成的全部内容。这时候，A、B、C、D这4个对象之间已经没有了耦合关系，彼此毫无联系，这样的话，当你在实现A的时候，根本无须再去考虑B、C和D了，对象之间的依赖关系已经降低到了最低程度。所以，如果真能实现IOC容器，对于系统开发而言，这将是一件多么美好的事情，参与开发的每一成员只要实现自己的类就可以了，跟别人没有任何关系！ 我们再来看看，控制反转(IOC)到底为什么要起这么个名字？我们来对比一下： 软件系统在没有引入IOC容器之前，如图1所示，对象A依赖于对象B，那么对象A在初始化或者运行到某一点的时候，自己必须主动去创建对象B或者使用已经创建的对象B。无论是创建还是使用对象B，控制权都在自己手上。 软件系统在引入IOC容器之后，这种情形就完全改变了，如图3所示，由于IOC容器的加入，对象A与对象B之间失去了直接联系，所以，当对象A运行到需要对象B的时候，IOC容器会主动创建一个对象B注入到对象A需要的地方。 通过前后的对比，我们不难看出来：对象A获得依赖对象B的过程,由主动行为变为了被动行为，控制权颠倒过来了，这就是“控制反转”这个名称的由来。 Spring IOCIOC为控制反转，把传统意义上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。由容器动态地将某种依赖关系注入到组件中 什么是IOC容器Spring 框架的核心是 Spring 容器。容器创建对象，将它们装配在一起，配置它们并管理它们的完整生命周期。Spring 容器使用依赖注入来管理组成应用程序的组件。容器通过读取提供的配置元数据来接收对象进行实例化，配置和组装的指令。该元数据可以通过 XML，Java 注解或 Java 代码提供。 IOC容器支持加载服务时的饿汉式初始化和懒加载。 Spring实现spring的IOC容器种类 BeanFactory - BeanFactory 就像一个包含 bean 集合的工厂类。它会在客户端要求时实例化 bean。 ApplicationContext - ApplicationContext 接口扩展了 BeanFactory 接口。它在 BeanFactory 基础上提供了一些额外的功能。 BeanFactory ApplicationContext 它使用懒加载 它使用即时加载 它使用语法显式提供资源对象 它自己创建和管理资源对象 不支持国际化 支持国际化 不支持基于依赖的注解 支持基于依赖的注解 IOC也叫依赖注入(DI)2004年，Martin Fowler探讨了同一个问题，既然IOC是控制反转，那么到底是“哪些方面的控制被反转了呢？”，经过详细地分析和论证后，他得出了答案：“获得依赖对象的过程被反转了”。控制被反转之后，获得依赖对象的过程由自身管理变为了由IOC容器主动注入。于是，他给“控制反转”取了一个更合适的名字叫做“依赖注入（Dependency Injection）”。他的这个答案，实际上给出了实现IOC的方法：注入。所谓依赖注入，就是由IOC容器在运行期间，动态地将某种依赖关系注入到对象之中。 所以，依赖注入(DI)和控制反转(IOC)是从不同的角度的描述的同一件事情，就是指通过引入IOC容器，利用依赖关系注入的方式，实现对象之间的解耦。 学过IOC的人可能都看过Martin Fowler(老马,2004年post)的这篇文章：Inversion of Control Containers and the Dependency Injection pattern[2]。 博客园的园友EagleFish(邢瑜琨)的文章： 深度理解依赖注入（Dependence Injection）[3]对老马那篇经典文章进行了解读。 CSDN黄忠成的Inside ObjectBuilder[4]也是，不过他应该来自台湾省，用的是繁体，看不管繁体中文的，可以看园中的吕震宇博友的简体中文版[转]Object Builder Application Block[5] 。 基础优缺优点 它将最小化应用程序中的代码量。 它将使您的应用程序易于测试，因为它不需要单元测试用例中的任何单例或 JNDI 查找机制。 它以最小的影响和最少的侵入机制促进松耦合。 它支持即时的实例化和延迟加载服务。 缺点 使用IOC框架产品能够给我们的开发过程带来很大的好处，但是也要充分认识引入IOC框架的缺点，做到心中有数，杜绝滥用框架[1]。 软件系统中由于引入了第三方IOC容器，生成对象的步骤变得有些复杂，本来是两者之间的事情，又凭空多出一道手续，所以，我们在刚开始使用IOC框架的时候，会感觉系统变得不太直观。所以，引入了一个全新的框架，就会增加团队成员学习和认识的培训成本，并且在以后的运行维护中，还得让新加入者具备同样的知识体系。 由于IOC容器生成对象是通过反射方式，在运行效率上有一定的损耗。如果你要追求运行效率的话，就必须对此进行权衡。 具体到IOC框架产品(比如：Spring)来讲，需要进行大量的配制工作，比较繁琐，对于一些小的项目而言，客观上也可能加大一些工作成本。 IOC框架产品本身的成熟度需要进行评估，如果引入一个不成熟的IOC框架产品，那么会影响到整个项目，所以这也是一个隐性的风险。 我们大体可以得出这样的结论： 一些工作量不大的项目或者产品，不太适合使用IOC框架产品。 如果团队成员的知识能力欠缺，对于IOC框架产品缺乏深入的理解，也不要贸然引入。 最后，特别强调运行效率的项目或者产品，也不太适合引入IOC框架产品，像WEB2.0网站就是这种情况。 实现IOC的技术实现方式 构造函数注入 setter注入 接口注入 实现步骤Spring 中的 IoC 的实现原理就是工厂模式加反射机制。 通过反射创造实例 获取需要注入的接口实现类并将其赋值给该接口 示例1234567891011121314151617181920212223242526272829303132interface Fruit &#123; public abstract void eat();&#125;class Apple implements Fruit &#123; public void eat()&#123; System.out.println("Apple"); &#125;&#125;class Orange implements Fruit &#123; public void eat()&#123; System.out.println("Orange"); &#125;&#125;class Factory &#123; public static Fruit getInstance(String ClassName) &#123; Fruit f=null; try &#123; f=(Fruit)Class.forName(ClassName).newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return f; &#125;&#125;class Client &#123; public static void main(String[] a) &#123; Fruit f=Factory.getInstance("io.github.dunwu.spring.Apple"); if(f!=null)&#123; f.eat(); &#125; &#125;&#125; 底层原理Spring 中的 IOC的实现原理就是工厂模式加反射机制。 IOC中最基本的技术就是“反射(Reflection)”编程，目前.Net C#、Java和PHP5等语言均支持，其中PHP5的技术书籍中，有时候也被翻译成“映射”。有关反射的概念和用法，大家应该都很清楚，通俗来讲就是根据给出的类名（字符串方式）来动态地生成对象。这种编程方式可以让对象在生成时才决定到底是哪一种对象。反射的应用是很广泛的，很多的成熟的框架，比如象Java中的Hibernate、Spring框架，.Net中 NHibernate、Spring.Net框架都是把“反射”做为最基本的技术手段。 IOC容器的实现需要实现的两个关键技术， 以明确服务的对象是谁、需要为服务对象提供什么样的服务 对象的构建 对象的绑定 实现方式 硬编码 配置文件 注解 BeanFactory如果没有特殊指定，默认采用延迟初始化策略(lazy-load)。只有当客户端对象需要访问容器中的某个受管对象的时候，才对该受管对象进行初始化以及依赖注入操作。所以，相对来说，容器启动初期速度较快，所需 要的资源有限。对于资源有限，并且功能要求不是很严格的场景，BeanFactory是比较合适的 IoC容器选择。 我们先来看一下BeanFactory类的关系图（如下所示） BeanDefinition 实现Bean的定义（即对象的定义）,且完成了对依赖的定义 BeanDefinitionRegistry ，将定义好的bean，注册到容器中（此时会生成一个注册码） BeanFactory 是一个bean工厂类，从中可以取到任意定义过的bean 最重要的部分就是BeanDefinition,它完成了Bean的生成过程。一般情况下我们都是通过配置文件（xml,properties）的方式对bean进行配置，每种文件都需要实现BeanDefinitionReader，因此是reader本身现了配置文字 到bean对象的转换过程。当然我们自己也可以实现任意格式的配置文件，只需要自己来实现reader即可。 Bean的生成大致可以分为两个阶段：容器启动阶段和bean实例化阶段 容器启动阶段： 只完成bean的定义 加载配置文件（通常是xml文件） 通过reader生成beandefinition beanDefinition注册到beanDefinitionRegistry bean实例化阶段： 完成bean的初始化 当某个bean 被 getBean()调用时 bean需要完成初时化，以及其依赖对象的初始化 如果bean本身有回调，还需要调用其相应的回调函数 Spring Ioc在初始化完成之后，给了我们提供一些方法，让我们来改变一些bean的定义org.springframework.beans.factory.config.PropertyPlaceholderConfigurer：使我们可能通过配置文件的形式，配置一些参数 PropertyOverrideConfigurer ：则可以覆盖原本的bean参数 CustomEditorConfigurer ：则提供类型转换支持（配置文件都是string,它需要知道转换成何种类型） Bean的初始化过程： 如果你认为实例化的对象就是通过我们定义的类new 出来的，那就大错特错了，其实这里用到了AOP机制，生成了其代理对象（通过反射机制生成接口对象，或者是通过CGLIB生成子对象） bean的具体装载过程是由beanWrapper实现的，它继承了PropertyAccessor （可以对属性进行访问）、PropertyEditorRegistry 和TypeConverter接口 （实现类型转换，就上前面说的）。 完成设置对象属性之后，则会检查是否实现了Aware类型的接口，如果实现了，则主动加载 BeanPostprocessor 可以帮助完成在初始化bean之前或之后 帮我们完成一些必要工作，比如我们在连接数据库之前将密码存放在一个加密文件，当我们连接数据库之前，需要将密码进行加载解密。只要实现 相应的接口即可 123456789101112131415161718192021222324252627282930313233343536373839public interface BeanPostProcessor &#123; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; if * &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; if * &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 在完成postProcessor之后，则会看对象是否定义了InitializingBean 接口，如果是，则会调用其afterProper- tiesSet()方法进一步调整对象实例的状态 ，这种方式并不常见。spring还提供了另外一种指定初始化的方式，即在bean定义中指定init-method 。 当这一切完成之后，还可以指定对象销毁 的一些回调，比如数据库的连接池的配置，则销毁前需要关闭连接等。相应的可以实现DisposableBean 接口或指定destroy-method ApplicationContextApplicationContext 容器建立BeanFactory之上，拥有BeanFactory的所有功能，但在实现上会有所差别。 我认为差别主要体现在两个方面： bean的生成方式； 扩展了BeanFactory的功能，提供了更多企业级功能的支持。 ApplicationContext采用的非懒加载方式。它会在启动阶段完成所有的初始化，并不会等到getBean()才执行 所以，相对于BeanFactory来 说，ApplicationContext要求更多的系统资源，同时，因为在启动时就完成所有初始化，容 器启动时间较之BeanFactory也会长一些。在那些系统资源充足，并且要求更多功能的场景中， ApplicationContext类型的容器是比较合适的选择。 bean的加载方式 BeanFactory提供BeanReader来从配置文件中读取bean配置。相应的ApplicationContext也提供几个读取配置文件的方式： FileSystemXmlApplicationContext：该容器从 XML 文件中加载已被定义的 bean。在这里，你需要提供给构造器 XML 文件的完整路径 ClassPathXmlApplicationContext：该容器从 XML 文件中加载已被定义的 bean。在这里，你不需要提供 XML 文件的完整路径，只需正确配置 CLASSPATH 环境变量即可，因为，容器会从 CLASSPATH 中搜索 bean 配置文件。 WebXmlApplicationContext：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。 AnnotationConfigApplicationContext ConfigurableWebApplicationContext ApplicationContext 还额外增加了三个历能： ApplicationEventPublisher ResourceLoader MessageResource ResourceLoaderResourceLoader并不能将其看成是Spring独有的功能，spring Ioc只是借助于ResourceLoader来实现资源加载。也提供了各种各样的资源加载方式： DefaultResourceLoader 首先检查资源路径是否以classpath:前缀打头，如果是，则尝试构造ClassPathResource类 型资源并返回。否则， 尝试通过URL，根据资源路径来定位资源 FileSystemResourceLoader 它继承自Default-ResourceLoader，但覆写了getResourceByPath(String)方法，使之从文件系统加载资源并以 FileSystemResource类型返回 ResourcePatternResolver 批量查找的ResourceLoader spring与ResourceLoader之间的关系 所有ApplicationContext的具体实现类都会直接或者间接地实现AbstractApplicationContext,AbstactApplicationContext 依赖了了DeffaultResourceLoader, ApplicationContext 继承了ResourcePatternResolver,所到头来ApplicationContext的具体实现类都会具有DefaultResourceLoader 和 PathMatchingResourcePatterResolver的功能。这也就是会什么ApplicationContext可以实现统一资源定位。 ApplicationEventPublisher（在介绍spring事件的时候再详细讲） ApplicationEvent：继承自EventObject，同时是spring的application中事件的父类，需要被自定义的事件继承。 ApplicationListener：继承自EventListener，spring的application中的监听器必须实现的接口，需要被自定义的监听器实现其onApplicationEvent方法 ApplicationEventPublisherAware：在spring的context中希望能发布事件的类必须实现的接口，该接口中定义了设置ApplicationEventPublisher的方法，由ApplicationContext调用并设置。在自己实现的ApplicationEventPublisherAware子类中，需要有ApplicationEventPublisher属性的定义。 ApplicationEventPublisher：spring的事件发布者接口，定义了发布事件的接口方法publishEvent。因为ApplicationContext实现了该接口，因此spring的ApplicationContext实例具有发布事件的功能(publishEvent方法在AbstractApplicationContext中有实现)。在使用的时候，只需要把ApplicationEventPublisher的引用定义到ApplicationEventPublisherAware的实现中，spring容器会完成对ApplicationEventPublisher的注入。 MessageSource 提供国际化支持，不讲了，有需要请转至：blog.sina.com.cn/s/blog_85d7… # 四、最佳实践注解扫描 1234567891011&lt;beans xmlns="http://www.springframework.org/schema/beans"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xmlns:context="http://www.springframework.org/schema/context"xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-2.5.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-2.5.xsd"&gt;&lt;context:component-scan base-package="org.spring21"/&gt;&lt;/beans&gt; component/service/controller注解 123456789@Componentpublic class Person &#123; @Resource private Food food; public void setFood(Food food) &#123; this.food = food; &#125;&#125; bean的前置后置 12345678910111213141516171819@Componentpublic class Person &#123; @Resource private Food food; public setFood(Food food) &#123; this.food = food; &#125; @PostConstruct public void wash() &#123; System.out.println("饭前洗手"); &#125; @PreDestroy public void brush() &#123; System.out.println("饭后刷牙"); &#125;&#125; IOC容器的初始化过程Resource 定位：我们一般使用外部资源来描述 Bean 对象，所以 IOC 容器第一步就是需要定位 Resource 外部资源 。Resource 的定位其实就是 BeanDefinition 的资源定位，它是由 ResourceLoader 通过统一的 Resource 接口来完成的，这个 Resource 对各种形式的 BeanDefinition 的使用都提供了统一接口 。 载入：第二个过程就是 BeanDefinition 的载入 ,BeanDefinitionReader 读取 , 解析 Resource 定位的资源，也就是将用户定义好的 Bean 表示成 IOC 容器的内部数据结构也就是 BeanDefinition, 在 IOC 容器内部维护着一个 BeanDefinition Map 的数据结构，通过这样的数据结构， IOC 容器能够对 Bean 进行更好的管理 。 在配置文件中每一个都对应着一个 BeanDefinition 对象 。 注册：第三个过程则是注册，即向 IOC 容器注册这些 BeanDefinition ，这个过程是通过 BeanDefinitionRegistery 接口来实现的 。 设计思想进阶深度理解依赖注入（Dependence Injection）依赖在哪里 老马举了一个小例子，是开发一个电影列举器（MovieList），这个电影列举器需要使用一个电影查找器（MovieFinder）提供的服务，伪码如下： 1234567891011121314151617181920212223242526272829/*服务的接口*/public interface MovieFinder &#123; ArrayList findAll();&#125;/*服务的消费者*/class MovieLister&#123; public Movie[] moviesDirectedBy(String arg) &#123; List allMovies = finder.findAll(); for (Iterator it = allMovies.iterator(); it.hasNext();) &#123; Movie movie = (Movie) it.next(); if (!movie.getDirector().equals(arg)) it.remove(); &#125; return (Movie[]) allMovies.toArray(new Movie[allMovies.size()]); &#125;/*消费者内部包含一个将指向具体服务类型的实体对象*/ private MovieFinder finder; /*消费者需要在某一个时刻去实例化具体的服务。这是我们要解耦的关键所在， *因为这样的处理方式造成了服务消费者和服务提供者的强耦合关系（这种耦合是在编译期就确定下来的）。 **/ public MovieLister() &#123; finder = new ColonDelimitedMovieFinder("movies1.txt"); &#125;&#125; 从上面代码的注释中可以看到，MovieLister和ColonDelimitedMovieFinder（这可以使任意一个实现了MovieFinder接口的类型）之间存在强耦合关系，如下图所示： 这使得MovieList很难作为一个成熟的组件去发布，因为在不同的应用环境中（包括同一套软件系统被不同用户使用的时候），它所要依赖的电影查找器可能是千差万别的。所以，为了能实现真正的基于组件的开发，必须有一种机制能同时满足下面两个要求： （1）解除MovieList对具体MoveFinder类型的强依赖（编译期依赖）。 （2）在运行的时候为MovieList提供正确的MovieFinder类型的实例。 换句话说，就是在运行的时候才产生MovieList和MovieFinder之间的依赖关系（把这种依赖关系在一个合适的时候“注入”运行时），这恐怕就是Dependency Injection这个术语的由来。再换句话说，我们提到过解除强依赖，这并不是说MovieList和MovieFinder之间的依赖关系不存在了，事实上MovieList无论如何也需要某类MovieFinder提供的服务，我们只是把这种依赖的建立时间推后了，从编译器推迟到运行时了。 依赖关系在OO程序中是广泛存在的，只要A类型中用到了B类型实例，A就依赖于B。前面笔者谈到的内容是把概念抽象到了服务使用者和服务提供者的角度，这也符合现在SOA的设计思路。从另一种抽象方式上来看，可以把MovieList看成我们要构建的主系统，而MovieFinder是系统中的plugin，主系统并不强依赖于任何一个插件，但一旦插件被加载，主系统就应该可以准确调用适当插件的功能。 其实不管是面向服务的编程模式，还是基于插件的框架式编程，为了实现松耦合（服务调用者和提供者之间的or框架和插件之间的），都需要在必要的位置实现面向接口编程，在此基础之上，还应该有一种方便的机制实现具体类型之间的运行时绑定，这就是DI所要解决的问题。 DI的实现方式和上面的图1对应的是，如果我们的系统实现了依赖注入，组件间的依赖关系就变成了图2： 说白了，就是要提供一个容器，由容器来完成（1）具体ServiceProvider的创建（2）ServiceUser和ServiceProvider的运行时绑定。下面我们就依次来看一下三种典型的依赖注入方式的实现。特别要说明的是，要理解依赖注入的机制，关键是理解容器的实现方式。本文后面给出的容器参考实现，均为黄忠成老师的代码，笔者仅在其中加上了一些关键注释而已。 Constructor Injection（构造器注入） 我们可以看到，在整个依赖注入的数据结构中，涉及到的重要的类型就是ServiceUser, ServiceProvider和Assembler三者，而这里所说的构造器，指的是ServiceUser的构造器。也就是说，在构造ServiceUser实例的时候，才把真正的ServiceProvider传给他： 12345678class MovieLister&#123; //其他内容，省略 public MovieLister(MovieFinder finder) &#123; this.finder = finder; &#125;&#125; 接下来我们看看Assembler应该如何构建： 12345678910111213141516private MutablePicoContainer configureContainer() &#123; MutablePicoContainer pico = new DefaultPicoContainer();//下面就是把ServiceProvider和ServiceUser都放入容器的过程，以后就由容器来提供ServiceUser的已完成依赖注入实例，//其中用到的实例参数和类型参数一般是从配置档中读取的，这里是个简单的写法。//所有的依赖注入方法都会有类似的容器初始化过程，本文在后面的小节中就不再重复这一段代码了。 Parameter[] finderParams = &#123;new ConstantParameter("movies1.txt")&#125;; pico.registerComponentImplementation(MovieFinder.class, ColonMovieFinder.class, finderParams); pico.registerComponentImplementation(MovieLister.class); //至此，容器里面装入了两个类型，其中没给出构造参数的那一个（MovieLister）将依靠其在构造器中定义的传入参数类型，在容器中 //进行查找，找到一个类型匹配项即可进行构造初始化。 return pico;&#125; 需要在强调一下的是，依赖并未消失，只是延后到了容器被构建的时刻。所以正如图2中您已经看到的，容器本身（更准确的说，是一个容器运行实例的构建过程）对ServiceUser和ServiceProvoder都是存在依赖关系的。所以，在这样的体系结构里，ServiceUser、ServiceProvider和容器都是稳定的，互相之间也没有任何依赖关系；所有的依赖关系、所有的变化都被封装进了容器实例的创建过程里，符合我们对服务应用的理解。而且，在实际开发中我们一般会采用配置文件来辅助容器实例的创建，将这种变化性排斥到编译期之外。 即使还没给出后面的代码，你也一定猜得到，这个container类一定有一个GetInstance(Type t)这样的方法，这个方法会为我们返回一个已经注入完毕的MovieLister。 一个简单的应用如下： 1234567public void testWithPico() &#123; MutablePicoContainer pico = configureContainer(); MovieLister lister = (MovieLister) pico.getComponentInstance(MovieLister.class); Movie[] movies = lister.moviesDirectedBy("Sergio Leone"); assertEquals("Once Upon a Time in the West", movies[0].getTitle());&#125; 上面最关键的就是对pico.getComponentInstance的调用。Assembler会在这个时候调用MovieLister的构造器，构造器的参数就是当时通过pico.registerComponentImplementation(MovieFinder.class, ColonMovieFinder.class, finderParams)设置进去的实际的ServiceProvider–ColonMovieFinder。下面请看这个容器的参考代码： Setter Injection（设值注入） 这种注入方式和构造注入实在很类似，唯一的区别就是前者在构造函数的调用过程中进行注入，而它是通过给属性赋值来进行注入。无怪乎PicoContainer和Spring都是同时支持这两种注入方式。Spring对通过XML进行配置有比较好的支持，也使得Spring中更常使用设值注入的方式： 123456789101112 &lt;beans&gt; &lt;bean id="MovieLister" class="spring.MovieLister"&gt; &lt;property name="finder"&gt; &lt;ref local="MovieFinder"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="MovieFinder" class="spring.ColonMovieFinder"&gt; &lt;property name="filename"&gt; &lt;value&gt;movies1.txt&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 下面也给出支持设值注入的容器参考实现，大家可以和构造器注入的容器对照起来看，里面的差别很小，主要的差别就在于，在获取对象实例（GetInstance）的时候，前者是通过反射得到待创建类型的构造器信息，然后根据构造器传入参数的类型在容器中进行查找，并构造出合适的实例；而后者是通过反射得到待创建类型的所有属性，然后根据属性的类型在容器中查找相应类型的实例。 Interface Injection (接口注入) 这是笔者认为最不够优雅的一种依赖注入方式。要实现接口注入，首先ServiceProvider要给出一个接口定义： 123public interface InjectFinder &#123; void injectFinder(MovieFinder finder);&#125; 接下来，ServiceUser必须实现这个接口： 123456class MovieLister: InjectFinder&#123; public void injectFinder(MovieFinder finder) &#123; this.finder = finder; &#125;&#125; 容器所要做的，就是根据接口定义调用其中的inject方法完成注入过程，这里就不在赘述了，总的原理和上面两种依赖注入模式没有太多区别。 除了DI，还有Service Locator上面提到的依赖注入只是消除ServiceUser和ServiceProvider之间的依赖关系的一种方法，还有另一种方法：服务定位器（Service Locator）。也就是说，由ServiceLocator来专门负责提供具体的ServiceProvider。当然，这样的话ServiceUser不仅要依赖于服务的接口，还依赖于ServiceContract。仍然是最早提到过的电影列举器的例子，如果使用Service Locator来解除依赖的话，整个依赖关系应当如下图所示： 用起来也很简单，在一个适当的位置（比如在一组相关服务即将被调用之前）对ServiceLocator进行初始化，用到的时候就直接用ServiceLocator返回ServiceProvider实例： 123456789//服务定位器的初始化ServiceLocator locator = new ServiceLocator();locator.loadService("MovieFinder", new ColonMovieFinder("movies1.txt"));ServiceLocator.load(locator);//服务定义器的使用//其实这个使用方式体现了服务定位器和依赖注入模式的最大差别：ServiceUser需要显示的调用ServiceLocator，从而获取自己需要的服务对象；//而依赖注入则是隐式的由容器完成了这一切。MovieFinder finder = (MovieFinder) ServiceLocator.getService("MovieFinder"); 正因为上面提到过的ServiceUser对ServiceLocator的依赖性，从提高模块的独立性（比如说，你可能把你构造的ServiceUser或者ServiceProvider给第三方使用）上来说，依赖注入可能更好一些，这恐怕也是为什么大多数的IOC框架都选用了DI的原因。ServiceLocator最大的优点可能在于实现起来非常简单，如果您开发的应用没有复杂到需要采用一个IOC框架的程度，也许您可以试着采用它。 3.广义的服务文中很多地方提到服务使用者（ServiceUser）和服务提供者（ServiceProvider）的概念，这里的“服务”是一种非常广义的概念，在语法层面就是指最普通的依赖关系（类型A中有一个B类型的变量，则A依赖于B）。如果您把服务理解为WCF或者Web Service中的那种服务概念，您会发现上面所说的所有技术手段都是没有意义的。以WCF而论，其客户端和服务器端本就是依赖于Contract的松耦合关系，其实这也从另一个角度说明了SOA应用的优势所在。 反省总结参考 深度理解依赖注入（Dependence Injection） 浅谈IOC–说清楚IOC是什么 JAVA关于Spring 面试题汇总 IoC-spring 的灵魂(带你轻松理解IOC思想及bean对象的生成过程)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring：入门]]></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpring%EF%BC%9A%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring介绍Spring诞生： 创建Spring的目的就是用来替代更加重量级的的企业级Java技术 简化Java的开发 基于POJO轻量级和最小侵入式开发 通过依赖注入和面向接口实现松耦合 基于切面和惯例进行声明式编程 通过切面和模板*减少样板式代码 * 侵入式概念 侵入式框架 对于EJB、Struts2等一些传统的框架， 通常是要实现特定的接口，继承特定的类才能增强功能 改变了java类的结构 非侵入式 对于Hibernate、Spring等框架，对现有的类结构没有影响，就能够增强JavaBean的功能 松耦合 前面我们在写程序的时候，都是面向接口编程，通过DaoFactroy等方法来实现松耦合 DAO层和Service层通过DaoFactory来实现松耦合 如果Serivce层直接new DaoBook()，那么DAO和Service就紧耦合了【Service层依赖紧紧依赖于Dao】 而Spring给我们更加合适的方法来实现松耦合，并且更加灵活、功能更加强大！—-&gt;IOC控制反转 切面编程 切面编程也就是AOP编程，其实我们在之前也接触过…动态代理就是一种切面编程了… 当时我们使用动态代理+注解的方式给Service层的方法添加权限. 123456789101112131415161718192021222324252627@Override@permission("添加分类")/*添加分类*/public void addCategory(Category category) &#123; categoryDao.addCategory(category);&#125;/*查找分类*/@Overridepublic void findCategory(String id) &#123; categoryDao.findCategory(id);&#125;@Override@permission("查找分类")/*查看分类*/public List&lt;Category&gt; getAllCategory() &#123; return categoryDao.getAllCategory();&#125;/*添加图书*/@Overridepublic void addBook(Book book) &#123; bookDao.addBook(book);&#125; Controller调用Service的时候，Service返回的是一个代理对象 代理对象得到Controller想要调用的方法，通过反射来看看该方法上有没有注解 如果有注解的话，那么就判断该用户是否有权限来调用 此方法，如果没有权限，就抛出异常给Controller，Controller接收到异常，就可以提示用户没有权限了。 AOP编程可以简单理解成：在执行某些代码前，执行另外的代码 Struts2的拦截器也是面向切面编程【在执行Action业务方法之前执行拦截器】 Spring也为我们提供更好地方式来实现面向切面编程！ Spring概述Spring框架目标是简化Java企业级应用开发，并通过POJO为基础的编程模型促进良好的编程习惯。 Spring是分层的Java SE/EE应用一站式的轻量级开源框架，以IOC和AOP为内核，提供了展现层Spring MVC、持久层Spring JDBC以及业务层事务管理等一站式的企业级应用技术。 spring优点 轻量：Spring 是轻量的，基本的版本大约2MB。 方便解耦，简化开发。通过IOC容器，用户可以将对象间的依赖关系交由Spring进行控制，避免硬编码造成的过度耦合。 Ioc使得用户不必再为单例模式类、属性文件解析等底层需求编写代码，可以更专注于上层应用。 面向切面的编程(AOP)：Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开。 容器：Spring 包含并管理应用中对象的生命周期和配置。 MVC框架：Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品。 声明式事务的支持：Spring支持用户以声明的方式进行事务，Spring支持事务管理，提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA）。 异常处理：Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常。 Spring模块组成 Spring可以分为6大模块： Spring Core：Spring的核心功能： IOC容器, 解决对象创建及依赖关系。 Spring Web：Spring对web模块的支持。 1可以与struts整合,让struts的action创建交给spring 1spring mvc模式 Spring DAO：Spring 对jdbc操作的支持 【JdbcTemplate模板工具类】 Spring ORM：spring对orm的支持： 既可以与hibernate整合，【session】。 也可以使用spring的对hibernate操作的封装。 Spring AOP：切面编程。 SpringEE：spring 对javaEE其他模块的支持。 并且 核心容器 Core module Bean module Context module Expression Language module 数据集成/访问。提供与数据库交互的支持 JDBC module ORM module OXM module Java Messaging Service(JMS) module Transaction module Web应用程序的支持 Web module Web-Servlet module Web-Struts module Web-Portlet module AOP Instrumentation：类检测和类加载器支持 Test 杂项 Messaging Aspects 什么是 Spring 配置文件？Spring 配置文件是 XML 文件。该文件主要包含类信息。它描述了这些类是如何配置以及相互引入的。但是，XML 配置文件冗长且更加干净。如果没有正确规划和编写，那么在大项目中管理变得非常困难。 Spring 应用程序有哪些不同组件？Spring 应用一般有以下组件： 接口 - 定义功能。 Bean 类 - 它包含属性，setter 和 getter 方法，函数等。 Spring 面向切面编程（AOP） - 提供面向切面编程的功能。 Bean 配置文件 - 包含类的信息以及如何配置它们。 用户程序 - 它使用接口。 使用 Spring 有哪些方式？使用 Spring 有以下方式： 作为一个成熟的 Spring Web 应用程序。 作为第三方 Web 框架，使用 Spring Frameworks 中间层。 用于远程使用。 作为企业级 Java Bean，它可以包装现有的 POJO（Plain Old Java Objects）。 模块概述IOCSpring核心模块实现了IOC的功能，它将类与类之间的依赖从代码中脱离出来，用配置的方式进行依赖关系描述，由IOC容器负责依赖类间的创建、拼接、管理、获取等工作。 BeanFactory接口是Spring框架的核心接口，实现了容器的许多核心功能。 Context模块构建于核心模块上，扩展了BeanFactory的功能，添加了il8n国际化、Bean生命周期控制、框架事件体系、资源架子啊透明化等多项功能。并提供许多企业级服务的支持，如邮件服务、任务调度、JNDI获取、EJB集成、远程访问等，ApplicationContext是Context模块的核心接口。 引出Spring我们试着回顾一下没学Spring的时候，是怎么开发Web项目的 实体类—&gt;class User{ } daoclass–&gt; UserDao{ .. 访问**db} service—&gt;class UserService{ UserDao userDao = new UserDao();} actionclass UserAction{UserService userService = new UserService();} 用户访问： Tomcat-&gt;action-&gt;service-&gt;dao 我们来思考几个问题： ①：对象创建创建能否写死？ ②：对象创建细节 对象数量 1action 多个 【维护成员变量】 1service 一个 【不需要维护公共变量】 1dao 一个 【不需要维护公共变量】 创建时间 1action 访问时候创建 1service 启动时候创建 1dao 启动时候创建 ③：对象的依赖关系 action 依赖 service service依赖 dao 对于第一个问题和第三个问题，我们可以通过DaoFactory解决掉(虽然不是比较好的解决方法) 对于第二个问题，我们要控制对象的数量和创建事件就有点麻烦了…. 而Spring框架通过IOC就很好地可以解决上面的问题…. IOC控制反转Spring的核心思想之一：Inversion of Control , 控制反转 IOC 那么控制反转是什么意思呢？？？对象的创建交给外部容器完成，这个就做控制反转。 Spring使用控制反转来实现对象不用在程序中写死 控制反转解决对象处理问题【把对象交给别人创建】 那么对象的对象之间的依赖关系Spring是怎么做的呢？？依赖注入，dependency injection.即DI Spring使用依赖注入来实现对象之间的依赖关系 在创建完对象之后，对象的关系处理就是依赖注入 上面已经说了，控制反转是通过外部容器完成的，而Spring又为我们提供了这么一个容器，我们一般将这个容器叫做：IOC容器. 无论是创建对象、处理对象之间的依赖关系、对象创建的时间还是对象的数量，我们都是在Spring为我们提供的IOC容器上配置对象的信息就好了。 那么使用IOC控制反转这一思想有什么作用呢？？？我们来看看一些优秀的回答… 来自知乎：www.zhihu.com/question/23… 我摘取一下核心的部分： ioc的思想最核心的地方在于，资源不由使用资源的双方管理，而由不使用资源的第三方管理，这可以带来很多好处。第一，资源集中管理，实现资源的可配置和易管理。第二，降低了使用资源双方的依赖程度，也就是我们说的耦合度。 也就是说，甲方要达成某种目的不需要直接依赖乙方，它只需要达到的目的告诉第三方机构就可以了，比如甲方需要一双袜子，而乙方它卖一双袜子，它要把袜子卖出去，并不需要自己去直接找到一个卖家来完成袜子的卖出。它也只需要找第三方，告诉别人我要卖一双袜子。这下好了，甲乙双方进行交易活动，都不需要自己直接去找卖家，相当于程序内部开放接口，卖家由第三方作为参数传入。甲乙互相不依赖，而且只有在进行交易活动的时候，甲才和乙产生联系。反之亦然。这样做什么好处么呢，甲乙可以在对方不真实存在的情况下独立存在，而且保证不交易时候无联系，想交易的时候可以很容易的产生联系。甲乙交易活动不需要双方见面，避免了双方的互不信任造成交易失败的问题。因为交易由第三方来负责联系，而且甲乙都认为第三方可靠。那么交易就能很可靠很灵活的产生和进行了。这就是ioc的核心思想。生活中这种例子比比皆是，支付宝在整个淘宝体系里就是庞大的ioc容器，交易双方之外的第三方，提供可靠性可依赖可灵活变更交易方的资源管理中心。另外人事代理也是，雇佣机构和个人之外的第三方。 ==========================update=========================== 在以上的描述中，诞生了两个专业词汇，依赖注入和控制反转所谓的依赖注入，则是，甲方开放接口，在它需要的时候，能够将乙方传递进来(注入)所谓的控制反转，甲乙双方不相互依赖，交易活动的进行不依赖于甲乙任何一方，整个活动的进行由第三方负责管理。 参考优秀的博文①：www.tianmaying.com/tutorial/sp… 参考优秀的博文②：这里写链接内容 知乎@Intopass的回答： 不用自己组装，拿来就用。 享受单例的好处，效率高，不浪费空间。 便于单元测试，方便切换mock组件。 便于进行AOP操作，对于使用者是透明的。 统一配置，便于修改。 Spring事务事务的七种传播属性所谓事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。Spring支持以下7种事务传播行为。 传播行为 含义 PROPAGATION_REQUIRED（XML文件中为REQUIRED) 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。（如果被调用端发生异常，那么调用端和被调用端事务都将回滚） PROPAGATION_SUPPORTS(XML文件中为SUPPORTS） 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 PROPAGATION_MANDATORY(XML文件中为MANDATORY） 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 PROPAGATION_NESTED(XML文件中为NESTED) 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以独立于被封装的事务中进行提交或者回滚。如果封装事务存在，并且外层事务抛出异常回滚，那么内层事务必须回滚，反之，内层事务并不影响外层事务。如果封装事务不存在，则同PROPAGATION_REQUIRED的一样 PROPAGATION_NEVER（XML文件中为NEVER) 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 PROPAGATION_REQUIRES_NEW(XML文件中为REQUIRES_NEW） 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行。 PROPAGATION_NOT_SUPPORTED（XML文件中为NOT_SUPPORTED） 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 PROPAGATION_NESTED 与PROPAGATION_REQUIRES_NEW的区别:它们非常类似,都像一个嵌套事务，如果不存在一个活动的事务，都会开启一个新的事务。使用 PROPAGATION_REQUIRES_NEW时，内层事务与外层事务就像两个独立的事务一样，一旦内层事务进行了提交后，外层事务不能对其进行回滚。两个事务互不影响。两个事务不是一个真正的嵌套事务。同时它需要JTA事务管理器的支持。使用PROPAGATION_NESTED时，外层事务的回滚可以引起内层事务的回滚。而内层事务的异常并不会导致外层事务的回滚，它是一个真正的嵌套事务。DataSourceTransactionManager使用savepoint支持PROPAGATION_NESTED时，需要JDBC 3.0以上驱动及1.4以上的JDK版本支持。其它的JTATrasactionManager实现可能有不同的支持方式。PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 “内部” 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行。另一方面, PROPAGATION_NESTED 开始一个 “嵌套的” 事务, 它是已经存在事务的一个真正的子事务. 潜套事务开始执行时, 它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交。由此可见, PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED 的最大区别在于, PROPAGATION_REQUIRES_NEW 完全是一个新的事务, 而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 嵌套事务也会被 commit, 这个规则同样适用于 roll back.REQUIRED,REQUIRES_NEW,NESTED异同PROPAGATION_NESTED，这是一个嵌套事务,使用JDBC 3.0驱动时,仅仅支持DataSourceTransactionManager作为事务管理器。需要JDBC 驱动的java.sql.Savepoint类。使用PROPAGATION_NESTED，还需要把PlatformTransactionManager的nestedTransactionAllowed属性设为true(属性值默认为false)。 嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。 NESTED和REQUIRED修饰的内部方法都属于外围方法事务，如果外围方法抛出异常，这两种方法的事务都会被回滚。但是REQUIRED是加入外围方法事务，所以和外围事务同属于一个事务，一旦REQUIRED事务抛出异常被回滚，外围方法事务也将被回滚。而NESTED是外围方法的子事务，有单独的保存点，所以NESTED方法抛出异常被回滚，不会影响到外围方法的事务。NESTED和REQUIRES_NEW都可以做到内部方法事务回滚而不影响外围方法事务。但是因为NESTED是嵌套事务，所以外围方法回滚之后，作为外围方法事务的子事务也会被回滚。而REQUIRES_NEW是通过开启新的事务实现的，内部事务和外围事务是两个事务，外围事务回滚不会影响内部事务。 参考 Spring：7种事务传播行为]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：工厂模式]]></title>
    <url>%2F2019%2F03%2F26%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式提出问题问题案例基础概述是什么工厂模式的好处就是解耦。 分类 简单/静态工厂模式 工厂方法模式 抽象工厂模式 应用适用性 需要准备一个对象要做很多工作，而耦合在具体业务类当中并不恰当 当进行文件IO时，需要创建一个对象BufferedReader对象 1234567 // 创建一个BufferedReader对象 BufferedReader bf = new BufferedReader(new FileReader(new File("aa.txt"))); // 也可能是这样的 File file = new File("aa.txt"); FileReader fileReader = new FileReader(file); BufferedReader bufferedReader = new BufferedReader(fileReader); 当需要在很多地方使用到这个对象时，就会略显臃肿 同时，如果需要更换IO读写的类，如LineNumberReader，那么工作量相对很大 有时候需要判断具体new一个什么样的类 1234567891011public orderPizza(String type)&#123; Pizza pizza; //在业务类当中如此做会使得代码很脆弱而且很繁琐。 //并且如果出现了新的变化，需要反复修改。 //无法让类对修改关闭。 if(type.equals("cheese"))&#123; pizza = new CheesePizza(); &#125;else if(type.equals("greek"))&#123; pizza = new GreekPizza(); &#125;....&#125; 因此使用工厂模式，将对象创建委托给工厂 案例1协作结构参与者协作 类关系 逻辑关系 权衡分类结构效果（优缺）使用工厂模式的好处 让创建对象变得简单而且修改对象时能很方便呢 从面向对象的角度来看：我一个操作文件的类还要我会创建BufferReader是不是有点过分了？(职责没有分工好)，交给工厂来创建对象这就很面向对象了！ 专业一些即： 我们修改了具体的实现类，对客户端(调用方)而言是完全不用修改的。 如果我们使用new的方式来创建对象的话，那么我们就说：new出来的这个对象和当前客户端(调用方)耦合了！ 也就是，当前客户端(调用方)依赖着这个new出来的对象！ 即使得解耦，低耦合 实现实现步骤案例1相关模式进阶使用Lambda反省总结如何使用工厂模式 简单/静态工厂模式 工厂方法模式 抽象工厂模式 简单/静态工厂模式是在工厂方法模式上缩减，抽象工厂模式是在工厂方法模式上再增强。 工厂方法模式Java3y每天写代码很无聊，想要买只宠物来陪陪自己。于是乎就去宠物店看宠物啦~ 作为一间宠物店，号称什么宠物都有！于是乎，店主宣传的时候就说：我的宠物店什么宠物都有！ 于是构建宠物的工厂就诞生了~ 12345// 号称什么宠物都有public interface AnimalFactory &#123; // 可以获取任何的宠物 Animal createAnimal();&#125; 当然了，主流的宠物得进货一些先放在店里充充门面，一些特殊的宠物就告诉顾客要时间进货~ 所以，我们就有了构建猫和狗的工厂(继承着所有宠物的工厂) 猫工厂： 123456789// 继承着宠物工厂public class CatFactory implements AnimalFactory &#123; @Override // 创建猫 public Animal createAnimal() &#123; return new Cat(); &#125;&#125; 狗工厂也是一样的： 12345678// 继承着宠物工厂public class DogFactory implements AnimalFactory &#123; // 创建狗 @Override public Animal createAnimal() &#123; return new Dog(); &#125;&#125; 嗯，还有我们的实体类：猫、狗、动物(多态：猫和狗都是动物，可以直接用动物来表示了) 动物实体类： 1234public abstract class Animal &#123; // 所有的动物都会吃东西 public abstract void eat();&#125; 猫实体类： 1234567public class Cat extends Animal &#123; // 猫喜欢吃鱼 @Override public void eat() &#123; System.out.println("猫吃鱼"); &#125;&#125; 狗实体类： 1234567public class Dog extends Animal &#123; // 狗喜欢吃肉 @Override public void eat() &#123; System.out.println("狗吃肉"); &#125;&#125; 那么现在Java3y想要一只狗，跟了宠物店老板说，宠物店老板就去找狗回来了： 123456// 去找狗工厂拿一只狗过来AnimalFactory f = new DogFactory();// 店主就拿到了一只狗给Java3yAnimal a = f.createAnimal();a.eat(); 那么现在Java3y想要一只猫，跟了宠物店老板说，宠物店老板就去找猫回来了： 123456 // 去找猫工厂拿一只猫过来 AnimalFactory ff = new CatFactory();// 店主就拿到了一只猫给Java3y Animal aa = ff.createAnimal(); aa.eat(); 如果这个时候Java3y说想要一只蜥蜴怎么办啊？没问题啊，店主搞个蜥蜴工厂就好了~~ 1234// 要买蜥蜴..AnimalFactory fff = new LizardFactory();Animal aaa = ff.createAnimal();aaa.eat(); 优点: 1:客户端不需要在负责对象的创建,明确了各个类的职责 2:如果有新的对象增加，只需要增加一个具体的类和具体的工厂类即可 3:不会影响已有的代码，后期维护容易,增强系统的扩展性 缺点: 1:需要额外的编写代码,增加了工作量 工厂方法类图： 简单/静态工厂模式现在宠物店生意不好做啊，号称“什么宠物都有”,这吹过头了~~于是店主只卖两种常见的宠物了。 既然就只有两种宠物的话，那就没必要有”猫厂“、”狗厂“了，一个猫狗厂就行了！ 所以我们的工厂是这样子的： 123456789101112131415161718192021public class AnimalFactory &#123; public static Dog createDog() &#123; return new Dog(); &#125; public static Cat createCat() &#123; return new Cat(); &#125; // 外界想要猫要狗，这里创建就好了 public static Animal createAnimal(String type) &#123; if ("dog".equals(type)) &#123; return new Dog(); &#125; else if ("cat".equals(type)) &#123; return new Cat(); &#125; else &#123; return null; &#125; &#125;&#125; 三个实体还是没变(动物、猫、狗)…. 那么Java3y去宠物店买猫狗的时候，告诉老板我要猫、我要狗： 1234567// 拿到狗 Animal A = AnimalFactory.createAnimal("dog"); A.eat();// 拿到猫 Animal C = AnimalFactory.createAnimal("cat"); C.eat(); 现在问题来了: 1:我想要一个猪,可是我的工厂类没有猪 2:我就去改代码,写可以创建猪对象的 3:接着,我又要其他的动物 4:我还是得改代码 5………………. 6:这就是简单工厂类的缺点：当需求改变了,我就要改代码. 简单工厂类的优点也很明显：我就一个具体的工厂来创建对象，代码量少。 抽象工厂模式抽象工厂模式就比较复杂了，我们一般的应用都写不到。我首先来简述一下需求吧： 现在非常流行在猫狗届也吹起了一股“性别风” 有的喜欢公的 有的喜欢母的 那我们的猫和狗都是有性别的，不是公的就是母的~~ 我们之前在工厂方法模式下是每个动物都开一个工厂，如果动物过多的话，那么就有很多的工厂~ 那现在我们可以抽取出来：每个动物不是公的就是母的~ 所以我们有两个工厂就足够了！ 具体的代码是这样的： 我们的最大工厂还是定义了创建什么动物 1234public interface AnimalFactory &#123; Animal createDog(); Animal createCat();&#125; 创建母猫和母狗的工厂： 123456789101112public class FemaleAnimalFactory implements AnimalFactory &#123; // 生产母狗和母猫 @Override public Animal createDog() &#123; return new FemaleDog(); &#125; @Override public Animal createCat() &#123; return new FemaleCat(); &#125;&#125; 创建公猫和公狗的工厂： 123456789101112public class MaleAnimalFactory implements AnimalFactory &#123; // 生产公狗和公猫 @Override public Animal createDog() &#123; return new MaleDog(); &#125; @Override public Animal createCat() &#123; return new MaleCat(); &#125;&#125; 这是所有动物都拥有的普遍行为： 1234567public abstract class Animal &#123; // 所有的动物都会吃东西 public abstract void eat(); // 所有的动物都有性别 public abstract void gender();&#125; 这是猫都拥有的普遍行为： 1234567public abstract class Cat extends Animal &#123; // 猫喜欢吃鱼 @Override public void eat() &#123; System.out.println("猫吃鱼"); &#125;&#125; 这是狗都拥有的普遍行为： 1234567public abstract class Dog extends Animal &#123; // 狗喜欢吃肉 @Override public void eat() &#123; System.out.println("狗吃肉"); &#125;&#125; 猫分为公猫、母猫。狗分为公狗和母狗： 12345public class FemaleCat extends Cat &#123; public void gender() &#123; System.out.println("I am a female Cat"); &#125;&#125; ….. 简单来说：工厂方法模式的工厂是创建出一种产品，而抽象工厂是创建出一类产品。 一类的产品我们称之为产品族 猫是一类的，狗也是一类的。所以AnimalFactory定义了两类产品—&gt;Animal createDog();和Animal createCat(); 产品的继承结构称之为产品等级 所有的动物都是会吃东西的，它们都是有性别的，这是最普遍的。所以Animal定义了两个抽象方法：public abstract void eat();和public abstract void gender(); 所有的狗都是会吃肉的，所以Dog实现了eat()方法 狗又分成了公狗和母狗，所以定义了两个类FemaleDog和MaleDog继承了Dog，实现了gender()方法 所有的猫都是会吃鱼的，所以Cat实现了eat()方法 猫又分成了公猫和母猫，所以定义了两个类FemaleCat和MaleCat继承了Cat，实现了gender()方法 具体的工厂是面向多个产品等级结构进行生产。 所以FemaleAnimalFactory定义了createDog()和createCat()生产母狗和母猫 所以MaleAnimalFactory定义了createDog()和createCat()生产公狗和共猫 找到母工厂就可以创建母猫和母狗，找到公工厂就可以创建公猫和公狗 抽象工厂模式说到底就是多了一层抽象，减少了工厂的数量。 抽象工厂缺点也很明显： 难以扩展产品族—&gt;如果我再要宠物猪的话 那我要修改AnimalFactory、FemaleAnimalFactory、MaleAnimalFactory这些类了~ 总结总的来说我们用简单工厂模式比较多，工厂方式模式的话代码量会比较大，抽象工厂模式的话需要业务比较大的情况下才会用到 工厂模式将初始化一个类所需要的繁杂操作，包装在了一个工厂的方法当中。如考虑声明一个缓冲区，缓冲区有不同的类型，封装在不同的工厂方法当中 工厂模式配合反射来使用也是极好的~ 参考 工厂模式理解了没有？]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统：协程]]></title>
    <url>%2F2019%2F03%2F22%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[协程生产者消费者模式1.定义了一个生产者类，一个消费者类。 2.生产者类循环100次，向同步队列当中插入数据。 3.消费者循环监听同步队列，当队列有数据时拉取数据。 4.如果队列满了（达到5个元素），生产者阻塞。 5.如果队列空了，消费者阻塞。 该生产者/消费者模式，但是却并不是一个高性能的实现。为什么性能不高呢？原因如下： 1.涉及到同步锁。 2.涉及到线程阻塞状态和可运行状态之间的切换。 3.涉及到线程上下文的切换。 以上涉及到的任何一点，都是非常耗费性能的操作。 什么是协程协程，英文Coroutines，是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。 子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。 所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。 子程序调用总是一个入口，一次返回，调用顺序是明确的。 而协程的调用和子程序不同。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。 但是子程序之间不相互调用，而是类似线程，在并行执行 最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。 这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。 使用因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 子例程（函数）的起始处是惟一的入口点，一旦退出即完成了子例程的执行，子例程的一个实例只会返回一次。 协程的起始处是第一个入口点，在协程里，返回点之后是接下来的入口点。子例程的生命期遵循后进先出（最后一个被调用的子例程最先返回）；相反，协程的生命期完全由他们的使用的需要决定。 由于Java的原生语法中并没有实现协程（某些开源框架实现了协程，但是很少被使用），所以我们来看一看python当中对协程的实现案例，同样以生产者消费者模式为例： 这段代码十分简单，即使没用过python的小伙伴应该也能基本看懂。 代码中创建了一个叫做consumer的协程，并且在主线程中生产数据，协程中消费数据。 其中 yield 是python当中的语法。当协程执行到yield关键字时，会暂停在那一行，等到主线程调用send方法发送了数据，协程才会接到数据继续执行。 优势 协程的开销远远小于线程的开销。 yield让协程暂停，和线程的阻塞是有本质区别的。协程的暂停完全由程序控制，线程的阻塞状态是由操作系统内核来进行切换。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：Map]]></title>
    <url>%2F2019%2F03%2F21%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9AMap%2F</url>
    <content type="text"><![CDATA[MapMap代表一种映射关系，其指这个key与它的value存在某种相关的联系。 当这个Key与一个概念存在某种抽象的联系时，就需要使用Map。 前言符号表（Symbol Table）是一种存储键值对的数据结构，可以支持快速查找操作。 符号表分为有序和无序两种，有序符号表主要指支持min()、max()等根据键的大小关系来实现的操作。 有序符号表的键需要实现Comparable接口。 1234567891011121314151617181920212223242526public interface UnorderedST&lt;Key, Value&gt; &#123; int size(); Value get(Key key); void put(Key key, Value value); void delete(Key key);&#125;Copy to clipboardErrorCopiedpublic interface OrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; int size(); void put(Key key, Value value); Value get(Key key); Key min(); Key max(); int rank(Key key); List&lt;Key&gt; keys(Key l, Key h);&#125; 初级实现链表实现无序符号表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class ListUnorderedST&lt;Key, Value&gt; implements UnorderedST&lt;Key, Value&gt; &#123; private Node first; private class Node &#123; Key key; Value value; Node next; Node(Key key, Value value, Node next) &#123; this.key = key; this.value = value; this.next = next; &#125; &#125; @Override public int size() &#123; int cnt = 0; Node cur = first; while (cur != null) &#123; cnt++; cur = cur.next; &#125; return cnt; &#125; @Override public void put(Key key, Value value) &#123; Node cur = first; // 如果在链表中找到节点的键等于 key 就更新这个节点的值为 value while (cur != null) &#123; if (cur.key.equals(key)) &#123; cur.value = value; return; &#125; cur = cur.next; &#125; // 否则使用头插法插入一个新节点 first = new Node(key, value, first); &#125; @Override public void delete(Key key) &#123; if (first == null)&#123; return; &#125; if (first.key.equals(key))&#123; first = first.next; &#125; Node pre = first, cur = first.next; while (cur != null) &#123; if (cur.key.equals(key)) &#123; pre.next = cur.next; return; &#125; pre = pre.next; cur = cur.next; &#125; &#125; @Override public Value get(Key key) &#123; Node cur = first; while (cur != null) &#123; if (cur.key.equals(key))&#123; return cur.value; &#125; cur = cur.next; &#125; return null; &#125;&#125; 二分查找实现有序符号表使用一对平行数组，一个存储键一个存储值。 二分查找的rank()方法至关重要，当键在表中时，它能够知道该键的位置；当键不在表中时，它也能知道在何处插入新键。 二分查找最多需要logN + 1次比较，使用二分查找实现的符号表的查找操作所需要的时间最多是对数级别的。但是插入操作需要移动数组元素，是线性级别的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class BinarySearchOrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; implements OrderedST&lt;Key, Value&gt; &#123; private Key[] keys; private Value[] values; private int N = 0; public BinarySearchOrderedST(int capacity) &#123; keys = (Key[]) new Comparable[capacity]; values = (Value[]) new Object[capacity]; &#125; @Override public int size() &#123; return N; &#125; @Override public int rank(Key key) &#123; int l = 0, h = N - 1; while (l &lt;= h) &#123; int m = l + (h - l) / 2; int cmp = key.compareTo(keys[m]); if (cmp == 0)&#123; return m; &#125; else if (cmp &lt; 0)&#123; h = m - 1; &#125; else&#123; l = m + 1; &#125; &#125; return l; &#125; @Override public List&lt;Key&gt; keys(Key l, Key h) &#123; int index = rank(l); List&lt;Key&gt; list = new ArrayList&lt;&gt;(); while (keys[index].compareTo(h) &lt;= 0) &#123; list.add(keys[index]); index++; &#125; return list; &#125; @Override public void put(Key key, Value value) &#123; int index = rank(key); // 如果找到已经存在的节点键为 key，就更新这个节点的值为 value if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0) &#123; values[index] = value; return; &#125; // 否则在数组中插入新的节点，需要先将插入位置之后的元素都向后移动一个位置 for (int j = N; j &gt; index; j--) &#123; keys[j] = keys[j - 1]; values[j] = values[j - 1]; &#125; keys[index] = key; values[index] = value; N++; &#125; @Override public Value get(Key key) &#123; int index = rank(key); if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0)&#123; return values[index]; &#125; return null; &#125; @Override public Key min() &#123; return keys[0]; &#125; @Override public Key max() &#123; return keys[N - 1]; &#125;&#125; HashMap散列表类似于数组，可以把散列表的散列值看成数组的索引值。访问散列表和访问数组元素一样快速，它可以在常数时间内实现查找和插入操作。 由于无法通过散列值知道键的大小关系，因此散列表无法实现有序性操作。 散列函数对于一个大小为M的散列表，散列函数能够把任意键转换为[0, M-1]内的正整数，该正整数即为hash值。 散列表存在冲突，也就是两个不同的键可能有相同的hash值。 散列函数应该满足以下三个条件： 一致性：相等的键应当有相等的hash值，两个键相等表示调用equals()返回的值相等。 高效性：计算应当简便，有必要的话可以把hash值缓存起来，在调用hash函数时直接返回。 均匀性：所有键的hash值应当均匀地分布到[0, M-1]之间，如果不能满足这个条件，有可能产生很多冲突，从而导致散列表的性能下降。 除留余数法讲所有的数据类型以某种规则转换到一个整数。 除留余数法可以将整数散列到[0, M-1]之间，例如一个正整数 k，计算k%M既可得到一个[0, M-1]之间的hash值。注意M最好是一个素数，否则无法利用键包含的所有信息。例如M为 10k，那么只能利用键的后k位。 对于其它数，可以将其转换成整数的形式，然后利用除留余数法。例如对于浮点数，可以将其的二进制形式转换成整数。 对于多部分组合的类型，每个部分都需要计算 hash 值，这些 hash 值都具有同等重要的地位。为了达到这个目的，可以将该类型看成 R 进制的整数，每个部分都具有不同的权值。 例如，字符串的散列函数实现如下： 123int hash = 0;for (int i = 0; i &lt; s.length(); i++) hash = (R * hash + s.charAt(i)) % M; 再比如，拥有多个成员的自定义类的哈希函数如下： 1int hash = (((day * R + month) % M) * R + year) % M; R通常取31。 Java 中的hashCode()实现了哈希函数，但是默认使用对象的内存地址值。在使用hashCode()时，应当结合除留余数法来使用。因为内存地址是32位整数，我们只需要31位的非负整数，因此应当屏蔽符号位之后再使用除留余数法。 1int hash = (x.hashCode() &amp; 0x7fffffff) % M; 使用Java的HashMap等自带的哈希表实现时，只需要去实现Key类型的hashCode()函数即可。Java规定hashCode()能够将键均匀分布于所有的32位整数，Java中的String、Integer 等对象的hashCode()都能实现这一点。以下展示了自定义类型如何实现hashCode()： 123456789101112131415161718192021public class Transaction &#123; private final String who; private final Date when; private final double amount; public Transaction(String who, Date when, double amount) &#123; this.who = who; this.when = when; this.amount = amount; &#125; public int hashCode() &#123; int hash = 17; int R = 31; hash = R * hash + who.hashCode(); hash = R * hash + when.hashCode(); hash = R * hash + ((Double) amount).hashCode(); return hash; &#125;&#125; hashCodeJava的hashCode是int类型的，即拥有符号。 哈希冲突拉链法拉链法使用链表来存储hash值相同的键，从而解决冲突。 查找需要分两步，首先查找Key所在的链表，然后在链表中顺序查找。 对于N个键，M条链表(N&gt;M)，如果哈希函数能够满足均匀性的条件，每条链表的大小趋向于N/M，因此未命中的查找和插入操作所需要的比较次数为~N/M。 线性探测法线性探测法使用空位来解决冲突，当冲突发生时，向前探测一个空位来存储冲突的键。 使用线性探测法，数组的大小 M 应当大于键的个数 N（M&gt;N)。 12345678910111213141516171819202122232425public class LinearProbingHashST&lt;Key, Value&gt; implements UnorderedST&lt;Key, Value&gt; &#123; private int N = 0; private int M = 16; private Key[] keys; private Value[] values; public LinearProbingHashST() &#123; init(); &#125; public LinearProbingHashST(int M) &#123; this.M = M; init(); &#125; private void init() &#123; keys = (Key[]) new Object[M]; values = (Value[]) new Object[M]; &#125; private int hash(Key key) &#123; return (key.hashCode() &amp; 0x7fffffff) % M; &#125;&#125; 查找 12345678public Value get(Key key) &#123; for (int i = hash(key); keys[i] != null; i = (i + 1) % M)&#123; if (keys[i].equals(key))&#123; return values[i]; &#125; &#125; return null;&#125; 插入 1234567891011121314151617public void put(Key key, Value value) &#123; resize(); putInternal(key, value);&#125;private void putInternal(Key key, Value value) &#123; int i; for (i = hash(key); keys[i] != null; i = (i + 1) % M)&#123; if (keys[i].equals(key)) &#123; values[i] = value; return; &#125; &#125; keys[i] = key; values[i] = value; N++;&#125; 删除 删除操作应当将右侧所有相邻的键值对重新插入散列表中。 1234567891011121314151617181920212223242526public void delete(Key key) &#123; int i = hash(key); while (keys[i] != null &amp;&amp; !key.equals(keys[i]))&#123; i = (i + 1) % M; &#125; // 不存在，直接返回 if (keys[i] == null)&#123; return; &#125; keys[i] = null; values[i] = null; // 将之后相连的键值对重新插入 i = (i + 1) % M; while (keys[i] != null) &#123; Key keyToRedo = keys[i]; Value valToRedo = values[i]; keys[i] = null; values[i] = null; N--; putInternal(keyToRedo, valToRedo); i = (i + 1) % M; &#125; N--; resize();&#125; 调整数组大小 线性探测法的成本取决于连续条目的长度，连续条目也叫聚簇。当聚簇很长时，在查找和插入时也需要进行很多次探测。例如下图中 2~5 位置就是一个聚簇。 α = N/M，把α称为使用率。理论证明，当α小于1/2时探测的预计次数只在1.5到2.5之间。为了保证散列表的性能，应当调整数组的大小，使得α在[1/4, 1/2]之间。 1234567891011121314151617181920private void resize() &#123; if (N &gt;= M / 2)&#123; resize(2 * M); &#125; else if (N &lt;= M / 8)&#123; resize(M / 2); &#125;&#125;private void resize(int cap) &#123; LinearProbingHashST&lt;Key, Value&gt; t = new LinearProbingHashST&lt;Key, Value&gt;(cap); for (int i = 0; i &lt; M; i++)&#123; if (keys[i] != null)&#123; t.putInternal(keys[i], values[i]); &#125; &#125; keys = t.keys; values = t.values; M = t.M;&#125; 再哈希法当一个哈希函数产生了哈希冲突后，再用另外一个哈希方法再次进行哈希索引。 小结符号表算法比较 算法 插入 查找 是否有序 链表实现的无序符号表 N N yes 二分查找实现的有序符号表 N logN yes 二叉查找树 logN logN yes 2-3 查找树 logN logN yes 拉链法实现的散列表 N/M N/M no 线性探测法实现的散列表 1 1 no 应当优先考虑散列表，当需要有序性操作时使用红黑树。 Java 的符号表实现 java.util.TreeMap：红黑树。 java.util.HashMap：拉链法的散列表。 稀疏向量乘法当向量为稀疏向量时，可以使用符号表来存储向量中的非 0 索引和值，使得乘法运算只需要对那些非0元素进行即可。 123456789101112131415161718192021public class SparseVector &#123; private HashMap&lt;Integer, Double&gt; hashMap; public SparseVector(double[] vector) &#123; hashMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; vector.length; i++) if (vector[i] != 0) hashMap.put(i, vector[i]); &#125; public double get(int i) &#123; return hashMap.getOrDefault(i, 0.0); &#125; public double dot(SparseVector other) &#123; double sum = 0; for (int i : hashMap.keySet()) sum += this.get(i) * other.get(i); return sum; &#125;&#125; 参考 Cyc2018]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：JUC-Lock]]></title>
    <url>%2F2019%2F03%2F21%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJUC-Lock%2F</url>
    <content type="text"><![CDATA[Lock当内置加锁机制不适用时，作为一种可选的高级功能 Lock ReentrantLock Condition ReadWriteLock LockSupport 概述Lock提供了一种无条件的、可轮询的、定时的以及可中断的锁获取操作，所有加锁和解锁的方法都是显式的。在Lock的实现中必须提供与内部锁相同的内存可见性语义，但在加锁语义、调度算法、顺序保证以及性能特性等方面可以有所不同。 使用lock必须使用finally进行lock.unlock(); 适用性 内置锁在一些功能上存在局限性。 无法中断一个正在等待获取锁的线程， 无法在请求获取一个锁时无限地等待下去，即无法实现非阻塞的加锁规则。 性能考虑因素公平性synchronized与ReentrantLockReentrantLock在内存和加锁上提供的语义与内置锁相同，并提供了定时、可中断、公平、非块结构的加锁等。 但是ReentrantLock的危险性更高 synchronized简洁紧凑，并更加熟悉。仅当内置锁不能满足需求才考虑使用ReentrantLock。 ReentrantLock 与synchronized相同的互斥性、内存可见性和可重入的加锁语义。 等待可中断：持有锁的线程长期不释放锁的时候，正则等待的线程可以选择放弃等待，改为处理其他事情。对于处理执行时间非常长的同步块有帮助 可实现公平锁：多个新车等待同一个锁时，按申请的先后次序获得锁 锁可以帮定多个条件：可以同时绑定多个Condition 使用 synchronized 来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。 而 ReentrantLock 就是一个普通的类，它是基于 AQS(AbstractQueuedSynchronizer)来实现的。 是一个重入锁：一个线程获得了锁之后仍然可以反复的加锁，不会出现自己阻塞自己的情况。 AQS 是 Java 并发包里实现锁、同步的一个重要的基础框架。 锁类型ReentrantLock分为公平锁和非公平锁，可以通过构造方法来指定具体类型： 123456789//默认非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 默认一般使用非公平锁，它的效率和吞吐量都比公平锁高的多(后面会分析具体原因)。 获取锁通常的使用方式如下: 1234567891011private ReentrantLock lock = new ReentrantLock();public void run() &#123; lock.lock(); try &#123; //do bussiness &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125;&#125; 公平锁获取锁首先看下获取锁的过程： 123public void lock() &#123; sync.lock();&#125; 可以看到是使用 sync的方法，而这个方法是一个抽象方法，具体是由其子类(FairSync)来实现的，以下是公平锁的实现: 12345678910 final void lock() &#123; acquire(1); &#125; //AbstractQueuedSynchronizer 中的 acquire() public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 第一步是尝试获取锁(tryAcquire(arg)),这个也是由其子类实现： 1234567891011121314151617181920 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 首先会判断 AQS 中的 state 是否等于 0，0 表示目前没有其他线程获得锁，当前线程就可以尝试获取锁。 注意:尝试之前会利用 hasQueuedPredecessors() 方法来判断 AQS 的队列中中是否有其他线程，如果有则不会尝试获取锁(这是公平锁特有的情况)。 如果队列中没有线程就利用 CAS 来将 AQS 中的 state 修改为1，也就是获取锁，获取成功则将当前线程置为获得锁的独占线程(setExclusiveOwnerThread(current))。 如果 state 大于 0 时，说明锁已经被获取了，则需要判断获取锁的线程是否为当前线程(ReentrantLock 支持重入)，是则需要将 state + 1，并将值更新。 写入队列如果 tryAcquire(arg) 获取锁失败，则需要用 addWaiter(Node.EXCLUSIVE) 将当前线程写入队列中。 写入之前需要将当前线程包装为一个 Node 对象(addWaiter(Node.EXCLUSIVE))。 AQS 中的队列是由 Node 节点组成的双向链表实现的。 包装代码: 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 首先判断队列是否为空，不为空时则将封装好的 Node 利用 CAS 写入队尾，如果出现并发写入失败就需要调用 enq(node);来写入了。 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 这个处理逻辑就相当于自旋加上 CAS 保证一定能写入队列。 挂起等待线程写入队列之后需要将当前线程挂起(利用acquireQueued(addWaiter(Node.EXCLUSIVE), arg))： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先会根据 node.predecessor() 获取到上一个节点是否为头节点，如果是则尝试获取一次锁，获取成功就万事大吉了。 如果不是头节点，或者获取锁失败，则会根据上一个节点的 waitStatus 状态来处理(shouldParkAfterFailedAcquire(p, node))。 waitStatus 用于记录当前节点的状态，如节点取消、节点等待等。 shouldParkAfterFailedAcquire(p, node) 返回当前线程是否需要挂起，如果需要则调用 parkAndCheckInterrupt()： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 他是利用 LockSupport 的 part 方法来挂起当前线程的，直到被唤醒。 非公平锁获取锁公平锁与非公平锁的差异主要在获取锁： 公平锁就相当于买票，后来的人需要排到队尾依次买票，不能插队。 而非公平锁则没有这些规则，是抢占模式，每来一个人不会去管队列如何，直接尝试获取锁。 非公平锁: 1234567final void lock() &#123; //直接尝试获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 公平锁: 123final void lock() &#123; acquire(1);&#125; 还要一个重要的区别是在尝试获取锁时tryAcquire(arg)，非公平锁是不需要判断队列中是否还有其他线程，也是直接尝试获取锁： 12345678910111213141516171819final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //没有 !hasQueuedPredecessors() 判断 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 释放锁公平锁和非公平锁的释放流程都是一样的： 12345678910111213141516171819202122232425262728public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒被挂起的线程 unparkSuccessor(h); return true; &#125; return false;&#125;//尝试释放锁protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 首先会判断当前线程是否为获得锁的线程，由于是重入锁所以需要将 state 减到 0 才认为完全释放锁。 释放之后需要调用 unparkSuccessor(h) 来唤醒被挂起的线程。 轮询锁与定时锁可定时与可轮询的锁获取模式是由tryLock实现的，用于更完善的错误恢复机制。对于内置锁，死锁只能重新启动程序，防止死锁的唯一方法就是在构造上避免。 如果不能获得全部需要的锁，使用可定时或可轮询的锁获取方式，可以重新获得控制权，他会释放已经获得的锁，然后重新尝试获取所有锁 123456789101112131415161718//轮询while(true)&#123; if(lock.lock)&#123; try&#123; &#125;finally&#123; lock.unlock &#125; &#125;&#125;//定时if(!lock.tryLock(lock,Time))&#123; return;&#125;try&#123; &#125;finally&#123; lock.unlock;&#125; 可中断的锁可中断的锁获取操作同样能在可取消的操作中使用加锁。lockInterruptibly()能在获取锁的提示保持对中断的响应。 123456lock.lockInterruptibly();try&#123; return;&#125;finally&#123; lock.unlock()&#125; 非块结构的加锁在内置锁中，锁的获取和释放都是基于代码块的，释放锁的操作总是与获取锁的操作处于同一个代码块，而不考虑控制权如何退出该代码块。 使用lock可以实现分段锁、对链表节点加锁等 ReadWriteLock1234public interface ReadWriteLock&#123; Lock readLock(); Lock writeLock();&#125; 读写锁是一种性能优化措施，在一些特定的情况下能实现更高的并发现。但是必须是被频繁读取的数据结构，否则由于其复杂性更高，会导致性能差于ReentrantLock。 ReadWriteLock的可选实现： 释放优先。当应该写入操作释放写入锁时，并且队列中同时存在读线程和写线程，那么应该选择读线程还是写线程还是最先发出请求的线程。 读线程插队。如果锁由读线程持有，但有写线程正在等待，那么新到达的读线程能否立即得到访问权 重入性。读取锁与写入锁释放可重入 降级。如果应该线程持有写入锁，那么它能否在不释放该锁的情况下获取读取锁。 升级。读取锁能否优先于其他正在等待的读线程和写线程而升级为应该写入锁，（死锁：两个读线程试图同时升级为写入锁，那么二者都不会释放读取锁） ConditionCondition是一种广义的内置条件队列。 适用性相比于内置条件队列，每个内置锁都只能有一个相关联的条件队列，并且在最常见的加锁模式下公开条件队列对象。这些因素都使得无法满足在使用notifyAll时所有等待线程为同一类型的需求。 如果像编写一个带有多个条件谓词的并发对象，或向获得除了条件队列可见性之外的更多控制权，就可以使用显式的Lock和Condition。 是什么一个Condition于一个Lock关联在一起，要创建一个Condition，可以在相关联的Lock上调用Lock.newCondition()。并且一个Lock可以有任意数量的Condition对象，Condition会继承相关的Lock的公平性，对于公平锁，线程会依照FIFO从Condition.await()中释放。 Condition可以是可中断的或不可中断的、基于时限的等待、以及公平的或非公平的队列操作。 实现1有界缓存的一种实现，使用两个Condition，分别为notFull与notEmpty 1234567891011121314151617181920212223242526272829303132333435363738394041424344@ThreadSafepublic class ConditionBoundedBuffer&lt;T&gt;&#123; protected final Lock lock = new ReentrantLock(); private final Condition notFull = lock.newCondition(); private final Condition notEmpty = lock.newCondition(); private final T[] items = (T[]) new Object[Buffer_size]; private int tail, head, count; public void put(T x) throws InterruptedException&#123; lock.lock(); try&#123; while(count == items.length)&#123; notFull.await(); &#125; items[tail] = x; if(++tail == items.length)&#123; tail = 0; &#125; ++count; notEmpty.signal(); &#125;finally&#123; lock.unlock(); &#125; &#125; public void take(T x) throws InterruptedException&#123; lock.lock(); try&#123; while(count == 0)&#123; notEnpty.await(); &#125; T x = items[head]; items[head] = null; if(++head == items.length)&#123; head = 0; &#125; --count; notFull.signal(); return x; &#125;finally&#123; lock.unlock(); &#125; &#125;&#125; 在该示例当中，分析使用多个Condition的类，比分析一个使用单一条件队列的类简单很多。并且singal更为高效。 源码123456789public interface Condition&#123; void await() throws InterruptedException; boolean await(long time, TimeUnit unit) throws InterruptedException; long awaitNanos(long nanosTimeout) throws InterruptedException; void awaitUninterruptibly(); boolean awaitUntil(Data deadline) throws InterruptedException; void singal(); void singalAll();&#125; await对应于wait singal对应notify singalAll对应notifyAll 总结由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。 所以也就能解释非公平锁的效率会被公平锁更高。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用算法：排序算法]]></title>
    <url>%2F2019%2F03%2F21%2F%E7%AE%97%E6%B3%95%2F%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%EF%BC%9A%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法排序算法的比较当N&lt;60，虽然插入排序O(N^2^)，但是常数项很低，因此速度非常快，甚至大于快排。 算法 稳定性 时间复杂度 空间复杂度 备注 选择排序 × N2 1 冒泡排序 √ N2 1 插入排序 √ N ~ N2 1 时间复杂度和初始顺序有关 希尔排序 × N 的若干倍乘于递增序列的长度 1 改进版插入排序 快速排序 × NlogN logN 三向切分快速排序 × N ~ NlogN logN 适用于有大量重复主键 归并排序 √ NlogN N 堆排序 × NlogN 1 无法利用局部性原理 快速排序是最快的通用排序算法，它的内循环的指令很少，而且它还能利用缓存，因为它总是顺序地访问数据。它的运行时间近似为 ~cNlogN，这里的 c 比其它线性对数级别的排序算法都要小。 使用三向切分快速排序，实际应用中可能出现的某些分布的输入能够达到线性级别，而其它排序算法仍然需要线性对数时间。 约定待排序的元素需要实现Java的Comparable接口，该接口有 compareTo()方法，可以用它来判断两个元素的大小关系。 研究排序算法的成本模型时，统计的是比较和交换的次数。 使用辅助函数less()和swap()来进行比较和交换的操作，使得代码的可读性和可移植性更好。 1234567891011121314public abstract class Sort&lt;T extends Comparable&lt;T&gt;&gt; &#123; public abstract void sort(T[] nums); protected boolean less(T v, T w) &#123; return v.compareTo(w) &lt; 0; &#125; protected void swap(T[] a, int i, int j) &#123; T t = a[i]; a[i] = a[j]; a[j] = t; &#125;&#125; 稳定性排序的稳定性：排序过后，能否保证原始的相应次序不变，即在原始序列当中的第一个最小值依然出现在第一个位置上。即使有两个一样的最小值，那么第二个最小值也会出现在第一个最小值的后面。 即稳定的排序算法不会打乱原始的相应次序。 选择排序选择出数组中的最小元素，将它与数组的第一个元素交换位置。再从剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 选择排序需要 ~N2/2 次比较和 ~N 次交换，它的运行时间与输入无关，这个特点使得它对一个已经排序的数组也需要这么多的比较和交换操作。 12345678910111213141516public class Selection&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; int N = nums.length; for (int i = 0; i &lt; N - 1; i++) &#123; int min = i; for (int j = i + 1; j &lt; N; j++) &#123; if (less(nums[j], nums[min])) &#123; min = j; &#125; &#125; swap(nums, i, min); &#125; &#125;&#125; 冒泡排序从左到右不断交换相邻逆序的元素，在一轮的循环之后，可以让未排序的最大元素上浮到右侧。 在一轮循环中，如果没有发生交换，就说明数组已经是有序的，此时可以直接退出。 1234567891011121314151617public class Bubble&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; int N = nums.length; boolean hasSorted = false; for (int i = N - 1; i &gt; 0 &amp;&amp; !hasSorted; i--) &#123; hasSorted = true; for (int j = 0; j &lt; i; j++) &#123; if (less(nums[j + 1], nums[j])) &#123; hasSorted = false; swap(nums, j, j + 1); &#125; &#125; &#125; &#125;&#125;Copy to clipboardErrorCopied 插入排序每次都将当前元素插入到左侧已经排序的数组中，使得插入之后左侧数组依然有序。 对于数组 {3, 5, 2, 4, 1}，它具有以下逆序：(3, 2), (3, 1), (5, 2), (5, 4), (5, 1), (2, 1), (4, 1)，插入排序每次只能交换相邻元素，令逆序数量减少 1，因此插入排序需要交换的次数为逆序数量。 插入排序的复杂度取决于数组的初始顺序，如果数组已经部分有序了，逆序较少，那么插入排序会很快。 平均情况下插入排序需要 ~N2/4 比较以及 ~N2/4 次交换； 最坏的情况下需要 ~N2/2 比较以及 ~N2/2 次交换，最坏的情况是数组是倒序的； 最好的情况下需要 N-1 次比较和 0 次交换，最好的情况就是数组已经有序了。 以下演示了在一轮循环中，将元素 2 插入到左侧已经排序的数组中。 123456789101112public class Insertion&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; int N = nums.length; for (int i = 1; i &lt; N; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(nums[j], nums[j - 1]); j--) &#123; swap(nums, j, j - 1); &#125; &#125; &#125;&#125; 希尔排序对于大规模的数组，插入排序很慢，因为它只能交换相邻的元素，每次只能将逆序数量减少1。 希尔排序的出现就是为了解决插入排序的这种局限性，它通过交换不相邻的元素，每次可以将逆序数量减少大于1。 希尔排序使用插入排序对间隔h的序列进行排序。通过不断减小h，最后令 h=1，就可以使得整个数组是有序的。 12345678910111213141516171819202122public class Shell&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; int N = nums.length; int h = 1; while (h &lt; N / 3) &#123; h = 3 * h + 1; // 1, 4, 13, 40, ... &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(nums[j], nums[j - h]); j -= h) &#123; swap(nums, j, j - h); &#125; &#125; h = h / 3; &#125; &#125;&#125; 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。后面介绍的高级排序算法只会比希尔排序快两倍左右。 归并排序归并排序的思想是将数组分成两部分，分别进行排序，然后准备一个辅助数组归并起来。 归并方法归并方法将数组中两个已经排序的部分归并成一个。 1234567891011121314151617181920212223public abstract class MergeSort&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; protected T[] aux; protected void merge(T[] nums, int l, int m, int h) &#123; int i = l, j = m + 1; for (int k = l; k &lt;= h; k++) &#123; aux[k] = nums[k]; // 将数据复制到辅助数组 &#125; for (int k = l; k &lt;= h; k++) &#123; if (i &gt; m) &#123; nums[k] = aux[j++]; &#125; else if (j &gt; h) &#123; nums[k] = aux[i++]; &#125; else if (aux[i].compareTo(aux[j]) &lt;= 0) &#123; nums[k] = aux[i++]; // 先进行这一步，保证稳定性 &#125; else &#123; nums[k] = aux[j++]; &#125; &#125; &#125;&#125; 自顶向下归并排序 将一个大数组分成两个小数组去求解。 因为每次都将问题对半分成两个子问题，这种对半分的算法复杂度一般为 O(NlogN)。 123456789101112131415161718public class Up2DownMergeSort&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; aux = (T[]) new Comparable[nums.length]; sort(nums, 0, nums.length - 1); &#125; private void sort(T[] nums, int l, int h) &#123; if (h &lt;= l) &#123; return; &#125; int mid = l + (h - l) / 2; sort(nums, l, mid); sort(nums, mid + 1, h); merge(nums, l, mid, h); &#125;&#125; 自底向上归并排序 先归并那些微型数组，然后成对归并得到的微型数组。 123456789101112131415public class Down2UpMergeSort&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; int N = nums.length; aux = (T[]) new Comparable[N]; for (int sz = 1; sz &lt; N; sz += sz) &#123; for (int lo = 0; lo &lt; N - sz; lo += sz + sz) &#123; merge(nums, lo, lo + sz - 1, Math.min(lo + sz + sz - 1, N - 1)); &#125; &#125; &#125;&#125; 示例问题小和问题在一个数组中，每一个数左边比当前数小的数类加起来，叫做这个数组的小和，求一个数组的小和。 123456789101112131 3 4 2 51 3 4 || 2 51 3 || 4 ||2 ||51||3||4||2||5merge过程中产生小和1与3merge产生小和11 3与4merge产生小和1 32与5merge产生小和21 3 4与2 5merge-&gt;1&lt;2，产生2个1（即根据下标可得出）3&gt;2，不产生3&lt;5，产生1个34&lt;5，产生1个4 即在寻找当先数current有多少个数比current大 原理 首先有多少个数比current大，是一个近排序问题。 其次归并可以知道依照组进行计算，即批量化的。 快速排序基本算法 归并排序将数组分为两个子数组分别排序，并将有序的子数组归并使得整个数组排序； 快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。 12345678910111213141516171819202122public class QuickSort&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; @Override public void sort(T[] nums) &#123; shuffle(nums); sort(nums, 0, nums.length - 1); &#125; private void sort(T[] nums, int l, int h) &#123; if (h &lt;= l) return; int j = partition(nums, l, h); sort(nums, l, j - 1); sort(nums, j + 1, h); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 切分 取a[l]作为切分元素，然后从数组的左端向右扫描直到找到第一个大于等于它的元素，再从数组的右端向左扫描找到第一个小于它的元素，交换这两个元素。不断进行这个过程，就可以保证左指针i的左侧元素都不大于切分元素，右指针j的右侧元素都不小于切分元素。当两个指针相遇时，将切分元素a[l]和a[j]交换位置。 12345678910111213private int partition(T[] nums, int l, int h) &#123; int i = l, j = h + 1; T v = nums[l]; while (true) &#123; while (less(nums[++i], v) &amp;&amp; i != h) ; while (less(v, nums[--j]) &amp;&amp; j != l) ; if (i &gt;= j) break; swap(nums, i, j); &#125; swap(nums, l, j); return j;&#125; 性能分析 快速排序是原地排序，不需要辅助数组，但是递归调用需要辅助栈。 快速排序最好的情况下是每次都正好将数组对半分，这样递归调用次数才是最少的。这种情况下比较次数为 CN=2CN/2+N，复杂度为 O(NlogN)。 最坏的情况下，第一次从最小的元素切分，第二次从第二小的元素切分，如此这般。因此最坏的情况下需要比较 N2/2。为了防止数组最开始就是有序的，在进行快速排序时需要随机打乱数组。 算法改进切换到插入排序 因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 三数取中 最好的情况下是每次都能取数组的中位数作为切分元素，但是计算中位数的代价很高。一种折中方法是取 3 个元素，并将大小居中的元素作为切分元素。 三向切分 对于有大量重复元素的数组，可以将数组切分为三部分，分别对应小于、等于和大于切分元素。 三向切分快速排序对于有大量重复元素的随机数组可以在线性时间内完成排序。 1234567891011121314151617181920212223public class ThreeWayQuickSort&lt;T extends Comparable&lt;T&gt;&gt; extends QuickSort&lt;T&gt; &#123; @Override protected void sort(T[] nums, int l, int h) &#123; if (h &lt;= l) &#123; return; &#125; int lt = l, i = l + 1, gt = h; T v = nums[l]; while (i &lt;= gt) &#123; int cmp = nums[i].compareTo(v); if (cmp &lt; 0) &#123; swap(nums, lt++, i++); &#125; else if (cmp &gt; 0) &#123; swap(nums, i, gt--); &#125; else &#123; i++; &#125; &#125; sort(nums, l, lt - 1); sort(nums, gt + 1, h); &#125;&#125; 基于切分的快速选择算法快速排序的partition()方法，会返回一个整数j使得a[l..j-1] 小于等于a[j]，且 [j+1..h]大于等于a[j]，此时a[j]就是数组的第j大元素。 可以利用这个特性找出数组的第k个元素。 该算法是线性级别的，假设每次能将数组二分，那么比较的总次数为 (N+N/2+N/4+..)，直到找到第 k 个元素，这个和显然小于 2N。 1234567891011121314151617public T select(T[] nums, int k) &#123; int l = 0, h = nums.length - 1; while (h &gt; l) &#123; int j = partition(nums, l, h); if (j == k) &#123; return nums[k]; &#125; else if (j &gt; k) &#123; h = j - 1; &#125; else &#123; l = j + 1; &#125; &#125; return nums[k];&#125; 示例问题堆排序堆堆中某个节点的值总是大于等于其子节点的值，并且堆是一颗完全二叉树。 堆可以用数组来表示，这是因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。这里不使用数组索引为 0 的位置，是为了更清晰地描述节点的位置关系。 123456789101112131415161718192021222324252627public class Heap&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T[] heap; private int N = 0; public Heap(int maxN) &#123; this.heap = (T[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return heap[i].compareTo(heap[j]) &lt; 0; &#125; private void swap(int i, int j) &#123; T t = heap[i]; heap[i] = heap[j]; heap[j] = t; &#125;&#125; 上浮和下沉在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; swap(k / 2, k); k = k / 2; &#125;&#125; 类似地，当一个节点比子节点来得小，也需要不断地向下进行比较和交换操作，把这种操作称为下沉。一个节点如果有两个子节点，应当与两个子节点中最大那个节点进行交换。 1234567891011private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; swap(k, j); k = j; &#125;&#125; 插入元素将新元素放到数组末尾，然后上浮到合适的位置。 1234public void insert(Comparable v) &#123; heap[++N] = v; swim(N);&#125; 删除最大元素从数组顶端删除最大的元素，并将数组的最后一个元素放到顶端，并让这个元素下沉到合适的位置。 1234567public T delMax() &#123; T max = heap[1]; swap(1, N--); heap[N + 1] = null; sink(1); return max;&#125; 堆排序把最大元素和当前堆中数组的最后一个元素交换位置，并且不删除它，那么就可以得到一个从尾到头的递减序列，从正向来看就是一个递增序列，这就是堆排序。 构建堆无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 交换堆顶元素与最后一个元素交换之后需要进行下沉操作维持堆的有序状态。 1234567891011121314151617181920212223242526272829303132public class HeapSort&lt;T extends Comparable&lt;T&gt;&gt; extends Sort&lt;T&gt; &#123; /** * 数组第 0 个位置不能有元素 */ @Override public void sort(T[] nums) &#123; int N = nums.length - 1; for (int k = N / 2; k &gt;= 1; k--) sink(nums, k, N); while (N &gt; 1) &#123; swap(nums, 1, N--); sink(nums, 1, N); &#125; &#125; private void sink(T[] nums, int k, int N) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(nums, j, j + 1)) j++; if (!less(nums, k, j)) break; swap(nums, k, j); k = j; &#125; &#125; private boolean less(T[] nums, int i, int j) &#123; return nums[i].compareTo(nums[j]) &lt; 0; &#125;&#125; 分析一个堆的高度为 logN，因此在堆中插入元素和删除最大元素的复杂度都为 logN。 对于堆排序，由于要对 N 个节点进行下沉操作，因此复杂度为 NlogN。 堆排序是一种原地排序，没有利用额外的空间。 现代操作系统很少使用堆排序，因为它无法利用局部性原理进行缓存，也就是数组元素很少和相邻的元素进行比较和交换。 桶排序示例问题给定一个数组，求如果排序之后，相邻两数的最大差值，要求时间复杂度o(N)，且要求不能用非基于比较的排序。 使用桶排序，如果N个数字，则使用N+1个桶，一定有至少一个桶会空下来，则在一个桶内部的相邻数一定不会有最大差值。只与数字的数目相关，与范围无关。 小结Java 的排序算法实现Java主要排序方法为java.util.Arrays.sort()，对于原始数据类型使用三向切分的快速排序，对于引用类型使用归并排序。 参考 CyC2018]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常用算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构：树]]></title>
    <url>%2F2019%2F03%2F21%2F%E7%AE%97%E6%B3%95%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E6%A0%91%2F</url>
    <content type="text"><![CDATA[二叉树分类 完全二叉树。 满二叉树。 二叉搜索树。 AVL树。 红黑树。 线段树。 二叉查找树 左子树的键值总是小于根的键值。右子树的键值总是大于根的键值。即没有键值相等的节点。 中序遍历结果有序。 二叉查找树的常用操作有： put()：插入节点 get()：寻找一个节点 floor(key)：小于等于键的最大键 rank(key) 返回key的排名。 min()：返回最小值 deleteMin()：删除最小值 delete()：删除一个节点 keys()：将键值排序输出 二叉树 是一个空链接，或者是一个有左右两个链接的节点，每个链接都指向一颗子二叉树。 二叉查找树 （BST）是一颗二叉树，并且每个节点的值都大于等于其左子树中的所有节点的值而小于等于右子树的所有节点的值。 BST 有一个重要性质，就是它的中序遍历结果递增排序。 数据结构与操作基本数据结构： 123456789101112131415161718192021222324252627282930313233343536public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; implements OrderedST&lt;Key, Value&gt; &#123; protected Node root; protected class Node &#123; Key key; Value val; Node left; Node right; // 以该节点为根的子树节点总数 int N; // 红黑树中使用 boolean color; Node(Key key, Value val, int N) &#123; this.key = key; this.val = val; this.N = N; &#125; &#125; @Override public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; return x.N; &#125; protected void recalculateSize(Node x) &#123; x.N = size(x.left) + size(x.right) + 1; &#125;&#125; 为了方便绘图，下文中二叉树的空链接不画出来。 get() 如果树是空的，则查找未命中； 如果被查找的键和根节点的键相等，查找命中； 否则递归地在子树中查找：如果被查找的键较小就在左子树中查找，较大就在右子树中查找。 12345678910111213141516@Overridepublic Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x.val; else if (cmp &lt; 0) return get(x.left, key); else return get(x.right, key);&#125; put() 当插入的键不存在于树中，需要创建一个新节点，并且更新上层节点的链接指向该节点，使得该节点正确地链接到树中。 123456789101112131415161718 @Overridepublic void put(Key key, Value value) &#123; root = put(root, key, value);&#125;private Node put(Node x, Key key, Value value) &#123; if (x == null) return new Node(key, value, 1); int cmp = key.compareTo(x.key); if (cmp == 0) x.val = value; else if (cmp &lt; 0) x.left = put(x.left, key, value); else x.right = put(x.right, key, value); recalculateSize(x); return x;&#125; floor() floor(key)：小于等于键的最大键 如果键小于根节点的键，那么 floor(key) 一定在左子树中； 如果键大于根节点的键，需要先判断右子树中是否存在 floor(key)，如果存在就返回，否则根节点就是 floor(key)。 123456789101112131415161718public Key floor(Key key) &#123; Node x = floor(root, key); if (x == null) return null; return x.key;&#125;private Node floor(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x; if (cmp &lt; 0) return floor(x.left, key); Node t = floor(x.right, key); return t != null ? t : x;&#125; rank() rank(key) 返回 key 的排名。 如果键和根节点的键相等，返回左子树的节点数； 如果小于，递归计算在左子树中的排名； 如果大于，递归计算在右子树中的排名，加上左子树的节点数，再加上 1（根节点）。 12345678910111213141516@Overridepublic int rank(Key key) &#123; return rank(key, root);&#125;private int rank(Key key, Node x) &#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp == 0) return size(x.left); else if (cmp &lt; 0) return rank(key, x.left); else return 1 + size(x.left) + rank(key, x.right);&#125; min() 123456789101112@Overridepublic Key min() &#123; return min(root).key;&#125;private Node min(Node x) &#123; if (x == null) return null; if (x.left == null) return x; return min(x.left);&#125; deleteMin() 令指向最小节点的链接指向最小节点的右子树。 1234567891011public void deleteMin() &#123; root = deleteMin(root);&#125;public Node deleteMin(Node x) &#123; if (x.left == null) return x.right; x.left = deleteMin(x.left); recalculateSize(x); return x;&#125; delete() 如果待删除的节点只有一个子树， 那么只需要让指向待删除节点的链接指向唯一的子树即可； 否则，让右子树的最小节点替换该节点。 123456789101112131415161718192021222324public void delete(Key key) &#123; root = delete(root, key);&#125;private Node delete(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else &#123; if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; &#125; recalculateSize(x); return x;&#125; keys() 利用二叉查找树中序遍历的结果为递增的特点。 12345678910111213141516171819@Overridepublic List&lt;Key&gt; keys(Key l, Key h) &#123; return keys(root, l, h);&#125;private List&lt;Key&gt; keys(Node x, Key l, Key h) &#123; List&lt;Key&gt; list = new ArrayList&lt;&gt;(); if (x == null) return list; int cmpL = l.compareTo(x.key); int cmpH = h.compareTo(x.key); if (cmpL &lt; 0) list.addAll(keys(x.left, l, h)); if (cmpL &lt;= 0 &amp;&amp; cmpH &gt;= 0) list.add(x.key); if (cmpH &gt; 0) list.addAll(keys(x.right, l, h)); return list;&#125; 分析二叉查找树所有操作在最坏的情况下所需要的时间都和树的高度成正比。二叉查找树的算法运行时间取决于树的形状，而树的形状又取决于键被插入的先后顺序。 最好的情况下树是完全平衡的，每条空链接和根节点的距离都为 logN。 在最坏的情况下，树的高度为 N。 AVL树平衡二叉树（Balanced Binary Tree）又被称为AVL树（有别于AVL算法），且具有以下性质： 它是一棵空树或它的左右两个子树的高度差的绝对值不超过1。 并且左右两个子树都是一棵平衡二叉树。 平衡二叉树的常用算法有红黑树、AVL树等。在平衡二叉搜索树中，我们可以看到，其高度一般都良好地维持在O(log2n)，大大降低了操作的时间复杂度。 AVL树定义：AVL树是最先发明的自平衡二叉查找树。AVL树得名于它的发明者 G.M. Adelson-Velsky 和 E.M. Landis，他们在 1962 年的论文 “An algorithm for the organization of information” 中发表了它。在AVL中任何节点的两个儿子子树的高度最大差别为1，所以它也被称为高度平衡树，n个结点的AVL树最大深度约1.44log2n。查找、插入和删除在平均和最坏情况下都是O(logn)。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。这个方案很好的解决了二叉查找树退化成链表的问题，把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)。但是频繁旋转会使插入和删除牺牲掉O(logN)左右的时间，不过相对二叉查找树来说，时间上稳定了很多。 数据结构与算法AVL树的自平衡操作——旋转： AVL树最关键的也是最难的一步操作就是旋转。旋转主要是为了实现AVL树在实施了插入和删除操作以后，树重新回到平衡的方法。下面我们重点研究一下AVL树的旋转。 对于一个平衡的节点，由于任意节点最多有两个儿子，因此高度不平衡时，此节点的两颗子树的高度差2.容易看出，这种不平衡出现在下面四种情况： 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左。 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右。 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左。 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右。 从图2中可以可以看出，1和4两种情况是对称的，这两种情况的旋转算法是一致的，只需要经过一次旋转就可以达到目标，我们称之为单旋转。2和3两种情况也是对称的，这两种情况的旋转算法也是一致的，需要进行两次旋转，我们称之为双旋转。 单旋转 单旋转是针对于左左和右右这两种情况的解决方案，这两种情况是对称的，只要解决了左左这种情况，右右就很好办了。图3是左左情况的解决方案，节点k2不满足平衡特性，因为它的左子树k1比右子树Z深2层，而且k1子树中，更深的一层的是k1的左子树X子树，所以属于左左情况。 为使树恢复平衡，我们把k2变成这棵树的根节点，因为k2大于k1，把k2置于k1的右子树上，而原本在k1右子树的Y大于k1，小于k2，就把Y置于k2的左子树上，这样既满足了二叉查找树的性质，又满足了平衡二叉树的性质。 这样的操作只需要一部分指针改变，结果我们得到另外一颗二叉查找树，它是一棵AVL树，因为X向上一移动了一层，Y还停留在原来的层面上，Z向下移动了一层。整棵树的新高度和之前没有在左子树上插入的高度相同，插入操作使得X高度长高了。因此，由于这颗子树高度没有变化，所以通往根节点的路径就不需要继续旋转了。 双旋转 对于左右和右左这两种情况，单旋转不能使它达到一个平衡状态，要经过两次旋转。双旋转是针对于这两种情况的解决方案，同样的，这样两种情况也是对称的，只要解决了左右这种情况，右左就很好办了。图4是左右情况的解决方案，节点k3不满足平衡特性，因为它的左子树k1比右子树Z深2层，而且k1子树中，更深的一层的是k1的右子树k2子树，所以属于左右情况。 为使树恢复平衡，我们需要进行两步，第一步，把k1作为根，进行一次右右旋转，旋转之后就变成了左左情况，所以第二步再进行一次左左旋转，最后得到了一棵以k2为根的平衡二叉树。 堆堆是一颗完全二叉树。 操作 插入节点 删除元素。 删除最大(最小元素) 其存在一部分的私有方法： 上浮/下沉。 分类数组堆可以看常用算法：排序算法。 假设以数组0位开始存储。则假设节点的index为i，其父类节点的index=(i-1)/2其左孩子的index=2*i+1 二(d)叉堆d叉堆在下沉时需要考虑d次。 索引堆数组堆只能看到堆首的元素，而不能看到堆中间的元素。 如果需要看到堆中间的元素，或需要对中间的元素进行修改。则需要使用索引堆，其维护了一个元素的索引。 2-3查找树2-3查找树引入了2-节点和3-节点，目的是为了让树平衡。即一个节点可以存放一个元素或两个元素，其具有2/3个孩子，也是其名称的原因。 一颗完美平衡的2-3查找树的所有空链接到根节点的距离应该是相同的。2-3树是一颗绝对平衡的树。 操作算法操作维持平衡：对于2-3树而言，添加节点永远不会添加到一个空的位置，即它会和最后找到的叶子节点进行融合。 常用操作有： 插入操作。 删除操作。 插入操作 插入操作和BST的插入操作有很大区别，BST 的插入操作是先进行一次未命中的查找，然后再将节点插入到对应的空链接上。但是2-3查找树如果也这么做的话，那么就会破坏了平衡性。它是将新节点插入到叶子节点上。 根据叶子节点的类型不同，有不同的处理方式： 如果插入到2-节点上，那么直接将新节点和原来的节点组成3-节点即可。 如果是插入到3-节点上，就会产生一个临时4-节点时，需要将4-节点分裂成3个2-节点，并将中间的2-节点移到上层节点中。如果上移操作继续产生临时4-节点则一直进行分裂上移，直到不存在临时4-节点。 性质2-3查找树插入操作的变换都是局部的，除了相关的节点和链接之外不必修改或者检查树的其它部分，而这些局部变换不会影响树的全局有序性和平衡性。 2-3查找树的查找和插入操作复杂度和插入顺序无关，在最坏的情况下查找和插入操作访问的节点必然不超过logN个，含有10亿个节点的2-3查找树最多只需要访问30个节点就能进行任意的查找和插入操作。 红黑树概述红黑树是2-3查找树，但它不需要分别定义2-节点和3-节点，而是在普通的二叉查找树之上，为节点添加颜色。指向一个节点的链接颜色如果为红色，那么这个节点和上层节点表示的是一个3-节点，而黑色则是普通链接。 性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制的一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 如果一个节点是红色的，那么它的孩子节点都是黑色的。 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 则没有路径能多于任何其他路径的两倍长。 其性质有： 红链接都为左链接； 完美黑色平衡，即任意空链接到根节点的路径上的黑链接数量相同。 它可以在O(logn)时间内做查找，插入和删除，这里的n是树中元素的数目。 画红黑树时可以将红链接画平。 1234567891011public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; extends BST&lt;Key, Value&gt; &#123; private static final boolean RED = true; private static final boolean BLACK = false; private boolean isRed(Node x) &#123; if (x == null) return false; return x.color == RED; &#125;&#125; 算法以下内容整理自wiki百科之红黑树。 红黑树的自平衡操作： 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质。恢复红黑树的性质需要少量(O(logn))的颜色变更(实际是非常快速的)和不超过三次树旋转(对于插入操作是两次)。虽然插入和删除很复杂，但操作时间仍可以保持为O(logn)次。 我们首先以二叉查找树的方法增加节点并标记它为红色。如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的（违背性质5）。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换（color flips）和树旋转来调整。下面要进行什么操作取决于其他临近节点的颜色。同人类的家族树中一样，我们将使用术语叔父节点来指一个节点的父节点的兄弟节点。注意： 性质1和性质3总是保持着。 性质4只在增加红色节点、重绘黑色节点为红色，或做旋转时受到威胁。 性质5只在增加黑色节点、重绘红色节点为黑色，或做旋转时受到威胁。 算法红黑树的操作思想与2-3树的思想完全一致，只是变为了一颗二叉树而已。 在操作方面，红黑树不同的地方主要在于插入操作与删除操作。其他操作与一般2-3树并无太大不同。 并且由于其插入操作与删除操作，额外带来了颜色转换操作，以及更为复杂的旋转操作。 插入操作插入的节点一定为红色，红色的节点代表它要和它的父亲节点做融合。 情形1: 该树为空树，直接插入根结点的位置，违反性质1，把节点颜色有红改为黑即可。 情形2：Black Root，并拥有一个Red left，插入Red Right。 则此时Root是一个4-节点，为将其分裂，使得子节点颜色为Black，父节点转为Red Root。 情形3：Black Root，拥有一个Red Left1，Red Left1拥有一个Red Left2。 此时Root依然是一个4-节点，为将其分裂，进行右旋转操作。 G.left = 3;，P.right = G;，P.color = G.color;，G.color=Red 情形4：Black Root，拥有一个Red Left，Red Left拥有Red Right。 由于红链接都是左链接，因此首先需要进行左旋转操作。 之后转变为了情形3，即需要右旋转。 删除操作如果需要删除的节点有两个儿子，那么问题可以被转化成删除另一个只有一个儿子的节点的问题。对于二叉查找树，在删除带有两个非叶子儿子的节点的时候，我们找到要么在它的左子树中的最大元素、要么在它的右子树中的最小元素，并把它的值转移到要删除的节点中。我们接着删除我们从中复制出值的那个节点，它必定有少于两个非叶子的儿子。因为只是复制了一个值，不违反任何性质，这就把问题简化为如何删除最多有一个儿子的节点的问题。它不关心这个节点是最初要删除的节点还是我们从中复制出值的那个节点。 我们只需要讨论删除只有一个儿子的节点(如果它两个儿子都为空，即均为叶子，我们任意将其中一个看作它的儿子)。如果我们删除一个红色节点（此时该节点的儿子将都为叶子节点），它的父亲和儿子一定是黑色的。所以我们可以简单的用它的黑色儿子替换它，并不会破坏性质3和性质4。通过被删除节点的所有路径只是少了一个红色节点，这样可以继续保证性质5。另一种简单情况是在被删除节点是黑色而它的儿子是红色的时候。如果只是去除这个黑色节点，用它的红色儿子顶替上来的话，会破坏性质5，但是如果我们重绘它的儿子为黑色，则曾经通过它的所有路径将通过它的黑色儿子，这样可以继续保持性质5。 需要进一步讨论的是在要删除的节点和它的儿子二者都是黑色的时候，这是一种复杂的情况。我们首先把要删除的节点替换为它的儿子。出于方便，称呼这个儿子为N(在新的位置上)，称呼它的兄弟(它父亲的另一个儿子)为S。在下面的示意图中，我们还是使用P称呼N的父亲，SL称呼S的左儿子，SR称呼S的右儿子。 如果N和它初始的父亲是黑色，则删除它的父亲导致通过N的路径都比不通过它的路径少了一个黑色节点。因为这违反了性质5，树需要被重新平衡。有几种情形需要考虑: 情形1: N是新的根。在这种情形下，我们就做完了。我们从所有路径去除了一个黑色节点，而新根是黑色的，所以性质都保持着。 注意: 在情形2、5和6下，我们假定N是它父亲的左儿子。如果它是右儿子，则在这些情形下的左和右应当对调。 情形2: S是红色。在这种情形下我们在N的父亲上做左旋转，把红色兄弟转换成N的祖父，我们接着对调N的父亲和祖父的颜色。完成这两个操作后，尽管所有路径上黑色节点的数目没有改变，但现在N有了一个黑色的兄弟和一个红色的父亲（它的新兄弟是黑色因为它是红色S的一个儿子），所以我们可以接下去按情形4、情形5或情形6来处理。 情形3: N的父亲、S和S的儿子都是黑色的。在这种情形下，我们简单的重绘S为红色。结果是通过S的所有路径，它们就是以前不通过N的那些路径，都少了一个黑色节点。因为删除N的初始的父亲使通过N的所有路径少了一个黑色节点，这使事情都平衡了起来。但是，通过P的所有路径现在比不通过P的路径少了一个黑色节点，所以仍然违反性质5。要修正这个问题，我们要从情形1开始，在P上做重新平衡处理。 情形4: S和S的儿子都是黑色，但是N的父亲是红色。在这种情形下，我们简单的交换N的兄弟和父亲的颜色。这不影响不通过N的路径的黑色节点的数目，但是它在通过N的路径上对黑色节点数目增加了一，添补了在这些路径上删除的黑色节点。 情形5: S是黑色，S的左儿子是红色，S的右儿子是黑色，而N是它父亲的左儿子。在这种情形下我们在S上做右旋转，这样S的左儿子成为S的父亲和N的新兄弟。我们接着交换S和它的新父亲的颜色。所有路径仍有同样数目的黑色节点，但是现在N有了一个黑色兄弟，他的右儿子是红色的，所以我们进入了情形6。N和它的父亲都不受这个变换的影响。 情形6: S是黑色，S的右儿子是红色，而N是它父亲的左儿子。在这种情形下我们在N的父亲上做左旋转，这样S成为N的父亲（P）和S的右儿子的父亲。我们接着交换N的父亲和S的颜色，并使S的右儿子为黑色。子树在它的根上的仍是同样的颜色，所以性质3没有被违反。但是，N现在增加了一个黑色祖先: 要么N的父亲变成黑色，要么它是黑色而S被增加为一个黑色祖父。所以，通过N的路径都增加了一个黑色节点。 此时，如果一个路径不通过N，则有两种可能性: 它通过N的新兄弟。那么它以前和现在都必定通过S和N的父亲，而它们只是交换了颜色。所以路径保持了同样数目的黑色节点。 它通过N的新叔父，S的右儿子。那么它以前通过S、S的父亲和S的右儿子，但是现在只通过S，它被假定为它以前的父亲的颜色，和S的右儿子，它被从红色改变为黑色。合成效果是这个路径通过了同样数目的黑色节点。 在任何情况下，在这些路径上的黑色节点数目都没有改变。所以我们恢复了性质4。在示意图中的白色节点可以是红色或黑色，但是在变换前后都必须指定相同的颜色。 操作左旋转因为合法的红链接都为左链接，如果出现右链接为红链接，那么就需要进行左旋转操作。 12345678910public Node rotateLeft(Node root) &#123; Node B = root.right; toot.right = B.left; B.left = root; B.color = root.color; root.color = RED; B.N = root.N; recalculateSize(toot); return x;&#125; 右旋转进行右旋转是为了转换两个连续的左红链接，这会在之后的插入过程中探讨。 123456789public Node rotateRight(Node root) &#123; Node A = root.left; root.left = A.right; A.color = root.color; root.color = RED; A.size = root.size; recalculateSize(root); return x;&#125; 颜色转换维护颜色的时机：与AVL树一样。 一个4-节点在红黑树中表现为一个节点的左右子节点都是红色的。分裂4-节点除了需要将子节点的颜色由红变黑之外，同时需要将父节点的颜色由黑变红，从2-3树的角度看就是将中间节点移到上层节点。 12345void flipColors(Node h) &#123; h.color = RED; h.left.color = BLACK; h.right.color = BLACK;&#125; 插入先将一个节点按二叉查找树的方法插入到正确位置，然后再进行如下颜色操作： 如果右子节点是红色的而左子节点是黑色的，进行左旋转； 如果左子节点是红色的，而且左子节点的左子节点也是红色的，进行右旋转； 如果左右子节点均为红色的，进行颜色转换。 123456789101112131415161718192021222324252627282930@Overridepublic void put(Key key, Value value) &#123; root = put(root, key, value); root.color = BLACK;&#125;private Node put(Node x, Key key, Value value) &#123; if (x == null) &#123; Node node = new Node(key, value, 1); node.color = RED; return node; &#125; int cmp = key.compareTo(x.key); if (cmp == 0) x.val = value; else if (cmp &lt; 0) x.left = put(x.left, key, value); else x.right = put(x.right, key, value); if (isRed(x.right) &amp;&amp; !isRed(x.left)) x = rotateLeft(x); if (isRed(x.left) &amp;&amp; isRed(x.left.left)) x = rotateRight(x); if (isRed(x.left) &amp;&amp; isRed(x.right)) flipColors(x); recalculateSize(x); return x;&#125; 可以看到该插入操作和二叉查找树的插入操作类似，只是在最后加入了旋转和颜色变换操作即可。 根节点一定为黑色，因为根节点没有上层节点，也就没有上层节点的左链接指向根节点。flipColors() 有可能会使得根节点的颜色变为红色，每当根节点由红色变成黑色时树的黑链接高度加 1. 分析一颗大小为N的红黑树的高度不会超过2logN。最坏的情况下是它所对应的2-3树，构成最左边的路径节点全部都是3-节点而其余都是2-节点。 红黑树大多数的操作所需要的时间都是对数级别的。 对于完全随机的数据，普通二分搜索树更有效。 缺点：极端情况退化为链表。 对于查询较多的情况，AVL有效。 红黑树一定程度上牺牲了平衡性。 统计性能更优（综合增删改查所有操作）。 B树B-树B树也是一种用于查找的平衡树，但是它不是二叉树。 B树的定义：B树（B-tree）是一种树状数据结构，能够用来存储排序后的数据。这种数据结构能够让查找数据、循序存取、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树，可以拥有多于2个子节点。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。这种数据结构常被应用在数据库和文件系统的实作上。 在B树中查找给定关键字的方法是，首先把根结点取来，在根结点所包含的关键字K1,…,Kn查找给定的关键字（可用顺序查找或二分查找法），若找到等于给定值的关键字，则查找成功；否则，一定可以确定要查找的关键字在Ki与Ki+1之间，Pi为指向子树根节点的指针，此时取指针Pi所指的结点继续查找，直至找到，或指针Pi为空时查找失败。 特征B树作为一种多路搜索树（并不是二叉的）： 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）； 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； B树创建的示意图： B+树B+树是B树的变体，也是一种多路搜索树：B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树，所有记录节点都是按照键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。 其定义基本与B-树相同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； B+树的搜索与B树也基本相同，区别是B+树只有达到叶子结点才命中（B树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的性质： 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 更适合文件索引系统。 下面为一个B+树创建的示意图： B+树的插入B+树的插入必须保证插入后叶子结点中的记录依然排序 页的拆分意味着磁盘的操作，所以应该在可能情况下尽量减少页的拆分操作 旋转 当leaf Page已经满，但是其左右的兄弟结点没有满，则进行旋转，将记录移到所在页的兄弟结点上。 删除B+树使用填充因子来控制删除，填充因子的最小值是50% B*树B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针，将结点的最低利用率从1/2提高到2/3。 B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）； B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 所以，B*树分配新结点的概率比B+树要低，空间使用率更高。 线段树Segment Tree概述为什么要用 有一种问题只关注一个区间 是一个动态的问题，数据是不断变化的。 案例问题 区间染色：有一面墙长度为n，每次选择一段墙进行染色。在m次操作后可以看到多少种颜色？在[i,j]区间内可以看到多少种颜色。 动态的，因为染色的次数不确定。 区间查询：对一个区间内的所有数据进行统计查询，例如查询[i,j]内的最大值、最小值、或区间数字和。 数据结构与操作Trie树Tire树称为字典树，又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 Tire树的三个基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符； 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串； 每个节点的所有子节点包含的字符都不相同。 应用 串的快速检索 给出N个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。 在这道题中，我们可以用数组枚举，用哈希，用字典树，先把熟词建一棵树，然后读入文章进行比较，这种方法效率是比较高的。 “串”排序 给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出。用字典树进行排序，采用数组的方式创建字典树，这棵树的每个结点的所有儿子很显然地按照其字母大小排序。对这棵树进行先序遍历即可。 最长公共前缀 对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为求公共祖先的问题。 并查集用于解决动态连通性问题，能动态连接两个点，并且判断两个点是否连通。 参考 Cyc2018]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java接口：常用接口]]></title>
    <url>%2F2019%2F03%2F21%2FJava%2Fbase%2FJava%E6%8E%A5%E5%8F%A3%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[Cloneable接口浅拷贝和深拷贝浅拷贝是指拷贝对象时仅仅拷贝对象本身和对象中的基本变量，以及它所包含的所有对象的引用地址，而不拷贝对象包含的引用指向的对象（这是 java 中的浅拷贝，其他语言的浅拷贝貌似是直接拷贝引用，即新引用和旧引用指向同一对象） 深拷贝不仅拷贝对象本身和对象中的基本变量，而且拷贝对象包含的引用指向的所有对象 注意：对于常量池方式创建的 String 类型，会针对原值克隆，不存在引用地址一说，对于其他不可变类，如 LocalDate，也是一样 Cloneable接口使用clone克隆方法必须实现的接口 三句话总结： （1）此类实现了Cloneable接口，以指示Object的clone()方法可以合法地对该类实例进行按字段复制 （2）如果在没有实现Cloneable接口的实例上调用Object的clone()方法，则会导致抛出CloneNotSupporteddException （3）按照惯例，实现此接口的类应该使用公共方法重写Object的clone()方法，Object的clone()方法是一个受保护的方法 2、Object的clone()方法 创建并返回此对象的一个副本。对于任何对象x，表达式： （1）x.clone() != x为true （2）x.clone().getClass() == x.getClass()为true （3）x.clone().equals(x)一般情况下为true，但这并不是必须要满足的要求 接口定义Cloneable 没有定义任何的方法签名，clone 方法定义在 Object 类中： 1protected native Object clone() throws CloneNotSupportedException; 从 JVM 的角度看，Cloneable 就是一个标记接口而已。到 clone() 的基本实现中，JVM 会去检测要 clone 的对象的类有没有被打上这个标记，有就让 clone，没有就抛异常。 Object 类的 clone() 一个 native 方法，native 方法的效率一般来说都远高于非 native 方法。这也解释了为什么要用 Object 中 clone() 方法而不是先 new 一个类，然后把原始对象中的信息赋到新对象中。 如果类没有实现 Cloneable 接口，直接调用从 Object 继承下来的 clone 方法，会抛出 CloneNotSupportedException 123456public class Test &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Test test = new Test(); Object cloned = test.clone(); // 结果是抛出 Clone NotSupportedException 异常 &#125; &#125; 所有数组类型都有一个 public 的 clone 方法，而不是 protected。可以用这个方法建立一个新数组，包含原数组所有元素的副本。（数组类型由 JVM 独立实现） 123int[] numbers = &#123; 1, 2, 3, 4 &#125;;int[] cloned = numbers.clone();cloned[0] = 11; // 不会改变 numbers Object 提供的 clone 方法是浅复制，如果要深克隆，需要重写（override）Object 类的 clone() 方法，并且在方法内部调用持有对象的 clone() 方法 123456789101112131415public class Employee implements Cloneable &#123; private String name; private double salary; private Date hireDay; public Employee clone() throws CloneNotSupportedException &#123; // call Object.clone() Employee cloned = (Employee) super.clone(); // clone mutable fields cloned.hireDay = (Date) hireDay.clone(); return cloned; &#125;&#125; 继承链上的祖先必须要有一个类声明实现 Cloneable 接口 12345678910111213141516171819202122public class Person &#123; &#125; public class Male extends Person implements Cloneable &#123; protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; &#125; public class ChineseMale extends Male &#123; &#125; public class Test &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Person person = new Person(); Male male = new male(); ChineseMale chineseMale = new ChineseMale(); person.clone(); // 报错 male.clone(); chineseMale.clone(); &#125;&#125; 为什么 clone() 是 protected 方法clone() 方法是 protected 方法，为了让其它类能调用这个类的 clone() 方法，重载之后要把 clone() 方法的属性设置为 public 。 之所以把 Object 类中的 clone 方法定义为 protected，是因为若把 clone 方法定义为 public 时，就失去了安全机制。这样的 clone 方法会被子类继承，而不管它对于子类有没有意义。比如，我们已经为 Employee 类定义了 clone 方法，而其他人可能会去克隆它的子类 Manager 对象。Employee 克隆方法能完成这件事吗？这取决于 Manager 类中的字段类型。如果 Manager 的实例字段是基本类型，不会发生什么问题。但通常情况下，需要检查你所扩展的任何类的 clone 方法。 如果，只是进行浅度克隆，那就没有没有必要把它设写成 protected，public 就可以了。 总之，把 Object 类中的 clone 方法定义为 protected，就是确保深度克隆时派生类中的 clone 方法会被检查。 protected 利与弊一般不会使用 protected 域，因为会破坏类的封装性 但是 protected 方法对于指示那些不提供一般用途而应在子类中重新定义的方法很有用 另一种克隆事实上，若想实现对象的克隆，就不重写 Object 的 clone() 方法，还得实现 Cloneable 接口，有点麻烦。 而且如果某字段是个 final 的可变类，就不能将该引用指向原型对象新的克隆体了。 有更好的做法： 深克隆（deep clone/copy）： SerializationUtils 浅克隆（shallow clone/copy）：BeanUtils 简单的克隆，也可以通过编写拷贝构造方法实现 参考 Cloneable 接口]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java接口：序列化]]></title>
    <url>%2F2019%2F03%2F21%2FJava%2Fbase%2FJava%E6%8E%A5%E5%8F%A3%EF%BC%9A%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[序列化 序列化 (Serialization)是将对象的状态信息转换为可以存储或传输的格式的过程。 即将数据转换为字节流 反序列化 (Deserialization)是通过从存储或者网络读取对象的状态，重新创建该对象。即将字节流转换回对象 序列化广泛应用在远程调用（RPC）或者数据存取。 Serializable接口Serializable接口，这是一个空接口； 如果一个类实现了Serializable接口，那么就代表这个类是自动支持序列化和反序列化的，毋须我们编程实现。 如果一个类没有实现Serializable接口，那么默认是不能被序列化的，除非使用其他办法。 只能序列化类的状态，不能序列化类的方法。 如果一个类实现了Serializable接口，那么它的子类默认也可以被序列化和反序列化，不论子类是否实现了Serializable接口。 如果一个类实现了Serializable接口，其父类没有实现Serializable接口，那么父类必须有无参的构造器，并且父类中的状态默认不能被序列化。如果想要序列化和反序列化父类，需要在子类里干预序列化的过程，例如使用readObject和writeOjbect方法来序列化和反序列化父类的状态。 实例 如何把一个对象序列化到磁盘上，并从磁盘上将该对象恢复，使用的是ObjectOutputStream和ObjectInputStream。 使用transient关键字、readObject和writeOjbect方法、writeReplace和readresolve方法干预序列化。 实现序列化下面的例子演示了如何使用ObjectOutputStream把一个Person对象写到磁盘上，之后再通过ObjectInputStream把对象恢复。 执行下面的代码可以发现： 创建Person对象的时候，Person构造器输出了I am constructor，too.；但反序列化构建Person对象的时候，并没有使用构造器。 反序列化回来得到的Person对象p2和之前的p1内地地址不一样，是深拷贝。 1234567891011121314151617181920public static void main(String[] args) throws IOException,ClassNotFoundException &#123; // Person对象文件路径 String path = "d:/tmp/person.dat"; // 创建一个Person对象 Person p1 = new Person("张三", 18); // 序列化Person对象 ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(path)); out.writeObject(p1); out.close(); // 反序列化 ObjectInputStream in = new ObjectInputStream(new FileInputStream(path)); Person p2 = (Person) in.readObject(); in.close(); // 打印反序列化的结果 System.out.println("p2: " + p2); // 反序列化后对象的内存地址和原来的地址不同，是深拷贝。 System.out.println("p1 == p2 is: " + (p1 == p2)); &#125; Person类，仅有name和age两个属性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.io.Serializable;/** * 使用java本身的序列化，必须实现Serializable 接口 */public class Person implements Serializable &#123; private String name; private int age; public Person() &#123; System.out.println("I am constructor"); &#125; public Person(String name, int age) &#123; System.out.println("I am constructor，too."); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125; 干预序列化3.1 transient并不是所有java对象里的内容，都是我们想要序列化写出去的，例如一些隐私数据，比如password等。对于上面的Person对象，假如age是一个隐私字段，我们不想序列化写到磁盘上，那么我们可以用transient关键字来标记它。 1private transient int age; 3.2 readObject和writeOjbect方法我们可以通过readObject和writeOjbect方法来干预序列化，例如把待序列化的对象的某个属性字段加密和解密，或者把transient关键字标记的属性序列化写出去。 1234567891011121314151617181920212223242526/** * 序列化transient修饰的字段,通过ObjectOutputStream把想要序列化的transient字段写出去。 * &lt;p&gt; * 访问控制符必须是private，一定要先执行out.defaultWriteObject(); * * @param out ObjectOutputStream * @throws IOException */private void writeObject(ObjectOutputStream out) throws IOException &#123; out.defaultWriteObject(); out.writeInt(age +10);&#125;/** * 反序列化transient修饰的字段，通过ObjectInputStream把transient字段读出来 * &lt;p&gt; * 访问控制符必须是private，一定要先执行in.defaultReadObject(); * * @param in ObjectInputStream * @throws IOException */private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); age = in.readInt() - 10;&#125; 3.3 readResolve和writeReplace方法前文已经说过，反序列化得到的对象，和序列化之前的对象，不是同一个对象，它们的内存地址不相同。那么，假设一个单例类实现了Serializable接口，反序列化时内存里就会出现多个实例，这违背了当初设计单例的初衷。 Java的序列化机制提供了一个钩子方法，即私有的readresolve方法，允许我们来控制反序列化时得到的对象。下面的代码就说明了readresolve方法的用法，可以看出反序列化得到的对象，还是唯一的单例对象。 与readresolve方法对应，还有一个writeReplace方法，可以让我们在writeOjbect方法之前修改序列化的对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Singleton implements Serializable &#123; private Singleton() &#123; &#125; private static final Singleton INSTANCE = new Singleton(); public static Singleton getInstance() &#123; return INSTANCE; &#125; private void writeObject(ObjectOutputStream out) throws IOException &#123; System.out.println("writeObject"); &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; System.out.println("readObject"); &#125; /** * writeReplace方法会在writeObject方法之前执行。 * ObjectOutputStream会把writeReplace方法返回的对象序列化写出去。 * * @return Object * @throws ObjectStreamException */ private Object writeReplace() throws ObjectStreamException &#123; System.out.println("writeReplace"); return INSTANCE; &#125; /** * readResolve方法会在readObject方法之后执行，可以再次修改readObject方法返回的对象数据。 * * @return Object * @throws ObjectStreamException */ private Object readResolve() throws ObjectStreamException &#123; System.out.println("readResolve"); return INSTANCE; &#125;&#125; 验证代码如下，同时也可以看出，序列化时，先执行了writeReplace方法，后执行了writeObject方法；在反序列化的时候，先执行了readObject方法，最后执行了readResolve方法。 1234567891011121314151617public static void main(String[] args) throws IOException,ClassNotFoundException &#123; String path = "d:/tmp/singleton.dat"; Singleton singleton = Singleton.getInstance(); // 序列化Singleton对象 ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(path)); out.writeObject(singleton); out.close(); // 反序列化 ObjectInputStream in = new ObjectInputStream(new FileInputStream(path)); Singleton Singleton2 = (Singleton) in.readObject(); in.close(); // 反序列化后对象的内存地址和原来的地址相同。 System.out.println(singleton == Singleton2);&#125; 输出结果如下： 12345readResolvewriteObjectreadObjectreadResolvetrue 通常情况下，如无必要，只需要writeObject只和readObject配合使用就够了。此外，关于Serializable，还可能有readObjectNoData()和serialVersionUID需要关注。假如Person对象被序列化到磁盘上了，第二天Person类被修改了，多了旧对象里没有的内容，那么可以实现readObjectNoData，弥补这种因临时扩展而无法兼容反序列化的缺陷。serialVersionUID用于标记对象的版本。 拓展部分上面已经知道可以通过writeObject和readObject、readResolve和writeReplace、还有readObjectNoData方法来干预序列化和反序列化。那么这些方法是什么时候被调用的呢？ 他们是在ObjectOutputStream或ObjectInputStream中，配合SerialCallbackContext、ObjectStreamClass类，通过反射回调实现的。ObjectStreamClass类中有invokeWriteObject、invokeReadObject、invokeReadObjectNoData、invokeWriteReplace、invokeReadResolve等方法；有兴趣的同学，可以去看看源码。 以前文的Person类中private void writeObject(ObjectOutputStream out) throws IOException的调用为例，我们去ObjectOutputStream类的writeObject()方法开始，依次看下列方法就知道了。 123456789101.ObjectOutputStream.writeObject(Object obj)2.ObjectOutputStream.writeObject0(Object obj, boolean unshared)3.ObjectOutputStream.writeOrdinaryObject(Object obj, ObjectStreamClass desc, boolean unshared)// 就是在第4个方法里初始化了序列化回调上下文SerialCallbackContext4.ObjectOutputStream.writeSerialData(Object obj, ObjectStreamClass desc)5.ObjectStreamClass.invokeWriteObject(Object obj, ObjectOutputStream out)// 6：通过反射调用Person类中的writeObject(ObjectOutputStream out)方法。6.Method.invoke(Object obj, Object... args) 参考 序列化-Serializable接口 序列化-Externalizable接口]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器：并发容器]]></title>
    <url>%2F2019%2F03%2F21%2FJava%2Fbase%2FJava%E5%AE%B9%E5%99%A8%EF%BC%9A%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[同步容器早期版本的JDK提供的同步容器类为Vector和Hashtable和Stack JDK1.2 提供了Collections.synchronizedXxx等工程方法，将普通的容器继续包装。对每个共有方法都进行同步。 Vector Stack HashTable Collections.synchronized方法生成，例如： Collectinons.synchronizedList() Collections.synchronizedSet() Collections.synchronizedMap() Collections.synchronizedSortedSet() Collections.synchronizedSortedMap() Vector1. 同步它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2. 与 ArrayList 的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。 3. 替代方案可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); 也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); Map由上面的分析我们知道，同步容器并不能保证多线程安全，而并发容器是针对多个线程并发访问而设计的，在jdk5.0引入了concurrent包，其中提供了很多并发容器，极大的提升同步容器类的性能。 并发容器J.U.CJDK下的一个包Java.util.concurrent ArrayList-&gt;CopyOnWriteArrayList 写操作的时候复制，在新的数组上操作，写完后，将原有的数据指向新数组 拷贝数组消耗内存 不能用于实时读数组，可能读取到旧的，适合读多写少 HashSet、TreeSet-&gt;CopyOnWriteArraySet、ConcurrentSkipListSet ConcurrentSkipListSet：支持自然排序（TreeSet），基于map。对于批量操作并不能保证原子操作，对于单个cotains操作可以 HashMap、TreeMap-&gt;ConcurrentHashMap、ConcurrentSkipListMap ConcurrentHashMap:针对读操作做了大量的优化，能应付很大的并发，速度快 ConcurrentSkipListMap：TreeMap的安全版，基于跳表实现，支持更高的并发，线程越多越优秀 Collections.synchronizedXXX(List、Set、Map) HashMap与ConcurrentHashMapHashMap 数据结构： 数组 引用 参数 初始容量 加载因子 寻址方式 取模操作消耗操作较大，使用与操作与2^n-1进行与运算 ConcurrentHashMap 对应的非并发容器：HashMap 目标：代替Hashtable、synchronizedMap，支持复合操作 原理：JDK6中采用一种更加细粒度的加锁机制Segment“分段锁”，JDK8中采用CAS无锁算法，详细分析推荐阅读【JDK】：ConcurrentHashMap高并发机制——【转载】。 ConcurrentHashMap使用了一种粒度更细的加锁机制来实现更大程序的共享，称为分段锁。在这种机制中，任意数量的读取线程可以并发地访问Map，执行读操作的线程和执行写操作的线程可以并发访问Map，并且一定数量的写入线程可以并发修改Map。 ConcurrentHashMap的迭代器不会抛出ConcurrentModificationException，因此不需要在迭代过程中对容器加锁，它们返回的迭代器具有弱一致性，可以容忍并发的修改，当创建迭代器时会遍历已有元素，并可以(不保证)在迭代器被构造后将修改操作反映给容器。 1. 存储结构123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 Segment 继承自 ReentrantLock。 123456789101112131415161718static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;&#125; final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行size操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用RETRIES_BEFORE_LOCK定义，该值为2，retries初始值为-1，因此尝试次数为3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */static final int RETRIES_BEFORE_LOCK = 2;public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; // 超过尝试次数，则对每个 Segment 加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; JDK 1.8 的改动JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且JDK1.8的实现也在链表过长时会转换为红黑树。 ConcurrentHashMapConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。 Base 1.7先来看看 1.7 的实现，下面是他的结构图： 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 它的核心成员变量： 1234567/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下： 12345678910111213141516static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶 transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor; &#125; 看看其中 HashEntry 的组成： 和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。 原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。 下面也来看看核心的 put get 方法。 put 方法1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false);&#125; 首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。 12345678910111213141516171819202122232425262728293031323334353637383940414243final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。 尝试自旋获取锁。 如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。 再结合图看看 put 的流程。 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。 最后会解除在 1 中所获取当前 Segment 的锁。 get 方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; get 逻辑比较简单： 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。 ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。 Base 1.81.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。 那就是查询遍历链表效率太低。 因此 1.8 做了一些数据结构上的调整。 首先来看下底层的组成结构： 看起来是不是和 1.8 HashMap 结构类似？ 其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。 其中的 val next 都用了 volatile 修饰，保证了可见性。 put 方法重点来看看 put 函数： 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 get 方法 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 就不满足那就按照链表的方式遍历获取值。 1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。 ConcurrentSkipListMap代替同步的SortedMap SetConcurrentSkipListSet代替同步的SortedSet ListCopyOnWriteArrayList 对应的非并发容器：ArrayList 目标：代替Vector、synchronizedList 原理：利用高并发往往是读多写少的特性，对读操作不加锁，对写操作，先复制一份新的集合，在新的集合上面修改，然后将新集合赋值给旧的引用，并通过volatile 保证其可见性，当然写操作的锁是必不可少的了。 仅当迭代操作远远多于修改操作时才应该使用。 关于这一部分可参考【JDK】：CopyOnWriteArrayList、CopyOnWriteArraySet 源码解析 12public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; 读写分离写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。 写操作需要加锁，防止并发写入时导致写入数据丢失。 写操作结束之后需要把原始数组指向新的复制数组。 1234567891011121314151617181920212223public boolean add(E e) &#123; final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; final void setArray(Object[] a) &#123; array = a; &#125;@SuppressWarnings("unchecked")private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 适用场景CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 但是 CopyOnWriteArrayList 有其缺陷： 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 CopyOnWriteArraySet 对应的非并发容器：HashSet 目标：代替synchronizedSet 原理：基于CopyOnWriteArrayList实现，其唯一的不同是在add时调用的是CopyOnWriteArrayList的addIfAbsent方法，其遍历当前Object数组，如Object数组中已有了当前元素，则直接返回，如果没有则放入Object数组的尾部，并返回。 关于这一部分可参考【JDK】：CopyOnWriteArrayList、CopyOnWriteArraySet 源码解析 ConcurrentSkipListMap 对应的非并发容器：TreeMap 目标：代替synchronizedSortedMap(TreeMap) 原理：Skip list（跳表）是一种可以代替平衡树的数据结构，默认是按照Key值升序的。Skip list让已排序的数据分布在多层链表中，以0-1随机数决定一个数据的向上攀升与否，通过”空间来换取时间”的一个算法。ConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）结构实现，在理论上能够在O（log（n））时间内完成查找、插入、删除操作。 ConcurrentSkipListSet 对应的非并发容器：TreeSet 目标：代替synchronizedSortedSet 原理：内部基于ConcurrentSkipListMap实现 Queue非阻塞队列ConcurrentLinkedQueue**不会阻塞的队列 对应的非并发容器：Queue 原理：基于链表实现的FIFO队列（LinkedList的并发版本） 阻塞队列阻塞队列最核心的功能是，能够可阻塞式的插入和删除队列元素。当前队列为空时，会阻塞消费数据的线程，直至队列非空时，通知被阻塞的线程；当队列满时，会阻塞插入数据的线程，直至队列未满时，通知插入数据的线程（生产者线程）。 对应的接口：BlockingQueue 特点：拓展了Queue，增加了可阻塞的插入和获取等操作 原理：通过ReentrantLock实现线程安全，通过Condition实现阻塞和唤醒 实现类： LinkedBlockingQueue：基于链表实现的可阻塞的FIFO队列 ArrayBlockingQueue：基于数组实现的可阻塞的FIFO队列 PriorityBlockingQueue：按优先级排序的队列 BlockingQueuejava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现： FIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。 使用 BlockingQueue 实现生产者消费者问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ProducerConsumer &#123; private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5); private static class Producer extends Thread &#123; @Override public void run() &#123; try &#123; queue.put("product"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("produce.."); &#125; &#125; private static class Consumer extends Thread &#123; @Override public void run() &#123; try &#123; String product = queue.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("consume.."); &#125; &#125;&#125;public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; Producer producer = new Producer(); producer.start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; Consumer consumer = new Consumer(); consumer.start(); &#125; for (int i = 0; i &lt; 3; i++) &#123; Producer producer = new Producer(); producer.start(); &#125;&#125;produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. ArrayBlockingQueue该并发集合其底层是使用了java.util.ReentrantLock和java.util.Condition来完成并发控制的 主要属性ArrayBlockingQueue的主要属性如下: 123456789101112131415161718192021222324252627282930/** The queued items *///采用数组存储final Object[] items;/** items index for next take, poll, peek or remove */int takeIndex;/** items index for next put, offer, or add */int putIndex;/** Number of elements in the queue */int count;/* * Concurrency control uses the classic two-condition algorithm * found in any textbook. *//** Main lock guarding all access *///使用ReentrantLock保证线程安全final ReentrantLock lock;/** Condition for waiting takes *///Condition实现锁的条件//当获取数据的消费者线程被阻塞时会将该线程放置到notEmpty等待队列中private final Condition notEmpty;/** Condition for waiting puts *///当插入数据的生产者线程被阻塞时，会将该线程放置到notFull等待队列中private final Condition notFull; 从源码中可以看出ArrayBlockingQueue内部是采用数组进行数据存储的（属性items） 为了保证线程安全，采用的是ReentrantLock lock，为了保证可阻塞式的插入删除数据利用的是Condition 当获取数据的消费者线程被阻塞时会将该线程放置到notEmpty等待队列中 当插入数据的生产者线程被阻塞时，会将该线程放置到notFull等待队列中。 而notEmpty和notFull等中要属性在构造方法中进行创建： 12345678public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125; 接下来，主要看看可阻塞式的put和take方法是怎样实现的。 put方法详解put(E e)方法源码如下： 1234567891011121314public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //如果当前队列已满，将线程移入到notFull等待队列中 while (count == items.length) notFull.await(); //满足插入数据的要求，直接进行入队操作 enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 该方法的逻辑很简单，当队列已满时（count == items.length）将线程移入到notFull等待队列中，如果当前满足插入数据的条件，就可以直接调用enqueue(e)插入数据元素。enqueue方法源码为： 123456789101112private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //插入数据 items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; //通知消费者线程，当前队列中有数据可供消费 notEmpty.signal();&#125; enqueue方法的逻辑同样也很简单，先完成插入数据，即往数组中添加数据（items[putIndex] = x），然后通知被阻塞的消费者线程，当前队列中有数据可供消费（notEmpty.signal()）。 take方法详解take方法源码如下： 12345678910111213public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //如果队列为空，没有数据，将消费者线程移入等待队列中 while (count == 0) notEmpty.await(); //获取数据 return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; take方法也主要做了两步：1. 如果当前队列为空的话，则将获取数据的消费者线程移入到等待队列中；2. 若队列不为空则获取数据，即完成出队操作dequeue。dequeue方法源码为： 1234567891011121314151617private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings("unchecked") //获取数据 E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); //通知被阻塞的生产者线程 notFull.signal(); return x;&#125; dequeue方法也主要做了两件事情： 获取队列中的数据，即获取数组中的数据元素（(E) items[takeIndex]）； 通知notFull等待队列中的线程，使其由等待队列移入到同步队列中，使其能够有机会获得lock，并执行完成功退出。 从以上分析，可以看出put和take方法主要是通过condition的通知机制来完成可阻塞式的插入数据和获取数据。在理解ArrayBlockingQueue后再去理解LinkedBlockingQueue就很容易了。 LinkedBlockingQueueLinkedBlockingQueue是用链表实现的有界阻塞队列，当构造对象时为指定队列大小时，队列默认大小为Integer.MAX_VALUE。从它的构造方法可以看出： 123public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125; LinkedBlockingQueue的主要属性LinkedBlockingQueue的主要属性有： 1234567891011121314151617181920212223242526/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** * Head of linked list. * Invariant: head.item == null */transient Node&lt;E&gt; head;/** * Tail of linked list. * Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 可以看出与ArrayBlockingQueue主要的区别是，LinkedBlockingQueue在插入数据和删除数据时分别是由两个不同的lock（takeLock和putLock）来控制线程安全的，因此，也由这两个lock生成了两个对应的condition（notEmpty和notFull）来实现可阻塞的插入和删除数据。并且，采用了链表的数据结构来实现队列，Node结点的定义为： 12345678910111213static class Node&lt;E&gt; &#123; E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125; 接下来，我们也同样来看看put方法和take方法的实现。 put方法详解put方法源码为: 12345678910111213141516171819202122232425262728293031323334public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; /* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ //如果队列已满，则阻塞当前线程，将其移入等待队列 while (count.get() == capacity) &#123; notFull.await(); &#125; //入队操作，插入数据 enqueue(node); c = count.getAndIncrement(); //若队列满足插入数据的条件，则通知被阻塞的生产者线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty();&#125; put方法的逻辑也同样很容易理解，可见注释。基本上和ArrayBlockingQueue的put方法一样。take方法的源码如下： 123456789101112131415161718192021222324public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; //当前队列为空，则阻塞当前线程，将其移入到等待队列中，直至满足条件 while (count.get() == 0) &#123; notEmpty.await(); &#125; //移除队头元素，获取数据 x = dequeue(); c = count.getAndDecrement(); //如果当前满足移除元素的条件，则通知被阻塞的消费者线程 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; take方法的主要逻辑请见于注释，也很容易理解。 比较相同点： ArrayBlockingQueue和LinkedBlockingQueue都是通过condition通知机制来实现可阻塞式插入和删除元素，并满足线程安全的特性； 不同点： ArrayBlockingQueue底层是采用的数组进行实现，而LinkedBlockingQueue则是采用链表数据结构； ArrayBlockingQueue插入和删除数据，只采用了一个lock，而LinkedBlockingQueue则是在插入和删除分别采用了putLock和takeLock，这样可以降低线程由于线程无法获取到lock而进入WAITING状态的可能性，从而提高了线程并发执行的效率。 PriorityBlockingQueueBlockingDequeCondition详解Condition的await和signal等待/通知机制 参考 crossoverJie]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器：普通容器]]></title>
    <url>%2F2019%2F03%2F21%2FJava%2Fbase%2FJava%E5%AE%B9%E5%99%A8%EF%BC%9A%E6%99%AE%E9%80%9A%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[一、概览容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 Collection 1. Set TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。 LinkedHashSet：具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。 2. List ArrayList：基于动态数组实现，支持随机访问。 Vector：和 ArrayList 类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 3. Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列，默认是最小堆。 Deque：双端队列。 Map TreeMap：基于红黑树实现。 HashMap：基于哈希表实现。 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 二、容器中的设计模式迭代器模式 Collection 继承了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("a");list.add("b");for (String item : list) &#123; System.out.println(item);&#125; 适配器模式java.util.Arrays#asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 应该注意的是 asList() 的参数为泛型的变长参数，不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = &#123;1, 2, 3&#125;;List list = Arrays.asList(arr); 也可以使用以下方式调用 asList()： 1List list = Arrays.asList(1, 2, 3); 三、源码分析如果没有特别说明，以下源码分析基于 JDK 1.8。 ArrayList非线程安全 概览 实现了 RandomAccess 接口，因此支持随机访问。这是理所当然的，因为 ArrayList 是基于数组实现的。 java.io.Serializable接口，实现序列化。 Cloneable接口，实现对象的可克隆 List接口 123//ArrayList&lt;E&gt;定义泛型的元素类型public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1private static final int DEFAULT_CAPACITY = 10; 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 1234567891011121314151617181920212223242526272829303132333435363738394041//向ArrayList里增加元素public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!!保证容量足够 elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; //elementData是存放数组元素的数组 ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 当第一次调用add(E e)方法的时候，判读是不是无参构造函数创建的对象，如果是， // 将DEFAULT_CAPACITY即10作为ArrayList的容量，此时minCapacity = 1 //DEFAULTCAPACITY_EMPTY_ELEMENTDATA if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//修改次数，在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化 // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length;//原有长度 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//新长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //方法传回的数组是新的数组对象，改变传回数组中的元素值，不会影响原来的数组。 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 删除元素需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。 12345678910public E remove(int index) &#123; rangeCheck(index);//检查越界 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; Fail-FastmodCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 123456789101112131415161718private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 序列化ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。 1transient Object[] elementData; // non-private to simplify nested class access ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 123456789101112131415161718192021222324252627282930313233343536373839private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。 123ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list); LinkedList概览基于双向链表实现，使用 Node 存储链表节点信息。 12345private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;&#125; 每个链表存储了 first 和 last 指针： 12transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; 与 ArrayList 的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 HashMap为了便于理解，以下源码分析以 JDK 1.7 为主。 12345678910111213141516171819public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; /** * 核心成员变量 */ //初始化桶大小，因为底层是数组，所以这是数组默认的大小。 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //桶最大值。 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认的负载因子（0.75） static final float DEFAULT_LOAD_FACTOR = 0.75f; //table 真正存放数据的数组。 transient Entry&lt;K,V&gt;[] table =(Entry&lt;K,V&gt;[]) EMPTY_TABLE; //Map 存放数量的大小。 transient int size; //桶大小，可在初始化时显式指定。 int threshold; //负载因子，可在初始化时显式指定。 final float loadFactor; 存储结构内部包含了一个 Entry 类型的数组 table。 1transient Entry[] table; Entry 存储着键值对。它包含了四个字段，从 next 字段我们可以看出 Entry 是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。HashMap 使用拉链法来解决冲突，同一个链表中存放哈希值相同的 Entry。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125;&#125; 拉链法的工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put("K1", "V1");map.put("K2", "V2");map.put("K3", "V3"); 新建一个 HashMap，默认大小为 16； 插入 &lt;K1,V1&gt; 键值对，先计算 K1 的 hashCode 为 115，使用除留余数法得到所在的桶下标 115%16=3。 插入 &lt;K2,V2&gt; 键值对，先计算 K2 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6。 插入 &lt;K3,V3&gt; 键值对，先计算 K3 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6，插在 &lt;K2,V2&gt; 前面。 应该注意到链表的插入是以头插法方式进行的，例如上面的 &lt;K3,V3&gt; 不是插在 &lt;K2,V2&gt; 后面，而是插入在链表头部。 查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度显然和链表的长度成正比。 put 操作1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;&#125; 判断当前数组是否需要初始化。 如果 key 为空，则 put 一个空值进去。 根据 key 计算出 hashcode。 根据计算出的 hashcode 定位出所在桶。 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。 如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。 HashMap 允许插入键为 null 的键值对。但是因为无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 当调用 addEntry 写入 Entry 时需要判断是否需要扩容。 如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位。 而在 createEntry 中会将当前位置的桶传入到新建的桶中，如果当前桶有值就会在位置形成链表。 12345678910111213141516171819202122void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125;Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h;&#125; get操作123456789101112131415161718192021222324public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。 判断该位置是否为链表。 不是链表就根据 key、key 的 hashcode 是否相等来返回值。 为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。 啥都没取到就直接返回 null 。 确定桶下标很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); 计算 hash 值 1234567891011121314151617final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; 取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123y : 10110010x : 00010000y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 扩容-基本原理设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此平均查找次数的复杂度为 O(N/M)。 为了让查找的成本降低，应该尽可能使得 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数主要有：capacity、size、threshold 和 load_factor。 参数 含义 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size 键值对数量。 threshold size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = capacity * loadFactor。 123456789101112131415static final int DEFAULT_INITIAL_CAPACITY = 16;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;transient Entry[] table;transient int size;int threshold;final float loadFactor;transient int modCount; 从下面的添加元素代码中可以看出，当需要扩容时，令 capacity 为原来的两倍。 123456void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);//先进行赋值 if (size++ &gt;= threshold)//然后进行扩容 resize(2 * table.length);&#125; 扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。 123456789101112131415161718192021222324252627282930void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 扩容-重新计算桶下标在进行扩容时，需要把键值对重新放到对应的桶上。HashMap 使用了一个特殊的机制，可以降低重新计算桶下标的操作。 假设原数组长度 capacity 为 16，扩容之后 new capacity 为 32： 12capacity : 00010000new capacity : 00100000 对于一个 Key， 它的哈希值如果在第 5 位上为 0，那么取模得到的结果和之前一样； 如果为 1，那么得到的结果为原来的结果 +16。 计算数组容量HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。 先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到： 123mask |= mask &gt;&gt; 1 11011000mask |= mask &gt;&gt; 2 11111110mask |= mask &gt;&gt; 4 11111111 mask+1 是大于原始数字的最小的 2 的 n 次方。 12num 10010000mask+1 100000000 以下是 HashMap 中计算数组容量的代码： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 链表转红黑树从 JDK 1.8 开始，一个桶存储的链表长度大于 8 时会将链表转换为红黑树。 HashMap在JDK1.8及以后的版本中引入了红黑树结构，若桶中链表元素个数大于等于8时，链表转换成树结构；若桶中链表元素个数小于等于6时，树结构还原成链表。因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。 还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。 与 HashTable 的比较 HashTable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 JDK1.8不知道 1.7 的实现大家看出需要优化的点没有？ 其实一个很明显的地方就是： 当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)。 因此 1.8 中重点优化了这个查询效率。 1.8 HashMap 结构图： 先来看看几个核心的成员变量： 12345678910111213static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;transient Node&lt;K,V&gt;[] table;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;transient int size; 和 1.7 大体上都差不多，还是有几个重要的区别： TREEIFY_THRESHOLD 用于判断是否需要将链表转换为红黑树的阈值。 HashEntry 修改为 Node。 Node 的核心组成其实也是和 1.7 中的 HashEntry 一样，存放的都是 key value hashcode next 等数据。 再来看看核心方法。 put 方法 看似要比 1.7 的复杂，我们一步步拆解： 判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到 key 相同时直接退出遍历。 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。 最后判断是否需要进行扩容。 get 方法123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; get 方法看起来就要简单许多了。 首先将 key hash 之后取得所定位的桶。 如果桶为空则直接返回 null 。 否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。 如果第一个不匹配，则判断它的下一个是红黑树还是链表。 红黑树就按照树的查找方式返回值。 不然就按照链表的方式遍历匹配返回值。 从这两个核心方法（get/put）可以看出 1.8 中对大链表做了优化，修改为红黑树之后查询效率直接提高到了 O(logn)。 但是 HashMap 原有的问题也都存在，比如在并发场景下使用时容易出现死循环。 123456789final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; map.put(UUID.randomUUID().toString(), &quot;&quot;); &#125; &#125;).start();&#125; 但是为什么呢？简单分析下。 看过上文的还记得在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。 如下图： 遍历方式还有一个值得注意的是 HashMap 的遍历方式，通常有以下几种： 123456789101112Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator(); while (entryIterator.hasNext()) &#123; Map.Entry&lt;String, Integer&gt; next = entryIterator.next(); System.out.println("key=" + next.getKey() + " value=" + next.getValue()); &#125; Iterator&lt;String&gt; iterator = map.keySet().iterator(); while (iterator.hasNext())&#123; String key = iterator.next(); System.out.println("key=" + key + " value=" + map.get(key)); &#125; 强烈建议使用第一种 EntrySet 进行遍历。 第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低。 简单总结下 HashMap：无论是 1.7 还是 1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至 1.7 中出现死循环导致系统不可用（1.8 已经修复死循环问题）。 因此 JDK 推出了专项专用的 ConcurrentHashMap ，该类位于 java.util.concurrent 包下，专门用于解决并发问题。 哈希算法扰动函数 123456//混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。static final int hash(Object key)&#123; int h; return (key==null) ? 0 : (h = key.hashCode())^(h&gt;&gt;&gt;16);&#125;//计算下标，指与桶的个数进行取余，通过异或运算实现，异或运算运算速度快。 LinkedHashMap存储结构继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。 1public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; 内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。 123456789/** * The head (eldest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; head;/** * The tail (youngest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; tail; accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。 1final boolean accessOrder; LinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。 12void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125; next用于维护HashMap各个桶中的Entry链 before、after用于维护LinkedHashMap的双向链表 afterNodeAccess()当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。 123456789101112131415161718192021222324void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; afterNodeInsertion()在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。 evict 只有在构建 Map 的时候才为 false，在这里为 true。 1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; removeEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据。 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; LRU 缓存以下是使用 LinkedHashMap 实现的一个 LRU 缓存： 设定最大缓存空间 MAX_ENTRIES 为 3； 使用 LinkedHashMap 的构造函数将 accessOrder 设置为 true，开启 LRU 顺序； 覆盖 removeEldestEntry() 方法实现，在节点多于 MAX_ENTRIES 就会将最近最久未使用的数据移除。 123456789101112131415161718192021class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private static final int MAX_ENTRIES = 3; protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_ENTRIES; &#125; LRUCache() &#123; super(MAX_ENTRIES, 0.75f, true); &#125;&#125; public static void main(String[] args) &#123; LRUCache&lt;Integer, String&gt; cache = new LRUCache&lt;&gt;(); cache.put(1, "a"); cache.put(2, "b"); cache.put(3, "c"); cache.get(1); cache.put(4, "d"); System.out.println(cache.keySet());&#125; [3, 1, 4] TreeMap如果我们希望Map可以保持key的大小顺序的时候，我们就需要利用TreeMap了。 123456789101112TreeMap&lt;Integer, String&gt; tmap = new TreeMap&lt;Integer, String&gt;();tmap.put(1, "语文");tmap.put(3, "英语");tmap.put(2, "数学");tmap.put(4, "政治");tmap.put(5, "历史");tmap.put(6, "地理");tmap.put(7, "生物");tmap.put(8, "化学");for(Entry&lt;Integer, String&gt; entry : tmap.entrySet()) &#123; System.out.println(entry.getKey() + ": " + entry.getValue());&#125; 其大致的结构如下所示：使用红黑树的好处是能够使得树具有不错的平衡性，这样操作的速度就可以达到log(n)的水平了。 put函数如果存在的话，old value被替换；如果不存在的话，则新添一个节点，然后对做红黑树的平衡操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; // 如果该节点存在，则替换值直接返回 if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 如果该节点未存在，则新建 Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; // 红黑树平衡调整 fixAfterInsertion(e); size++; modCount++; return null;&#125; get函数get函数则相对来说比较简单，以log(n)的复杂度进行get 1234567891011121314151617181920212223242526final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; // 按照二叉树搜索的方式进行搜索，搜到返回 while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125;public V get(Object key) &#123; Entry&lt;K,V&gt; p = getEntry(key); return (p==null ? null : p.value);&#125; successor后继TreeMap是如何保证其迭代输出是有序的呢？其实从宏观上来讲，就相当于树的中序遍历(LDR)。我们先看一下迭代输出的步骤 123for(Entry&lt;Integer, String&gt; entry : tmap.entrySet()) &#123; System.out.println(entry.getKey() + ": " + entry.getValue());&#125; for语句会做如下转换为： 1234for(Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = tmap.entrySet().iterator() ; tmap.hasNext(); ) &#123; Entry&lt;Integer, String&gt; entry = it.next(); System.out.println(entry.getKey() + ": " + entry.getValue());&#125; 在it.next()的调用中会使用nextEntry调用successor这个是过的后继的重点，具体实现如下： 1234567891011121314151617181920212223static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123; // 有右子树的节点，后继节点就是右子树的“最左节点” // 因为“最左子树”是右子树的最小节点 Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123; // 如果右子树为空，则寻找当前节点所在左子树的第一个祖先节点 // 因为左子树找完了，根据LDR该D了 Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; // 保证左子树 while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 怎么理解这个successor呢？只要记住，这个是中序遍历就好了，L-D-R。具体细节如下： a. 空节点，没有后继b. 有右子树的节点，后继就是右子树的“最左节点”c. 无右子树的节点，后继就是该节点所在左子树的第一个祖先节点 a.好理解，不过b, c，有点像绕口令啊，没关系，上图举个例子就懂了！ 有右子树的节点，节点的下一个节点，肯定在右子树中，而右子树中“最左”的那个节点则是右子树中最小的一个，那么当然是右子树的“最左节点”，就好像下图所示： 无右子树的节点，先找到这个节点所在的左子树(右图)，那么这个节点所在的左子树的父节点(绿色节点)，就是下一个节点。 WeakHashMap存储结构WeakHashMap 的 Entry 继承自 WeakReference，被 WeakReference 关联的对象在下一次垃圾回收时会被回收。 WeakHashMap 主要用来实现缓存，通过使用 WeakHashMap 来引用缓存对象，由 JVM 对这部分缓存进行回收。 1private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; ConcurrentCacheTomcat 中的 ConcurrentCache 使用了 WeakHashMap 来实现缓存功能。 ConcurrentCache 采取的是分代缓存： 经常使用的对象放入 eden 中，eden 使用 ConcurrentHashMap 实现，不用担心会被回收（伊甸园）； 不常用的对象放入 longterm，longterm 使用 WeakHashMap 实现，这些老对象会被垃圾收集器回收。 当调用 get() 方法时，会先从 eden 区获取，如果没有找到的话再到 longterm 获取，当从 longterm 获取到就把对象放入 eden 中，从而保证经常被访问的节点不容易被回收。 当调用 put() 方法时，如果 eden 的大小超过了 size，那么就将 eden 中的所有对象都放入 longterm 中，利用虚拟机回收掉一部分不经常使用的对象。 1234567891011121314151617181920212223242526272829303132public final class ConcurrentCache&lt;K, V&gt; &#123; private final int size; private final Map&lt;K, V&gt; eden; private final Map&lt;K, V&gt; longterm; public ConcurrentCache(int size) &#123; this.size = size; this.eden = new ConcurrentHashMap&lt;&gt;(size); this.longterm = new WeakHashMap&lt;&gt;(size); &#125; public V get(K k) &#123; V v = this.eden.get(k); if (v == null) &#123; v = this.longterm.get(k); if (v != null) this.eden.put(k, v); &#125; return v; &#125; public void put(K k, V v) &#123; if (this.eden.size() &gt;= size) &#123; this.longterm.putAll(this.eden); this.eden.clear(); &#125; this.eden.put(k, v); &#125;&#125; 参考 Java容器 crossoverJie Java TreeMap工作原理及实现]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：Spring实战]]></title>
    <url>%2F2019%2F03%2F14%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpringBoot%EF%BC%9ASpring%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Spring框架核心知识 spring容器 依赖注入DI 面向切面编程AOP 如何使用Spring构建Web应用程序 如何在应用程序的后端使用Spring JDBC等 如何使用Spring与其他的应用和服务进行集成 RESTful 对异步消息的支持，消息服务与消息队列 SpringBoot Spring的核心简化Java开发降低Java开发的复杂性 基于POJO的轻量级和最小入侵性编程 通过依赖注入和面向接口实现松耦合 基于切面和惯例进行声明式编程 通过切面和模板减少样板式代码 激发POJO的性能POJO： 简单的Java对象，即普通的JavaBeans 有一些属性已经getter与setter方法，以及简单的运算属性，但不包括业务逻辑 在Spring当中，类通常没有任何痕迹表明使用了Spring，最坏的场景是使用了Spring的注解。因此Spring的非侵入编程模型意味着这个类在非Srping应用中可以发挥同样的作用 Spring通过依赖注入（DI）来进行装配，实现POJO 依赖注入DI松耦合 前面我们在写程序的时候，都是面向接口编程，通过DaoFactroy等方法来实现松耦合 DAO层和Service层通过DaoFactory来实现松耦合 如果Serivce层直接new DaoBook()，那么DAO和Service就紧耦合了【Service层依赖紧紧依赖于Dao】 而Spring给我们更加合适的方法来实现松耦合，并且更加灵活、功能更加强大！—-&gt;IOC控制反转 DI功能的实现 任何一个实际意义的应用，都会有两个或者更多个类组成，这些类进行相互协作来完成特定的业务逻辑。 传统做法：每个对象负责管理与自己协作的对象（即它依赖的对象）的引用，这将会导致高度耦合和难以测试的代码。 耦合的两面性 紧密耦合的代码难以测试、复用、理解，并且典型地表现出“打地鼠”式bug的特性 一定程度的耦合是必须的，完全没有耦合的代码什么也做不了，不同的类必须以适当的方式进行交互。 DI：对象的依赖关系将由系统中负责协调各对象的第三方组件在创建对象时进行设定，对象无需自行创建或管理它们的依赖关系 构造器注入，同时Quest是一个接口，也因此它可以引用实现该接口的其他类。即松耦合 装配：创建应用组件间的协作的行为。即如何将一个Quest交给BraveKnight， XML装配 Java描述配置 尽管他们存在依赖关系，但是BraveKnight并不知道是什么样的Quest，也不知道来自哪里。 DI如何工作 通过应用上下文（Application Context）装载bean的定义，并把他们组装起来，Spring应用上下文全权负责对象的创建与组装 应用切面AOP AOP允许把遍布应用各处的功能分离出来形成可重用的组件。定义为促使软件系统实现关注点的分离一项技术。 AOP保持POJO的简单些，并使得组件更关注自身业务。 系统由许多不同的组件组成，每一个组件各负责一块特定的功能，除了实现自身核心的功能外，这些组件还常承担着额外的职责。诸如日志、安全这样的系统服务经常融入到自身具有核心业务逻辑的组件中，这些系统服务童车被称为横切关注点，因为他们会跨越系统的多个组件。 使用模板消除样板式代码 样板式的代码：通常为了实现通用的和简单的任务，不得不一遍遍地重复编写这样的代码。 例如JDBC的查询修改代码，有异常捕获、connect，API等重复性代码 使用jdbcTemplate解决 容纳你的Bean基于Spring的应用中，应用对象生存于Spring容器当中。Spring容器负责创建对象，装配他们，配置并管理他们整个生命周期。 Spring容器使用DI管理构成应用的组件，它会创建相互协作的组件间额关联。 两类容器实现 bean工厂，最简单的容器，提供基本的DI支持 应用上下文，基于BeanFactory构建，提供应用框架级别的服务。 AnnotationConfigApplicationContext：从一个或多个基于Java的配置类中加载Spring应用上下文。 AnnotationConfigWebApplicationContext：从一个或多个基于Java的配置类中加载Spring Web应用上下文。 ClassPathXmlApplicationContext：从类路径下的一个或多个XML配置文件中加载上下文定义，把应用上下文的定义文件作为类资源。 FileSystemXmlapplicationcontext：从文件系统下的一个或多个XML配置文件中加载上下文定义。 XmlWebApplicationContext：从Web应用下的一个或多个XML配置文件中加载上下文定义。 bean的生命周期 Spring对bean进行实例化； Spring将值和bean的引用注入到bean对应的属性中； 如果bean实现了BeanNameAware接口，Spring将bean的ID传递给setBean-Name()方法； 如果bean实现了BeanFactoryAware接口，Spring将调setBeanFactory()方法，将BeanFactory容器实例传入； 如果bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()方法，将bean所在的应用上下文的引用传入进来； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessBeforeInitialization()方法； 如果bean实现了InitializingBean接口，Spring将调用它们的after-PropertiesSet()方法。类似地，如果bean使用init-method声明了初始化方法，该方法也会被调用； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessAfterInitialization()方法； 此时，bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁； 如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。同样，如果bean使用destroy-method声明了销毁方法，该方法也会被调用。 俯瞰SpringSpring模块 Spring核心容器 AOP模块 数据访问与集成 Web与远程调用 Instrumentation 测试 装配Bean 声明bean 构造器注入与setter方法注入 装配bean 控制bean的创建于销毁 Spring配置的可选方案Spring容器负责创建应用程序的bean并通过DI来协调这些对象间的关系。但是开发人员需要告诉Spring要创建哪些bean以及如何装配。 Spring三种主要装配机制 在XML中进行显式配置 在Java中进行显式配置（JavaConfig） 隐式的bean发现机制和自动装配 可以混合搭配 尽量使用自动配置。在有些源码不是由你维护，而当你需要为这些代码配置bean，则JavaConfig。当JavaConfig没有同样实现，则XML 自动装配beanSpring从两个角度实现自动化装配 组件扫描：Spring会自动发现应用上下文中所创建的bean 自动装配：Spring自动满足bean间依赖 创建可被发现的bean 声明在类处的注解： @Component注解：表明该类会作为组件类，告知Spring要为这个类创建bean @ComponentScan注解：启用组件扫描 @ContextConfiguration注解：@ContextConfiguration（class=XXXConfig.class）表明从该config当中加载配置 声明在属性上： @Autowried注解：注入，声明要进行自动装配 required=false则会在没有匹配的bean时不抛出异常，此bean处于未装配状态 如果有多个bean满足依赖关系，则抛出异常，表明没有明确指定选择哪个bean进行自动装配 为组件扫描的bean命名 Spring应用上下文中所有的bean都会给定一个ID。一般将类名第一个字母小写。显式ID：@Component(ID)或@Named(ID) 设置组件扫描的基础包 @ComponentScan(扫描的包名称) 通过为bean添加注解实现自动装配 自动装配：让Spring自动满足bean依赖的一种方法，在满足依赖的过程中，会在Spring应用上下文中寻找匹配某个bean需求的其他bean。 构造器上添加@Autowried，即创建bean时，会选择该构造器进行实例化，并且传入符合需求参数的bean 通过Java代码装配bean使用场景： 要将第三方库中的组件装配到应用中，无法再它的类上添加@Component JavaConfig是配置代码，不应该包含任何业务逻辑，也不应该侵入业务逻辑代码 创建配置类 @Configuration注解：表明这个类是一个配置类，该类应该包含在Spring应用上下文中如何创建bean的细节。 声明简单的bean @Bean：方法会返回一个对象，对象要注册为Spring应用上下文中的bean，方法体包含了最终产生bean实例的逻辑 在JavaConfig中声明bean，需要编写一个方法，方法会创建需要的类型的实例。然后为方法添加@Bean。 借助JavaConfig实现注入 对于@Bean注解的方法，Spring会拦截所有对它的调用，并确保直接返回该方法所创建的bean，而不是每次都对其进行实际的调用。 默认情况下bean是单例的。 高级装配 Spring profile 条件化的bean声明 自动装配与歧义性 bean的作用域 Spring表达式语言 面向切面的SpringP137 面向切面编程的基本原理 通过POJO创建切面 使用@AspectJ注解 为AspectJ切面注入依赖 REST API498 Spring 消息539 Spring Boot638 参考 Spring实战（第四版） Spring入门看这一篇就够了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：线程实现与锁优化]]></title>
    <url>%2F2019%2F03%2F12%2FJava%2Fbase%2FJVM%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E4%B8%8E%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Java与线程线程的实现Java语言提供了在不同硬件和OS下对线程操作的统一处理，Thread类中的关键方法都是Native的，即方法没有使用或无法使用平台无关的手段来实现。即平台相关，因此是线程的实现，而不是Java线程的实现 内核线程实现内核线程KLT：直接由操作系统内核支持的线程，内核通过操纵调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。 程序一般不会直接使用内核线程，而是使用内核线程的一种高级接口：轻量级进程LWP，即线程。每个轻量级进程都由一个内核线程支持，这种轻量级进程与内核线程的1：1关系称为一对一的线程模型 每个轻量级进程都成为一个独立的调度单元，即使由一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作。 基于内核线程实现，所以各自操作都需要系统调用，需要在用户态与内核态间相互切换，代价高 每个轻量级线程都有一个内核线程支持，因此需要消耗一定内核资源，如栈空间，因此一个系统可支持的线程数量有限 使用用户线程实现广义：一个线程只要不是内核线程，就可以认为是用户线程。 狭义：完全建立在用户空间的线程库，内核不能感知线程的存在。 不需要系统内核支援，操作快速，低消耗，可以支持规模更大的并发 没有系统内核支援，所有线程操作都需要用户自己考虑 操作系统只把CPU分配给进程，阻塞处理、映射等问题解决非常困难 这种进程与用户线程间1：N的关系称为1对多的线程模型 使用用户线程加轻量级进程实现 Java线程的实现依据平台而定，windows与linux是一对一的线程模型实现，一条Java线程就映射到一条轻量级进程中。 Java线程调度协同式线程调度 线程的执行时间由线程本身控制，线程在自己的工作执行完后，主动通知系统切换到另一个线程，没有同步问题。 线程的执行时间不可控制，可能出现线程永久阻塞，使得整个系统不稳定 抢占式线程调度 线程由系统分配执行时间，线程的切换不由线程本身决定（yield让出执行时间） 设置线程优先级可以建议系统给某些线程多分配时间，但是并不可靠，因为Java的线程是通过映射到系统的原生线程实现的，所有线程的调度还是取决于操作系统 锁优化自旋锁与自适应自旋通常一些情况共享数据的锁定只持续很短时间，为此进行挂起与恢复并不值得。 让后面请求锁的线程稍等一会，但不放弃处理器执行时间，看持有锁的线程是否会释放锁。使线程执行一个忙循环（自旋，默认10次），JDK1.6当中默认开启 自适应自旋：由前一次在同一个锁上的自选时间以及锁拥有者状态决定。 如果同一个锁，自旋刚刚成功获得锁，那么此次自旋也有可能成功，允许自旋等待持续相对更长的时间。 如果这个锁自旋很少成功获得，那么以后可能忽略掉自旋过程 锁消除虚拟机即时编译器允许时，对一些代码上要求同步，但被检测到不可能存在共享数据竞争的锁进行消除 判定依据：逃逸分析的数据支持，如果判断一段代码中，堆上所有的数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁就无须进行了。 对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁： 123public static String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作： 1234567public static String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。 锁粗化推荐同步块的作用范围限制尽量小，但如果一系列连续操作都对同一个对象反复加锁和解锁。这时虚拟机探测到这些时，将会将加锁同步的范围扩展到整个操作序列的外部。 轻量级锁JDK 1.6引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。 在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 无竞争下使用CAS操作去消除同步使用的互斥量 HotSpot虚拟机的对象内存布局：对象头包括两部分 存储对象自身的运行时数据，如哈希码，GC分代年龄等，在64位虚拟机中为64Bits，称为Mark Word，是轻量级锁与偏向锁的关键 存储指向方法区对象类型数据的指针，如果是数组对象，则还会存储数组长度。 轻量级锁执行过程： 代码进入同步块时，如果此同步对象没有被锁定（标志位01），虚拟机将在当前线程的栈帧建立一个名为锁记录的空间，存储锁对象目前的Mark Word拷贝 虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针 如果更新成功，则线程拥有了该对象的锁，锁标志位变为00 更新失败，虚拟机首先检查对象的Mark Word是否指向当前线程的栈帧， 如果只说明当前线程已经拥有了这个对象的锁，那么就可以直接进入同步块继续执行。 否则说明这个锁对象已经被其他线程抢占 如果两条以上的线程争用同一个锁，则锁膨胀为重量级锁，标志位为10，Mark Word存放指向重量级锁的指针 依据：对于绝大部分锁，整个同步周期内是不存在竞争的 如果存在竞争，则额外CAS操作 不存在竞争，则避免了开销 偏向锁消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。在无竞争的情况下，把整个同步都消除掉。 锁会偏向于第一个获得它的线程，在接下来执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程永远不需要再进行同步。 当锁第一次被线程获取时，会把对象头中的标志设置为01。使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word中 如果CAS操作成功，持有偏向锁的线程每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作 当另一个线程尝试获取这个锁，偏向模式宣告结束。 转为轻量级锁 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：Java实现]]></title>
    <url>%2F2019%2F03%2F05%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJava%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[基本的线程机制定义任务有三种使用线程的方法： 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 Runnable接口线程可以驱动任务，因此需要一种描述任务的方式。 通过Runnable接口提供，只需要实现接口，并编写run方法。但是该方法并不产生任何内在的线程能力。 要实现线程行为，必须显式地将一个任务附着到线程上，通过Thread的start方法启动。 123456789101112131415161718192021222324//继承接口public class LiftOff implements Runnable &#123; protected int countDown = 10; // Default private static int taskCount = 0; private final int id = taskCount++; public LiftOff() &#123;&#125; public LiftOff(int countDown) &#123; this.countDown = countDown; &#125; public String status() &#123; return "#" + id + "(" + (countDown &gt; 0 ? countDown : "Liftoff!") + "), "; &#125; //实现run方法 public void run() &#123; while(countDown-- &gt; 0) &#123; System.out.print(status()); Thread.yield(); &#125; &#125;&#125; ///:~ Callable 从任务中返回值Runable与Callable Runnable是执行工作的独立任务，但是不返回任何值 使用ExecutorService.execute()调用 Callable在完成任务的时候，可以返回一个值 使用ExecutorService.sumbit()调用 返回的对象是Future对象 isDone方法查询是否完成，任务完成时具有结果 get方法会获取结果 如果没有结果，则会阻塞，直至结果就绪 Callable是一种具有类型参数的泛型，它的类型参数表示从方法call()当中返回的值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class TaskWithResult implements Callable&lt;String&gt; &#123; private int id; public TaskWithResult(int id) &#123; this.id = id; &#125; //执行的方法 public String call() &#123; return "result of TaskWithResult " + id; &#125;&#125;public class CallableDemo &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); ArrayList&lt;Future&lt;String&gt;&gt; results = new ArrayList&lt;Future&lt;String&gt;&gt;(); for(int i = 0; i &lt; 10; i++) results.add(exec.submit(new TaskWithResult(i))); for(Future&lt;String&gt; fs : results) try &#123; //get方法会阻塞，直至产生结果 // get() blocks until completion: System.out.println(fs.get()); &#125; catch(InterruptedException e) &#123; System.out.println(e); return; &#125; catch(ExecutionException e) &#123; System.out.println(e); &#125; finally &#123; exec.shutdown(); &#125; &#125;&#125; /* Output:result of TaskWithResult 0result of TaskWithResult 1result of TaskWithResult 2result of TaskWithResult 3result of TaskWithResult 4result of TaskWithResult 5result of TaskWithResult 6result of TaskWithResult 7result of TaskWithResult 8result of TaskWithResult 9*///:~ 继承Thread同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 123456789public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125;public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; Thread类将Runnable对象转变为工作任务的传统方式，是将它提交给一个Thread构造器 从输出中可以看到，start方法很快就返回了，是先于run方法执行的 1234567891011121314public class BasicThreads &#123; public static void main(String[] args) &#123; //构造器需要一个runnable对象 Thread t = new Thread(new LiftOff()); //start方法为该线程执行必要的初始化操作 //调用runnable的run方法，启动任务 t.start(); System.out.println("Waiting for LiftOff"); &#125;&#125;/* Output: (90% match)Waiting for LiftOff#0(9), #0(8), #0(7), #0(6), #0(5), #0(4), #0(3), #0(2), #0(1), #0(Liftoff!),*///:~ 生命周期 main函数创建Thread时，没有捕获这些对象的引用。但是每个Thread都注册了它自己，因此确实存在一个对它的引用，而且在它的任务退出run且死亡前，垃圾回收器无法清除它。因此一个线程会创建一个单独的执行线程，在对start调用完成后，它仍旧会继续存在。 休眠Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; 优先级线程的优先级将该线程的重要性传递给了调度器。调度器倾向于让优先级最高的线程执行。（通常不要设置） 12getPriority()//获取当前线程优先级setPriority()//修改优先级 让步Thread.yield()静态方法Thread.yield()的调用 是对线程调度器（Java线程机制的一部分，可以将CPU从一个线程转移给另一个线程）的一种建议 在声明：我已经执行完生命周期中最重要的部分，现在是切换给其他任务执行一段时间的大好时机 当一件完成了run中一次工作，可以给线程调度机制一个暗示，即可以让别的线程使用CPU了。但是，这只是一个暗示，没有任何机制保证它将会被采纳。因此在重要的控制中，不能依赖yield 123public void run() &#123; Thread.yield();&#125; 加入一个线程join()方法 一个线程可以在其他线程上调用join()方法 等待一段时间，直到第二个线程结束才继续执行 如果某个线程在另一个线程t上调用t.join()，此线程将被挂起，直到t结束才恢复 或者为join添加一个超时参数 对join的调用可以被中断，在调用线程上调用interrupt()方法（try -catch） 后台线程指在程序运行的时候，在后台提供一种通用服务的线程，并且这种线程并不属于程序中不可或缺的部分， 当所有的非后台线程结束时，程序就会终止，同时杀死进程所有后台线程。只要存在非后台线程，程序就不会终止。 在线程启动前调用setDaemon()方法，设置为后台线程。main属于非后台线程。 123public void run() &#123; Thread.yield();&#125; 线程组线程组持有一个线程集合 是一次不成功的尝试，忽略即可 ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor： CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 java.util.concurrent包当中的执行器（excutor）帮助管理Thread对象。 123456789101112131415public class CachedThreadPool &#123; public static void main(String[] args) &#123; //Executors.newFixedThreadPool(15);则可以预先进行现场分配，固定现场池大小 //newCachedThreadPool是首选，会创建与所需数量相同的线程，在它回收旧线程时停止创建新线程 //SingleThreadExecutor是数量为1的线程池，用于在一个线程中连续运行任何事物（长期存活的任务），例如监听进入的套接字连接 ExecutorService exec = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 5; i++) exec.execute(new LiftOff()); //该方法防止新任务提交给executor //将继续运行已经提交过的任务，并且程序在所有任务完成后尽快推出 exec.shutdown(); &#125;&#125; /* Output: (Sample)#0(9), #0(8), #1(9), #2(9), #3(9), #4(9), #0(7), #1(8), #2(8), #3(8), #4(8), #0(6), #1(7), #2(7), #3(7), #4(7), #0(5), #1(6), #2(6), #3(6), #4(6), #0(4), #1(5), #2(5), #3(5), #4(5), #0(3), #1(4), #2(4), #3(4), #4(4), #0(2), #1(3), #2(3), #3(3), #4(3), #0(1), #1(2), #2(2), #3(2), #4(2), #0(Liftoff!), #1(1), #2(1), #3(1), #4(1), #1(Liftoff!), #2(Liftoff!), #3(Liftoff!), #4(Liftoff!),*///:~ 捕获异常由于线程的本质特性，使得你不能捕获从线程中逃逸的异常。一旦逃逸出任务的run()方法，就会向外传播到控制台，除非采用特殊的步骤进行捕获。 Executor可以解决这个问题 修改产生线程的方式，Thread.UncaughtExceptionHandler是一个新的接口，允许在每个thread对象上附着一个异常处理器。 任务的多种启动任务类的实现方式： 实现runnable或callable 从thread继承 12345678910111213141516171819202122232425public class SimpleThread extends Thread &#123; private int countDown = 5; private static int threadCount = 0; public SimpleThread() &#123; // Store the thread name: super(Integer.toString(++threadCount)); start(); &#125; public String toString() &#123; return "#" + getName() + "(" + countDown + "), "; &#125; public void run() &#123; while(true) &#123; System.out.print(this); if(--countDown == 0) return; &#125; &#125; public static void main(String[] args) &#123; for(int i = 0; i &lt; 5; i++) new SimpleThread(); &#125;&#125; /* Output:#1(5), #1(4), #1(3), #1(2), #1(1), #2(5), #2(4), #2(3), #2(2), #2(1), #3(5), #3(4), #3(3), #3(2), #3(1), #4(5), #4(4), #4(3), #4(2), #4(1), #5(5), #5(4), #5(3), #5(2), #5(1),*///:~ 自管理的runnable 12345678910111213141516171819202122232425public class SelfManaged implements Runnable &#123; private int countDown = 5; //定义了一个thread，并以对象本身进行初始化 private Thread t = new Thread(this); //在构造器当中，进行线程启动 //但可能不处于不稳定状态，因为在构造器当中使用线程 public SelfManaged() &#123; t.start(); &#125; public String toString() &#123; return Thread.currentThread().getName() + "(" + countDown + "), "; &#125; public void run() &#123; while(true) &#123; System.out.print(this); if(--countDown == 0) return; &#125; &#125; public static void main(String[] args) &#123; for(int i = 0; i &lt; 5; i++) new SelfManaged(); &#125;&#125; /* Output:Thread-0(5), Thread-0(4), Thread-0(3), Thread-0(2), Thread-0(1), Thread-1(5), Thread-1(4), Thread-1(3), Thread-1(2), Thread-1(1), Thread-2(5), Thread-2(4), Thread-2(3), Thread-2(2), Thread-2(1), Thread-3(5), Thread-3(4), Thread-3(3), Thread-3(2), Thread-3(1), Thread-4(5), Thread-4(4), Thread-4(3), Thread-4(2), Thread-4(1),*///:~ 使用内部类将线程代码隐藏在类中 术语任务与线程是相互分离的 执行的任务 Runnable 驱动任务的线程 对于线程Thread类无实际的控制权 将一个线程附着到任务上，以使得这个线程可以驱动任务 共享受限资源两个线程试图同时使用一个资源。如在一个地方停车。 解决共享资源竞争永远不知道一个线程何时运行 解决冲突的方法：在资源被一个任务使用时，在其上加锁。 采用序列化访问共享资源的方案解决线程冲突问题，在给定时刻只允许一个任务访问共享资源。 Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronizedjava采用synchronized关键字提供锁，当任务执行该关键字保护的片段时 流程 检查锁是否可用 可用 获取锁，执行代码 释放锁 不可用 阻塞，直至锁释放 synchronized是可重入锁，即同一个对象可以重复获得该方法的锁。 只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 实现 同步代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 1234567891011121314151617public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 12345678public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125;0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 同步方法 123public synchronized void func () &#123; // ...&#125; 它和同步代码块一样，作用于同一个对象。 同步类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 123456789101112131415161718public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 同步静态方法 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 Lock 一种显式的互斥机制 Lock对象必须被显式地创建、锁定和释放。 因此相比于内建的锁形式相比，代码缺乏优雅性。 对于解决某些类型问题，更加灵活 锁的使用 ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。 12345678910111213141516171819202122public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125;public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//ReentrantLock允许尝试着获取但最终未获取锁public class AttemptLocking &#123; private ReentrantLock lock = new ReentrantLock(); //如果其他人已经获取了锁，那么你就可以决定离开去执行其他一些事情，而不是等待直至这个锁被释放 public void untimed() &#123; boolean captured = lock.tryLock(); try &#123; System.out.println("tryLock(): " + captured); &#125; finally &#123; if(captured) lock.unlock(); &#125; &#125; //尝试去获取锁，该尝试可以在2s后失败 public void timed() &#123; boolean captured = false; try &#123; captured = lock.tryLock(2, TimeUnit.SECONDS); &#125; catch(InterruptedException e) &#123; throw new RuntimeException(e); &#125; try &#123; System.out.println("tryLock(2, TimeUnit.SECONDS): " + captured); &#125; finally &#123; if(captured) lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final AttemptLocking al = new AttemptLocking(); al.untimed(); // True -- lock is available al.timed(); // True -- lock is available // Now create a separate task to grab the lock: new Thread() &#123; &#123; setDaemon(true); &#125; public void run() &#123; al.lock.lock(); System.out.println("acquired"); &#125; &#125;.start(); Thread.yield(); // Give the 2nd task a chance al.untimed(); // False -- lock grabbed by task al.timed(); // False -- lock grabbed by task &#125;&#125; /* Output:tryLock(): truetryLock(2, TimeUnit.SECONDS): trueacquiredtryLock(): falsetryLock(2, TimeUnit.SECONDS): false*///:~ Lock与synchronized比较 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 错误处理 使用synchronized，某些事物失败了，就会抛出异常，无法去做任何清理工作，维护系统处于良好 Lock对象可以使用finally子句将系统维护在正确状态 代码量 synchronized代码量较少，出现错误可能性较低 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 适用场景 synchronized不能尝试获取锁，且最终获取锁会失败，或者尝试获取锁一段时间，然后放弃它 Lock对于锁具有更细力度的控制力，对于实现专有同步结构是有效的 何时进行同步 如果你正在写一个变量，它可能接下来将被另一个线程读取，或者正在读取一个上一次已经被另一个线程写过的变量，那么你必须使用同步，并且，读写线程都必须用系统的监视器锁同步 原子性与易变性原子操作：不能被线程调度机制中断的操作。一旦操作开始，那么它一定可以在可能发生的“上下文切换”前执行完毕 原子操作需要进行同步控制 原子性可以应用于除long和double之外所有基本类型上的“简单操作”，对于这些操作可以保证它们会被当成原子操作来操作内存。 对于64位的long与double进行读与写操作会被JVM当做两个分离的32位操作，因此可能会出现上下文切换。 可见性一个任务做出的修改，即使在不中断的意义上讲是原子性的，对于其他任务也可能是不可视的。 修改可能只是暂时地存储在本地处理器的缓存时 因此不同的任务对于应用的状态有不同的视图。 volatile保证了应用的可视性，如果一个域为volatile的，那么只要对这个域进行了写操作，所有的读操作就都可以看到这个修改。 如果多个任务在同时访问某个域，那么这个域就应该是volatile的，否则这个域就只能由同步来访问。 如果一个域定义为volatile的，那么就会告知编译器不要只想任何一处读取和写入操作的优化。目的是用线程中的局部变量维护对这个域的精确同步。 意外 volatile无法工作的情况 如果一个域的值依赖于它之前的值 如果域的值受到其他域的值现在 原子类AtomicInteger、AtomicLong、AtomicReference等原子性变量类 CAS操作原子性更新操作CAS 1boolean compareAndSet(expectedValue，updateValue)； 临界区同步控制块 希望防止多个线程同时访问方法内部的部分代码而不是防止访问整个方法，通过这种方式分离出来的代码段被称为临界区 123synchronized（syncObjet）&#123; &#125; 在其他对象上同步synchronized块需要给定一个在其上进行同步的对象，使用synchronized（this）会使得该对象其他的synchronized方法无法被调用。 如果必须在另一个对象上进行同步，则必须确保所有相关的任务都在同一个对象上同步。 123456789101112131415161718192021222324252627282930class DualSynch &#123; private Object syncObject = new Object(); public synchronized void f() &#123; for(int i = 0; i &lt; 5; i++) &#123; print("f()"); Thread.yield(); &#125; &#125; public void g() &#123; synchronized(syncObject) &#123; for(int i = 0; i &lt; 5; i++) &#123; print("g()"); Thread.yield(); &#125; &#125; &#125;&#125;//两个任务同时进入了同时一个对象//对象上的方法是在不同的锁上进行同步public class SyncObject &#123; public static void main(String[] args) &#123; final DualSynch ds = new DualSynch(); new Thread() &#123; public void run() &#123; ds.f(); &#125; &#125;.start(); ds.g(); &#125;&#125; 线程本地存储 根除对变量的共享而防止任务在共享资源上产生冲突。 通过为使用相同变量的每个不同的线程都创建不同的存储 Global 意思是在当前线程中，任何一个点都可以访问到ThreadLocal的值。 Local 意思是该线程的ThreadLocal只能被该线程访问，一般情况下其他线程访问不到。 ThreadLocal为变量生成新的存储，并将状态与线程关联起来 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Accessor implements Runnable &#123; private final int id; public Accessor(int idn) &#123; id = idn; &#125; public void run() &#123; while(!Thread.currentThread().isInterrupted()) &#123; ThreadLocalVariableHolder.increment(); System.out.println(this); Thread.yield(); &#125; &#125; public String toString() &#123; return "#" + id + ": " + ThreadLocalVariableHolder.get(); &#125;&#125;public class ThreadLocalVariableHolder &#123; private static ThreadLocal&lt;Integer&gt; value = new ThreadLocal&lt;Integer&gt;() &#123; private Random rand = new Random(47); protected synchronized Integer initialValue() &#123; return rand.nextInt(10000); &#125; &#125;; public static void increment() &#123; value.set(value.get() + 1); &#125; public static int get() &#123; return value.get(); &#125; public static void main(String[] args) throws Exception &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 5; i++) exec.execute(new Accessor(i)); TimeUnit.SECONDS.sleep(3); // Run for a while exec.shutdownNow(); // All Accessors will quit &#125;&#125;/* Output: (Sample)#0: 9259#1: 556#2: 6694#3: 1862#4: 962#0: 9260#1: 557#2: 6695#3: 1863#4: 963...*///:~ 终结任务某些情况下，任务必须更加突然地终止 方法 在程序当中设置一个标志位，在程序的某一点当中检查标志，以决定是否跳出循环 线程状态 新建 就绪 阻塞 一个任务进入阻塞状态的原因 调用sleep()方法 调用wait()使得线程挂起，直到线程得到了notify()或notifyAll()，任务才会进入就绪 任务在等待某个输入、输出完成 任务视图在某个对象上调用其同步方法，但是对象锁不可用 死亡 在阻塞时终结对于处于阻塞状态的任务，不能等待其到达代码中可以检查状态值的某一点，因而决定让它主动终止，就必须强制这个任务跳出阻塞 中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 打断被阻塞的任务，可能需要清理资源，因此类似于抛出异常。 interruptThread类的一个方法，终止被阻塞的任务。 这个方法将设置线程的中断状态 如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112131415161718public class InterruptExample &#123; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // .. &#125; System.out.println("Thread end"); &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();&#125;Thread end InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 123456789101112131415161718192021222324252627public class InterruptExample &#123; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println("Main run");&#125;Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) 被互斥所阻塞试图在一个对象上调用synchronized方法，而这个对象的锁已经被其他任务获得，那么调用任务将被挂起（阻塞），直至这个锁可获得 Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 123456789101112131415161718192021public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); executorService.shutdownNow(); System.out.println("Main run");&#125;Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9) at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 检查中断线程间协作线程间相互协调，某些部分必须在其他部分被解决前解决。即存在前置条件 任务协作时，关键问题是这些任务间的握手，为了实现握手，使用了互斥。互斥确保只有一个任务可以响应某个信号，以消除任何困难的竞争条件。 在互斥上，为任务添加了一种途径，可以将自身挂起，直至某些外部条件发生变化。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。 1234567891011121314151617181920212223242526272829303132333435363738394041public class JoinExample &#123; private class A extends Thread &#123; @Override public void run() &#123; System.out.println("A"); &#125; &#125; private class B extends Thread &#123; private A a; B(A a) &#123; this.a = a; &#125; @Override public void run() &#123; try &#123; a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("B"); &#125; &#125; public void test() &#123; A a = new A(); B b = new B(a); b.start(); a.start(); &#125;&#125;public static void main(String[] args) &#123; JoinExample example = new JoinExample(); example.test();&#125;AB wait()与notifyAll()wait： 表示等待某个条件发生变化，而改变这个条件超出了当前方法的控制能力，通常需要另一个任务来改变 wait需要notify、notifyAll、或者令时间到期从而恢复执行 wait期间，对象锁是释放的，当wait时，即在声明：我已经做完能做的所有事情，因此等待，并且希望其他的synchronized操作在条件合适情况下执行 sleep方法不释放对象的锁 需要用一个检查感兴趣的条件的while循环包围wait。需要检查锁感兴趣的特定条件，在不满足条件下重新wait 可能有多个任务出于相同原因等待同一个锁，而第一个唤醒任务可能改变状态，此时应该再次通过调用wait以重新挂起 在这个任务从其wait被唤醒的时刻，可能有其他的任务已经做出改变，使得这个任务此时不能执行。此时应该再次调用wait以挂起 任务出于不同的原因在等待你的对象上的锁，需要检查是否已经由正确的原因唤醒，如果不是，再次调用wait 只能用在同步方法或者同步控制块中使用 如果在非同步控制块中，可以通过编译，但如果任务（线程）没有持有对象的锁，则会抛出异常 IllegalMonitorStateException。 123456789101112131415161718192021222324public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println("before"); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("after"); &#125;&#125;public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125;beforeafter wait与sleep wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 notify 唤醒wait调用而被挂起的任务 任务首先获取当它进入wait时释放的锁 锁不可用，则继续挂起 锁可用，并获取，任务被唤醒 调用区域 wait与notify是Object对象的一部分，因为这些方法操作的锁也是所有对象的一部分，因此他们不是Thread类中。 方法只能再同步控制块里进行调用，如果在非同步控制块中，可以通过编译，但如果任务（线程）没有持有对象的锁，则会抛出异常 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class Car &#123; private boolean waxOn = false; public synchronized void waxed() &#123; waxOn = true; // Ready to buff notifyAll(); &#125; public synchronized void buffed() &#123; waxOn = false; // Ready for another coat of wax notifyAll(); &#125; public synchronized void waitForWaxing() throws InterruptedException &#123; while(waxOn == false) wait(); &#125; public synchronized void waitForBuffing() throws InterruptedException &#123; while(waxOn == true) wait(); &#125;&#125;class WaxOn implements Runnable &#123; private Car car; public WaxOn(Car c) &#123; car = c; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; printnb("Wax On! "); TimeUnit.MILLISECONDS.sleep(200); car.waxed(); car.waitForBuffing(); &#125; &#125; catch(InterruptedException e) &#123; print("Exiting via interrupt"); &#125; print("Ending Wax On task"); &#125;&#125;class WaxOff implements Runnable &#123; private Car car; public WaxOff(Car c) &#123; car = c; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; car.waitForWaxing(); printnb("Wax Off! "); TimeUnit.MILLISECONDS.sleep(200); car.buffed(); &#125; &#125; catch(InterruptedException e) &#123; print("Exiting via interrupt"); &#125; print("Ending Wax Off task"); &#125;&#125;public class WaxOMatic &#123; public static void main(String[] args) throws Exception &#123; Car car = new Car(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new WaxOff(car)); exec.execute(new WaxOn(car)); TimeUnit.SECONDS.sleep(5); // Run for a while... exec.shutdownNow(); // Interrupt all tasks &#125;&#125; 错失的信号 假设T2获得someCondition的值为true 而此时调度器切换到T1，T1执行notify T2继续执行，进行wait，notify已经错失，进入死锁 123456789101112131415161718192021T1:synchronized（sharedMonitor）&#123; //防止T2调用wait的动作 &lt;setup condition for T2&gt; sharedMonitor.notify();&#125;T2:while(someCondition)&#123; //point1 synchronized(sharedMonitor)&#123; sharedMonitor.wait(); &#125;&#125;//消除竞争条件while(someCondition)&#123; //point1 synchronized(sharedMonitor)&#123; while(someCondition)&#123; sharedMonitor.wait(); &#125;&#125; notify()与notifyAll()使用notify的条件 使用notify而不是notifyAll是一种优化 使用notify，则必须保证被唤醒的是恰当的任务 使用notify则所有任务必须等待相同的条件 如果有多个任务在等待不同的条件，则不知道是否唤醒了恰当的任务 使用notify则条件变化时，必须只有一个任务从中受益 这些限制对所有可能存在的子类都必须总是起作用的 否则就必须使用notifyAll notifyAll 当notifyAll因某个特定锁而被调用时，只有等待这个锁的任务才会被唤醒 因为notifyAll语句是需要在一个同步控制块里面的，所以也清楚是哪个锁 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526272829303132333435public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println("before"); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println("after"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125;beforeafter 生产者与消费者任务协作的模型： 生产者 厨师，准备膳食，在准备好之后，通知服务员 消费者 服务员，等待厨师准备膳食 接到通知，上菜，返回继续等待 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class Meal &#123; private final int orderNum; public Meal(int orderNum) &#123; this.orderNum = orderNum; &#125; public String toString() &#123; return "Meal " + orderNum; &#125;&#125;//消费者class WaitPerson implements Runnable &#123; private Restaurant restaurant; public WaitPerson(Restaurant r) &#123; restaurant = r; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; synchronized(this) &#123; while(restaurant.meal == null) wait(); // ... for the chef to produce a meal &#125; print("Waitperson got " + restaurant.meal); //在消费者取走的动作当中，防止生产者写入数据 synchronized(restaurant.chef) &#123; restaurant.meal = null; restaurant.chef.notifyAll(); // Ready for another &#125; &#125; &#125; catch(InterruptedException e) &#123; print("WaitPerson interrupted"); &#125; &#125;&#125;//生产者class Chef implements Runnable &#123; private Restaurant restaurant; private int count = 0; public Chef(Restaurant r) &#123; restaurant = r; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; synchronized(this) &#123; while(restaurant.meal != null) wait(); // ... for the meal to be taken &#125; if(++count == 10) &#123; print("Out of food, closing"); restaurant.exec.shutdownNow(); &#125; printnb("Order up! "); synchronized(restaurant.waitPerson) &#123; restaurant.meal = new Meal(count); restaurant.waitPerson.notifyAll(); &#125; TimeUnit.MILLISECONDS.sleep(100); &#125; &#125; catch(InterruptedException e) &#123; print("Chef interrupted"); &#125; &#125;&#125;public class Restaurant &#123; Meal meal; ExecutorService exec = Executors.newCachedThreadPool(); WaitPerson waitPerson = new WaitPerson(this); Chef chef = new Chef(this); public Restaurant() &#123; exec.execute(chef); exec.execute(waitPerson); &#125; public static void main(String[] args) &#123; new Restaurant(); &#125;&#125; /* Output:Order up! Waitperson got Meal 1Order up! Waitperson got Meal 2Order up! Waitperson got Meal 3Order up! Waitperson got Meal 4Order up! Waitperson got Meal 5Order up! Waitperson got Meal 6Order up! Waitperson got Meal 7Order up! Waitperson got Meal 8Order up! Waitperson got Meal 9Out of food, closingWaitPerson interruptedOrder up! Chef interrupted*///:~ 生产者-消费者与队列基于同步队列来解决任务协作问题，同步队列在任何时刻只允许一个任务插入或移除数据 java.util.concurrent.（Linked/Array）BlockingQueue 当消费者任务试图从队列中获取对象，而此时队列为空，队列可挂起消费者 当有更多的元素可用，恢复消费者 相比于wait与notifyAll，简单并且可靠 解决了wait等存在的类之间的耦合 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class LiftOffRunner implements Runnable &#123; //一个blockingQueue private BlockingQueue&lt;LiftOff&gt; rockets; public LiftOffRunner(BlockingQueue&lt;LiftOff&gt; queue) &#123; rockets = queue; &#125; public void add(LiftOff lo) &#123; try &#123; rockets.put(lo); &#125; catch(InterruptedException e) &#123; print("Interrupted during put()"); &#125; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; LiftOff rocket = rockets.take(); rocket.run(); // Use this thread &#125; &#125; catch(InterruptedException e) &#123; print("Waking from take()"); &#125; print("Exiting LiftOffRunner"); &#125;&#125;public class TestBlockingQueues &#123; static void getkey() &#123; try &#123; // Compensate for Windows/Linux difference in the // length of the result produced by the Enter key: new BufferedReader( new InputStreamReader(System.in)).readLine(); &#125; catch(java.io.IOException e) &#123; throw new RuntimeException(e); &#125; &#125; static void getkey(String message) &#123; print(message); getkey(); &#125; static void test(String msg, BlockingQueue&lt;LiftOff&gt; queue) &#123; print(msg); LiftOffRunner runner = new LiftOffRunner(queue); Thread t = new Thread(runner); t.start(); for(int i = 0; i &lt; 5; i++) runner.add(new LiftOff(5)); getkey("Press 'Enter' (" + msg + ")"); t.interrupt(); print("Finished " + msg + " test"); &#125; public static void main(String[] args) &#123; test("LinkedBlockingQueue", // Unlimited size new LinkedBlockingQueue&lt;LiftOff&gt;()); test("ArrayBlockingQueue", // Fixed size new ArrayBlockingQueue&lt;LiftOff&gt;(3)); test("SynchronousQueue", // Size of 1 new SynchronousQueue&lt;LiftOff&gt;()); &#125;&#125; ///:~ 任务间使用管道进行输入/输出管道: PipedWriter允许任务向管道写 PipedReader允许不同任务从同一个管道中读取 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Sender implements Runnable &#123; private Random rand = new Random(47); private PipedWriter out = new PipedWriter(); public PipedWriter getPipedWriter() &#123; return out; &#125; public void run() &#123; try &#123; while(true) for(char c = 'A'; c &lt;= 'z'; c++) &#123; out.write(c); TimeUnit.MILLISECONDS.sleep(rand.nextInt(500)); &#125; &#125; catch(IOException e) &#123; print(e + " Sender write exception"); &#125; catch(InterruptedException e) &#123; print(e + " Sender sleep interrupted"); &#125; &#125;&#125;class Receiver implements Runnable &#123; private PipedReader in; public Receiver(Sender sender) throws IOException &#123; in = new PipedReader(sender.getPipedWriter()); &#125; public void run() &#123; try &#123; while(true) &#123; // Blocks until characters are there: //如果没有数据,管道将阻塞 printnb("Read: " + (char)in.read() + ", "); &#125; &#125; catch(IOException e) &#123; print(e + " Receiver read exception"); &#125; &#125;&#125;public class PipedIO &#123; public static void main(String[] args) throws Exception &#123; Sender sender = new Sender(); Receiver receiver = new Receiver(sender); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(sender); exec.execute(receiver); TimeUnit.SECONDS.sleep(4); exec.shutdownNow(); &#125;&#125; /* Output: (65% match)Read: A, Read: B, Read: C, Read: D, Read: E, Read: F, Read: G, Read: H, Read: I, Read: J, Read: K, Read: L, Read: M, java.lang.InterruptedException: sleep interrupted Sender sleep interruptedjava.io.InterruptedIOException Receiver read exception*///:~ 性能调优辨认在java.util.concurrent类库当中哪些类适用于常规应用，哪些类只适用于提高性能 比较各类互斥技术在互斥方法体很大时候，进入和退出互斥的开销可能很小，提高互斥速度可能对整体速度影响较小 Lock 在高并发下表现稳定 synchronized 高并发下非常不稳定 在数量较小下表现更高效 可读性好 Atomic 当一个对象的临界更新被限制为只涉及单个变量 高并发下稳定 免锁容器 基于synchronized vector hashTable 免锁 策略 对容器的修改可以与读取操作同时发生，只要读取者只能看到完成修改的结果即可。 修改时容器数据结构的某个部分的一个单独的副本，并且在修改过程中是不可视的，只有当修改完成时，被修改的结构才会自动与主数据结构交换 CopyOnWriteArrayList：整个数组复制 concurrentHashMap：部分内容可以复制和修改 乐观锁 只要你主要是从免锁容器中读取，就会比其synchronized对应物快很多。 如果需要向免锁容器中执行少量写入，情况依然如此 乐观加锁CAS操作 ReadWriteLock 对象数据结构相对不频繁地写入，但是有多个任务要经常读取的情况进行优化 如果写锁已经被其他任务持有，则如何读者都不能访问 活动对象替换多线程模型的一种并发模型 对象是活动的，每个对象都维护着它自己的工作器线程和消息队列 有了活动对象，就可以串行化消息而不是方法。即不再需要防备一个任务在其循环的中间被中断 当向一个活动对象发送消息时，消息会被转换为一个任务，插入到足够对象的队列中，等待在以后的某个时刻运行 实现 java的Future 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ActiveObjectDemo &#123; private ExecutorService ex = Executors.newSingleThreadExecutor(); private Random rand = new Random(47); // Insert a random delay to produce the effect // of a calculation time: private void pause(int factor) &#123; try &#123; TimeUnit.MILLISECONDS.sleep( 100 + rand.nextInt(factor)); &#125; catch(InterruptedException e) &#123; print("sleep() interrupted"); &#125; &#125; public Future&lt;Integer&gt; calculateInt(final int x, final int y) &#123; return ex.submit(new Callable&lt;Integer&gt;() &#123; public Integer call() &#123; print("starting " + x + " + " + y); pause(500); return x + y; &#125; &#125;); &#125; public Future&lt;Float&gt; calculateFloat(final float x, final float y) &#123; return ex.submit(new Callable&lt;Float&gt;() &#123; public Float call() &#123; print("starting " + x + " + " + y); pause(2000); return x + y; &#125; &#125;); &#125; public void shutdown() &#123; ex.shutdown(); &#125; public static void main(String[] args) &#123; ActiveObjectDemo d1 = new ActiveObjectDemo(); // Prevents ConcurrentModificationException: List&lt;Future&lt;?&gt;&gt; results = new CopyOnWriteArrayList&lt;Future&lt;?&gt;&gt;(); for(float f = 0.0f; f &lt; 1.0f; f += 0.2f) results.add(d1.calculateFloat(f, f)); for(int i = 0; i &lt; 5; i++) results.add(d1.calculateInt(i, i)); print("All asynch calls made"); while(results.size() &gt; 0) &#123; for(Future&lt;?&gt; f : results) if(f.isDone()) &#123; try &#123; print(f.get()); &#125; catch(Exception e) &#123; throw new RuntimeException(e); &#125; results.remove(f); &#125; &#125; d1.shutdown(); &#125;&#125; /* Output: (85% match)All asynch calls madestarting 0.0 + 0.0starting 0.2 + 0.20.0starting 0.4 + 0.40.4starting 0.6 + 0.60.8starting 0.8 + 0.81.2starting 0 + 01.6starting 1 + 10starting 2 + 22starting 3 + 34starting 4 + 468*///:~ 活动对象的优势 每个对象都可以用于自己的工作区线程 每个对象都将维护对它自己的域的全部控制权 所有在活动对象间的通信都将以在这些对象间的消息形式发生 活动对象间的所有消息都要排队 参考 Java编程思想]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis：独立功能的实现]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%EF%BC%9A%E7%8B%AC%E7%AB%8B%E5%8A%9F%E8%83%BD%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[事务Redis通过MULTI（开始）、EXEC（提交）、WATCH等实现事务功能 事务提供将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，在事务执行期间，服务器不会中断事务执行其他客户端的命令请求。 事务的原子性、一致性、隔离性、持久性 ACID Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务的实现事务的三个阶段 事务开始 MULTI命令 命令入队 事务执行 WATCH乐观锁，在EXEC命令执行前，监视任意数量的数据库键，并在EXEC命令执行时，检查被监视的键是否至少有一个已经被修改，如果是，则拒绝执行事务，并返回代表事务执行失败的空回复 主从复制主从模式： 主、从节点都可以挂从节点。 最终一致性。 广播模式： 全量同步： 传递RDB文件&amp;restore命令重建kv。 传递在RDB dump过程中的写入数据。 部分同步 根据offset传递积压缓存中的部分数据。 redis集群一致性hash存在中心。 实例宕机、加节点容易造成数据丢失。 redis cluster基于gossip协议，去中心化。 节点间两两通信，有节点数量上限。 参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis：单机数据库的实现]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%EF%BC%9A%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[数据库 Redis服务器的数据库实现 服务器保存数据库的方法 客户端切换数据库的方法 数据库保存键值对的方法 数据库的增删改查的实现方法 服务器保存键的过期时间的方法 服务器自动删除过期键的方法 Redis2.8数据库通知功能的实现 服务器中的数据库Redis服务器奖所有数据库保存在服务器状态中 123456struct redisServer&#123; //一个数组，保存着服务器中所有的数据库 redisDb *db; //服务器中的数据库数量 int dbnum;&#125; 切换数据库每个redis客户端都有自己的目标数据库，即写命令的操作对象，默认为0号数据库 执行select 2（需要转换到的数据库，即db[2]）命令可切换目标数据库 1234typedef struct redisClient;&#123; //记录客户端当前使用的数据库 redisDb *db;&#125;redisClient; 数据库键空间Redis是一个键值对数据库服务器，服务器每一个数据库都是由一个redisDb表示 1234typedef struct redisDb&#123; //数据库键空间，保存着数据库中所有的键值对 dict *dict;&#125;redisDb; 键空间与用户所见的数据库是直接对应的。键空间的键就是数据库的键，键空间的值就是数据库的值 添加新键 1set date "222" 删除键 1del date 更新键 1set date "balst" 取值 1get date 等命令 读写键空间的维护操作 当使用Redis命令对数据库进行读写，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作 读取一个键后，服务器会根据键是否存在来更新服务器的键空间命中次数或不明智次数 读取一个键后，服务器会更新键LRU时间，用于计算键的闲置时间 服务器在读取一个键时发现该键已经过期，服务器会先删除这个过期键，然后才执行余下的其他操作 如果有客户端使用Watch监视了某个键，服务器在对该键进行修改后，会将这个键标记为脏，从而让事务注意到这个键已经被修改 服务器每次修改一个键后，都会对脏键计数器++，这个计数器会触发服务器的持久化以及复制操作 如果服务器开启了数据库通知功能，那么在对键进行修改后，服务器将按配置发送给相应的数据库通知 设置键的生存时间或过期时间使用EXPIRE命令或者PEXPIRE，以毫秒或秒的精度为数据库的某个键设置生存时间。在经过指定的时间，服务器会自动删除生存时间为0的键。 以Expireat或PExpireat为键设置过期时间，当过期时间来临，自动删除该键。 保存过期时间 redisDb结构中的expires字典保存了数据库中所有键的过期时间，称为过期字典 1dict *expires;//值是long long类型的整数，保存这个键指向的数据库键的过期时间 过期键删除策略如果一个键过期了，那么它什么时候会被删除呢 定时删除 在设置键的过期时间的同时，创建一个定时器，让定时器在过期时间来临时，立即执行对键的删除操作 惰性删除 放任键过期不管，每次从键空间获取键时，都检查获得的键是否过期 定期删除 每隔一段时间，就对数据库进行一次检查，删除里面的过期键。删除的数量以及检查多少数据库由算法决定 Redis的过期键删除策略采用惰性删除与定期删除两种策略： 惰性删除：读写操作前判断ttl，如过期则删除。 定期删除：在redis定时事件中随机抽取部分key判断ttl。 特点： 并不一定是按照设置事件准时地过期。 定期删除的时候会判断过期比例，达到阈值才会退出。 建议打散key的过期事件，避免大量key在同一时间点过期。 AOF、RDB和复制功能对过期键的处理过期键对Redis服务器中其他模块的影响。 生成RDB文件 SAVE命令或BGSAVE命令创建一个新的RDB文件时，已过期的键不会被保存到新创建的RDB文件中。 是经过压缩的二进制格式，fork子进程dump可能会造成瞬间卡顿。 载入RDB文件 在启动Redis服务器，如果开启了RDB功能，服务器会对RDB文件载入： 如果服务器以主服务器模式允许，那么载入RDB文件时，过期键将会忽略。 如果以从服务器允许，文件中所有键，不管是否过期，都会载入到数据库中。 主从服务器进行数据同步时，从服务器的数据库就会被清空，因此过期键对从服务器也不会造成影响。 AOF文件写入 当服务器以AOF持久化模式运行时，如果键已经过期，但没有删除，那么AOF文件不会因为这个过期键产生任何影响。 当过期键被删除后，程序会向AOF文件追加DEL命令，以显式记录该键已经被删除。 先写aof缓存，再同步到aof文件。 AOF重写，达到阈值时触发，减少文件大小。 AOF重写 已过期的键不会被保存到重写后的AOF文件中。 复制 当服务器允许在复制模式下，从服务器的过期键删除动作由主服务器控制 主服务器在删除一个过期键后，会显式向所有从服务器发送一个DEL命令 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将其删除，而是继续像处理未过期键一样处理 从服务器只有在接到主服务器的DEL命令才会删除过期键 应用 利用AOF文件容灾。可以将数据恢复到最近3天任意小时粒度。 数据库通知Redis2.8，可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变化，以及数据库中命令的执行情况 RDB持久化Redis是一个键值对数据库服务器，服务器中通常包含着任意个非空数据库，每个非空数据库又可以包含任意个键值对。 数据库状态：服务器中的非空数据库以及它们的键值对。 Redis是内存数据库，将数据库状态存储在内存当中，如果服务器进程一旦退出，则数据库状态也会消失不见。 因此提供了RDB持久化功能，将Redis在内存当中的数据库状态保存到磁盘当中。 RDB持久化既可以手动，也可以根据服务器配置定期执行。将某个时间点上的数据库状态保存到一个RDB文件中 RDB持久化功能生成的RDB文件是一个压缩的二进制文件。 RDB文件的创建于载入 生成命令：SAVE于BGSAVE SAVE会阻塞Redis服务器进程，直到RDB文件创建完毕为止 BGSAVE会派生一个子进程，子进程负责创建RDB文件，服务器进程继续处理命令 RDB文件的载入时在服务器启动时自动执行，只要检测到RDB文件，就会自动载入。在载入文件期间，服务器一直处于阻塞状态。 与AOF对比 AOF文件的更新频率通常比RDB文件更新频率高，因此 如果服务器开启了AOF持久化功能，服务器会优先使用AOF文件来还原数据库状态 只有在AOF持久化功能处于关闭状态，服务器才会使用RDB文件来还原数据库状态 自动间隔保存Redis允许用户通过服务器配置save选项，让服务器每隔一段时间自动执行一次BGSAVE RDB文件结构结构： RDB文件保存的是二进制数据，而不是C字符串 REDIS：长度为5字节，通过检测该字符，快速检查所载入的文件是否为RDB文件 db_version：4字节，是一个字符串表示的整数，记录了RDB文件版本号 database：包含0或任意个数据库，以及各个数据库中的键值对数据 EOF：长度为1字节，表示正文内容结束 check_sum：一个8字节长的无符号整数，保存一个校验和，通过对前4部分计算得出。服务器载入RDB文件时，会将载入数据计算得出的校验和与check_sum进行比较，以检查文件是否出错或损坏 database部分 如果0号与3号数据库非空，则： 每个非空数据库在RDB文件中的保存： SELECTDB：长度为1字节，表示接下来读取的是一个数据库号码 db_number：保存着一个数据库号码，长度1、2、5字节，当读取到的时候，服务器使用select进行数据库切换 key_value_pairs保存所有键值对数据 key_value_pairs 如果键值对带有过期时间，则也会保存在内。不带过期时间的表示： TYPE：对象类型或者底层编码，决定如何读入和解释value数据 key：字符串对象 EXPIRETIME_MS：1字节，表示接下来将读取一个过期时间，以毫秒为单位 ms：8字节带符号整数，记录一个毫秒为单位的UNIX时间戳 value的编码 不同类型的值对象在RDB文件中的保存结构 字符串对象 列表对象 集合对象 哈希表对象 有序集合对象 分析RDB文件AOF持久化通过保存Redis服务器所执行的写命令来记录数据库状态 写入的命令都是以Redis的命令请求协议格式保存的。 AOF持久化的实现功能实现分为：命令追加、文件写入、文件同步三个步骤 命令追加 当服务器执行完一个写命令后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾 文件写入与同步 文件写入：只是写入到了内存缓冲区，可能还没有写到文件所拥有的磁盘数据块上 文件同步：将缓冲区中的内容冲洗到磁盘上 Redis服务器进程就是一个事件循环，在循环中的 文件事件负责接收客户端的命令请求，以及向客户端发送命令恢复 时间事件负责执行像serverCron函数这样需要定时运行的函数 服务器在处理文件事件时可能执行写命令，使得一些内容被追加到aof_buf缓冲区，因此服务器每次结束一个事件循环前，都会调用函数，考虑是否将aof_buf缓冲区里的内容写入和保存到AOF文件中。 flushAppendOnlyFile函数的行为由服务器配置的appendfsync选项的值决定 值为always，将缓冲区内所有内容写入并同步到AOF文件 默认为everysec，将缓冲区内所有内容写入到AOF文件，如果上次同步AOF文件的时间距离现在超过1S，则再次对AOF文件进行同步 no，将缓冲区内所有内容写入并同步到AOF文件，但并不进行同步，何时同步由操作系统决定 AOF文件载入与数据还原 AOF重写随着服务器允许，AOF文件内容与体积会越来越大，可能会对服务器造成影响，并且文件太大会使得AOF文件进行数据还原时间太长。 AOF文件重写：创建一个新的AOF文件替代现有的AOF文件，新旧的AOF保存的数据库状态相同，但是新的AOF文件不包含任何浪费空间的冗余指令。 冗余指令： AOF文件重写的实现 通过读取服务器当前数据的状态来实现 AOF后台重写 因为Redis使用单个线程处理命令请求，如果由服务器调用重写，则会无法处理客户端命令请求 使用子进程进行重写。 子进程带有服务器进程的数据副本，使用子进程而不是线程，可以避免在使用锁的情况下，保证数据的安全性 在AOF重写期间，可能会出现对现有数据库状态的修改 设置AOF重写缓冲区，当Redis执行完一个写命令，会将命令同时发送给AOF缓冲区与AOF重写缓冲区 当子进程完成AOF后，向父进程发送信号，将AOF重写缓冲区所有内容写入新AOF文件 替换原有的AOF文件 事件Redis服务器是一个事件驱动程序，需要处理一下两类事件 文件事件：Redis服务器通过套接字与客户端进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端的通信会产生相应的文件事件，服务器通过监听并处理这些事件完成一系列的网络通信操作 时间事件：需要在给定的时间点执行的操作 客户端Redis服务器是典型的一对多服务器程序：一个程序可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令请求，而服务器接收并处理客户端发送的命令请求，并向客户端返回命令回复。 通过使用由IO多路复用技术实现的文件事件处理器，Redis使用单线程单进程处理命令，并与多个客户端进行网络通信 客户端连接池客户端是线程池，而redis是单线程，即客户端与redis建立多个连接。 为每个proxy建立一个连接池。 连接池初始是空的，每次请求从连接池取连接，若没有则新建，请求完成后将连接放回。 负载均衡策略：轮询。 连接池参数： 服务器参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis：数据结构与对象]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[数据结构与对象Redis数据库里面的每个键值对都是由对象组成的： 数据库键总是一个字符串对象。 数据库值是一个对象，对象的实现可以是各种数据结构。 字符串对象。 列表对象。 哈希对象。- 集合对象（set）。 intset、hashtable。 有序集合对象。 ziplist、skiplist。 简单动态字符串SDSRedis的字符串与传统字符串（以空字符结尾的字符数组，C字符串）不同，Redis自己构建了一种简单动态字符串（SDS）的抽象类型，并用作默认字符串表示。 传统字符串在Redis当中只会作为字符串字面量用在一些无须对字符串进行修改的地方。 当需要一个可以被修改的字符串值时，就会使用SDS来表示字符串值。 SDS使用： 保存数据库的可变字符串值。 用作缓冲区： AOF模块中的AOF缓冲区。 客户端状态中的输入缓冲区。 SDS定义123456789struct sdshdr&#123; //记录buf数组已经使用的字节的数量 int len; //记录未被使用字节的数量 int free; //保存字符串 //最后一个字节保存空字符'\0'，不记在len当中 char buf[];&#125; 与C字符串的区别C字符串：以长度N+1的字符数组来表示长度为N的字符串，并且字符数组的最后一个元素总是空元素’\0’ C字符串的字符串表示方法不能满足Redis对字符串在安全性、效率以及功能方面的要求： C字符串需要常数复杂度获取字符串长度。 它不记录自身长度，程序必须遍历整个字符串才能获取长度。 C字符串容易造成缓冲区溢出。 C语言字符串拼接函数strcat，假定用户在执行函数时分字符串分配了足够多的内存，如果内存不够，则会缓冲区溢出。 这是因为字符串本身不记录其本身的内存信息。 SDS有free与len，可以知道自身剩余内存大小。 减少修改字符串时带来的内存重分配次数： C字符串每次修改时，都要对保存字符串的数组进行一次内存重分配操作。 如果扩展字符串，则需要先分配内存；如果截断，则需要释放不适用的空间，否则会内存泄露。 也因此需要进行系统调用，较为费时。 SDS空间预分配优化策略： 优化字符串增长操作，当需要对SDS进行空间扩展时，程序不仅会为SDS分配必要空间，还会为SDS分配额外的未使用空间。 如果SDS修改后，len&lt;1MB，则程序分配和len同样大小的未使用空间。 如果len&gt;=1MB，则分配1MB的未使用空间。 SDS惰性空间释放优化策略： 优化缩短操作，程序并不立即使用内存重分配来回收多出来的字节，而是使用free记录下来，等待将来使用。 同时提供了相应API，在需要时刻真正释放空间。 二进制安全： C字符串的字符必须包含某种编码，并且不能有空字符。因此只能保存文本，不能保存图片等二进制数据。 SDS的API都以处理二进制的方式来处理SDS里的数据。 兼容部分C字符串函数。 SDS的主要操作API 链表应用 列表键的底层实现之一 当一个列表键包含了数量较多的元素，或者列表中包含的元素都是比较常的字符串时，会使用链表作为链表键的底层实现 发布与订阅 慢查询 监视器 保存多个客户端的状态信息 构建客户端输出缓冲区 实现123456789101112131415161718192021typedef struct listNode&#123; struct listNode *prev; struct listNode *next; //节点的值 void *value;&#125;listNode;typedef struct list&#123; listNode *head; listNode *tail; //长度 unsigned long len; //节点值赋值函数 dup void *(*dup)(void *ptr); //节点释放函数 free void *(*free)(void *ptr); //节点值对比函数 match void *(*match)(void *ptr,void *key);;&#125;list; 特性 双端 无环 表头的prev与表尾的next都指向null 表头指针与表尾指针 长度计数器 多态 void*保存节点值，可以保存各种不同类型的值 使用三个属性可以为节点值设置类型特定函数 API 字典map 应用 哈希键的底层实现之一，当一个哈希键包含的键值对比较多，或者键值对中的元素都是比较长的字符串时。 当字典用作数据库底层实现或哈希键的底层实现时，使用MurmurHash2算法计算键的哈希值 即使输入的键有规律，算法依然能给出一个很好地随机分布性，并且计算速度也很快 实现使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，每个哈希表节点就保存了字典中的一个键值对 哈希表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//字典//type与privdata属性针对不同类型的键值对，创建动态字典而设置//dictType保存了一族用于操作特定类型键值对的函数//privdata保存了需要传给那些类型特定函数的可选参数typedef struct dict&#123; //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 //一般使用ht[0],ht[1]在rehash时使用 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 in trehashidx;&#125;dict;typedef struct dictType&#123; //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata,const void *key); //复制值的函数 void *(*valDup)(void *privdata,const void *obj); //对比键的函数 int (*keyCompare)(void *privdata,const void *key1,const void *key2); //销毁键的函数 void (*keyDestructor)(void *privdata, void *key); //销毁值的函数 void (*valDestructor)(void *privdata, void *obj);&#125;//哈希表typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 //与哈希值一起决定一个键应该放到table的哪个索引上 unsigned long sizemask; //已有节点数量 unsigned long used;&#125;dictht;//哈希表节点typedef struct dictEntry&#123; void *key; //值 union&#123; void *val; uint_tu64; int64_ts64; &#125;v; //解决冲突 strut dictEntry *next；&#125;dictEntry; 哈希算法 根据键值对的键计算出哈希值和索引值 根据索引值，将包含新键值对的哈希表节点放到哈希表数组的制定索引上 index=hash&amp;dict-&gt;ht[x].sizemask; 解决键冲突链地址法，并且将新节点加到表头，则复杂度为O1 rehash随着操作不断执行，哈希表的键值对数目变化，为了保持负载因子维持在一个合理范围内，对哈希表进行相应的扩展或者收缩。 步骤 为ht[1]哈希表分配空间，大小取决于要执行的操作，以及ht[0]当前包含的键值对数量，即used值 如果扩展，则大小为第一个&gt;=ht[0].used*2的2^n 如果收缩，则大小为第一个&gt;=ht[0].used的2^n 将保存在ht[0]的所有键值对rehash到ht[1]上。 rehash指重新计算键的哈希值与索引值 释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]创建一个空白哈希表 扩展： 服务器没有执行BGSAVE或BGREWRITEAOF命令，并且哈希表负载因子&gt;=1 服务器在执行BGSAVE或BGREWRITEAOF命令，并且哈希表负载因子&gt;=5 执行命令过程中，Redis需创建当前服务器进程的子进程 大多数OS采用写时复制技术优化子进程的使用效率 父进程和子进程共享页面而不是复制页面。然而，只要页面被共享，它们就不能被修改。 无论父进程和子进程何时试图写一个共享的页面，就产生一个错误，这时内核就把这个页复制到一个新的页面中并标记为可写。原来的页面仍然是写保护的： 当其它进程试图写入时，内核检查写进程是否是这个页面的唯一属主；如果是，它把这个页面标记为对这个进程是可写的。 子进程存在期间，服务器会提高负载因子，以尽可能避免在子进程存在期间进行扩展，避免不必要的内存写入操作，节约内存 收缩：当负载因子小于0.1时 渐进式rehash在哈希表内保存极大量键值对时，一次性rehash会导致服务器停止服务。因此分多次、渐进式rehash 为ht[1]哈希表分配空间 在字典中维持一个索引计数器变量rehashidx标识rehash开始 rehash进行期间，每次对字典执行增删改查操作时，除了执行指定操作，还会将ht[0]在rehashidx索引上的键值对rehas到ht[1]，在rehash完成后，rehashidx自增 全部rehash结束，rehashidx=-1 查找时，会先查ht[0]后查ht[1]。 API 跳跃表应用 一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 支持平均OlgN,最坏ON的节点查找，可以通过顺序性操作批处理节点 大部分情况下，效率与平衡树媲美，并且实现简单。 有序集合键的底层实现之一，如果一个有序集合包含的元素量比较多，或者元素的成员是比较长的字符串时。 集群节点中用作内部数据结构 实现123456789101112131415161718192021222324252627282930313233typedef struct zskiplist&#123; //表头表尾 structz skiplistNode *header,*tail; //表中节点数量 unsigned long length; //表中层数最大的节点的层数 int level;&#125;typedef struct zskiplistNode&#123; //层 //包含多个元素，每个元素都包含一个指向其他节点的指针，可以通过层加快访问其他节点的速度 //层越多，访问其他节点速度越快 //创建一个新的节点时，随机生成一个1-32的值，作为层数 struct zskiplistLevel&#123; //前进指针 //用于访问位于表尾方向的其他节点 struct zskiplistNode *forward; //跨度 //前进指针所指向节点和当前节点的距离 unsigned int span; &#125;level[];//是一个数组 //后退指针 //当前节点的前一个节点 struct zskiplistNode *backward; //分值 //节点按各自保存的分值从小到大排列 double score; //成员对象，一个SDS，较小的排前面，较大排后面（表尾） //成员对象必须唯一，但是分值可以相同 robj *obj;&#125;zskiplistNode; 查找 API 整数集合intset应用 集合键的底层实现之一。当一个集合只包含整数值元素，并且这个结合数量不多。 实现12345678910typedef struct intset&#123; //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 //从小到大有序排列，并不包含重复项 //真正类型取决于encoding的值 int8_t contents[];&#125;intset; 当向一个int16_t的数组，添加一个int64_t的数值时，所有元素都会被转换为int64_t。 升级当要将一个新元素添加到整数集合里，并且新元素的类型比整数集合现有所有元素类型都长时，整数集合需要先进行升级，然后才能添加元素。 根据新元素的类型，扩展整数集合底层数组的空间，并为新元素分配空间 将底层数组现有的所有元素转换成新元素的类型，并将转换后的元素放置到正确的位置，且维持有序性 将新元素添加进去 不支持降级操作 优势 提升灵活性，不担心类型错误 节约内存 API 压缩列表应用 列表键与哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度较短的字符串 实现 Redis为了节约内存而开发，由一系列特殊编码的连续内存块组成的顺序性数据结构。 一个压缩列表可以包含多个节点，每个节点可以保存一个字节数或者一个整数值 构成 zibytes：记录整个压缩列表占用的内存字节数 zltail：记录压缩列表表尾节点距离首部的偏移 zllen：节点数目 entry[]：包含的节点 zlend：特殊值，标记末端 节点构成 previous_entry_length：记录前一个节点的长度（字节为单位），因此可以从尾部向头部遍历 长度可能1个字节（上一个结点的长度小于254）或5个字节 encoding：记录content属性所保存数据的类型已经长度 content：保存节点的值 连锁更新当新插入或删除的节点导致相邻的节点的previous_entry_length属性所占据的空间无法保存正确的数据，而导致需要空间分配。并且出现连锁反应 实际触发可能性较低，并且更新的节点一般不会太多，因此不存在性能问题 API 对象 Redis基于数据结构创建了一个对象系统，而不是直接实现数据库。包括字符串对象、列表对象、哈希对象、集合对象、有序集合对象。 在执行命令前，可以根据对象的类型判断对象是否可以执行给定的命令 可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化使用效率 实现了基于引用计数的内存回收机制、对象共享共享机制（多个数据库键共享同一个对象来节约内存） 对象带有访问时间记录信息，可以用于计算数据库键的空转时长，在服务器启用maxmemory下，空转时长较大的键可能被服务器优先删除 对象的类型与编码Redis使用对象来表示数据库中的键和值，每次创建一个键值对，则会至少创建两个对象：键对象、值对象 对象的实现： 12345678910111213typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层实现数据结构的指针 void *ptr; //引用计数 int refcount; //对象最后一次被命令程序的访问的时间 unsigned lru:22; //....&#125; 类型 键总是一个字符串对象，而值可能是其中一种。 字符串键：则指该键对应的值为字符串对象 编码和底层实现 ptr指向对象的底层实现数据结构，而数据结构由encoding属性决定 根据不同使用场景为对象设置不同的编码，优化对象效率 在列表对象包含元素较少，则使用压缩列表。更节约内存，在内存中连续块保存更快载入到内存 元素越多时，双端链表更优 字符串对象 int raw embstr embstr专门用于保存短字符串的一种优化编码方式。raw编码会调用两次内存分配函数创建redisObject与sdshdr，而embstr调用一次内存分配函数来分配一块连续空间，能更好地利用缓存带来的优势。 列表对象 ziplist linkedlist 哈希对象 ziplist 当有新的键值对加入，先将保存了键的压缩列表节点推入到表尾，再将保存了值的节点推入表尾 两个节点总是紧挨，键节点在前，值节点在后 先添加到哈希对象中的键值对放在表头方向 hashtable 字典作为底层实现 集合对象 intset 整数集合 hashtable 字典 有序集合对象 ziplist skiplist 类型检查与命令多态操作键的命令可分为两种类型 可对任何类型的键执行 DEL、EXPIRE、RENAME、TYPE、OBJECT 只能对特定类型的键执行 SET、GET等只能对字符串键执行 HDEL、HSET等只能对哈希键执行 … 类型检查的实现 在执行一个类型特定的命令前，Redis会先检查redisObject的type属性 多态命令的实现 根据值对象的编码方式，选择正确的命令实现代码来执行命令 根据类型的多态 DEL等 根据编码的多态 SET等，对于一种类型的多种实现编码 内存回收根据redisObject的refcount属性记录 当创建一个新对象时，引用计数的值初始化为1 当被一个新程序使用时，引用计数+1 变为0时，占用内存会释放 对象共享当键A与键B都创建了一个包含整数值100的字符串对象作为值对象 为键B创建一个新的对象 键A与键B共享一个对象 将键B的指针指向原有的对象 被共享值的对象引用计数+1 Redis只对包含整数值的字符串对象进行共享，因为对于包含字符串的话，做一个equal的时间复杂度太高，CPU占用时间太长 对象的空转时长依据对象的lru时间，如果占用内存超出maxmemory则lru较高的部分键会优先被释放 参考 《Redis设计与实现》]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis：概述]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Redis起源：为了实现一个访客信息追踪网站，展示网站最近的n条访问记录。而当时数据库在负载高时无法很好满足。 分布式内存key-value的数据库。 事件循环Redis服务在启动后会陷入一个巨大的while循环，不停处理文件事件和时间事件。 所有的事件都存在于一个队列当中。 文件事件：在多个客户端实现多路复用，文件事件在一个有序队列当中，其排列规则是文件事件建立的规则。 时间事件：记录那些要在指定事件点运行的事件，多个事件事件以无序链表的形式存放在服务器状态中。 Redis自身的任务。 更新服务器的各类统计信息，如时间、内存占用等。 数据库后台操作，key过期清理，数据库rehash等。 关闭、清理失效的客户端连接。 检查是否需要RDB dump，AOF重写。 主节点、对从节点定期同步。 集群模式，集群定期同步信息。 流程： beforeSleep epollwait 处理请求，即文件事件。 定时时间。 逐出当执行write单内存达到上限时，强制将一些key删除。逐出策略有： allkeys：所有key。 volatile：设置了过期的key。 LRU。 random。 ttl：最快过期的。 特点 不是精确算法，而是抽样对比。 每次写入操作前判断。 逐出时阻塞请求的。 逐出的QPS过高会影响正常请求。 数据结构与对象Redis数据库里面的每个键值对都是由对象组成的 数据库键总是一个字符串对象。 数据库键的值可以是： 字符串对象。 列表对象。 哈希对象。 集合对象（set）。 有序集合对象， 命令set Redis将在数据库创建一个新的键值对，键值为msg，值为helloworld。 1set msg "helloworld" rpush 将创建一个列表对象，key为fruits，value为列表。 1rpush fruits "apple" "banana" "cherry" 批量操作pipeline client：将多个命令缓存起来，缓冲区满了就发送。 redis：处理一个tcp连接法来的多个命令，处理完一个就发一个。 twemproxy：既要处理一个client连接法来的多个命令，又要将到同一个下游redis server的命令缓存起来一起发送。 节省往返时间。 减少了proxy、redis server的IO次数。 mget 弱于pipline client：使用mget。 redis：一个命令中处理多个key，等所有key处理完组装完后组装恢复一起发送。 twmproxy：拆key分发到不同redis server，需要等待、缓存mget中全部恢复。 节省往返时间。 proxy缓存 延迟删除为什么要用cache与db数据不一致问题。 产生原因：请求回源时，由于DB主从延迟导致用DB从节点的老数据更新了cache。 解决方案：cache延迟多次删除，当前删除一次，过几秒(大于DB主从延迟)后再次删除一次。 概述读取操作：先redis，redis没有就读db。 写操作： 先更新redis再更新db。 先更新db再更新redis。 先更新DB再删除redis。 先删除redis再更新DB。 延迟双删。 延迟删除等变种。 非一致性先更新redis再更新db。AB为两个线程，则此时db最终为a值，但redis为b值： A_update_redis。 B_update_redis。 B_update_db。 A_update_db。 先更新db再更新redis。最终db是b值但是redis是a值： A_update_db。 B_update_db。 B_update_redis。 A_update_redis。 先更新DB再删除redis。 A_update_db。 B_update_db。 B_rm_redis。 A_rm_redis。 不一致的原因为： A_get_data。 redis_cache_miss。 A_get_db。 B_update_db。 B_rm_redis。(此时如果拿db是b值，但是redis没有值)。 A_update_redis。 依赖于A_update_redis在B_update_db之后，极端情况此时redis是old，db是new。 先删除redis再更新DB。此时redis是old值，db是new值 A_rm_redis。 B_get_data。 B_redis_miss。 B_get_db。 B_update_redis。 A_update_db。 最终一致性延迟双删。最后一次sleep一段时间再rm_redis保证再次读请求回溯打到db，用最新值写redis。 rm_redis。 update_db。 sleep xxx ms。 rm_redis。 变种。解决了3中的极端情况（靠sleep解决），并且减少5中第一次不必要的rm redis请求。当然，这个rm_redis还可以考虑异步化（提高吞吐）以及重试（避免异步处理失败）。 update_db。 sleep xxx ms。 rm_redis。 单机数据库的实现 数据库： Redis数据库的实现原理。 说明了服务器保存键值对的方法。 服务器保存键值对过期时间的方法。 服务器自动删除过期键值对的方法。 RDB持久化、AOF持久化： Redis两种持久化方法的实现原理。 服务器根据数据库来生成持久化文件的方法。 服务器根据持久化文件还原数据库的方法。 BGSAVE与BGREWAITEAOF的实现原理。 事件： 文件事件： 应答客户端连接请求。 接收客户端发送的命令请求。 向客户端返回命令回复。 时间事件： 执行redis.c/serverCron函数，通过执行常规的维护和管理操作保持Redis服务器的正常运作。 触发一些定时操作。 客户端。 服务器。 缓存使用如何利用有限的资源提供尽可能大的吞吐量。 请求直接从缓存中获取数据，直接返回。 缓存特征 命中率：命中数/（命中数+没有命中数）： 没有命中，缓存过期，需要从数据库当中重新获取。 影响因素： 业务场景和业务需求：读多写少，实时性要求越低。 缓存的设计（粒度和策略）：粒度越小，命中率越高。如果缓存一个对象与一个组的对象，一个对象的命中率更高。缓存策略，即缓存的更新。 缓存容量和基础设施：多数采用LRU算法。 并发越高，即使过期时间很短，缓存收益也很高。 当缓存结点出现故障，需要避免缓存失效，并最大程度降低影响。 最大元素（空间）：缓存中可以存放的最大数量。 清空策略：FIFO、LFU、LRU，过期时间、随机等。 缓存命中率影响因素 业务场景和业务需求： 业务场景：缓存适合读多写少的场景。 业务需求：决定对实时性的要求，直接影响缓存的更新策略与更新时间，实时性要求越低就越适合缓存。 缓存的设计（粒度和策略）： 缓存的粒度越小，命中率越高。如果只缓存一个用户信息，此时当用户更新才需要更新缓存；如果缓存了一个集合，则集合当中任一个值更新都要更新缓存。 当数据发生变化时，更新缓存的值比移除缓存或缓存更新的命中率更高。 缓存容量和基础设施： 缓存容量有限，则容易导致缓存被淘汰，多数缓存使用LRU。 使用本地缓存容易出现单机瓶颈，分布式缓存更容易扩展。 不同的缓存框架的效率与稳定性各不相同。 缓存节点故障需要避免缓存失效并最大程度降低影响： 通过一致性哈希或节点冗余方式。 并发越高，缓存受益越高。 缓存设计 尽可能地通过缓存获取数据，并避免缓存失效： 需要从业务需求、缓存粒度、缓存策略、技术选型等各方面进行权衡，需要聚焦在高频访问且时效性要求不高的热点业务上。 通过缓存预热、增加缓存容量、调整缓存粒度、更新缓存等手段来提高命中率。 缓存分类和应用场景根据缓存与应用的耦合度： 本地缓存： 编程实现，成员变量、局部变量、静态变量。 Guava Cache。设计灵感来自于ConcurrentHashMap。 无法共享。 分布式缓存。自身是一个独立的应用，与应用程序隔离。 Memcache。本身不提供分布式解决方案，分布式通过客户端实现路由实现分布式。 Redis。 Memcache在服务端，Memcache的集群环境就是服务器节点的堆积。 通过一致性hash算法实现路由，除了计算key的哈希值还会计算每一个对应Server的哈希值，然后将哈希值映射到一个有限的值域中。 通过寻找server hash&gt;key hash的最小server作为目标server，如果找不到，则直接将最小hash值的server作为目标server，增加或删除单个节点对于集群不会有大的影响。 内存结构图 stab_class： stab：Memcache将内存空间分为了一组stab，有相同大小的chunk被组织为一个stab。LRU针对stab而不是整体 page：每个stab拥有一组page，申请内存以page为单位。page大小1M，不会有1M大小的value，不会有256字节的key。 chunk：chunk是存放数据的地方，一组chunk大小是一样的。 value总会被存放在与chunk大小最接近的地方。即总会有内存浪费 Memcache不能遍历它内部的item。 高性能： 一致性哈希找到server。 通过hash算法找到item。 Memcache是一个非阻塞的基于事件的服务器程序， Redis Redis具有复制特性扩展读性能，使用分片扩展写性能，可以持久化到硬盘，支持主从备份，所有操作都是原子性的，支持合并多个操作为原子性。 使用场景： 取单个最新数据的操作。 排行榜类似应用。 精准设定过期时间。 实时系统、垃圾系统、实时消息系统、队列系统。 唯一性检查应用。 高并发场景下缓存常见问题 缓存一致性： 当数据时效要求很高，要保证缓存中的数据与数据库中的数据保持一致。并且缓存结点与副本中的数据也保持一致。 依赖缓存的过期与更新策略。在数据发生更改时，主动更改缓存中的数据，或移除对应的缓存： 更新数据库成功，更新缓存失败，数据不一致。 更新缓存成功，更新数据库失败，数据不一致。 更新数据库成功，淘汰缓存失败，数据不一致。 淘汰缓存成功，更新数据库失败，查询缓存miss。 缓存并发问题： 缓存过期后，将尝试从后端数据库获取数据。在高并发下，可能多个请求同时向数据库请求获取。 缓存穿透问题： 某个key在高并发的访问下没有被命中，出于容错率的情况，尝试去后端数据库中获取，导致大量的请求到达数据库本身。当该key对应的数据本身为空，就会导致数据库中并发执行很多不必要的操作。 缓存空对象，对查询结果为空的对象也进行缓存。 缓存的雪崩现象： 缓存抖动（颠簸），缓存结点故障，通过一致性哈希算法解决。 由于缓存的原因，导致大量请求到达后端数据库，导致数据库崩溃，系统崩溃。 可能由于缓存抖动、缓存并发、或者部分缓存集体失效过期导致。 通过限流、降级、熔断手段降低影响，通过多级缓存。 参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：高并发]]></title>
    <url>%2F2019%2F03%2F04%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E9%AB%98%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[概念并发相关概念吞吐率我们一般使用单位时间内服务器处理的请求数来描述其并发处理能力。称之为吞吐率（Throughput），单位是 “req/s”。吞吐率特指Web服务器单位时间内处理的请求数。 另一种描述，吞吐率是，单位时间内网络上传输的数据量，也可以指单位时间内处理客户请求数量。它是衡量网络性能的重要指标。通常情况下，吞吐率“字节数/秒”来衡量。当然你也可以用“请求数/秒”和“页面数/秒”来衡量。其实不管一个请求还是一个页面，它的本质都是在网络上传输的数据，那么用来表述数据的单位就是字节数。 吞吐量吞吐量，是指在一次性能测试过程中网络上传输的数据量的总和。 对于交互式应用来说，吞吐量指标反映的是服务器承受的压力，在容量规划的测试中，吞吐量是一个重点关注的指标，因为它能够说明系统级别的负载能力，另外，在性能调优过程中，吞吐量指标也有重要的价值。如一个大型工厂，他们的生产效率与生产速度很快，一天生产10W吨的货物，结果工厂的运输能力不行，就两辆小型三轮车一天拉2吨的货物，比喻有些夸张，但我想说明的是这个运输能力是整个系统的瓶颈。 提示，用吞吐量来衡量一个系统的输出能力是极其不准确的，用个最简单的例子说明，一个水龙头开一天一夜，流出10吨水；10个水龙头开1秒钟，流出0.1吨水。当然是一个水龙头的吞吐量大。你能说1个水龙头的出水能力是10个水龙头的强？所以，我们要加单位时间，看谁1秒钟的出水量大。这就是吞吐率。 事务，TPS(Transaction Per second)就是用户某一步或几步操作的集合。不过，我们要保证它有一个完整意义。比如用户对某一个页面的一次请求，用户对某系统的一次登录，淘宝用户对商品的一次确认支付过程。这些我们都可以看作一个事务。那么如何衡量服务器对事务的处理能力。又引出一个概念—-TPS 每秒钟系统能够处理事务或交易的数量，它是衡量系统处理能力的重要指标。 点击率可以看做是TPS的一种特定情况。点击率更能体现用户端对服务器的压力。TPS更能体现服务器对客户请求的处理能力。 每秒钟用户向web服务器提交的HTTP请求数。这个指标是web 应用特有的一个指标；web应用是“请求-响应”模式，用户发一个申请，服务器就要处理一次，所以点击是web应用能够处理的交易的最小单位。如果把每次点击定义为一个交易，点击率和TPS就是一个概念。容易看出，点击率越大。对服务器的压力也越大，点击率只是一个性能参考指标，重要的是分析点击时产生的影响。 需要注意的是，这里的点击不是指鼠标的一次“单击”操作，因为一次“单击”操作中，客户端可能向服务器发现多个HTTP请求。 吞吐量、吞吐率的意义 吞吐量的限制是性能瓶颈的一种重要表现形式，因此，有针对地对吞吐量设计测试，可以协助尽快定位到性能冰晶所在的位置 80%系统的性能瓶颈都是由吞吐量制约 并发用户和吞吐量瓶颈之间存在一定的关联 通过不断增加并发用户数和吞吐量观察系统的性能瓶颈。然后，从网络、数据库、应用服务器和代码本身4个环节确定系统的性能瓶颈。 吞吐率和压力测试单从定义来看，吞吐率描述了服务器在实际运行期间单位时间内处理的请求数，然而，我们更加关心的是服务器并发处理能力的上限，也就是单位时间内服务器能够处理的最大请求数，即最大吞吐率。 所以我们普遍使用“压力测试”的方法，通过模拟足够多数目的并发用户，分别持续发送一定的HTTP请求，并统计测试持续的总时间，计算出基于这种“压力”下的吞吐率，即为一个平均计算值 处理思路 扩容 水平扩容 垂直扩容 缓存 redis memcache guavaCache 队列 kafka rabbitMQ rocketMQ 拆分 服务化Dubbo 微服务spring cloud 服务降级与熔断 hystrix介绍与使用 服务降级的多种选择 数据库切库分库分表 切库、分表、支持多数据源的原理及实现 高可用的一些手段 任务调度分布式elastic-job 主备curator的实现 监控报警机制 限流 guava rateLimiter 常用限流算法 分布式限流 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：拓展]]></title>
    <url>%2F2019%2F03%2F04%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E6%8B%93%E5%B1%95%2F</url>
    <content type="text"><![CDATA[Spring与线程安全参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统：处理机调度]]></title>
    <url>%2F2019%2F03%2F03%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[处理机调度是OS中用来管理处理机执行能力的这一部分的资源的功能 CPU资源的时分复用 进程切换：CPU资源的当前占用者切换 保存当前进程在PCB中的执行上下文（CPU状态） 恢复下一个进程的CPU状态 处理机调度 从就绪队列中挑选下一个占用CPU运行的进程 从多个可用CPU中挑选就绪进程可以使用的CPU资源（多处理器） 调度程序：挑选就绪进程的内核函数 调度策略：依据什么原则挑选进程、线程 调度时机：什么时候进行调度 概念处理机概念 调度时机 内核运行调度程序的条件 进程从运行状态切换到等待状态 进程被终结了 非抢占系统 当前进程主动放弃CPU 可抢占系统 中断请求被服务例程响应完成时 当前进程被抢占 进程时间片用完 进程从等待切换到就绪 调度准则调度策略 确定如何从就绪队列中选择下一个执行进程 调度策略要解决的问题 挑选就绪队列的哪一个进程 通过什么样的准则来选择 调度算法 在调度程序中实现的调度策略 比较调度算法的准则 哪一个策略、算法比较好 CPU使用率 CPU处于忙状态的时间百分比 吞吐量 单位时间内完成的进程数量 周转时间 进程从初始化到结束的总时间 等待时间 进程在就绪队列中的总时间 响应时间 从提交请求到产生响应所花费的时间 调度算法的要求 吞吐量与延迟 希望更快地服务 传输文件时的高带宽，调度算法的高吞吐量 玩游戏时的低延迟，调度算法的低响应延迟 与水管类比 低延迟：喝水时要一打开水龙头水就流出 高带宽：给泳池充水，希望从水龙头更快地充满 处理机调度策略的目标 响应时间目标 减少响应时间 减少平均响应时间的波动 可预测性比高差异低平均更重要 低延迟调度改善了用户的交互体验 响应时间是OS的计算延时 吞吐量目标 增加吞吐量 减少开销，OS开销，上下文切换 系统资源的高效利用，CPU与IO设备 减少等待时间 减少每个进程的等待时间 OS需要保证吞吐量不受用户交互的影响 吞吐量是OS的计算带宽 公平性目标 公平的定义 保证每个进程占用相同的CPU时间 保证每个进程的等待时间相同 公平通常会增加平均响应时间 处理机资源的使用模式 进程在CPU计算和I/O操作间交替 I/O操作期间，CPU等待 计算大多在8MS以内 在时间片机制下，进程可能在结束当前CPU计算前被迫放弃CPU 调度算法单处理器 调度算法分类 就绪队列如何排列 先来先服务 短进程优先 最高响应比优先 每一次执行时间长短的控制 时间片轮转 多种算法如何综合到一起 多级反馈队列 公平共享调度 先来先服务FCFS依据进程进入就绪状态的先后顺序排列 进程进入等待或结束状态时，就绪队列中的下一个进程占用CPU 特征 简单 平均等待时间波动很大 短进程可能排在长进程后面 IO资源和CPU资源利用率较低 CPU密集型进程会导致IO设备空闲时，IO密集型进程也等待 短进程优先SPN 短进程优先 选择就绪队列中执行时间最短进程占用CPU进入运行状态 就绪队列按预期（只有在执行时刻才真正知道）的执行时间排序 特征 最优平均周转时间 可能导致饥饿 连续的短进程流会使得长进程无法获得CPU资源 需要预知未来 如何预估下一个CPU计算的持续时间 解决： 询问用户 用历史执行时间预估未来执行时间 SJF 短作业优先 SRT 短剩余时间优先：SPN算法的可抢占改进 最高响应比优先进程在就绪队列里的等待时间 选择就绪队列中响应比R值最高的进程 R=(w+s)/s w：等待时间，s：执行时间 在短进程优先算法基础上的改进 不可抢占 关注进程的等待时间 可以避免无限期等待 时间片轮转RR时间片：分配处理机资源的基本时间单元 算法思想：时间片结束时，按FCFS算法切换到下一个就绪进程 时间片设置 RR算法开销 依靠时钟中断，存在额外的上下文开销 时间片太大 等待时间太长，极限情况退化为FCFS 时间片太小 反应迅速，但大量上下文切换，影响系统吞吐量 设置尺度 经验值：10MS左右，上下文切换开销1% 多级反馈队列MLFQ多级队列调度算法MQ 就绪队列被划分为多个独立的子队列 前台（交互），后台（批处理） 每个队列用于自己的调度策略 队列间的调度 固定优先级，则可能出现饥饿 时间片轮转 各个队列之间进行交互，则为多级反馈队列 进程可以在不同队列间移动的多级队列算法 时间片大小随着优先级增加而增加 如进程在当前的时间片没有完成，则降到下一个优先级 MLFQ算法的特征 CPU密集型进程的优先级下降很快 IO密集型进程停留在高优先级 使用CPU时间短 公平共享调度FSSFSS控制用户对系统资源的访问 一些用户组比其他用户组更重要 保证不重要的组无法垄断资源 未使用的资源按比例分配 没有达到资源使用率目标的组获得更高的优先级 实时调度实时操作系统 定义：正确性依赖于其时间和功能两方面的操作系统 性能指标 时间约束的及时性 速度和平均性能相对不重要 特性：时间约束的可预测性 实时任务 任务（工作单元） 一次计算，一次文件读写，一次消息传递 任务属性 完成任务需要的资源 定时参数 周期实时任务：一系列相似的任务 软时限 通常能满足任务时限，如果有时不能满足，则降低要求 尽力保证满足任务时限 硬时限 错过时限会导致灾难性的后果 必须验证，在最坏情况下能够满足时限 可调度性 表示一个实时操作系统能够满足任务时限要求 实时调度算法 静态调度算法：速率单调调度算法RM 通过周期安排优先级 周期越短优先级越高 执行周期最短的任务 动态调度算法：最早截止时间优先算法EDF 截止时间越早优先级越高 执行截止时间最早的任务 多处理器调度特征 多个处理机组成越高多处理机系统 处理机间可负载共享 对称多处理器调度SMP 每个处理器运行自己的调度程序 调度程序对共享资源的访问需要进行同步 SMP进程分配 静态进程分配 进程从开始到结束都被分配到一个固定的处理器上执行 每个处理机有自己的就绪队列 调度开销小 各处理机可能忙闲不均 动态进程分配 进程在执行中可分配到任意空闲处理机执行 所有处理机共享一个公共的就绪队列 调度开销大 负载是均衡的 优先级反置 指操作系统中高优先级进程长时间等待低优先级进程所占用资源的现象 基于优先级的可抢占调度算法存在这种问题 解决： 优先级继承 占用资源的低优先级进程继承申请资源的高优先级进程的优先级 优先级天花板协议 占用资源进程的优先级和所有可能申请该资源的进程的最高优先级相同 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统：进程和线程]]></title>
    <url>%2F2019%2F03%2F03%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程进程的概念出现原因 早期OS只允许 一次执行一个程序，现代OS允许将多个程序调入内存并发执行。要求对各种程序提供更为严格的控制和更好地划分。 概述 进程是指一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程。 即程序本身不是进程，程序只是被动实体（一个可执行文件），而进程是活动实体，拥有一个程序计数器用来表示下一个要执行的命令和相关资源集合。 当一个可执行文件装入内存，一个程序才能成为进程 进程的组成 进程包含了正在运行的一个程序的所有状态信息 程序代码。即可执行文件 数据。进程通常还包括进程堆栈段（临时数据，如函数参数、返回地址和局部变量）和数据段（全局变量等） 可能包括堆，是在进程运行期间动态分配的内存。 当前活动 状态寄存器。CPU状态CR0、指令指针IP 通用寄存器。AX、BX。。。 进程占用系统资源 打开文件、已分配内存 因此即使是运行同一个程序代码两次，也是两个不同的进程。就像打开两个浏览器一样 进程的特点 动态性 可动态地创建、结束进程 并发性 进程可以被独立调度并占用处理机（CPU）运行 独立性 不同进程的工作不相互影响 制约性 因访问共享数据、资源或进程间同步而产生制约 进程和程序的联系 进程是OS处于执行状态程序的抽象 程序=文件（静态的可执行文件） 进程=执行的程序=程序+执行状态 同一个程序的多次执行过程对应为不同进程 如命令ls的多次执行对应多个进程 进程执行所需要的资源 内存：保存代码和数据 CPU：执行指令 进程和程序的区别 进程是动态的，程序是静态的 程序是有序代码的集合 进程是程序的执行，进程有核心态\用户态 进程是暂时的，程序是永久的 进程是一个状态变化的过程 程序可以长久保存 进程和程序的组成不同 进程的组成包括程序、数据和PCB 进程控制块PCBPCB：操作系统控制进程运行所用的信息集合 操作系统用PCB来描述进程的基本情况以及运行变化的过程 PCB是进程存在的唯一标志。每个进程都在OS中有一个对应的PCB 进程控制块的使用 进程创建。生成该进程的PCB 进程终止。回收它的PCB 进程的组织管理。通过对PCB的组织管理来实现 进程控制块的内容 进程状态。创建、就绪、运行等 进程标识信息。进程编号，PID 程序计数器。进程要执行的下个指令的地址 CPU寄存器。 与计算机体系结构相关 包括累加器、索引寄存器、堆栈指针、通用寄存器和其他条件码信息寄存器。 CPU调度信息。进程优先级、调度队列的指针和其他调度参数 内存管理信息。OS所使用的内存系统，包括基址和界限寄存器的值、页表或段表 记账信息。CPU时间、实际使用时间、时间界限、记账数据、作业或进程数量等 IO状态信息。包括分给进程的IO设备列表、打开的文件列表等 进程控制块的组织 链表 同一状态的进程其PCB成一链表，多个状态对应多个不同的链表 各状态的进程形成不同的链表：就绪链表、阻塞链表 索引表 同一状态的进程归入一个索引表，由索引指向PCB 进程状态进程生命周期划分 进程创建 导致创建的事件 系统初始化时 用户请求创建一个新进程 正在运行的进程执行了创建进程的系统调用 进程执行 内核选择一个就绪的进程，让它占用处理机并执行 依据CPU调度算法 进程等待 进程进入等待（阻塞）的情况 请求并等待系统服务，无法马上完成 启动某种操作，无法马上完成 需要的数据没有到达 只有进程自身才能知道何时需要等待某种事件发生 即是由进程本身内部原因引起的 进程抢占 被抢占情况 高优先级进程就绪 进程执行当前时间用完 进程唤醒 唤醒可能情况 被阻塞进程需要的资源可被满足 被阻塞进程等待的时间到达 进程只能被别的进程或OS唤醒 进程结束 结束可能情况 正常退出（自愿） 错误退出（自愿，进行了相应的处理保存） 致命错误 被其他进程杀死 进程切换 IO设备为定时器 三状态进程模型与CPU相关 进程状态 运行 进程正在处理机上运行 就绪 进程获得了除处理机以外所需的资源 等待状态 （阻塞） 进程正在等待某一时间的出现而暂停运行 创建状态 进程正在被创建，还没有赚到就绪状态之前的状态 正在分配资源，已经相应数据结构完成初始化 结束 进程正在从系统中消失的状态 状态变迁 挂起进程模型与存储相关 进程挂起： 处于挂起状态的进程映像在磁盘上 目的是减少进程占用内存 等待挂起状态 进程在外存并等待事件的出现 就绪挂起状态 进程在外存，但只要进入内存即可运行 内存不够 优先级不够高 状态转换 挂起：把一个进程从内存转到外存 等待到等待挂起 没有进程处于就绪状态或就绪进程要求更多的内存资源 就绪到就绪挂起 当有高优先级等待进程和低优先级就绪进程 运行到挂起就绪 对抢先式分时系统，当有高优先级等待挂起进程因时间出现而进入就绪 在外存时的状态转换 等待挂起到就绪挂起 当有等待挂起进程因相关事件出现 激活：把一个进程从外存转到内存 就绪挂起到就绪 没有就绪进程或挂起就绪进程优先级高于就绪进程 等待挂起到等待 当一个进程释放足够内存，并有高优先级等待挂起进程 状态队列 由操作系统维护一组队列，表示系统中所有进程的当前状态 不同队列表示不同状态 就绪队列、等待队列等 根据进程状态不同，PCB加入相应队列 进程状态变化时，PCB会换到另一个队列 线程为什么引入线程 在一个进程当中希望有很好地并发性，多线程解决思路 在进程内部增加一类实体，满足一下特性 实体之间可以并发执行 实体之间共享相同的地址空间 线程的概念线程是进程的一部分，描述指令流执行状。 它是进程中的指令执行流（从进程中剥离）的最小单元，是CPU调度的基本单位 进程的资源分配角色：进程由一组相关资源构成，包括地址空间，打开的文件等各种资源 线程的处理机调度角色：线程描述在进程资源环境中的指令流执行状态 线程控制块TCB 进程和线程的关系 线程=进程-共享资源 线程的优点 一个进程中可以同时存在多个线程 各个线程间可以并发地执行 各个线程间可以共享地址空间和文件等资源 线程的缺点 一个线程崩溃，会导致其所属进程的所有线程崩溃 用户线程线程的实现方式 用户线程：在用户空间实现 内核线程：在内核中实现 轻量级线程：在内核中实现，支持用户线程 用户线程：由一组用户级的线程库函数来完成线程的管理 用户线程的特征 不依赖OS的内核 内核不了解用户线程的存在 可用于不支持线程的多进程操作系统 在用户空间实现的线程机制 每个进程有私有的线程控制块列表 TCB由线程库函数维护 同一进程内的用户线程切换速度快 无需用户态-&gt;核心态切换 允许每个进程拥有自己的线程调度算法 不足 线程发起系统调用而阻塞，则整个进程进入等待 不支持基于线程的处理机抢占 除非当前允许线程主动放弃，它所在进程的其他线程无法抢占CPU 线程只能按进程分配CPU时间 多个线程进程中，每个线程的时间片较少 内核线程由内核通过系统调用实现的线程机制，由内核来完成线程的创建、终止、管理 内核线程的特征 由内核维护PCB和TCB 线程执行系统调用而被阻塞不影响其他线程 线程的创建终止、切换开销相对较大 通过系统调用/内核函数，在内核中实现 要先由用户态转到内核态 以线程为单位进行CPU时间分配 多线程进程可以获得更多CPU时间 轻权进程内核支持的用户线程。一个进程可以有一个或多个轻量级进程，每个轻权进程由一个单独的内核线程来支持。 内核线程与用户线程的结合，过于复杂，没体现优势 进程与线程区别进程与线程的比较 进程是资源分配的单位，线程是CPU调度单位 进程拥有一个完整的资源平台，线程只独享指令流执行的必要资源，如寄存器和栈 线程具有就绪、等待和运行三种基本状态和状态间的转换关系 线程能减少并发执行的时间和空间开销 线程的创建时间比进程短 线程的终止时间比进程短 同一进程内的线程切换时间比进程短 由于同一进程的各线程间共享内存和文件资源，可不通过内核进行直接通信 进程调度进程调度选择一个可用的进程到CPU上执行。 调度队列 进程进入系统时，会被加到作业队列中，队列中包括系统中的所有进程。 队列通常使用链表来实现，头指针指向链表的第一个和最后一个PCB块的指针，每个PCB包括一个指向就绪队列的下一个PCB的指针域 上下文切换进程上下文由进程PCB表示 包括CPU寄存器的值、进程状态、内存管理信息等。 上下文切换：将CPU切换到另一个进程需要保存当前进程的状态并恢复另一个进程状态，这一个任务称为上下文切换。 速度依赖于内存速度、必须复制的寄存器数量、是否有特殊指令（如装入或保存所有寄存器的单个指令） 与硬件支持相关。有的处理器提供了多组寄存器集合，只需要简单地改变当前寄存器组的指针即可。 进程控制进程切换定义 暂停当前运行进程，从运行状态变成其他状态 调度另一个进程从就绪状态变成运行状态 进程切换的要求 切换前，保存进程上下文 切换后，恢复进程上下文 快速切换 进程生命周期的信息 寄存器 PC SP CPU状态 内存地址空间 PCB：内核的进程状态记录 内核为每个进程维护了相应的进程控制块 内核将相同状态的进程的PCB放置在同一队列 进程创建fork复制原有进程 exec进行重写 进程加载用户的应用程序通过系统调用加载来完成一个新的可执行文件的加载 进程等待与退出父子进程的一种交互 wait()系统调用用于父进程等待子进程的结束 子进程结束时，通过exit向父进程返回一个值 父进程通过wait接受并处理返回值 wait系统调用的功能 有子进程存活时，父进程进入等待状态，等待子进程的返回结果 当某子进程调用exit时，唤醒父进程，将exit的返回值作为副进程中wait的返回值 有僵尸子进程等待时，wait立即返回其中一个值 无子进程存活，wait立刻返回 进程的有序终止exit 进程结束执行时调用exit，完成进程资源回收 exit系统调用的功能 将调用参数作为进程的结果 关闭所有打开的文件等占用资源 释放内存 释放大部分进程相关的内核数据结构 检查释放父进程是存活着的 如存活，保留结果的值直到父进程需要它，进入僵尸状态 如果没有，释放所有数据结构，进程结束 清理所有等待的僵尸进程 进程终止是最终的垃圾回收（资源回收） 其他进程控制系统调用 优先级控制 进程调试支持 允许一个进程控制另一个进程的执行 设置断点和查看寄存器 定时 sleep 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统（三）：虚拟内存]]></title>
    <url>%2F2019%2F03%2F02%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[虚拟内存概念物理内存的管理：分区、非连续分区等 虚拟内存是非连续内存分配的基础上，把原来要放在内存里的整个进程地址空间的信息，将其中的一部分数据放到外存当中，使得内存空间更大。 具体做法：覆盖与交换。 局部性原理：程序的执行有一定特征，要么是指令顺序执行，要么是跳转（循环，跳转到之前的一个地方） 目标 只把部分程序放到内存，从而运行比物理内存大的程序 由OS完成 实现进程在内存与外存之间的交换，从而获得更多的空闲内存空间 在内存和外存间只交换进程的部分内容 需求背景 增长迅速的存储需求，OS当中常出现的内存空间不够用 解决：覆盖，应用程序手动把需要的指令和数据保存在内存中（将代码分为若干模块，相互独立，在需要的时候加载） 交换，OS自动把暂时不能执行的程序保存到外存当中（一次对换是整个进程） 虚拟存储，在有限容量的内存中，以页为单位自动装入更多更大的程序 存储层次结构 理想中的存储器 容量更大，速度更快，价格更便宜、非易失 实际 寄存器、高速缓存、内存、磁盘、磁带 操作系统的存储抽象 地址空间 覆盖和交换覆盖目标：在较小的可用内存中运行较大的程序（单个大程序无法运行） 方法： 依据程序的逻辑结构，将程序划分为若干功能相对独立的模块。将不会同时执行的模块共享同一块内存区域 必要部分的代码和数据常驻内存 可选部分放在其他程序模块中，只在需要时装入 不存在调用关系的模块相互覆盖，放在同一内存区域 覆盖示例： 不足： 增加编程困难 需要划分功能模块 增加复杂度 增加执行时间 从外存装入 交换目的：增加正在运行或需要运行的程序的内存（考虑多个程序时候空间不够） 实现方法 将暂时不能运行的程序放到外存 换入换出的基本单位 整个进程的地址空间 换出：将一个进程的整个地址空间保存到外存 换入：将外存中莫进程的地址空间换入内存 问题： 交换时机：何时需要发生交换 当内存空间不够或有不够的可能时 交换区的大小 存放所有用户进程的所有内存映像的拷贝 程序换入时的重定位：换出后再换入要放在原处吗？ 动态地址映射 局部性原理概念：指访问的数据具有很好的集中性 程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域 时间局部性 一条指令的一次执行与下一次执行，一个数据的一次访问与下次访问都集中在一个较短时期内 空间局部性 当前指令与邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内 分支局部性 一条跳转指令的两次执行，很可能跳到相同的内存位置 虚拟存储概念思路：将不常用的部分内存块暂存到外存 原理： 加载程序时，只将当前指令执行需要的部分页面或段装入内存 指令执行中需要的指令或数据不在内存（缺页）时 处理器通知操作系统将相应的页面调入内存 OS将内存中暂时不用的页面保存到外存（置换算法） 实现方式：虚拟页式、段式存储 支持技术： 硬件 页式或短时存储中的地址转换机制 操作系统 管理内存和外存间页面或段的换入或换出 虚拟页式存储在页式存储管理的基础上，增加请求调页和页面置换 思路 在用户程序要装在到内存运行时，只装入部分页面，就启动程序 进程在运行中发现有需要的代码或数据不在内存时，则向系统发出缺页异常请求 操作系统在处理缺页异常时，将外存中相应的页面调入内存 页表项结构 驻留位，表示该页是否存在内存 修改位：表示在内存中的该页是否被修改过 访问位：表示该页面是否被访问过（读或写） 保护位：表示该页的允许访问方式 缺页异常 虚拟页式存储中的外存管理 在何处保存未被映射的页 应能方便地找到在外存中的页面内容 交换空间（磁盘或者文件） 采用特殊格式存储未被映射的页面 外存选择 代码段：可执行二进制文件 动态加载的共享库程序段：动态调用的库文件 其他段：交换空间 虚拟页式存储管理的性能 有效存储访问时间 EAT=访存（内存）时间×（1-p）+缺页异常处理时间（远大于访存时间）×缺页率p 虚拟存储页面置换算法概念功能 当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面 设计目标： 尽可能减少页面的调入调出此时 把未来不再访问或短期内不访问的页面调出 页面锁定： 描述必须常驻内存的逻辑页面（OS的关键代码等） OS的关键部分 要求响应速度的代码和数据 页表中的锁定标志位 置换算法的评价 记录进程访问内存的页面轨迹 虚拟地址访问用（页号，位移）表示 评价方法： 模拟页面置换行为，记录产生缺页的次数 更少的缺页，更好的性能 算法分类 局部页面置换算法 分配一个进程的物理页面数是确定的 置换页面的选择范围仅限于当前进程占用的物理页面内 难以实现：最优算法、先进先出算法（性能差）、最近最久未使用算法 常用：时钟算法、最不常用算法 全局页面置换算法 分配一个进程的物理页面数是确定的 局部页面置换算法 分配一个进程的物理页面数是确定的 置换页面的选择范围仅限于当前进程占用的物理页面内 最优算法OPT预测未来 基本思路 置换在未来最长时间不访问的页面 算法实现 缺页时，计算内存中每个逻辑页面的下一次访问时间（假设可以） 选择未来最长时间不访问的页面 特征 缺页最少，最好 实际系统无法实现 无法预知每个页面在下次访问前的等待时间 作为性能评价依据 先进先出算法FIFO思路 选择在内存中驻留时间最长的页面进行置换 实现 维护一个记录所有位于内存中的逻辑页面链表 链表元素按驻留内存的时间排序 出现缺页时，选择链首页面进行置换，新页面加到链尾 特征 实现简单 性能较差 进程分配物理页面数增加时，缺页不一定减少 belady现象 很少单独使用 最近最久未使用算法LRU统计过去，实现复杂度较高 思路 选择最长时间没有被引用的页面进行置换 依据：如某些页面长时间未被访问，则它们在将来还可能会长时间不会访问 实现 缺页时，计算内存中每个逻辑页面的上一次访问时间 选择上一次使用到当前时间最长的页面 特征 最优置换算法的一种近似 非常复杂，不太可能实现 LRU算法的可能实现方法 页面链表 系统维护一个按最近一次访问时间排序的页面链表 链表首节点是最近刚刚使用过的页面 链表尾节点是最久未使用的页面 访问内存时，找到相应的页面，并把它移到链表首 缺页时，置换链表尾部的页面 活动页面栈，相对较优 访问页面时，将页号压入栈顶，并将栈内相同的页号抽出 缺页时，置换栈底的页面（双端栈） 时钟置换算法CLOCK思路： 仅对页面的访问情况作大致统计 数据结构： 在页表项中增加访问位，描述页面在过去一段时间的内访问情况 各页面组织成环形链表 指针指向最先调入的页面，指针在链表上进行周期性循环 算法 访问页面时，在页表项纪录页面访问情况 缺页时，从指针处开始顺序查找未被访问的页面进行置换 在LRU与FIFO折中 实现 页面装入内存时，访问位初始化为0 访问页面时，访问位置1 缺页时，从指针当前位置顺序检查环形链表 访问位为0，置换该页 访问位为1，则重置为0，指针移动到下一个位置直到找到可置换页面 改进的clock算法 思路 减少修改页的缺页处理开销（修改的页面要写回外存，因此存在开销） 算法 在页面中增加修改位，并在访问时进行相应修改 缺页时，修改页面的标志位，以跳过有修改的页面 数据写回外存有一定的延迟 最不常用算法LFU思路 缺页时，置换访问次数最少的页面 实现 每个页面设置一个访问计数 访问页面，访问计数+1 缺页时，置换计数最小的页面 特征 算法开销大 开始时频繁使用，但以后不使用的页面很难置换 解决：计数定期右移 LRU与LFU区别 LRU关注多久没访问 LFU关注次数 belady现象局部置换算法的一个特征 采用FIFO等算法时，可能会出现分配的物理页面增加，缺页次数反而会升高的异常现象 原因 FIFO算法的置换特征与进程访问内存的动态特征矛盾（进程的访问特征不同，排序算法与word编辑进程的访问特征完全不同） 被它置换出去的页面并不一定是进程近期不会访问的 LRU算法无belady现象 LRU、FIFO、Clock的比较 LRU算法与FIFO本质上都是先进先出 LRU依据页面的最近访问时间排序 LRU需要动态调整顺序 LRU算法性能好，但是开销大 FIFO依据页面进入内存的时间排序 FIFO顺序固定不变 LRU开销小，但是belady现象 LRU可退化为FIFO 如果页面进入内存后没有被访问（视频信息等） Clock算法是折中 对于被访问的页面，clock算法不能记录准确访问顺序，而LRU算法可以 全局页面置换算法考虑不同进程对于内存需求量的差异 思路 给进程分配可变数目的物理页面 需要解决的问题 进程在不同阶段的内存需求是变化的 分配给进程的内存也需要在不同阶段有所变化 全局置换算法需要确定分配给进程的物理页面数 CPU利用率与并发进程数的关系 局部性特征的下降！ 工作集置换算法最优算法在全局里的一种体现 工作集：一个进程当前正在使用的逻辑页面集合，表示为二元函数W（t,L） t是当前执行时刻 L为工作集窗口，即一个订场的页面访问时间窗口 W指在当前时刻t前的L时间窗口中的所有访问页面所组成的集合 |W|指工作集的大小，即页面数目 工作集的变化 常驻集 当前时刻，进程实际驻留内存当中的页面集合 工作集与常驻集的关系 工作集是进程在运行过程中固有的性质 常驻集取决于系统分配给进程的物理页面数目和页面置换算法 缺页率与常驻集关系 常驻集包含工作集，缺页较少 工作集发生剧烈变动，缺页较多 进程常驻集大小达到一定数目后，缺页率也不会明显下降 思路 换出不在工作集的页面 窗口大小L，当前时刻前T个内存访问的页引用是工作集 实现方法 访问链表：维护窗口内的访问页面链表 访存时，换出不在工作集的页面，更新访存链表 缺页时，换入页面，更新访存链表 缺页率置换算法PFF缺页率：缺页次数/内存访问次数 或 缺页平均时间间隔的倒数 影响缺页率因素 页面置换算法 分配给进程的物理页面数目 页面大小 编程内容 原理： 通过调节常驻集大小，使每个进程的缺页率保持在一个合理的范围内 若进程缺页率过高，则增加常驻集以分配更多 若缺页率过低，则减小常驻集 实现 访存时，设置引用位标志 缺页时，计算上次缺页时间到现在缺页时间的间隔 如果间隔&gt;T，则置换所有在该间隔中所有没有被引用的页 否则，增加缺失页到常驻集 抖动和负载控制抖动： 进程物理页面太少，不能包含工作集 造成大量缺页，频繁置换 进程运行速度变慢 产生抖动的原因 随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减小，缺页率不断上升 操作系统需要在并发和缺页率到达一个平衡。 负载控制 通过调节并发进程数来进行系统负载控制 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：线程安全-理论]]></title>
    <url>%2F2019%2F03%2F01%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8-%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[线程安全概念 线程安全：当多个线程访问一个对象，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要额外的同步，或者在调用方进行任何其他的协调操作， 调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。 即要求线程安全的代码都必须具备一个特征：代码本身封装了所有必要的正确性保障手段(互斥同步等)，令调用者无须关系多线程的问题，更无须自己采用任何措施来保证多线程的正确调用。但这个并不容易做到。 因此一般将定义弱化一些,即将调用这个对象的行为限定为单次调用，若其他描述成立，则称它线程安全。 在一项工作进行前，会被不停中断与切换，对象的属性可能会在中断期间被修改和变脏。如何保证程序在计算机中准确无误地运行。 概念编写线程安全的代码，本质上就是管理对状态的访问，而且通常都是共享、可变的状态。 一个对象的状态就是它的数据，存储在状态变量中，如静态域、实例域。共享即一个变量可以被多个线程访问。可变即变量的值在其生命周期内都可以改变。真正要做到的线程安全是在不可控制的并发访问当中保护数据。 无论何时，只要有多于一个的线程访问给定的状态变量，而且其中某个线程会写入该变量，此时必须使用同步来协调线程对该变量的访问。 java的锁机制：synchronized(独占锁)，volatile、显示锁和原子变量的使用 修复同步隐患 不跨线程的共享变量 使用状态变量为不可变的 在任何访问状态变量的时候使用同步 原子性当我们在一个无状态对象中增加一个状态时，例如增加一个命中计数器count++来统计所处理的请求数量。 但是在多线程下，这种自增操作可能会丢失一些更新操作，该语句会转换为多个字节码指令，包含3个独立的操作：读取、修改、写入。其结果状态依赖于之前的状态，即这三个操作并不能作为一个原子操作。 而多线程在没有同步的情况下对一个count进行操作，如果初始值为0，则可能会出现每个线程读取得到的指都时0，之后进行递增操作，并将计数器的值设为1，之后写入。在这个过程中丢失了一次更改。 在Web服务中，命中计数器的少量偏差是我们可以接受的， 但是如果我们是在生成唯一的对象标识符，那么将导致严重的问题。 竞态条件 竞态条件：由于不恰当的执行时序而出现不正确的结果，即结果的出现依赖于线程的执行顺序 当某个计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。即正确的结果依赖于运气 常见场景 先检查后执行，即检查-修改。然鹅在检查-修改的中间时间，观察结果可能会失效，从而导致各种问题 延迟初始化，确保只初始化一次。在多线程下可能会初始多次。 竞态条件并不总是产生错误，需要某种不恰当的执行时序。 数据竞争 数据竞争：如果在访问共享的非final类型的域时没有采用同步来进行协同，那么就会出现数据竞争。当一个线程写入一个变量而另一个线程接下来读取这个变量，或者读取一个之前由另一个线程写入的变量时，并且在这两个线程间没有使用同步，就可能会出现数据竞争。 如果代码存在数据竞争，那么这段代码就没有确定的语义 并非所有的竞态条件都是数据竞争，也并非所有的数据竞争都是竞态条件，但二者都可能导致并非程序失败。 复合操作要避免竞态条件，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或之后读取和修改状态，而不是在修改状态的过程中。 原子操作：假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说就是原子的。 原子操作是指，对于访问同一个状态的所有操作(包括操作本身)来说，这个操作是一个以原子方式执行的操作。 加锁机制当在Servlet中添加了一个状态变量，可以通过线程安全的对象来管理Servlet的状态来维护其线程安全性，但是当想在Servlet添加更多的状态，是否只需要增加更多的线程安全状态变量就可以了。 然而尽管两个状态变量都是安全的，但是对两个安全的状态变量进行操作并不一定是安全的，即它们独立的操作都是原子的，而对它们两个的操作是两个原子操作，在两次操作间存在空隙，因此不是一个原子操作，而存在竞态条件。 要保证状态的一致性，就需要在单个原子操作中更新所有相关的状态变量 内置锁Java提供了一种内置的锁机制来支持原子性，即同步代码块synchronized，同步代码块包括两部分：一个作为锁的对象引用，一个作为由这个锁保护的代码块。之所以内置锁只是为了免去显式创建锁对象， 以synchronized修饰的方法是一种横跨整个方法体的同步代码块，锁就是方法调用所在的对象。静态的synchronized以Class对象为锁。 每个Java对象都可以用做一个实现同步的锁，这些锁被称为内置锁或监视器锁(Monitor)。获得内置锁的唯一途径就是进入由整个锁保护的同步代码块或方法。 而内置锁的存在使得线程安全变得简单，但是却过于极端，导致服务的响应性会很低，即一个性能问题。 重入当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞，然而由于内置锁可重入，即当某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。 重入意味着锁的操作粒度是线程，而不是调用。重入的一种实现是为每个锁关联一个获取计数值和一个所有者线程，当计数值为0时，这个锁被认为是没有被任何线程持有，当线程请求一个未被持有的锁时，JVM记录锁的持有者，并将计数器+1。 重入使得子类如果重写了父类的synchronized方法，之后调用父类的方法不会产生死锁。 理解：父类的方法与子类本身的方法都是在子类的方法表当中，即这些方法归属于同一个类，同一个对象，而不是说有两个对象。因此在调用子类的synchronized方法时首先获得了该对象的锁，此时调用父类的方法，如果不是可重入的，则因为该对象的锁已经被获取而发生死锁。 1234567891011public class Widget&#123; public synchronized void do()&#123; &#125; &#125;public class log extends Widget&#123; @Override public synchronized void do()&#123; super.do(); &#125; &#125; 因为两个do都时synchronized的，因此每个方法都会在执行前获取Widget的锁，如果不可重入，则当调用super.do时会阻塞。而重入避免了该情况 用锁来保护状态锁能使其保护的代码路径以串行形式来访问，因此可以通过锁来构造一些协议以实现对共享状态的独占访问，只要始终遵循这些协议就能保持状态的一致性。 访问共享状态的复合操作都必须是原子操作以避免产生竞态条件，如果在复合操作中持有一个锁，则会使得复合操作称为原子操作。仅仅将复合操作封装到一个同步代码块中是不够的，如果使用同步来协调对某个变量的访问，那么在访问这个变量的所有位置上都需要使用同步。 常见的错误是只有在写入共享变量时才需要使用同步。 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，这种情况下我们称状态变量是由这个锁保护的。 每个共享的和可变的变量都应该只有一个锁来保护，从而使维护人员知道是哪一个锁 一种常见的加锁约定是将所有的可变状态都封装在对象内部，帮通过对象的内置锁对所有访问可边状态的代码路径进行同步，使得在该对象上不会发生并发访问。但是这种模式不会得到强制，即如果在添加新的方法时忘记使用了同步，则加锁协议就被破坏了。 对于包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护 活跃性与性能对于Servlet，如果通过Servlet对象的内置锁保护每一个状态变量，即对整个service方法进行同步，这种简单且粗粒度的方法能确保线程安全性，但是代价很高。service如果同步了，则每次只能有应该线程可以执行，背离了Servlet的初衷，即需要能同时处理多个请求，在负载过高的情况下将给用户带来糟糕的体验。 不良并发应用程序：可同时调用的数量，不仅受到可用处理资源的限制，还受到应用程序本身结构的限制。 通过缩小同步代码块的作用范围可以很容易做到既确保Servlet的并发性，同时又维护线程安全性。要确保同步代码块不要过小，并且不要将本应时原子的操作拆分到多个同步代码块中，应尽量将不影响共享状态且执行时间较长的操作从同步代码块中分离出去，从而在这些操作的执行过程中，其他线程可以访问共享状态。 应当在程序中使用一种同步机制，两种不同的同步机制会带来混乱，并且不会在性能或安全性上带来任何好处，例如在synchronized中使用Atomic。 判断同步代码块的合理大小。需要权衡安全性、简单性、性能。 通常，在简单性和性能间存在相互制约因素。当实现某个同步策略时，一定不要盲目地未了性能而牺牲简单性(可能会破坏安全性) 当使用锁时，应当清楚代码块中实现地功能，以及在执行该代码块时是否需要很长时间。如果需要，则都会带来活跃性或性能问题。 当执行时间较长地计算或者可能无法快速完成地操作时，例如网络IO或IO，一定不要持有锁。 总结 编写线程安全的代码，本质上就是管理对状态的访问，而且通常都是共享、可变的状态。 动机：无论何时，只要有多于一个的线程访问给定的状态变量，而且其中某个线程会写入该变量，此时必须使用同步来协调线程对该变量的访问。 要保证状态的一致性，就需要在单个原子操作中更新所有相关的状态变量 并不仅仅是只需要在写入的时候需要同步 每个共享的和可变的变量都应该只由一个锁来保护，从而使维护人员知道是哪一个锁(封装在对象中) 同步将使得性能降低。判断同步代码块地合理大小 当执行时间较长地计算或者可能无法快速完成地操作时，例如网络IO或IO，一定不要持有锁。 加锁的机制不仅仅局限于互斥行为，还包括内存可见性，为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。 实现线程安全实现线程安全有两种方式： 对象的共享。需要自己去设计线程安全的类 对象的组合。通过将对象的线程安全委托给其他类 对象的共享如何共享和发布对象，从而使它们能够安全地由多个线程同时访问。并且实现内存可见性。 内存可见性：希望确保当一个线程修改了对象状态后，其他线程能够看到发生地状态变化。 线程安全级别线程安全限定于多个线程间存在共享数据访问这个前提，如果一段代码根本不会与其他线程共享数据，那么从线程安全的角度看，程序是串行执行还是多线程执行对它没有区别 依照线程安全的安全程度排序来看，Java中各种操作共享的数据分为以下5类： 不可变final对象，不可变的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要采用任何的线程安全保障措施。 只要一个不可变的对象被正确地构建出来(this引用没有逃逸)，那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程中处于不一致的状态。 对于一个数据类型，只需要在定义时使用final即可 对于一个对象，则需要保证对象的行为不会对其状态产生任何影响才行。例如String，subString会返回一个新的字符串，对其本身没有影响。 绝对线程安全指完全满足定义。而即使一个类的所有方法都时被synchronized修饰的，也不意味着调用它永远都不需要同步手段了 1234567891011121314151617181920public static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;();public static void main(String[] args)&#123; while(true)&#123; for(int i=0; i &lt; 10; i++)&#123; vector.add(i); &#125; &#125; Thread removeThread = new Thread(() -&gt; &#123; for(int i = 0; i &lt; vector.size(); i++)&#123; vector.remove(); &#125; &#125;); Thread printThread = new Thread(() -&gt; &#123; for(int i = 0; i &lt; vector.size(); i++)&#123; System.out.println(vector.get(i)); &#125; &#125;); removeThread.start(); printThread.start();&#125; 在上面的示例当中，依然时线程不安全的，当remove刚好删除一个元素，导致序号i已经不可用，此时去访问数组会抛出ArrayIndexOutOfBoundsException 而要改为绝对安全则需要将synchronized(vector) 相对线程安全保证单次调用下，线程是安全的，对于特定顺序的连续调用，则可能需要使用额外的同步手段。Java中的大多数线程安全类都属于该类型 线程兼容对象本身并不是线程安全，但可以在调用端正确使用同步手段来保证对象在并发环境可以安全使用。一般常说类不是线程安全的绝大部分是指该情况。 线程对立无论调用端是否采用了同步措施，都无法在多线程环境并发使用的代码。 例如Thread的suspend()与resume()，如果两个线程同时持有一个线程对象，一个尝试中断线程，另一个尝试恢复线程。当并发进行时，无论调用是否同步，目标线程都存在死锁风险。 内存可见性导致共享变量在线程间不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存间及时更新 因为我认为这块属于JMM方面，因此详情查看Java并发：JMM 发布与逸出发布发布对象：发布一个对象指它能够被当前作用域以外的代码所使用。发布一个对象，同时将发布该对象所有的非私有域引用的对象。 发布对象的场景：例如将应该指向该对象的引用保存到其他代码可以访问的地方，或者在某一个非私有的方法中返回该引用，或者将引用传递到其他类的方法中。 很多情况下，我们确保对象及其内部状态不被发布。而某些情况下，我们又需要发布某个对象，如果在发布时要确保线程安全，则可能需要同步。发布内部状态可能会破坏封装性，并使得程序难以维持不变性条件。不安全发布的示例： 12345678910111213141516171819202122public class UnsafePublish &#123; private String[] states = &#123;"a","b","c"&#125;; /** * 直接获得了私有对象states的引用 * @return */ public String[] getStates()&#123; return states; &#125; public static void main(String[] args)&#123; UnsafePublish unsafePublish = new UnsafePublish(); log.info("&#123;&#125;", Arrays.toString(unsafePublish.getStates())); //发布states对象,无法确定其他线程是否会修改该对象的数据 //因此在使用这个对象的数据的时候,无法完全确定对象里面的数据 //即线程不安全的 unsafePublish.getStates()[0] = "d"; log.info("&#123;&#125;", Arrays.toString(unsafePublish.getStates())); &#125;&#125; 逸出对象逸出：一个对象在尚未准备好的时候就发布，使得它被其他线程可见。 逸出会破坏线程安全性，当应该对象逸出后，你必须假设有某个类或线程可能会误用对象，这正是使用封装的最主要原因。封装能够使得对程序的正确性进行分析变得可能，使得无意中破坏涉及约束条件变得更难。 逸出： this引用在构造期间逸出，即对象在没有通过构造函数构造完毕（执行到了构造函数的某一句）时候逸出。 当对象在构造函数当中创建一个线程，this引用总是被新线程共享 当发布一个内部的类的实例，也会隐式发布了实例本身，因为内部类的实例中包含了对其原类的实例的隐含引用 如果要在构造函数中创建线程 使用工厂方法或者私有构造函数来完成 12345678910111213141516171819public class SafeListener &#123; private final EventListener listener; private SafeListener()&#123; //在这里启动了一个线程,新线程已经可以看到escape类的对象 listener = new EventListener()&#123; public void onEvent(Event e)&#123; do(e); &#125; &#125; &#125; public static SafeListener newInstance(EventSource source) &#123; SafeListener safe = new SafeListener(); source.registerListener(safe.listener); return safe &#125;&#125; 线程封闭访问共享的、可变的数据要求使用同步。一个可以避免同步的方法就是不共享数据。当对象封装在一个线程当中，则自动成为线程安全的。即使被封闭的对象本身不是线程安全的。 线程封闭：如果数据仅仅在单线程当中访问，则不需要任何同步 Java中并没有强制规定某个变量必须由锁来保护，同样在Java语言中也无法强制将对象封闭在某个线程中，Java通过使用局部变量和ThreadLocal实现。 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 示例 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 Swing将事件分发到线程当中 JDBC从池中分配一个对象给线程。 线程封闭方法： Ad-hoc线程封闭：维护线程封闭性完全由程序实现来承担。 程序控制实现，最糟糕。因为没有任何一种语言特性能够将对象封闭到目标线程上。 volatile存在一种特殊的线程访问，确保只通过单一线程写入共享的volatile变量，则操作便是共享 堆栈封闭：局部变量，无并发问题。 是线程限制的特例，只能通过局部变量才可以触及对象。本地变量使得对象更容易被限制在线程本地中，本地变量本身就被限制在执行线程中，它们存在于执行线程栈。其他线程无法访问这个栈 堆栈封闭比Ad-hoc更易于维护，也更健壮。JVM保证了基本类型的局部变量始终封闭在堆栈中。 123456789101112131415161718public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125;public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125;100100 例如下面方法当中的numPairs。在该方法当中，实例化的animals只有一个引用指向它，因此它保存在线程的栈当中，确保了不会破坏栈封闭性。倘若发布了animals或其内部对象的引用，则破坏了限制，并导致了对象逸出。 如果在线程内部上下文使用非线程安全的对象，那么该对象仍然时线程安全的，但是只有开发代码的人员才知道那些对象需要被封闭到执行线程中，以及被封闭的对象是否线程安全，如果没有明确说明，则后续维护很容易使得对象逸出。 123456789101112131415161718public int loadTheArk(Collection&lt;Animal&gt; candidates)&#123; SortedSet&lt;Animal&gt; animals; int numPairs = 0; Animal candidate = null; animals = new TreeSet&lt;Animal&gt;(new SpeciesGenderComparator()); animals.addAll(candidates); for(Animal a : animals)&#123; if(candidate == null || !candidate.isPotentialMate(a))&#123; candidate = a; &#125;else&#123; ark.load(new AnimalPair(candidate, a)); ++numPairs; candidate = null; &#125; &#125; return numPairs;&#125; ThreadLocal：使得线程中的某个值与保存值的对象关联起来。 ThreadLocal线程封闭：特别好的封闭方法。 内部维护了一个map，key是线程名称，值是对象 更规范的方式，允许将每个线程与持有数值的对象关联在一起。ThradLocal提供了get和set，为每个使用它的线程维护一份单独的拷贝，所以get总是返回当前执行线程通过set设置的最新值。 通常用于防止对可变的单实例变量或者全局变量进行共享。 ThreadLocal提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。 总的来说，ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景。可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 应用 当某个频繁执行的操作需要一个临时对象，例如缓冲区，而同时又希望避免在每次执行时都重新分配该临时对象，就可以使用该技术。 如果将单线程的应用程序移植到多线程中，通过将共享的全局变量转换为Th’readLoacl对象(如果全局变量的语义允许)，可以维持线程安全性。 例如JDBC的全局连接不是线程安全的，因此将其保存到ThreadLocal当中，每个线程拥有属于自己的副本。 缺陷 ThreadLocal会降低代码的可重用性，并在类间引入隐含的耦合性。 示例 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 12345678910111213141516171819202122public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125;1 不变性不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 在不可变对象的内部仍可以使用可变对象来管理它们的状态。但这些可变对象对外而言是不可变的。 除非需要更高的可见性，否则应将所有的域都声明为私有域 除非需要某个域是可变的，否则应将其声明为final域 不可变的类型： final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 不可变对象需要满足的条件 对象创建以后状态就不能修改 将类声明为final 对象所有域都是final类型 所有域声明为私有 不设置set方法 将所有可变数据声明为final 对象是正确创建的，this引用没有逸出 通过构造器初始化所有成员 在get方法不直接返回对象本身，而是返回一个clone final关键字：类、方法、变量 final确保初始化过程的安全性，从而可以不受限制地访问不可变对象，并在共享这些对象时无须同步。 修饰类： 不能被继承 所有成员方法会隐式选择为final 修饰方法 锁定方法不能被继承修改 修饰变量 基本数据类型变量 引用类型变量（初始化后，不能指向另一个对象） 其他创建不可变对象方法 对于集合类型，Collections.unmodifiableXXX：Collection、List、Set、Map… 123456789101112131415161718public class ImmutableExample2 &#123; private static Map&lt;Integer,Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1,2); map.put(3,4); map.put(5,6); //创建final的map map = Collections.unmodifiableMap(map); &#125; public static void main(String[] args) &#123; //会抛出异常, map无法被修改 map.put(1,3); log.info("&#123;&#125;",map.get(1)); &#125;&#125; 将返回一个新的map，将数据拷贝过去，然后将所有更改数据转换为了抛出异常 123public static &lt;K,V&gt; Map&lt;K,V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; return new UnmodifiableMap&lt;&gt;(m);&#125; Guava：ImmutableXXX：Collection、List、Set、Map… 1234567891011121314151617public class ImmutableExample3 &#123; private final static ImmutableList&lt;Integer&gt; list = ImmutableList.of(1,2,3); private final static ImmutableSet set = ImmutableSet.copyOf(list); private final static ImmutableMap&lt;Integer,Integer&gt; map = ImmutableMap.of(1,2,3,4); private final static ImmutableMap&lt;Integer,Integer&gt; map2 = ImmutableMap.&lt;Integer,Integer&gt;builder() .put(1,2).put(3,4).put(5,6).build(); public static void main(String[] args) &#123;// set.add(4);// map2.put(1,4); System.out.println(map2.get(3)); &#125;&#125; 安全发布当某些情况下希望在多个线程间共享对象，此时必须确保安全地进行共享。 不正确的发布1234public Holder holderpublic void initHolder()&#123; holder = new Holder(42);&#125; 上述代码会存在可见性问题，其他线程看到地Holder对象将处于不一致地状态，即使在该对象地构造函数中已经正确地构建了不变性条件，这种不正确的发布会使得其他线程看到尚未创建完成的对象。未被正确发布的对象存在两个问题： 除了发布对象的线程外，其他线程可以看到的Holder域是一个失效值，因此将看到一个空引用或之前的旧值 线程看到Holder引用的值是最新的，但Holder状态的值是失效的，即可能线程第一次读取域时得到失效值，再次读取这个域会得到一个更新值。 不可变对象与初始化安全性JMM为不可对象的共享提供了一种特殊的初始化安全性保证。 即使某个对象的引用对其他线程是可见的，也并不意味着对象状态对于使用该对象的线程来说一定是可见的，因此为了确保对象状态能呈现一致性，则必须使用同步。而即使在发布不可变对象的引用时没有使用同步，也仍然可以安全地访问该对象。 任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。 安全发布的常用模式可变对象必须通过安全地方式来发布，意味着在发布和使用该对象的线程时都必须使用同步。要安全地发布一个对象，对象地引用以及对象地状态必须同时对其他线程可见，一个正确构造地对象可以通过以下方式来安全发布 在静态初始化函数中初始化一个对象引用 将对象地引用保存到volatile类型的域或者AtomicReferance对象中 将对象的引用保存保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中。 在线程安全容器内部的同步意味着，在对象放入到例如Vector当中将满足最后一条要求。线程安全库中的容器类提供了以下的安全发布保证 通过将一个键或值放入HashTable等可以安全地将它发布给任何从这些容器中访问它的线程 通过将某个元素放入Vector等，可以将该元素安全地发布到任何从这些容器中访问该元素的线程 通过将某个元素放入BlockingQueue等，可以将元素安全地发布到任何从这些队列中访问该元素地线程。 对于静态发布，静态的初始化器由JVM在类的初始化阶段执行，由于JVM内部存在同步机制，因此通过这种方式初始化的任何对象都可以被安全地发布。 1public static Holder holder = new Holder(42) 事实不可变对象如果对象在发布后不会被修改，那么对于其他在没有额外同步地情况下安全地访问这些对象的线程来说，安全发布是足够的。所有安全发布机制都能保证，当对象的引用对所有访问该对象的线程可见时，对象发布时的状态对于所有线程也将时可见的，并且如果对象的状态不会再改变，则足以确保任何访问都是安全的。 事实不可变对象：如果对象从技术上来看是可变的，但其状态再发布后不会再改变。 可变对象如果对象再构造后可以修改，那么安全发布只能保证发布当时状态的可见性，对于可变对象，不仅在发布对象时需要使用同步，而且在每次对象访问时同样需要使用同步来确保后续修改操作的可见性。 要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是线程安全地或者由某个锁保护起来的。对象的发布需求取决于它的可变性 不可变对象可以通过任意机制来发布 事实不可变对象必须通过安全方式来发布 可变对象必须通过安全方式来发布，并且必须是线程安全的或者由某个锁保护起来。 安全地共享对象当获得对象的一个引用时，需要知道在这个引用上可以执行哪些操作。在使用它之前是否需要获得一个锁，是否可以修改它的状态，或者只能读取它。当发布一个对象时，必须明确地说明对象地访问方式。 发布策略 线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口进行访问而不需要进一步的同步 保护对象。被保护的对象只能通过持有特定的锁来访问，保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。 线程安全策略首先安全发布对象 在静态初始化函数中初始化一个对象引用 将对象地引用保存到volatile类型的域或者AtomicReferance对象中 将对象的引用保存保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中。 并发容器 不可变final 无同步方案对于一些方法本身不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此由一些代码天生就是线程安全的。 可重入代码。 即纯代码。不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。如果一个方法，它的返回结果时可以预测的，即只要输入了相同的数据，就能返回相同的结果。那么就满足可重入的要求。 线程封闭。包括堆栈封闭、ThreadLocal 互斥同步锁等操作 非阻塞同步由于硬件指令集的发展而出现。基于冲突检测的乐观并发策略，先进行操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据有争用，则采用其他补偿措施（例如不断重试，直到成功）。 由于该方法大多实现不需要将线程挂起，即称为非阻塞同步。 测试并设置 Test and Set 获取并增加 Fetch and Increment 交换 Swap 比较并交换 Compare and Swap CAS ABA问题，如果要解决ABA问题可以使用Atomic，但是可能互斥同步更高效一些。 加载链接/条件存储 Load-Linked/Store-Conditional LL/SC 无同步方案对于一些方法本身不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此由一些代码天生就是线程安全的。 即纯代码。不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 如果一个方法，它的返回结果时可以预测的，即只要输入了相同的数据，就能返回相同的结果。那么就满足可重入的要求。 设计线程安全的类在线程安全的程序中，虽然可以将程序的所有状态都保存在公有的静态域中，但与那些将状态封装起来的程序相比，这些程序的线程安全性更难以得到验证，并且在修改时也更难以始终保持其线程安全性。 通过使用封装，可以使得在不对整个程序进行分析的情况下就可以判断一个类是否是线程安全的。 在设计线程安全类的过程中，需要包含以下三个基本要素： 找出构成对象状态的所有变量 从对象的域开始，如果对象中所有的域都是基本类型的变量，那么这些域将构成对象的全部状态。 如果在对象的域中引用了其他对象，那么该对象的状态将包含被引用对象的域 找出约束状态变量的不变性条件 建立对象状态的并发访问管理策略 同步策略定义了如何在不违背对象不变条件或后验条件的情况下对其状态的访问操作进行协同。同步策略规定了如何将不可变性、线程封闭与加锁机制等结合起来以维护线程的安全性，并且还规定了哪些变量由哪些锁来保护。 思想收集同步需求要确保类的安全性，就需要确保它的不变性条件不会在并发访问的情况下被破坏，这就需要对其状态进行推断。 对象与变量都有一个状态空间，即所有可能的取值。状态空间越小，就越容易判断对象的状态。final类型的域使用越多，就越能简化对象可能状态的分析过程。 状态迁移 不可变条件 后验条件 在许多类中定义了一些不可变条件，用于判断状态是有效的还是无效的。即一些对象的一些值不能为负数等限定条件。 在某些操作中还会包含一些后验条件来判断状态迁移是否有效，对于计数器Counter，如果当前状态为17，那么下一个有效状态只能为18。当下一个状态依赖当前状态时，整个操作必须是一个复合操作。而并非所有的操作都会在状态转换上增加限制，例如更新温度这个状态，其之前的值并不影响结果。 后验条件：对状态的值进行检验，如果不符合，则异常 状态迁移：一个对象的下一个状态源于当前状态。如果某些状态是非法的，则必须封装该状态下的状态变量，否则客户代码会将对象置于非法状态。如果一个操作的过程当中出现非法状态，则该操作必须是原子的 如果不了解对象的不变性条件与后验条件，那么就不能确保线程安全性。要满足在状态变量的有效值或状态转换上的各种约束条件，就需要借助于原子性于封装性。 由于不变性条件以及后验条件在状态及状态转换上施加了各种约束，因此就需要额外的同步与封装。 如果某些状态是无效的，那么必须对底层的状态变量进行封装，否则客户代码可能使对象处于无效状态 如果某个操作中存在无效的状态转换，那么该操作必须是原子的。 在类中也可能包含同时约束多个状态变量的不变性条件，而此时在执行任何访问相关变量的操作时，都必须持有保护这些变量的锁。 依赖状态的操作类的不变性条件与后验条件约束了在对象上有哪些状态和状态转换时有效的。在某些对象的方法中含包含一些基于状态的先验条件，例如不能从空队列中删除一个元素。 如果在某个操作中包含有基于状态的先验条件，那么这个操作就称为依赖状态的操作 在单线程中，如果某个操作无法满足先验条件，那么只能失败。但是在并非程序中，先验条件可能会由于其他线程执行的操作而为真，在并发程序中要一直等到先验条件为真，然后再执行操作。 实现某个等待先验条件为真时才执行的操作的简单实现是通过现有的库的类。 状态的所有权如果以某个对象为根节点构造一张对象图，那么该对象的状态将是对象图中所有对象包含的域的一个子集。为什么是一个子集？在凑够对象可以到达的所有域中，需要满足哪些条件才不属于对象状态的一部分。 在定义哪些变量将构成对象的状态时，只考虑对象拥有的数据。所有权在Java中并没有得到充分的体现，而是类设计的一个要素。在许多情况下，所有权与封装性总是相互关联的：对象封装它拥有的状态，反之也成立，即对它封装的状态拥有所有权。 状态变量的所有者将决定采用何种加锁协议来维持变量状态的完整性。所有权意味着控制权，如果发布了某个可变对象的引用，那么就不再拥有独占的控制权，最多是”共享控制权“。 对于从构造函数或者从方法中传递过来的对象，类通常并不拥有这些对象，除非这些方法是被专门设计为转移传递进来的对象的所有权（同步容器封装器的工厂方法）。 容器类通常表现出一种”所有权分离“的形式。容器类拥有其自身的状态，而客户代码则拥有容器中的各个对象的状态。例如SynchronizedList当中，List对象是线程安全的，即当使用get或add时是不需要使用同步的。但是使用保存在List当中的对象时，可能需要使用同步，这些对象由应用程序拥有，而List只是替应用程序保管它们。与所有共享对象一样，它们必须安全地被共享。因此为了线程安全，这些对象应该要么是线程安全的对象，要么是事实不可变的对象，或者是由锁来保护的对象。 实例封闭如果某对象不是线程安全的，那么可以通过多种技术使其在多线程中安全地使用。可以确保该对象只能由单个线程访问，或者通过一个锁来保护对该对象的所有访问。 封装简化了线程安全类的实现过程，它提供了一种实例封闭机制，当一个对象被封装到另一个对象中时，能够访问被封装对象的所有的代码路径都是已知的。因此更易于对代码进行分析，通过将封闭机制与合适的加锁策略结合起来，可以确保以线程安全的方式来使用非线程安全的对象。 将数据封装在对象内部，可以将数据的访问限制在对象的方法上，从而更容易确保线程在访问数据时总能持有正确的 封闭在类的一个实例中，例如作为类的一个私有成员 封闭在某个作用域中，例如作为一个局部变量 封闭在一个线程中，例如通过ThreadLocal 封闭机制更易于构造线程安全的类，因为当封闭类的状态时，在分析类的线程安全性时就无须检查整个程序。 线程安全实现方式（委托）基于对象的组合实现线程安全。 当类中各个组件都已经是线程安全的，那么需要视情况而定是否需要额外增加一个线程安全层。 状态变量单状态当类中只有一个状态变量，则可以将该变量设置为Atomic，即该类的状态就是Atomic的状态，而Atomic是线程安全的，因此类是安全的，即将线程安全委托给了Atomic。 多状态而当存在多个状态变量，只要这些变量是彼此独立的，即组合的类不会在其包含的多个状态变量上增加任何不变性条件。此时依然可以使用Atomic。 发布底层的状态变量 如果一个类是由多个独立且线程安全的状态变量组成，并且在所有的操作中都不包含无效状态转换，那么可以将线程安全性委托给底层的状态变量。 如果一个状态变量是线程安全的，并且没有任何不变性条件约束它的值，在变量的操作上也不存在任何不允许的状态转换，那么就可以安全地发布这个变量 扩展类Java类库中包含很多基础模块类，我们应该进行重用，但是大部分时候现有的类只能支持大部分的操作，此时就需要在不破坏线程安全性的情况下添加应该新的操作。 修改原始类，但通常无法做到 扩展类，扩展方法比直接添加代码到类中更加脆弱，因为同步策略实现被分布到多个单独维护的代码中。 客户端加锁机制将扩展代码放入应该辅助类当中，并且需要确保整个对象使用的是同一个锁，如果在类内部使用了Vector与synchronized，则会有两个锁的存在。 通过添加一个原子操作来扩展类是脆弱的，因为将类的加锁代码分布到了多个类中。然而客户端加锁更脆弱。客户端加锁将类C的加锁代码放入了与C完全无关的其他类中， 组合创建一个新类A，持有一个List的引用，将它们组合起来。A通过将List对象的操作委托给底层的List实例来实现List的操作，同时添加一个原子操作，即使将List传递给客户端，也只能通过类A进行访问。 只要确保了List的唯一外部引用，则可以保证线程安全性。 同步容器类别 ArrayList-&gt;Vector、Stack HashMap-&gt;HashTable Collections.synchronizedXXX(List、Set、Map) collection的静态工厂创建 同步容器也未必线程安全 同步容器虽然保证了同一时刻只有一个线程可以访问，但是线程交替进行访问依然会出现问题 1234567891011121314151617181920Thread thread1 = new Thread() &#123; public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125;&#125;;Thread thread2 = new Thread() &#123; public void run() //在size=10,i=9时刻,上面的线程将其删除,而此时读取则会出现异常 for (int i = 0; i &lt; vector.size(); i++) &#123; vector.get(i); &#125; &#125;&#125;;thread1.start();thread2.start(); Java实现监视器模式遵循Java监视器模式的对象会将堆详细的所有可变状态都封装起来，并由对象自己的内置锁来保护。 123456789101112public final class Counter&#123; private long value=0; public synchronized long getValue()&#123; return value; &#125; public synchronized long increment()&#123; if(value == Long.MAX_VALUE)&#123; throw new IllegalStateException(); &#125; return ++value; &#125;&#125; 即对类内所有的状态变量都需要通过Counter的方法执行，而且这些方法都是同步的。例如Vector等都使用了监视器模式。 Java监视器模式仅仅是一种编写代码的约定，对于任何一种锁现象，只要自始至终都使用该锁对象，都可以用来保护对象的状态。 总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：类文件与类加载]]></title>
    <url>%2F2019%2F03%2F01%2FJava%2Fbase%2FJVM%EF%BC%9A%E7%B1%BB%E6%96%87%E4%BB%B6%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[类文件结构.class文件，类文件，字节码文件。 代码编译的结果从本期机器码转变为字节码，是存储格式发展的一步。 概述计算机只能识别0和1，因此程序需要经编译器翻译成二进制格式。 而随着虚拟机的发展，越来越多程序语言选择了与操作系统和机器指令集无关的、平台中立的格式作为程序编译后的存储格式。即将程序编译成二进制本地机器码已经不是唯一的选择。 无关性的基石 平台无关系 许多虚拟机都可以载入和执行同一种平台无关的字节码，实现“一次编写，到处运行。 各种不同平台的虚拟机与所有平台都统一使用的程序存储格式–字节码，是构成平台无关系的基石。 虚拟机的另一种中立特性，即语言无关性， 其他语言也可以允许在JVM上。Java虚拟机不和任何语言绑定，只与Class文件这种特定的二进制文件格式关联。 Class文件包含JVM指令集和符号表以及若干其他辅助信息。基于安全，要求Class文件使用许多强制性的语法和结构化约束。 Java语言中的各种变量、关键字和运算符号的语义最终都是由多条字节码命令组合而成。字节码所能提供的语言描述能力比Java更强大。 Class类文件结构任何一个Class文件都对应着唯一一个类或接口的定义信息，但是类或接口并不一定都得定义在文件里(譬如类或接口也可以通过类加载器直接生成) Class文件是一组以8字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件中，中间没有添加任何分割符，使得Class文件中存储的内容几乎全部是程序允许的必要数据，没有空隙存在 当遇到需要占用8字节以上空间的数据项时，则按照高位在前的方式分割成若干个8位字节进行存储 高位在前：最高位字节在地址最低位，最低位字节在地址最高处 Class文件格式采用类C语言结构体的伪结构存储数据 两种数据类型：无符号数，表 无符号数：基本的数据类型，描述数字、索引引用、数量值或按UTF8编码的字符串值。u1、u2、u4、u8分别代表1、2、4、8个字节的无符号数 表：由多个无符号数或其他表构成的符合数据结构，习惯性以_info结尾。用于描述具有层次关系的符合结构的数据。整个Class文件本质上是一张表 魔数与Class文件版本 魔数magic：Class文件的头4个字节。用于确定文件是否为一个能够被虚拟机接受的Class文件。 即用于身份识别，例如jpeg等在文件头都有魔数。基于安全考虑，因为扩展名可以随意改动。 5-8字节：Class文件的版本号，5-6字节：minor_version次版本号，7-8字节：major_version主版本号。 JDK能够向下兼容，但也必须拒绝执行超过其版本号的Class文件 常量池跟在主次版本号之后的是常量池入口。 常量池可以理解为Class文件中的资源仓库，是Class文件结构中与其他项目关联最多的数据类型，也是占用空间最大的数据项目之一，同时是Class文件中第一个出现表数据项目。 常量池中的常量的数量是不固定的，因此在入口需要放置一项u2类型的数据，代表常量池容量计数值：constant_pool_count。其计数从1开始，0表达不引用任何一个常量池项目。 常量池主要存放两大类常量： 字面量。文本字符串、声明为Final的常量值。 符号引用。类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。 虚拟机加载Class文件会进行动态连接，并不会像C一样有连接步骤，即Class文件不会保存各个方法、字段的内存最终布局信息。因此需要通过运行期转换才能得到真正的内存入口地址。当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析，翻译到具体的内存地址之中。 常量池中的每个常量都是一个表，在JDK7中具有14中，其共同特点是表开始的第一位是一个u1类型标志位，戴白哦该常量属于那种常量类型。 其中CONSTANT_Class_info类型代表一个类或接口的符号引用。 name_index是一个索引值，指向一个CONSTANT_Utf8_info类型常量，代表了这个类或接口的全限定名。 若值为0x0002即指向常量池中的第二项常量 类型 名称 数量 u1 tag 1 u2 name_index 1 CONSTANT_Utf8_info结构如下： length说明该UTF-8编码的字符串长度 bytes字节的连续数据是一个UTF-8缩略编码表示的字符串。 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length 其它常量当利用javap进行分析常量池时，其中会出现一些其它的常量，例如I、V、&lt;init&gt;、LineNumberTable等，它们会被字段表、方法表、属性表引用到。用于描述一些不方便用固定字节表达的内容，例如方法的返回值是说明，有几个参数，每个参数的类型是说明等。 常量表常量项的结构总表 访问地址位于常量池之后，紧接的两个字节代表访问标志access_flags，标志用于标识一些类或者接口层次的访问信息。如该Class是类还是接口，是否为public等。如果是类，是否为final。 类索引、父类索引与接口索引集合类索引this_class、父类索引super_class：一个u2类型的数据。接口索引的集合interfaces：一组u2类型的数据。Class文件用于确定类的继承关系。 字段表集合field_info用于描述接口或者类中声明的变量。字段包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。 access_flags描述字段的访问级别。 name_index是对常量池的引用，描述字段的简单名称。 descriptor_index描述字段和方法的描述符，描述符的作用是描述字段的数据类型、方法的参数列表(数量、类型、顺序)和返回值。 方法表集合与字段表几乎一致，方法表的结构如下： access_flags描述作用域、静态or非静态、可变性、是否同步、是否本地方法、是否抽象。 descriptor_index是方法描述，例如参数、返回值。 name_index是方法名称。 attributes是方法内机器指令、异常信息、是否声明为deprecated。是属性表。 其access_flags的值： 方法内部的代码经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为Code属性中。 TODO属性表集合Class文件、字段表、方法表都可以携带自己的属性表集合，用于描述某些场景专有的信息。 属性表集合不再要求各个属性表具有严格的顺序，并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表写入自己定义的属性信息，JVM运行时会忽略其不认识的属性。 Code属性Java程序方法体中的代码经过java编译后，最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合中，但并非所有的方法表都必须存在这个属性。例如接口与抽象类是不存在的。Code属性表的结构： attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，其值固定为”Code“代表了该属性的名称。 max_stack代表了操作数栈深度的最大值，方法执行的任意时刻都不会超过该深度，虚拟机运行时要根据这个值来分配栈帧中操作栈深度。 max_locals代表了局部变量表所需的存储空间。单位为Slot，对于char、int等32位数据类型，其占据1个Slot，而对于Double等64位占据两个。 方法参数、显式异常处理器中的参数、方法体当中定义的局部变量。 Slot可以重用，当代码执行超过一个局部变量的作用域时，这个局部变量表中的Slot可以被其他局部变量使用。 code_length(要求长度不超过u2，否则拒绝编译)和code存储Java程序编译后生成的字节码指令。每个字节码指令是一个u1类型的单字节。（u1取值0x00-0xFF，即一共256条指令）。 当虚拟机读取到code当中的一个字节码，就可以对应找出这个字节码代表什么指令，并且可以知道这条指令后是否需要跟随参数，以及参数如何理解。 exception_table是异常处理跳转信息。 attributes包含Java源码行号与机器码的对应关系，以及局部变量表描述信息。 LineNumberTable。因此抛出异常时可以知道是在代码中的哪一行等。 LocalVaribale。会记录栈帧局部变量表和Java源码中定义的变量中的关系，不是运行时必须的属性。与IDE的代码提示有关。 实例 123456public class TestClass&#123; private int m; public int inc()&#123; return m + 1; &#125;&#125; 考虑TestClass.class的init方法的Code属性。 虚拟机顺序读取后面的5个字节，并根据字节码指令表翻译出对应的字节码指令： 2A。即aload_0，将第0个Slot中位reference类型的本地变量推送到操作数栈顶。 B7。即invokespecial，以栈顶的reference类型的数据所指向的对象作为方法接收者，调用此对象的实例构造器方法、private或父类方法。 之后跟随一个u2类型的参数说明具体调用哪一个方法，指向常量池中的一个CONSTANT_Mehodref_info类型的变量，即该方法的方法符号引用。 000A。是invokespecial的参数，查询常量池得对应一个实例构造器init方法的符号引用。 B1。即return，返回此方法，并且返回值为void。方法结束。 考虑inc()的方法调用 1234567891011121314151617181920&#123; Code: Stack = 1, Locals = 1, Args_Size = 1 0: aload_0 1: invokespecial #10 4: return LineNumberTable: line 3: 0 public int inc(); Code: Stack = 2, Locals = 1, Args_Size = 1 0: aload_0 1: getfield #10 4: return 5: iadd 6: ireturn LineNumberTable: line 8: 0&#125; 虽然类中的两个方法都没有参数，但是Args_Size=1是因为Java编译时将this转换成一个普通的方法参数，在调用实例方法时将该参数传入。 TODO：方法的显式异常处理表 公有设计与私有实现虚拟机类加载机制如何将字节码文件加载到虚拟机当中 java.lang.ClassNotFoundExcetpion类加载异常 某个Java包的子包是由类加载器定义的。Java或者它的子包中的类和接口都是由启动类加载器加载的。 概述虚拟机如何加载Class文件？Class文件中的信息进入虚拟机后会发生什么变化？ 类加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 Java里，类型的加载、连接和初始化过程都是在程序运行期间完成的，虽然使得类加载时稍增加一些性能开销，但是为应用提供高度灵活性。这实现了Java可以动态扩展的语言特性，其天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。 编写一个面向接口的应用程序，可以等到运行时再指定实际的实现类。 用户可以通过Java预定义的和自定义的类加载器，让一个本地应用程序可以在运行时从网络或其他地方加载一个二进制流作为程序代码的一部分。 这里的Class文件：一串二进制字节流 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存为止，整个生命周期： 加载、验证、准备、解析、初始化、使用、卸载 加载、验证、准备、初始化、卸载的顺序是确定的，依次顺序开始（只是开始，不是进行或者完成，他们中间混合交叉进行）。而解析阶段不一定，它在某些情况下可以在初始化之后再开始，以支持动态绑定 立即对类进行初始化的情况 有且只有：这5种场景中的行为称为对一个类进行主动引用，除此外，所有引用类的方式都不会触发初始化，称为被动引用。 遇到new、getstatic、putstatic、invokestatic的字节码指令，如果类没有初始化，则需要先触发其初始化 遇到java.lang.reflect包的方法对类进行反射调用时 当初始化一个类，如果其父类还没有进行初始化，则先父类初始化（如果是接口，则不要求父类接口全部完成初始化，只有真正使用到父类接口时才会初始化） 当虚拟机启动时，用户需要指定一个主类，先初始化主类 当使用JDK7的动态语言支持时，例如一个Java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化则要先进行初始化 类加载的过程加载 通过一个类的全限定名来获取定义此类的二进制字节流 读取途径 从ZIP包读取，成为日后JAR格式的基础 从网络中获取，如applet 运行时计算生成，动态代理技术，java.lang.reflect.Proxy，为特定接口生成形式为*$Proxy的代理类的二进制字节流 由其他文件生成，如JSP，由JSP文件生成Class类 从数据库中读取等 开发人员可控性最强（非数组类） 可以使用系统提供的引导类加载器完成，也可以由用户自定义的类加载器完成，重写一个loadClass()方法 数组类：由JVM直接创建，不由类加载器创建。但是内部的元素由类加载器创建。一个数组类C的创建过程： 如果数组的组件（即数组去掉一个维度的类型）是引用类型，则递归加载这个组件类型，数组C将在加载该组件类型的类加载器的类名空间上被标识 如果不是引用类型，Java虚拟机将在数组C标记为与引导类加载器关联 数组类的可见性与它的组件类型可见性一致，如果组件类型不是引用类型，那么数组类的可见性默认为public 加载结束后，虚拟机外部的二进制字节流就按照虚拟机要求的格式存储在方法区中。之后将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存（堆）中生成一个代表这个类的Java.lang.Class对象，作为方法区这个类的各种数据的访问入口 验证连接阶段的第一步，为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全。严重阶段的工作量在虚拟机的类加载子系统中占了相当大的一部分。 文件格式验证 验证字节流是否符合Class文件格式的规范，并能够被当前JVM处理 是否以魔数开头 主次版本号是否在当前虚拟机处理范围内 常量池的常量是否有不被支持的常量类型 指向常量的各种索引值是否有指向不存在的常量或不符合类型的常量 文件中各个部分已经文件本身是否有被删除或附加的其他信息。等等 只有该阶段直接操作字节流，并且只有通过文件格式验证后，字节流才会进入内存的方法区。其他三个验证阶段都是基于方法区的存储结构进行的。 元数据验证 对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范 这个类是否有父类 这个类的父类是否继承了不允许被继承的类 如果这个类不是抽象类，是否实现了父类或接口中要求的所有方法 类中的字段、方法是否与父类矛盾 字节码验证 目的是通过数据流和控制流分析，确定程序语义是合法的，符合逻辑的。 对类的方法体进行校验分析，保证方法在运行时不会做出危害虚拟机安全的事件 保证方法体中的类型转换时有效，不会出现对象赋值给与它无关的数据类型 保证跳转指令不会跳转到方法体以外的字节码指令上 符号引用验证 发生在虚拟机将符号引用转化为直接引用的时候，这个转化在解析阶段发生 对类自身以外的信息进行匹配性校验。 通过字符串描述的限定名是否能找到对应的类 符号引用中的类、字段、方法的访问性是否可以被当前类访问 确保解析动作能够正常执行 准备正式为类变量（static的）分配内存并设置类遍历初始值（0值）的阶段，这些变量使用的内存都将在方法区中进行分配。而实例变量将在对象实例化时随着对象一起分配在Java堆中。 如果类变量是final的，则初始化的时候即被赋值为final的那个值，如果不是的话，则会在初始化的时候进行静态赋值，即准备阶段后值依然为0。 解析解析是根据运行时常量池里的符号引用来动态决定具体值的过程。 符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。以字面量形式定义在Class文件中。 直接引用：直接指向目标的指针、相对偏移量或一个能够间接定位到目标的句柄。是与虚拟机实现的内存布局相关的。 符号引用可能不存在于内存当中，但直接引用一定存在内存中。 对于同一个符号引用进行多次解析是常见的，除invokedynamic指令外，虚拟机实现对第一次解析的结果进行缓存（缓存：在运行时常量池中记录直接引用，并将常量标识为已解析状态），从而避免解析重复进行。 虚拟机需要保证在同一个实体中，如果一个符号引用之前已经被成功解析过，那么后续的引用解析请求就应当一直成功。如果第一次失败了，那么其他指令对这个符号的解析请求也应该收到同样的异常 invokedynamic指令用于动态语言支持，只有当实际运行到该节点，才开始解析。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号 类或接口解析 假设当前代码所处的类为D，要将一个从未解析过的符号引用N解析为一个类或接口C的直接引用 如果C不是一个数组类型， 虚拟机会把代表N的全限定名传递给D的类加载器去加载这个类C，加载过程中，会涉及验证等一系列相关类加载动作，如果加载过程中出现了任何异常则解析过程就宣告失败 如果C是一个数组类型， 并且数组的元素类型为对象，则会按照之前的方式夹杂数组元素类型。如果是Integer则会由虚拟机生成一个代表此数组维度和元素的数组对象 如果上面步骤没有任何异常，则C在虚拟机中已经成为一个有效的类或接口了，但在解析完成前还要进行符号引用验证，确认D是否具备对C的访问权限。若不具备则抛出Java.lang.IllegalAccessError 字段解析如果要解析从了类D指向类或接口C中某个字段的未解析符号引用，那么必须先解析指向该字段引用所提到的那个C符号引用。 因此在解析类后接口引用时发生的任何异常都可以当做解析字段引用的异常而抛出，如果指向C的引用能够成功解析，那么可以抛出解析字段引用本身时发生的异常。 当解析字段引用时，字段解析过程会先尝试在C和它的父类中查找这个字段： 如果C中声明的某个字段，与字段引用具有相同的名称以及描述符，则此次查找成功，字段查找的结果就是C中声明的那个字段。 否则字段查找就会递归地应用到类或接口C地直接父接口上。 否则如果C有一个父类S，那么字段查找就会递归到S上，否则就失败。即抛出NoSuchFieldError。 确认访问权限是否可见，否则抛出IllgalAccessError。 普通方法解析为了解析D中对类或接口C中地某个方法的未解析符号引用，该方法引用所提到的对C的符号引用，就应当首先被解析。当解析一个方法引用时。 如果C是接口，那么方法解析抛出IncompatibleClassChangeError 否则方法引用解析过程会检查C和它的父类中是否包含此方法。 如果查找失败会抛出NoSuchMethodError，如果权限不可见抛出IllgalAccessError。 接口方法解析 同普通方法解析 方法类型与方法句柄解析 调用点限定符解析访问控制一个类或接口C对另外一个类或接口D是可见的，当且仅当以下条件之一成立： C是public的 C和D处于同一个运行时包下面， 一个字段或方法R对另外一个类或接口D是可见的，当且仅当以下条件之一成立： R是public的 R在C中protected，D要么与C相同，要么就是C的子类。如果R不是static的，那么指向R的符号引用就必须包含一个指向T类的符号引用，T要么与D相同，要么就是D的子类或父类 R要么是protected，要么具有默认访问权限，并且声明它的那个类与D处于同一运行时包下 R是private的，并且声明在D类中 初始化 初始化真正开始执行类中定义的Java程序代码。执行类构造器&lt;client&gt;()方法的过程 &lt;client&gt;方法由编译器收集类中所有类变量的赋值动作与静态语句块的语句合并而成，顺序由出现顺序而定。 &lt;client&gt;方法与类构造函数不同，不需要显式调用父类构造器，虚拟机保证在此前，父类的&lt;client&gt;方法已经执行完毕 虚拟机会保证一个类的&lt;client&gt;方法会在多线程环境正确被加锁、同步。多个线程同时初始化一个类，只有一个线程去执行该方法，其他线程阻塞 类加载器将类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”的动作放到虚拟机外部实现，以便让程序自己决定如何获取所需要的类。实现该动作的代码模块为类加载器。 类加载器（class loader）用来加载Java类到Java虚拟机中。一般来说，Java虚拟机使用Java类的方式如下：Java源程序（.java 文件）在经过Java编译器编译之后就被转换成Java字节代码（.class文件）。类加载器负责读取Java字节代码，并转换成java.lang.Class类的一个实例。每个这样的实例用来表示一个Java类。通过此实例的newInstance()方法就可以创建出该类的一个对象。实际的情况可能更加复杂，比如Java字节代码可能是通过工具动态生成的，也可能是通过网络下载的。 概述类与类加载器 基本职责：根据一个指定的类的名称，找到或者生成其对应的字节代码，然后从这些字节代码中定义出一个 Java 类，即java.lang.Class类的一个实例。还负责加载Java应用所需的资源。 对于任意一个类，都需要由加载它的类加载器与这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器都有一个独立的类名称空间。 判断两个类是否相等，只有两个类是由同一个类加载器加载的前提下才有意义。 相等：equals等方法返回的结果，如果没有考虑类加载器的影响，某些情况下可能或产生具有迷惑性的结果。 对于同一个Class，我们使用系统应用程序类加载器与自定义类加载器加载，instanceof会返回false。它们是一个类文件，但是是两个独立的类。 双亲委派模型从Java虚拟机角度讲，只存在两种不同的类加载器 启动类加载器，使用C++实现，是虚拟机自身一部分 所有其他的类加载器，Java实现，独立于虚拟机外部，并全部继承自抽象类java.lang.ClassLoader 从程序员角度讲 启动类加载器。负责将类库(\lib下的jar包)加载到虚拟机内存当中，该加载器无法被Java程序直接引用。用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可 扩展类加载器。负责加载&lt;JAVA_HOME&gt;\lib\ext目录，或者java.ext.dirs系统变量指定的路径中所有类库，开发者可以直接使用扩展类加载器 应用程序（系统）类加载器。负责加载用户类路径上指定的路径，可以直接使用这个类加载器，并且是程序中的默认加载器 要求除了顶层的启动类加载器，其余的类加载器都应当有自己的父类加载器。父子关系一般不会以继承关系实现，而都是以组合关系来复用代码。 工作过程： 如果一个类加载器收到了类加载的请求，首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此既 所有的加载请求都会传送到顶层的启动类加载器，只有父类无法完成这个加载请求，子加载器才会尝试自己去加载 优势： Java类随着它的类加载器一起具备了一种带有优先级的层次关系。如Object类，任何一个类加载器加载这个类，都委派给了启动类加载器，因此他们都是同一个类。而如果让各个类去自行加载，那么系统会出现多个不同的object类。 其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。 实现： 先检查是否已经被加载过 如果没有，则调用父类的loadClass 若父加载器为空，则默认使用启动类加载器作为父加载器 如果父加载失败，抛出异常，则调用子类的findClass方法加载 破坏双亲委派模型模型缺陷 双亲委派模型是为了解决各个类加载器的基础类的统一问题，基础类之所以基础是因为它们总是作为被用户代码调用的API，但是如果基础类又要调回用户的代码该如何解决 例如JNDI服务，它的代码由启动类加载器加载，但JNDI的目的是对资源进行集中管理和查找，因此需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者(SPI)的代码，但是启动类加载器不可能认识这些。 解决：引入了线程上下文类加载器，可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置，如果创建线程时还未设置，则会从父线程中继承一个，如果应用程序全局没有设置，则该加载器默认就是应用程序类加载器 JNDI使用线程上下文类加载器加载需要的SPI代码，即类加载器请求子类加载器去完成类加载行为。例如JDBC等都是这样实现的。 用户对程序动态性的追求而导致 例如代码热替换、模块热部署即类似计算机一样可以更新外设。 OSGI模块化热部署的关键是在它自定义的类加载器机制的实现，每一个程序模块(Bundle)都有一个自己的类加载器，当需要更换一个Bundle时就将Bundle连同类加载器一起换掉以实现代码的热替换。 在OSGI中类加载器不再是树状结构，而是发展为网状结构，当收到类加载请求时 将以java.*开头的类委派给父类加载器加载 否则将委派列表名单内的类委派给父类加载器加载 否则将Import列表内的类委派给Export这个类的Bundle的类加载器加载 否则查找当前Bundle的ClassPath，使用自己的类加载器加载 否则查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载 否则查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载 否则类查找失败 网络类加载器下面将通过一个网络类加载器来说明如何通过类加载器来实现组件的动态更新。即基本的场景是：Java 字节代码（.class）文件存放在服务器上，客户端通过网络的方式获取字节代码并执行。当有版本更新的时候，只需要替换掉服务器上保存的文件即可。通过类加载器可以比较简单的实现这种需求。 类 NetworkClassLoader负责通过网络下载 Java 类字节代码并定义出 Java 类。它的实现与 FileSystemClassLoader类似。在通过 NetworkClassLoader加载了某个版本的类之后，一般有两种做法来使用它。第一种做法是使用 Java 反射 API。另外一种做法是使用接口。需要注意的是，并不能直接在客户端代码中引用从服务器上下载的类，因为客户端代码的类加载器找不到这些类。使用 Java 反射 API 可以直接调用 Java 类的方法。而使用接口的做法则是把接口的类放在客户端中，从服务器上加载实现此接口的不同版本的类。在客户端通过相同的接口来使用这些实现类。网络类加载器的具体代码见 下载。 在介绍完如何开发自己的类加载器之后，下面说明类加载器和 Web 容器的关系。 自定义类加载器双亲委派模型首先看一下双亲委派模型的工作过程源码 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // 1. 检查是否已经加载过。 Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //2 .如果没有加载过，先调用父类加载器去加载 c = parent.loadClass(name, false); &#125; else &#123; // 2.1 如果没有加载过，且没有父类加载器，就用BootstrapClassLoader去加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; //3. 如果父类加载器没有加载到，调用findClass去加载 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。 如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用parent.loadClass(name, false);）.或者是调用bootstrap类加载器来加载。 如果父加载器及bootstrap类加载器都没有找到指定的类，那么调用当前类加载器的findClass方法来完成类加载。默认的findclass毛都不干，直接抛出ClassNotFound异常，所以我们自定义类加载器就要覆盖这个方法了。 可以猜测:ApplicationClassLoader的findClass是去classpath下去加载，ExtentionClassLoader是去java_home/lib/ext目录下去加载。实际上就是findClass方法不一样罢了。 自定义即继承ClassLoader覆盖findClass()方法 1234567891011121314151617181920212223242526272829303132333435import java.io.InputStream;public class MyClassLoader extends ClassLoader&#123; public MyClassLoader() &#123; &#125; public MyClassLoader(ClassLoader parent) &#123; //一定要设置父ClassLoader不是ApplicationClassLoader,否则不会执行findclass super(parent); &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; //1. 覆盖findClass，来找到.class文件，并且返回Class对象 try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; //2. 如果没找到，return null return null; &#125; byte[] b = new byte[is.available()]; is.read(b); //3. 将字节数组转换成了Class对象 return defineClass(name, b, 0, b.length); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 效果示范 123456 MyClassLoader mcl = new MyClassLoader();//父类为Application ClassLoader// MyClassLoader mcl = new MyClassLoader(ClassLoader.getSystemClassLoader().getParent());//父类为扩展类加载器 Class&lt;?&gt; c1 = Class.forName("Student", true, mcl); Object obj = c1.newInstance(); System.out.println(obj.getClass().getClassLoader()); System.out.println(obj instanceof Student); 实战自定义类加载器一次实际的编写自定义类加载器的经验。背景如下（来自于：我又不是架构师）: 我们在项目里使用了某开源通讯框架，但由于更改了源码，做了一些定制化更改，假设更改源码前为版本A，更改源码后为版本B，由于项目中部分代码需要使用版本A，部分代码需要使用版本B。版本A和版本B中所有包名和类名都是一样。那么问题来了，如果只依赖ApplicationClassLoader加载，它只会加载一个离ClassPath最近的一个版本。剩下一个加载时根据双亲委托模型，就直接返回已经加载那个版本了。所以在这里就需要自定义一个类加载器。大致思路如下图： 这里需要注意的是，在自定义类加载器时一定要把父类加载器设置为ExtentionClassLoader，如果不设置，根据双亲委托模型，默认父类加载器为ApplicationClassLoader，调用它的loadClass时，会判定为已经加载(版本A和版本B包名类名一样)，会直接返回已经加载的版本A，而不是调用子类的findClass.就不会调用我们自定义类加载器的findClass去远程加载版本B了。 顺便提一下，作者这里的实现方案其实是为了遵循双亲委托模型，如果作者不遵循双亲委托模型的话，直接自定义一个类加载器，覆盖掉loadClass方法，不让它先去父类检验，而改为直接调用findClass方法去加载版本B，也是可以的.大家一定要灵活的写代码。 类加载器实现Jar包隔离将服务框架自身用的类与应用用到的类都控制在User-Defined Class Loader级别，实现Jar包间的相互隔离。 参考 JVM系列之类加载流程-自定义类加载器]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：调优]]></title>
    <url>%2F2019%2F03%2F01%2FJava%2Fbase%2FJVM%EF%BC%9A%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[常用JVM参数GC日志Java的内存管理机制弱化了我们当程序出现内存溢出时定位问题和解决问题的能力。 当GC沦落为影响程序运行的性能瓶颈时，例如因为STW导致程序出现长时间暂停、GC频繁执行内存回收导致程序吞吐量下降等情况。我们必须通过分析这些GC日志来做出相应的调整和处理。即分析GC日志是故障排查和JVM性能调优的前提和基础。 理解GC日志每一种收集器的日志形式都是由它们自身的实现所决定的，即每个收集器的日志格式都可以不一样。但JVM设计时将各个收集器的日志都维持一定的共性。 12333.125: [GC [DefNew: 3324K-&gt;152K(3712K), 0.0025925 secs] 3324K-&gt;152K[11904K], 0.0031680sec]100.667: [Full GC [Tenured: 0K-&gt;210K(10240K), 0.0149142 secs] 4603K-&gt;210K(19456K), [Perm : 2999K-&gt;2999K(21248K)],0.0150007 secs] [Times:user=0.01 sys=0.00, real=0.02 secs] GC发生时间：33.125、100.667表示GC发生的时间，数字含义时从JVM启动以来经过的秒数 停顿类型：GC日志开头的GC、FullGC说明了此次垃圾收集的停顿类型。而不是新生代或老年代，即使时新生代也可能因为担保失败而导致Full GC GC区域：DefNew、Tenured、Perm表示GC发生的区域，与收集器密切相关 GC内存容量变化：方括号内部的3324K-&gt;152K(3712K)，GC前该内存区域已使用容量-&gt;GC后该内存区域已使用容量（该内存区域总容量） GC堆容量变化：方括号外部的3324K-&gt;152K(11904K)表示GC前Java堆已使用容量-&gt;GC后Java堆已使用容量(Java堆总容量) GC执行时间：0.0025925 secs表示该内存区域GC所占用时间。有些收集器给出更详细时间，Times: user=0.01 sys=0.00 real=0.02即分别代表用户态消耗的CPU时间、内核态消耗的CPU时间和操作从开始到结束所经过的墙钟时间（包括各种非运算的等待耗时，例如IO、线程阻塞等）。 CMS收集器 CMS的GC日志划分为初始标记、并发标记、再次标记、并发清除这4个主要阶段。 首先CMS会以一个初始标记阶段开始，这个阶段会导致STW，可以通过选项-XX:+PrintGCApplicationStoppedTime进行设置。耗时0.0001474s 之后并发标记，耗时0.005s 之后并发清除STW，耗时0.0003017s 最后进行并发清除。释放掉无用对象占用的可见。0.000/0.000代表并发清除耗时CPU的时间和墙上时间。如果排除并发预处理与并发重置，当执行完这4个主要阶段，CMS任务就完成了。 虚拟机性能监控与故障处理工具给一个系统定位问题时，知识、经验是关键基础，数据是一句，工具是运用只是处理数据的手段。数据包括：运行日志、异常堆栈、GC日志、线程快照(threaddump、javacore文件)、堆存储快照(heapdump、hprof文件)等。 JDK的命令行工具Sun JDK监控和故障处理工具 jps：JVM Proces Status Tool，显示指定系统内所有的HotSpot虚拟机进程 jstat：JVM Statistics Monitoring Tool，用于收集HotSpot虚拟机各方面的运行数据 jinfo：Configuration Info for Java jmap：Memory Map for Java，显示虚拟机配置信息 jhat：JVM Heap Dump Browser，生成虚拟机的内存转储快照(heapdump文件) jstack：Stack Trace for Java，显示虚拟机的线程快照。 JDK的很多小工具命名参考了UNIX命令的命名，例如jps，类似与ps jps 虚拟机进程状况工具jps可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（main函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier，LVMID） LVMID与操作系统的进程ID是一致的，使用ps命令也可以查询到虚拟机进程的LVMID，但是如果同时启动了多个虚拟机进程，无法根据进程名称定位时，只能依赖jps显示主类的功能才能区分了。 jps通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。jps的其他常用选项如下： -q。只输出LVMID，省略主类的名称 -m。输出虚拟机进程启动时传递给主类main()函数的参数 -l。输出主类的全名，如果进程执行的时Jar包，输出Jar路径 -v。输出虚拟机进程启动时JVM参数 jstat 虚拟机统计信息监视工具用于监视虚拟机各种运行状态信息的命令行工具，可以显示本地或远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 在只提供纯文本控制台环境的服务器上，是运行期定位虚拟机性能问题的首选工具 命令格式：jstat [option vmid [interval [s|ms] [count]] ] option。是一个选项代表用户希望查询的虚拟机信息，主要分为三类：类装载、垃圾收集、运行期编译状况。 -class。监视类装载、卸载数量、总空间以及类装载所耗费的时间 -gc。监视Java堆状况，包括Eden区、两个Survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息 -gccapacity。监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gcutil。监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause。与-gcutil相同，但额外输出上一次GC产生的原因 -gcnew。监视新生代GC状况 -gcnewcapacity。监视内容与gcnew一致，输出主要关注使用到的最大、最小空间 -gcold。监视老年代GC状况 -gcoldcapacity。监视内容与gcold一致，输出主要关注使用到的最大、最小空间 -gcpermcapacity。输出永久代使用到的最大、最小空间 -compiler。输出JIT编译器编译过的方法、耗时等信息 -printcompilation。输出已经被JIT编译的方法 等等 vmid：对于本地虚拟机进程，则vmid与LVMID是一致的，如果是远程虚拟机进程，则格式应为：[protocol:][//]lvmid[@hostname[:port]/servername] interval和count。代表查询间隔和次数。如果省略这两个参数，则说明只查询一次。 示例：每250ms查询一次进程2764垃圾收集状况，一共查询20此，则命令为：jstat -gc 2764 250 20 jinfo java配置信息工具jinfo的作用是实时查看和调整虚拟机各项参数。 命令格式：jinfo [option] pid option选项 -sysprops。将虚拟机进程的System.getProperties内容打印出来。 -flag 。 -flag [name]查询未被显式指定的参数的系统默认值。或使用Java -XX:PrintFlagsFinal。而jps -v只可以查看虚拟机启动时显式指定的参数列表。 可以在运行期修改参数，-flag [+|-] name或-flag name = value修改一部分运行期可写的虚拟机参数值 jmap Java内存映像工具 用于生成堆存储快照，一般称为heapdump或dump文件。 可以查询finalize执行队列、Java堆和永久代的详细信息，例如空间使用率，当前使用的收集器等。 对于dump文件，也可以采用-XX:+HeapDumpOnOutOfMemoryError参数，让虚拟机在OOM异常出血后自动生成dump文件。-XX:+HeapDumpOnCtrlBreak参数则可以使用Ctrl+Break键让虚拟机生成dump文件。 命令格式：jmap [option] vmid option选项 -dump。格式为-dump:[live,]format=b, file=&lt;filename&gt;其中live子参数说明是否只dump出存活的对象 -finalizerinfo。显示在F-Queue中等待Finalizer线程执行finalize方法的对象 -heap。显示Java堆详细信息，如使用哪种回收器、参数配置、粉黛状况等 -histo。显示堆中对象统计信息，包括类、实例数量、合计容量 -permstat。以ClassLoader为统计口径显示永久代内存状态 -F。当虚拟机进程对-dump无响应时，强制生成dump快照 jhat 虚拟机堆转存储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。 一般不会在部署应用程序的服务器上直接分析dump文件，即使可以也会尽量将dump文件复制到其他机器上分析，英文分析工作耗时且耗费硬件资源，而在其他机器上就不需要受到命令行限制 jhat的分析功能相对简陋 jstack Java堆栈跟踪工具用于生成虚拟机当前时刻的线程快照，一般为threaddump或者Javacore文件。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。 线程快照的主要目的时定位线程出现长时间停顿的原因，如线程间思索、死锁循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿时就可以通过jstack查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情或者在等待什么资源。 命令格式jstack [option] vmid -F。当正常输出的请求不被响应时，强制输出线程堆栈 -l。除堆栈外，显示关于锁的附加信息 -m。如果调用到本地方法的话，可以显示C/C++的堆栈 hsdis jit生成代码反汇编在Java虚拟机规范中，详细描述了虚拟机指令集中每条指令的执行过程、执行前后对操作数栈、局部变量表的影响等细节，这些细节与早期的JVM高度吻合。 但是随着虚拟机的发展导致真正的细节实现方式已经渐渐与虚拟机规范描述的内容产生了越来越大的差距，其逐渐成为了概念模型，即实现只能保证规范描述等效。 基于以上原因，我们分析程序的执行语义问题(虚拟机做了什么)时，在字节码上分析完全可行，但分析程序的执行行为问题(虚拟机是怎样做的、性能如何)时，字节码层面分析就没有什么意义，需要通过其他方式解决。 HSDIS将HotSpot的-XX:+PrintAssembly指令调用它来把动态生成的本地代码还原成为汇编代码输出，并生成大量的注释。 JDK的可视化工具JconsoleJava监视与管理控制台。 VisualVM调优案例分析与实战JVM分析内存泄漏定义 内存泄漏就是存在一些被分配的对象，有两个特点 在可达性分析时可达，即无法被GC回收 这些对象是无用的，即程序以后不会再使用这些对象。但占有着内存。 原因 长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄漏，尽管短生命周期对象已经不再需要，但是因为长生命周期持有它的引用而导致不能被回收，这就是Java中内存泄漏的发生场景 工具 MemoryAnalyzer。Java堆转储文件分析工具，帮助发现内存漏洞和减少内存消耗。 EclipseMAT。开源Java内存分析软件，查找内存泄漏，能容易找到大块内存并验证谁在一直占用它。 JProbe。分析Java的内存泄漏。 示例集合类泄漏 像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，他们所引用的所有的对象Object也不能被释放，因为他们也将一直被Vector等引用着。 如果是非静态，那么在方法执行结束时，由于vector=null释放，因此内部的对象也释放了。 123456Vector v = new Vector(10);for (int i = 1; i &lt; 100; i++) &#123; Object o = new Object(); v.add(o); o = null; &#125; 我们仅仅释放引用本身，那么 Vector 仍然引用该对象，所以这个对象对 GC 来说是不可回收的。因此，如果对象加入到Vector 后，还必须从 Vector 中删除，最简单的方法就是将 Vector 对象设置为 null。 当集合里面的对象属性被修改后，再调用remove()方法时不起作用。 1234567891011121314151617181920public static void main(String[] args)&#123; Set&lt;Person&gt; set = new HashSet&lt;Person&gt;(); Person p1 = new Person("唐僧","pwd1",25); Person p2 = new Person("孙悟空","pwd2",26); Person p3 = new Person("猪八戒","pwd3",27); set.add(p1); set.add(p2); set.add(p3); System.out.println("总共有:"+set.size()+" 个元素!"); //结果：总共有:3 个元素! p3.setAge(2); //修改p3的年龄,此时p3元素对应的hashcode值发生改变 set.remove(p3); //此时remove不掉，造成内存泄漏 set.add(p3); //重新添加，居然添加成功 System.out.println("总共有:"+set.size()+" 个元素!"); //结果：总共有:4 个元素! for (Person person : set) &#123; System.out.println(person); &#125;&#125; 单例/静态变量造成的内存泄漏 不正确使用单例模式是引起内存泄漏的一个常见问题，单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏 1234567891011121314151617181920class A&#123; public A()&#123; B.getInstance().setA(this); &#125;....&#125;//B类采用单例模式class B&#123; private A a; private static B instance=new B(); public B()&#123;&#125; public static B getInstance()&#123; return instance; &#125; public void setA(A a)&#123; this.a=a; &#125;//getter...&#125; 匿名内部类/非静态内部类 内部类的引用是比较容易遗忘的一种，而且一旦没释放可能导致一系列的后继类对象没有释放。此外程序员还要小心外部模块不经意的引用，例如程序员A 负责A 模块，调用了B 模块的一个方法如：public void registerMsg(Object b); 这种调用就要非常小心了，传入了一个对象，很可能模块B就保持了对该对象的引用，这时候就需要注意模块B 是否提供相应的操作去除引用。 资源未关闭造成的内存泄漏 如各种连接，包括数据库连接等。 比如数据库连接（dataSourse.getConnection()），网络连接(socket)和io连接，除非其显式的调用了其close（）方法将其连接关闭，否则是不会自动被GC 回收的，因为这些连接是独立于JVM的。 对于Resultset 和Statement 对象可以不进行显式回收，但Connection 一定要显式回收，因为Connection 在任何时候都无法自动回收，而Connection一旦回收，Resultset 和Statement 对象就会立即为NULL。但是如果使用连接池，情况就不一样了，除了要显式地关闭连接，还必须显式地关闭Resultset Statement 对象（关闭其中一个，另外一个也会关闭），否则就会造成大量的Statement 对象无法释放，从而引起内存泄漏。这种情况下一般都会在try里面去的连接，在finally里面释放连接，就能避免此类泄漏。 监听器 在java 编程中，我们都需要和监听器打交道，通常一个应用当中会用到很多监听器，我们会调用一个控件的诸如addXXXListener()等方法来增加监听器，但往往在释放对象的时候却没有记住去删除这些监听器，从而增加了内存泄漏的机会。 ThreadLocal内存泄漏 实际上 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，弱引用的特点是，如果这个对象只存在弱引用，那么在下一次垃圾回收的时候必然会被清理掉。 所以如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来 ThreadLocalMap中使用这个 ThreadLocal 的 key 也会被清理掉。但是，value 是强引用，不会被清理，这样一来就会出现 key 为 null 的 value。 ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。如果说会出现内存泄漏，那只有在出现了 key 为 null 的记录后，没有手动调用 remove() 方法，并且之后也不再调用 get()、set()、remove() 方法的情况下。 线程死锁如何判断JVM线程死锁。 在间隔两分钟后再次收集一次thread dump，如果输出相同，仍然是大量thread都在等待给同一个地址上锁，则是死锁 如果使用VisualVM dump线程信息出来，会有哪些信息 JConsoleJVM调优OOM分析参考 Java内存溢出(OOM)异常完全指南]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：内存管理]]></title>
    <url>%2F2019%2F03%2F01%2FJava%2Fbase%2FJVM%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[java内存区域与内存溢出异常Java将内存扩展的权利交给了JVM，虚拟机自动内存管理机制的帮助下，不再需要为每个new操作写配对的delete/free代码，不容易出现内存泄露与内存溢出问题。如果出现问题，如果不了解JVM如何使用内存，那么排查错误将会成为一项异常艰难的工作。 运行时数据区域 Java虚拟机在执行Java程序的过程中，会将它管理的内存划分为若干个不同的数据区域。 区域有各自的用途、创建时间、销毁时间。 有的区域随着虚拟机进程的启动而存在，有的区域随着用户线程的启动和结束而建立和销毁。 区域包括 对于JVM的内存区域，其实远远不止堆内存、栈内存，这种方式的流行只是说明大多数程序员最关注的、与对象内存分配关系最密切的内存区域是这两块。 方法区 各个线程共享的内存区域，存储了每一个类的结构信息，它存储了已被虚拟机加载的类信息、常量、静态变量、class文件、即时编译器编译后的代码、方法的字节码内容等数据 垃圾回收器也会对这部分进行回收，如常量池的清理和类型的卸载。是Non-Heap、永久代。 可以支持动态扩展与收缩，当无法满足内存分配需求时，OutOfMemoryError异常 可以以方法区只有一个类的角度去思考。 运行时常量池 JVM为每个类型都维护着一个常量池，该常量池是JVM的运行时数据结构，class文件中每一个类或接口的常量池表的运行时表示形式。 存放该类型编译期生成的各种字面量和符号引用。 包括直接常量CONSTANT_String_info、CONSTANT_Integer_info等。 对其他类型、字段和方法的符号引用，以索引进行访问。对于该类型的字段可能必须在运行期解析后才能获得直接引用，即多态的实现。 相对于Class文件常量池的另一个重要特征时具备动态性，Java并不要求常量一定在编译期才能产生，即并非Class文件中常量池的内容才能进入该区域。运行期间也可以将新的常量放入池中，例如String的intern() 当无法满足内存分配需求时，OutOfMemoryError异常 类型信息 类型的全限定名、类型直接超类的全限定名、直接接口的全限定名列表、该类型是类信息还是接口类型、类型的访问修饰符。 字段信息 类中声明的所有字段，例如类级变量和实例变量的描述，不包括局部变量。如字段名称、字段修饰符、字段的类型。 方法信息 方法名、方法的返回类型、方法参数的个数和类型、顺序等、方法的修饰符、方法的字节码、操作数栈和该方法在栈帧中的局部变量区的大小、异常表。 类变量 类中使用static修饰的变量，类变量是所有对象共享，保存在方法区当中。 非编译时变量。虚拟机使用某类前，必须为此类变量分配内存空间。 编译时变量。对于编译时常量，则直接将其复制到使用它们的类的常量池当中，或者作为字节码流的一部分 指向类加载器的引用 一个类可以被启动类加载器或者自定义的类加载器加载，如果一个类被某个自定义类加载器的对象加载，则方法区必须保持该对象的引用 指向Class实例的引用 在加载过程中，虚拟机会创建一个代表该类型的Class对象，方法区中必须保存对该对象的引用 方法表 是为了提高访问效率，JVM对每个加载的非虚拟类的类型信息中都添加了一个方法表，方法表是一组对类实例方法的直接引用（包括从父类继承的方法），JVM通过方法表快速激活实例方法。 堆 虚拟机管理的内存中最大的一块，在虚拟机启动时创建，所有线程共享 可以处于物理上不连续的内存空间中，只要逻辑上时连续的即可。 存放对象实例，几乎所有对象实例都在这里分配内存 随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术会导致一部分对象不会分配到堆上。 垃圾收集器管理的主要区域，也称为GC堆 从内存回收的角度，使用分代收集算法 堆可分为新生代和老年代 Eden空间、From Survivor空间、To Survivor空间 从内存分配的角度，划分出多个线程私有的分配缓冲区TLAB 可以支持动态扩展，并在不需要过多空间时自动收缩，其使用的内存不需要保证是连续的。当堆无法再扩展OutOfMemoryError 虚拟机栈 线程私有，生命周期与线程相同。描述Java方法执行的内存模型（栈内存）。每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 一个方法从调用至完成则对应一个栈帧在虚拟机栈入栈到出栈。除了栈帧的出栈与入栈外，JVM不会再受其他因素的影响，因此栈帧可以在堆中分配，JVM栈使用的内存不需要保证是连续的 线程请求栈深度大于虚拟机允许深度，StackOverflowError异常 大部分虚拟机允许动态扩展，如果扩展无法申请到足够内存，则OutOfMemoryError 栈帧的组成 参见JVM：Java虚拟机规范 本地方法栈其功能与虚拟机栈发挥作用非常类似，虚拟机使用到的Native方法服务，不一定是Java实现的。结构也于虚拟机栈一致 本地方法栈会抛出StackOverflawError和OutOfMemoryError异常 程序计数器程序计数器是一块较小的内存空间（线程私有），可以看作时当前线程所执行的字节码的行号指示器。如果共享，则无法准确的执行当前线程需要执行的语句。 在JVM的概念模型当中（实际虚拟机可能以更高效的方式实现），字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令。例如分支、循环、跳转、异常处理、线程恢复等基本功能 当执行Java方法时，其记录的是JVM正在执行的字节码指向的地址。如果执行本地方法时，值为undefined CPU通过时分复用实现多线程，对确定时刻，一个CPU只会执行一条线程中的指令。每个线程都有一个独立的程序计数器。 直接内存 不是虚拟机运行时数据区的一部分，也不是JVM定义的内存区域，但是可能导致OutOfMemoryError NIO，基于通道与缓冲区的IO方式，使用Native函数库直接分配堆外内存，通过一个堆中的对象引用 避免了在Java堆与native堆中来回复制 不受Java堆大小限制，受本机总内存等限制 Hotspot虚拟机对象揭秘虚拟机内存中的数据如何创建、如何布局、如何访问等问题 揭秘Hotspot虚拟机在Java堆中对象分配、布局和访问全过程 对象的创建对于普通的Java对象，不包括数组和Class对象 虚拟机遇到一条new指令，检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查一个符号引用代表的类是否已经被加载、解析和初始化过 如果没有，则必须先执行相应的类加载过程 为新生对象分配内存，所需内存在类加载完成后便可完全确定。将一块大小确定的内存从Java堆当中划分出来 划分内存的方法 指针碰撞：Java堆中内存绝对规整（所有已用在一边，空闲在另一边），中间一个指针作为分界点的知识点，即将指针向空闲移动一段距离 空闲列表：内存不规整，维护一个记录可用内存的列表，分配一个足够大的空间 内存是否规整由垃圾收集器是否带有压缩整理的功能决定，例如Serial、ParNew等带Compact则采用指针碰撞，而CMS这种基于Mark-Sweep的通常采用空闲列表。 分配内存空间可能存在线程安全问题，对象创建在虚拟机中是非常频繁的行为。 对分配内存空间的动作做同步处理，虚拟机采用CAS搭配失败重试的方法 把内存分配的动作按线程划分在不同的空间中进行。设定-XX:+/-UseTLAB以开启 每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB），线程在各自的TLAB上分配内存。当TLAB用完，才需要同步锁定。 虚拟机将分配到的内存空间初始化为0（不包括对象头），此时读取实例字段值为0。如果使用TLAB，则可以提前到TLAB分配时进行。 对对象进行必要的设置，存放在对象头中。如对象是哪个类的实例、如何找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。根据JVM当前运行状态不同，是否启用偏向锁等。 从虚拟机视角看，对象已经产生。从程序视角看，对象刚刚开始，即对象进行init，进行构造 对象的内存布局对象内存中存储的布局分为三部分 对象头Header Mark Word存储对象自身的运行时数据。哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。在32位、64位虚拟机长度为32bit、64bit Mark Word时一个非固定的数据结构，以便在极小的空间内存储尽量多的信息。会根据对象的状态复用自己的存储空间。 类型指针。对象指向它类元数据的指针，JVM通过这个指针来确定这个对象是那个类的实例 并不是所有JVM实现都必须在对象数据上保留类型指针，即查找对象的元数据不一定经过对象本身 如果是数组，则记录数组长度的数据 实例数据Instance Data 对象真正存储的有效信息 存储顺序受虚拟机分配策略参数与字段在Java源码中定义顺序的影响 longs/double、ints、shorts/chars、bytes/booleans、oops。相同宽度的字段被分配到一起 父类变量会出现在子类前（CompactFields为true（默认），子类中较窄的变量也可能插入到父类变量的空隙中） 对齐填充Padding 并不必然存在，起到占位符作用 Hotspot自动内存管理相同要求对象的其实对这必须为8字节的整数倍 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象。解释引用通过何种方式去定位、访问堆中的对象的具体位置。依据JVM实现而定 句柄 Java堆当中划分一块内存作为句柄池，reference中存储的是对象的句柄地址 句柄中包含了对象实例数据域类型数据各自的地址信息 稳定的句柄地址，即使对象被移动（垃圾收集时，非常普遍），也不会修改reference 直接指针 reference存储的就是对象地址 Java堆对象的布局中需要考虑如何放置访问类型数据的相关信息 速度快，节约一次指针定位，对于非常频繁的对象访问有较好的提升。Hotspot使用的方式 垃圾收集器与内存分配策略当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈是，就需要对垃圾回收技术实施必要的监控和调节。 概述垃圾收集GC需要完成的三件事情： 哪些内存需要回收 什么时候回收 如何回收 无需关注的内存：对于程序计数器、虚拟机栈、本地方法栈。随线程而生灭，一个栈帧内分配多少内存基本上在类结果确定下来就已知，因此内存分配与回收都具备确定性。并且方法结束或者线程线束，内存就回收了。 GC关注的内存：对于Java堆和方法区，一个接口中的多个实现类需要的内存可能不一样，一个方法中多个分支需要的内存也可能不一样，只能在程序运行期间才能知道会创建哪些对象，分配与回收都是动态的。 对象是否存活GC在对堆进行回收前，要确定这些对象中哪些还存活着，哪些已经死去（不可能再被任何途径使用的对象） 引用计数算法定义：为对象添加一个计数器，每当有一个地方引用它时，计数器就++，引用失效时，计数器– 优点：实现简单、判定效率高 缺陷：难以解决对象间相互循环引用的问题 123objA.instance=objB;objB.instance=objA;//相互引用，导致无法回收 可达性分析算法Java等语言的主流实现 基本思想： 通过一系列称为GC Roots的对象作为起始点，从这些结点开始向下搜索，走过的路径称为引用链 一个对象到GC Roots没有任何引用链，即不可达，则对象不可用 GC Roots对象： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中Native方法引用的对象 引用判断对象是否存活均与引用有关。对于引用我们希望描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾回收后还是非常紧张，则可以抛弃这些对象。很多对象的缓存功能都符合这样的场景 强引用 指在程序代码中还普遍存在，类似“Object o=new Object()”的引用，只要强引用还存在，则永不回收 软引用 描述还有用，但并非必须的对象。在系统将内存溢出异常前，会将这些对象进行第二次回收。如果还没有足够内存，才会异常。 以SoftReference类实现软引用 弱引用 描述非必须对象，强度弱于软引用只能生存到下一次垃圾回收前 WeafReference实现 虚引用 最弱的引用关系，无法通过虚引用获得一个对象的实例。唯一目的是能在这个对象被回收时收到一个系统通知 PhantomReference实现 生存还是死亡即使时不可达的对象，也并非会立即死亡，此时处于缓刑阶段。而要宣告一个对象死亡，至少要经历两次标记过程。 如果在可达性分析中，发现无连接，则进行第一次标记以及进行一次筛选 第一次筛选，条件为此对象是否有必要执行finalize方法。 没有必要执行的情况： 对象没有覆盖finalize方法 finalize方法已经被虚拟机调用过 有必要执行 将对象放置在一个F-Queue队列，并在稍后由一个虚拟机自动建立，低优先级的finalizer线程去执行 执行：虚拟机会触发这个方法，但并不承诺会等待它运行结束。为了防止一个对象在finalize执行缓慢，或者死循环，使得其他对象等待。 GC对F-Queue中对象进行第二次小规模标记， finalize是对象最后一次自救机会，如果对象此时与引用链上一个对象建立关联，则此时将被移出“即将回收”集合。否则就可以确定被回收了。 回收方法区永久代的垃圾回收效率非常低，回收内容： 废弃常量 常量池存在“abc”，无String引用引用，并无其他地方引用该字面量，则为废弃常量 常量池当中的其他类(接口)方法、字段的符号引用也与此类似 无用的类，但只是可以被回收，而不是一定被回收，是否回收需要进行JVM参数控制。对于大量使用反射、动态代理等框架会频繁自定义ClassLoader，需要虚拟机具备类卸载功能，保证永久代不溢出。 该类所有实例都被回收 加载该类的ClassLoader被回收 该类对应的Class对象没有被引用，无法通过反射访问该类的方法 垃圾回收算法标记-清除算法 Mark-Sweep最基础的算法，算法分为标记与清除两个阶段 标记出所有需要回收的对象，在标记完成后统一回收被标记的对象 不足： 效率低下 清除后会产生大量不连续的内存碎片 复制算法解决效率问题 将可用内存按容量划分为两块，每次使用一块，一块内存使用完后，将其复制到另一块，然后回收 用于回收新生代 新生代对象98%朝生夕死，因此将内存分为一块较大的Eden空间与两块较小的Survivor空间（8：1）。 每次使用Eden空间与一块Survivor空间 当Survivor空间不够时，依赖其他内存（老年代）进行分配担保 标记-整理算法 Mark-Compact标记过后，让所有存活的对象都向一端移动，然后清理端边界外的内存 分代收集算法实际采用的算法 根据对象存活周期的不同将内存划分为几块：新生代、老年代 根据各个年代的特点采用适当的收集算法，新生代：复制算法，老年代：标记-清理（整理）算法 HotSpot算法实现以上是理论实现，而虚拟机高效允许需要对算法的执行效率进行严格的考量 枚举根节点帮助快速准确完成GC Roots枚举，其困难有 GC Roots的节点非常多，逐个检查引用需要消耗非常多的时间。并且对于很多应用仅仅方法区就有数百兆 GC停顿问题（GC进行时必须停顿所有执行线程），必须在一个确保一致性（整个执行系统冻结在某个时间节点，不可以出现在分析过程中，引用关系还在不断变化）的快照中进行 主流JVM使用准确式GC，当执行系统停顿下来，并不需要一个不漏检查完所有的引用位置，应当有办法直接得知哪些地方存放着对象引用 HotSpot使用OopMap达到目的，在类加载完成时，HotSpot将对象内什么偏移量是什么类型数据计算出来，在JIT编译时也会在特点位置记录栈和寄存器哪些位置是引用。 OopMap数据解构： 保存GC Roots 节点，避免全局扫描去一一查找。 安全点 引用关系可能变化，OopMap内容变化指令非常多，如果为每一条指令生成对应的OopMap则需要大量空间 程序执行时只有在到达安全点时才能暂停，进行GC。 安全点的选择：以是否具有让程序长时间执行的特征为标准选定。即指令序列复用，如方法调用、循环跳转、异常跳转等。安全点的选定不能太少以致于让GC等待时间太长，也不能过于频繁过分增大运行时的负荷。 如何在GC发生时，让所有线程都跑到最近的安全点再停顿 抢先式中断（几乎没有JVM使用） GC发生时，首先把所有线程中断，如果线程不在安全点，就恢复线程，让它跑到安全点 主动式中断 当GC需要中断时，不直接对线程操作，设置一个标志（与安全点重合），各个线程执行时轮询这个标志，如果为真则自己中断挂起 安全区域安全点机制保证了程序执行时在不太长时间内就会遇到可进入GC的安全点，但是无法解决程序不执行的时候进入安全点。 对于不执行的程序，如挂起或者blocked状态，无法响应中断请求，走到安全点。 安全区域：在一段代码片段中，引用关系不会发生变化。则在这个区域的任意地方开始GC都是安全的 当线程执行到安全区域时，标识自己已经进入安全区域，当JVM发生GC时，不用管已经标识的线程。当线程离开时，需要检查系统是否完成GC，如果完成则继续执行，否则继续等待 垃圾收集器并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。 内存回收的具体实现 存在连线，则说明可以搭配使用。所处区域，说明属于新生代还是老年代收集器。为了对具体应用最合适的收集器。 Serial收集器Serial （Old）收集器是最基本最古老的收集器，是一个单线程收集器，并且在它进行垃圾回收时，必须暂停所有的用户线程。 Serial是针对新生代收集器，采用copying算法。 Serial Old针对老年代，采用Mark-Compact算法。 作为CMS收集器的后备预案，在并发收集出现Concurrent Mode Failture使用。 简单高效，但是给用户带来停顿，client模式下默认的新生代收集器。对于限定单个CPU的环境下，没有线程交互的开销，可以获得最高的单线程收集效率。 对于一般用户，虚拟机内存一般比较小，停顿时间可以控制在最多100ms以内。 ParNew收集器是Seial收集器的多线程版本 是许多运行在Server模式下的虚拟机中的首选新生代收集器。重要原因是除了serial收集器外，只有它可以与CMS收集器配合工作 在单CPU环境中不会比Serial更好，由于线程开销，在两个CPU环境下都未必超越Serial，默认开启的收集线程数与CPU数量相同，可以通过-XX:ParallelGCThreads限制其线程数。 ParNew Old是老年代版本，采用Mark-Compact 搭配Parallel Scavenge Parallel Scavenge收集器是新生代的多线程收集器，吞吐量优先收集器，它在回收期间不需要暂停其他用户线程，采用Copying算法，它主要是为了达到一个可控的吞吐量。吞吐量=运行用户代码时间/(用户代码+垃圾收集)而停顿时间与吞吐量是矛盾的 GC时，垃圾回收的工作总量是不变的 停顿时间减少，就越适合与用户交互的程序，提高用户体验，但是GC频率提高， 频率提高，则频繁进行GC，即吞吐量降低，性能降低，因此是以牺牲吞吐量和新生代空间换取的。 吞吐量提高，则高效率利用CPU时间，尽快完成程序运算，适合在后台运算而不需要太多交互的任务。 对于注重吞吐量和CPU资源敏感的场合，优先考虑Parallel Scavenge与Parallel Old -XX:MaxGCPauseMillis设置最大垃圾收集停顿时间，-XX:GCTimeRatio设置吞吐量大小（垃圾收集时间占总时间的比率，值为0-100）。 CMS收集器以获取最短回收停顿时间为目标的收集器，重视服务的响应速度，希望系统停顿时间最短，给用户带来体验，是一种并发收集器，采用Mark-Sweep（标记清除）算法 运作过程 初始标记 需要stop the world。仅仅只标记一下GC Roots能直接关联到的对象，速度较快 并发标记 进行GC Roots Tracing。耗时长，但可以与用户线程一起工作，但是会占用一定CPU资源，使得程序变慢 重新标记 需要stop the world。修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录 并发清除 缺点： 对CPU资源非常敏感。 会占用CPU资源，使得程序变慢，总吞吐量降低。默认线程数是(CPU数+3)/4，即在CPU4个以上，获得至少25%的CPU资源，当CPU不足4时，对用户程序影响较大。当CPU负载比较大，则分出一半运算能力会使得用户程序执行速度降低一半。 无法处理浮动垃圾，可能出现Concurrent Mode Failure失败(预留的内存空间不足以程序运行)而导致另一次Full GC（进行全部GC，老年代临时使用Serial Old收集器）的产生 由于用户线程依然运行，可能产生新的垃圾。这部分垃圾产生在标记过程后，只能在下一次GC清理，即浮动垃圾 由于在垃圾收集时，用户线程依然需要运行，则需要预留足够的内存给用户线程。设定合理的阈值，减少FULL GC出现的机会。设定-XX:CMSInitiatingOccupancyFraction的值来确定阈值。 空间碎片。-XX:UseCMSCompactAtFullCollection开关参数，默认开启，在CMS即将进行FullGC时开启内存碎片的合并整理，该过程无法并发，但是时间不会太长。-XX:CMSFullGCsBeforeCompaction设定执行多少次不压缩的FullGC后跟着来一次带压缩的。 G1收集器当前收集器最前沿的成果，面向服务端应用的收集器，能充分利用多CPU、多核环境。因此是一款并行和并发收集器，并能建立可预测的停顿时间模型。 G1特点： 并行与并发 能充分利用CPU、多核环境下的硬件优势，缩短Stop The World停顿时间，可以以并发使得Java程序继续执行 分代收集 空间整合 整体上是标记整理算法实现，局部（两个区域Region间）上是基于复制算法，不会产生内存碎片，导致提前GC 可预测的停顿 低停顿，并可建立可预测的停顿时间模型，能让使用者明确指定一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒 实时Java的垃圾回收器特征 原因： 可以有计划地避免在整个Java堆当中进行全区域的垃圾收集。跟踪各个Region的垃圾堆积的价值大小（回收所获得的空间大小以及需要的时间），在后台维护一个优先列表，根据允许的时间，优先回收价值最大的Region Region困难 垃圾回收不能真的以Region为单位，因为一个对象存放在Region中，它可以与整个Java堆中任意对象发生引用关系。在可达性判断时，扫描困难，需要对整个堆扫描 使用Remembered Set避免全堆扫描，每个Region都有一个与之对应的Remembered Set，对引用类型数据进行写操作时，产生一个Write Barrier暂时中断，判断是否引用的对象处于不同的Region中，如果是，则通过CardTable把相关引用信息记录到该Region的Remembered Set中，在可达性分析中加入该Remembered Set。 G1将Java堆的内存布局划分为多个大小相等的独立区域（Region），保留新生代、老年代概念，但是不物理隔离，都是一部分Region的集合。 G1的步骤（不考虑Remembered Set操作） 初始标记 并发标记 最终标记 JVM将在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，记录在Remembered Set Logs中，最终标记阶段需要将Logs的数据合到Rembbered Set当中。 筛选回收 对各个Region的回收价值和成本进行排序，根据用户期望的GC停顿时间指定回收计划。 内存分配与回收策略Java的自动内存管理自动化解决了两个问题 给对象分配内存。（在堆上分配，也可能经过JIT编译后被拆散为标量类型并间接地栈上分配） 主要分配在新生代的Eden区。如果启动了本地线程分配缓冲，将线程优先在TLAB上分配 少数情况直接分配到老年代中 分配规则取决于当前使用哪一种垃圾回收器组合，还要虚拟机中与内存相关的参数的设置 回收分配给对象的内存 什么时候进行GCMinor GC 新生代当中的垃圾收集动作，采用复制算法 对于较大的对象，在Minor GC时候，直接进入老年代 Full GC 对象优先在Eden分配大多数情况，对象在新生代Eden区分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC 新生代GC（Minor GC）指发生在新生代的垃圾回收动作，因为Java对象大多具备朝生夕死的特性，所以该GC频繁，且速度快 老年代GC（Major GC/Full GC）指发生在老年代GC，比新生代GC慢10倍以上 大对象直接进入老年代大对象：需要大量连续内存空间的Java对象，例如很长的字符串与数组 经常出现大对象容易导致内存还有不少空间时就需要提前触发垃圾收集以获得连续空间 长期存活的对象进入老年代虚拟机为每个对象定义了一个对象年龄Age计数器，每经过一次Minor GC则age+1，当达到15（MaxTenuringThreshold设置）则升级到老年代 动态对象年龄判定为了更好适应不同程序内存情况，并不是永远要求年龄到达阈值才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小总和大于空间的一般，年龄大于等于该年龄的对象就可以直接进入老年代 空间分配担保 在发生Minor GC前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间。 如果大于，则Minor GC可以确保安全 如果不大于，则虚拟机查看HandlePromotionFailure设置值是否允许担保失败 允许，则继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小 如果大于则尝试进行Minor GC,尽管有风险 如果小于，或者HandlePromotionFailure不允许冒险，则进行一次Full GC 失败：新生代采用复制收集算法，当出现大量对象在Minor GC后仍然存活地情况，即一个Survivor存不下，就需要老年代进行分配担保，将Survivor无法容纳地对象直接进入老年代。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM：概述]]></title>
    <url>%2F2019%2F03%2F01%2FJava%2Fbase%2FJVM%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Java 一门结构严谨、面向对象的编程语言 摆脱硬件平台的约束，一次编写，到处运行 提供了一个相对安全的内存管理和访问机制，避免了绝大部分的内存泄漏和指针越界问题 实现了热点代码检测和运行时编译以及优化，使得Java应用能随着运行时间增加而获得更高的性能 Java生态非常完善。等 Java技术体系包括 Java程序设计语言 各种硬件平台上的Java虚拟机 Class文件格式 Java API类库 来自商业机构和开源社区的第三方Java类库 JDK： Java程序设计语言 Java虚拟机 Java API类库 支持Java程序开发的最小环境 JRE Java SE API子集 Java虚拟机 支持Java程序运行的标准环境 Java的跨平台特性将Java代码编译为字节码，可以在网络上进行传播，当碰到Java虚拟机，就可以在其上运行 JVMJVM是整个Java平台的基石，是Java实现硬件无关与OS无关的关键，是Java生成出极小体积的编译代码的运行平台，是保障用户机器免于恶意代码损害的屏障。 JVM可以看作是一台抽象的计算机，拥有自己的指令集以及各种运行时内存区域。JVM不局限于特定的代码执行方式，它虽然不强求使用解释器来执行程序，但是也可以通过把自己的指令集编译为实际CPU的指令来实现。它可以通过微代码来实现，甚至可以直接在CPU实现。 JVM只与特定的二进制文件格式.class文件关联，class文件包含了JVM指令集和符号表，以及其他一些辅助信息。而基于安全方面，JVM在class文件中施加了许多强制性的语法和结构化约束。 Java虚拟机体系结构 在Java虚拟机的规范中定义类一系列的子系统、内存区域、数据类型和使用指南。这些组件构成了Java虚拟机的内部结构，他们不仅仅为Java虚拟机的实现提供了清晰的内部结构，更规定了Java虚拟机实现的外部行为 每个Java虚拟机都有一个类加载子系统，负责加载程序中的类型（class与interface），并赋予唯一的名字。每一个Java虚拟机都有一个执行引擎，负责执行被加载类中包含的指令 数据类型： 原始数据类型 引用数据类型：类类型、接口类型、数组类型。 JVM体系结构 基本上由四部分组成 类加载器，在JVM启动时或者类运行时将需要的class加载到JVM中 执行引擎，执行引擎的任务是负责执行class文件中包含的字节码指令，相当于实际机器上的CPU 内存区，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者PC指针的记录器等 本地方法调用，调用C或C++实现的本地方法的代码返回结果 Java虚拟机的生存周期 一个运行中的Java虚拟机有着一个清晰的任务，执行Java程序，程序开始执行时它才运行，程序结束时它就停止。每个Java程序会单独运行一个Java虚拟机。 Java虚拟机总是开始于一个main方法，固定格式。 main方法是程序的起点，它被执行的线程初始化为程序的初始线程。程序中其他线程都由它启动，Java中线程分为两种：守护线程、普通线程。 守护线程：Java虚拟机自己使用的线程，比如负责GC的线程，也可以把自己的程序设置为守护线程。 初始线程不是守护线程。 只要Java虚拟机中还有普通的线程还在执行，就不会停止。也可以使用exit终止。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发：线程协作]]></title>
    <url>%2F2019%2F02%2F28%2FJava%2Fbase%2Fjava%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6-%E5%8D%8F%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[线程协作线程间进行协作时，则一般有着一些合作的条件，有一些与状态相关的依赖。 构建自定义的同步工具类库中包含许多存在状态依赖性的类，例如FutureTask、Semaphore和BlockingQueue等，这些类的一些操作中有着基于状态的前提条件。 创建状态依赖类的最简单方法通常是在类库中现有状态依赖类的基础上进行构造。如果没有所需要的功能，则可以使用Java与类库提供的底层机制来构造自己的同步机制。包括内置的条件队列，显式的Condition对象以及AbstractQueueSynchronizer框架。 状态依赖性的管理在单线程程序中调用一个方法时，如果某个基于状态的前提条件未得到满足，那么这个条件将永远无法成真，因此要使得这些类操作失败。 但是在并发中，基于状态的条件可能会由于其他线程的操作而改变：一个资源池可能在前几条指令前还是空的，现在变为非空的。对于并发对象上依赖状态的方法，虽然有时候在前提条件不满足的情况下会失败，但通常更好的选择时等待前提条件变为真。 依赖状态的操作可以一直阻塞直到可以继续执行，这比使它们先失败再实现起来要更为方便且不易出错。内置的条件队列可以使线程一直阻塞，直到对象进入某个进程可以继续执行的状态，并且当被阻塞的线程可以继续执行时在唤醒它们。 可阻塞的状态依赖性操作形式如下：即锁是在操作的执行过程中被释放与重新获取的，构成前提条件的状态变量必须由对象的锁来保护，从而使得它们在测试前提条件的同时保持不变。如果前提条件未满足就必须释放锁，以便其他线程可以修改对象的状态，否则前提条件永远无法变成真。 123456789scquire lock on object statewhile(precodition does not hold)&#123; release lock wait until precodition might hold optionally fail if interrupted or timeout expies reacquire lock&#125;perform action release lock 有界缓存在生产者与消费者的设计中，经常使用类似ArrayBlockingQueue这样的有界缓存，当执行put时，不能放入元素已满的缓存中，当条件未满足时 依赖状态的操作可以抛出一个异常或返回一个错误，使其成为调用者的一个问题 也可以保持阻塞直到对象进入正确的状态 有界缓存的几种实现 采用不同的方式处理前提条件失败的问题。其中的缓存状态变量buf、head、tail等均由缓存的内置锁保护，并提供同步的doPut，子类中通过这些方法实现put，底层的状态将对子类隐藏。 123456789101112131415161718192021222324252627282930313233343536@ThreadSafepublic abstarct class BaseBoundedBuffer&lt;V&gt;&#123; @GuardedBy("this") private final V[] buf; @GuardedBy("this") private int tail; @GuardedBy("this") private int head; @GuardedBy("this") private int count; protected BaseBoundedBuffer(int cap)&#123; this.buf = (V[]) new Object[cap]; &#125; protected synchronized final void doPut(V v)&#123; buf[tail] = b; if(++tail == buf.length)&#123; tail = 0; &#125; ++count; &#125; protected synchronized final V doTake()&#123; V v = buf[head]; buf[head] = null; if(++head == buf.length)&#123; head = 0; &#125; --count; return v; &#125; public synchronized final boolean ifFull()&#123; return count == buf.length; &#125; public synchronized final boolean isEmpty()&#123; return count == 0; &#125;&#125; 简单实现1234567891011@ThreadSafepublic class GrumpyBoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt;&#123; public GrumpyBoundedBuffer(int size)&#123;super(size);&#125; public synchronized void put(V v) throws BufferFullException&#123; if(isFull())&#123; throw new BufferFullException(); &#125; doPut(v); &#125;&#125; 对于有界队列来说，缓存已满并不是一个异常条件，只是一个信息。类似于红灯并不是交通异常一样，这样的实现带来了复杂性。 12345678while(true)&#123; try&#123; V item = buffer.take(); break; &#125;catch(BufferEmptyException)&#123; Thread.sleep(1000); &#125;&#125; 修改方式为，当缓存处于某种错误的状态时返回一个错误值，但这种实现没有解决根本问题，即调用者必须自行处理前提条件失败的问题 可选的实现方式： sleep 轮询 Thread.yield() 条件队列条件队列类似于一个任务完成的提示音，如果你注意听铃声，则当任务完成后会立刻得到停止，并放下或做完手头的事情，开始做提示的任务。 如果忽略了铃声，则会错过停止信息，但依然可以去观察任务的状态，如果任务完成则下一步，否则再次留意铃声。 条件队列使得一组线程能够通过某种方式来等待特定的条件变为真，传统队列当中的元素是一个个元素，而条件队列当中是一个个正在等待相关条件的线程。 每个对象同样可以作为一个条件队列，Object.notify、Object.wait、Object.notifyAll方法构成了内部条件队列的API。 对象的内置锁与其内部条件队列是相互关联的，要调用条件队列中任何一个方法，都必须持有对象X上的锁。这是因为“等待由状态构成的条件”和“维护状态的一致性”两种机制必须被紧密地绑定在一起：只有能对状态进行检查时，才能在某个条件上等待，并且只有能够修改状态时，才能从条件等待中释放另一个线程。 条件队列没有改变原来的语义，但是在CPU效率、上下文切换开销和响应性等进行了优化 如果某个功能无法通过轮询和休眠来实现，那么条件队列也无法实现。但是条件队列使得在表达和管理状态依赖性时更加简单高效 12345678910111213141516171819@ThreadSafepublic class BoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt;&#123; public synchronized void put(V v) throws InterruptedException&#123; while(isFull())&#123; wait(); &#125; doPut(); notifyAll(); &#125; public synchronized V take() throws InterruptedException&#123; while(isEmpty())&#123; wait(); &#125; V v = doTake(); notifyAll(); return v; &#125;&#125; 使用条件队列条件队列使构建高效以及高可响应性的状态依赖性变得更容易，但同时也很容易被不正确地使用，虽然许多规则都能够确保正确地使用条件队列，但在编译器或系统平台上却并没有强制要求遵循这些规则。 这也是为什么要尽量基于LinkedBlockingQueue、Latch、Semaphore、FutureTask等构造程序的原因之一，如果能够避免使用条件队列，那么实现起来将容易很多。 Object.wait自动释放锁，并请求OS挂起当前线程，从而使其他线程能够获取这个锁并修改对象的状态，当被挂起的线程醒来时，它将在返回之前重新获得锁。 即wait意味着线程休息，但当发生特定的事情时唤醒我。而调用通知方法就意味着特定的事件发生了。 Object.notify调用时必须持有与条件队列对象相关的锁。JVM会从这个条件队列上等待的多个线程中选择一个来唤醒。 由于这些线程需要获得锁，因此发出通知的线程应该尽快释放锁，确保正在等待的线程尽快解除阻塞。 由于多个线程可以基于不同的条件谓词在同一个条件队列上等待，因此如果使用notify而不是notifyAll将是一种危险的操作。很容易会产生信号丢失的问题。 只有同时满足以下两个条件时，才能使用单一的notify而不是notifyAll 所有等待线程的类型相同。只有一个条件谓词与条件队列相关，并且每个线程在从wait返回后将执行相同的操作 单进单出。在条件队列上的每次通知，最多只能唤醒一个线程来执行 Object.notifyAll调用时必须持有与条件队列对象相关的锁。JVM会唤醒所有在这个条件队列上等待的线程。 notifyAll可能存在性能问题 条件谓词要想正确地使用条件队列，关键是找出对象在哪个条件谓词上等待。在Java与JVM当中没有任何信息可以确保正确地使用条件谓词，但如果没有条件谓词，条件等待机制将无法发挥作用。 条件等待当中存在三元关系：加锁、wait、一个条件谓词。在条件谓词当中包含多个状态变量，而状态变量由一个锁保护，因此在测试条件谓词前必须先持有这个锁。锁对象与条件队列对象(调用wait和notify所在的对象)必须是同一个对象 每一次wait调用都会隐式地与特定的条件谓词关联起来，当调用某个特定条件谓词的wait时，调用者必须以及持有与条件队列相关的锁，并且这个锁必须保持着构成条件谓词的状态变量。 当使用条件等待时 通常都有一个条件谓词，包括一些对象状态的测试，线程在执行前必须首先通过这些测试 在调用wait之前测试条件谓词，并且从wait中返回时再次进行测试 在一个循环中调用wait 确保使用与条件队列相关的锁来保护构成条件谓词的各个状态变量 当调用wait、notify、notifyAll等方法时，一定要持有与条件队列相关的锁 在检查条件谓词之后以及开始执行相应的操作之前，不要释放锁 过早唤醒wait方法的返回并不一定意味着线程正在等待的条件谓词已经为真。内置条件队列可以与多个条件队列一起使用，即存在多个条件。wait方法也还可以假装返回，而不是由于某个线程调用了notify 当执行控制重新进入到wait的代码，已经重新获取了与条件队列相关联的锁。现在条件谓词可能为真，也可能为假(在notifyAll时为真，但是在重新获取锁的时候可能再次为假了)，因为并不清楚另一个线程为什么调用notify或notifyAll，也可能你需要电话的铃声，但其实是电脑发出了铃声。 丢失信号丢失的信号是指：线程必须等待一个已经为真的条件，但在开始等待之前没有检查条件谓词。即线程将等待一个已经发过的事件。 例如在手机响铃之后没有听到，依然在等待接起电话，但是由于电话已经响过了（它只会响一下，但是一直存在），而你没有去接，因此你可能会等待很长的事件。 通知条件等待的另一半内容是通知。在条件队列API中有两个发出通知的方法：notify与notifyAll。 每当在等待一个条件时，一定要确保在条件谓词变为真时通过某种方式发出通知。 子类的安全问题在使用条件通知或单次通知时，一些约束条件使得子类化的过程变得更加复杂，要想支持子类化，那么在设计类时需要保证：如果在实施子类化时违背了条件通知或单次通知的某个需求，那么在子类中可以增加合适的通知机制来代表基类。 当设计一个可被继承的状态依赖类时，至少需要公开条件队列与锁，并且将条件谓词和同步策略都写入文档，此外还可能需要公开一些底层的状态变量。 另一种选择是完全禁止子类化，例如final，或将条件队列、锁和状态变量隐藏起来，使子类看不见它们，否则子类破坏了在基类中使用notify的方法，那么基类需要修复这种破坏。 封装条件队列通常我们应该将条件队列封装起来，因而除了使用条件队列的类，就不能在其他地方访问它。否则调用者会自以为理解了在等待和通知上使用的协议，并采用一种违背设计的方式使用条件队列。 入口协议与出口协议对于每个依赖状态的操作，以及每个修改其他操作依赖状态的操作，都应该定义应该入口协议和出口协议。 入口协议：即wait与条件谓词 出口协议：包括检查该操作修改的所有状态变量，并确认它们释放使某个其他条件谓词为真，如果是，则notify或notifyAll。 Java类库详情参见Java并发：JUC Condition 广义的内置条件队列 Synchronized AbstarctQueuedSynchronizer ReentrantLock] Semaphore CountDownLatch FutureTask ReentrantReadWriteLock 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发：JUC]]></title>
    <url>%2F2019%2F02%2F28%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9AJUC%2F</url>
    <content type="text"><![CDATA[JUCjava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是J.U.C的核心。 AQS同步组件AQS：AbstractQueuedSynchronizer，即队列同步器。是许多同步类的基类，它是构建锁或者其他同步组件的基础框架（如ReentrantLock、ReentrantReadWriteLock、Semaphore等），JUC并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础。它是JUC并发包中的核心基础组件。 CountDownLatch Semaphore CyclicBarrier ReentrantLock 锁 Condition FutureTask 概述JDK下面的一个并发工具包，java.util.concurrent locks锁框架详情转Java并发：JUC-Lock i：Lock ReentrantLock i：Condition i：ReadWriteLock ReenttrantReadWriteLock LockSupport atomic原子类框架 AtomicStampledReference AtomicBoolean AtomicInteger AtomicIntegerArray AtomicInterFiledUpdater AtomicLong AtomicLongArray AtomicLongFiledUpdater AtomicReference tools框架 CocuntDownLatch CyclicBarrier Semaphore Executors Exchanger collections集合框架详情转：Java容器：并发容器 i：Queue ConcurrentLinkedQueue i：BlockingQueue ArrayBlockingQueue DelayQueue LinkedBlockingQueue PriorityBlockingQueue SynchronousQueue i：Deque ArrayDeque LinkedList i：BlockingDeque CopyOnWrite CopyOnWriteArrayList CopyOnWriteArraySet CopyOnWriteSkipListSet i：ConcurrentMap ConcurrentHashMap i：ConcurrentNavigableMap ConcurrentSkipListMap executors执行器框架详情转Java并发：JUC-Executor i：Future i：RunnableFuture i：RunnableScheduledFuture FutureTask i：ScheduledFuture i：Callable i：Executor i：ExecutorService ScheduledExectorService i：ScheduledThreadPoolExecutor ThreadPoolExecutor i：CompletionService ExecutorCompletionService i：RejectedExecutionhandler ThreadPoolExecutor.DiscardPolicy ThreadPoolExecutor.DiscardOldestPolicy ThreadPoolExecutor.CallerRunsPolicy ThreadPoolExecutor.AbortPolicy Enum：TimeUnit 底层数据结构 双向链表 Condition queue，单向链表 当使用到condition时存在，并可能存在多个 设计 使用Node实现FIFO队列，可以用于构建锁或者其他同步装置的基础框架 利用一个int类型表示状态 state变量，表示获取锁的线程锁，&gt;1表示重入锁的数量 使用方法是继承 复写其中方法 子类通过继承并通过实现它的方法管理其状态（acquire和release）的方法操纵状态 可以同时实现排它锁和共享锁模式（独占、共享） 实现思路 内部维护一个队列来管理锁 线程尝试获取锁 如果失败，将当前线程以及等待状态信息包装为一个node节点加入同步队列 不断尝试获取锁，只有head的直接后继才会尝试，如果失败则阻塞自己 当持有锁的线程释放锁的时候，唤醒head的直接后继 Atomic原子变量比锁的粒度更细、量级更轻，并对于在多CPU系统上实现高性能的并发代码来说是非常关键的。原子变量将发生竞争的范围缩小到单个变量上，是获得的粒度最细的情况。 在非竞争路径不会比锁慢，并通常更快，竞争下路径比锁更快，因为不需要挂起或重新调度。 标量类 AtomicLong AtomicBoolean AtomicInteger AtomicReference 原子数组类 AtomicIntegerArray AtomicLongArray AtomicReferenceArray 更新器类 AtomicInterFiledUpdater AtomicLongFiledUpdater AtomicReferenceFiledUpdater AtomicStampledReference 复合变量类 性能比较在高度竞争下，锁的性能将超过原子变量。原子变量的失败重试在激烈竞争下导致了更多的竞争。 但在真实的竞争情况下，原子变量的性能将超过锁，因为锁在竞争时会挂起线程，导致CPU使用率与共享内存上的同步通信量降低。 真实场景下，原子变量的可伸缩性要更高，在面对常见的竞争程度时，效率更高 域更新器原子的域更新器表示现有的volatile域的一种基于反射的视图，从而能够在已有的volatile域上使用CAS。 使用newUpdater工厂方法，定制类域域名字来创建域更新器。域更新器类没有与某个特定的实例关联在一起，因而可以更新目标类的任意实例的域。 更新器类提供的原子性保证比普通的原子类更弱一些，因为无法保证底层的域不被直接修改————CAS只能保证其他使用原子域更新器方法的线程的原子性。 适用性 执行原子更新的同时还需要维持现有类的串行化形式。 ToolsCountDownLatch是什么用来控制一个线程等待多个线程。其相当于一扇门，当闭锁到达结束状态前，门一直是关闭的。可以用来确保某些活动直到其他活动都完成后才继续执行。 确保某个计算在其需要的所有资源都被初始化后才继续执行。 确保某个服务在其依赖的所有其他服务都已经启动后才启动 等待直到某个操作的所有参与者都就绪再继续执行。 原理维护了一个计数器cnt，每次调用countDown()方法会让计数器的值减 1，减到0的时候，那些因为调用await()方法而在等待的线程就会被唤醒。 await()：等待计数器到达0，会一直阻塞，或等待中的线程中断，或等待超时。 123456789101112131415161718public class CountdownLatchExample &#123; public static void main(String[] args) throws InterruptedException &#123; final int totalThread = 10; CountDownLatch countDownLatch = new CountDownLatch(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("run.."); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); System.out.println("end"); executorService.shutdown(); &#125;&#125;run..run..run..run..run..run..run..run..run..run..end 功能：用来同步一个或多个任务，强制它们等待由其他任务执行的一组操作完成 对象初始化时设置一个值 任何在这个对象上调用wait方法都将阻塞，直至计数为0 在对象上调用countDown来减小计数值 只能触发一次，计数值不能被重置 可重置版为CyclicBarrier 在对await的调用会被阻塞，直至计数值达到0 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// Performs some portion of a task:class TaskPortion implements Runnable &#123; private static int counter = 0; private final int id = counter++; private static Random rand = new Random(47); //这只是个引用 private final CountDownLatch latch; TaskPortion(CountDownLatch latch) &#123; //在这里引用到真正的对象 this.latch = latch; &#125; public void run() &#123; try &#123; doWork(); //计数值减一 latch.countDown(); &#125; catch(InterruptedException ex) &#123; // Acceptable way to exit &#125; &#125; public void doWork() throws InterruptedException &#123; TimeUnit.MILLISECONDS.sleep(rand.nextInt(2000)); print(this + "completed"); &#125; public String toString() &#123; return String.format("%1$-3d ", id); &#125;&#125;// Waits on the CountDownLatch:class WaitingTask implements Runnable &#123; private static int counter = 0; private final int id = counter++; private final CountDownLatch latch; WaitingTask(CountDownLatch latch) &#123; this.latch = latch; &#125; public void run() &#123; try &#123; //等待CountDownLatch的值到达0 latch.await(); print("Latch barrier passed for " + this); &#125; catch(InterruptedException ex) &#123; print(this + " interrupted"); &#125; &#125; public String toString() &#123; return String.format("WaitingTask %1$-3d ", id); &#125;&#125;public class CountDownLatchDemo &#123; static final int SIZE = 100; public static void main(String[] args) throws Exception &#123; ExecutorService exec = Executors.newCachedThreadPool(); // 初始化值为100All must share a single CountDownLatch object: CountDownLatch latch = new CountDownLatch(SIZE); //尽管这些线程先启动，但是由于CountDownLatch的原因，他们阻塞 for(int i = 0; i &lt; 10; i++) //他们使用的是同一个latch exec.execute(new WaitingTask(latch)); for(int i = 0; i &lt; SIZE; i++) exec.execute(new TaskPortion(latch)); print("Launched all tasks"); exec.shutdown(); // Quit when all tasks complete &#125;&#125; CyclicBarrier是什么用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。 和CountdownLatch相似，都是通过维护计数器来实现的。线程执行 await()方法之后计数器会减1，并进行等待，直到计数器为0，所有调用await()方法而在等待的线程才能继续执行。 CyclicBarrier和CountdownLatch的一个区别是，CyclicBarrier的计数器通过调用reset()方法可以循环使用，所以它才叫做循环屏障。 CyclicBarrier有两个构造函数，其中parties指示计数器的初始值，barrierAction在所有线程都到达屏障的时候会执行一次。 应用 用于实现一些协议，所有线程必须同时到达才能执行。 可以用于分解问题成一系列独立子问题，并当所有子问题解决后进入下一轮迭代。 12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123; this(parties, null);&#125; 123456789101112131415161718192021public class CyclicBarrierExample &#123; public static void main(String[] args) &#123; final int totalThread = 10; CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("before.."); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.print("after.."); &#125;); &#125; executorService.shutdown(); &#125;&#125;before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after.. 原理 与CountDownLatch一样 reset()：重置锁的计数器 功能： 希望创建一组任务，它们并行地执行工作，然后再进行下个步骤前等待，直至所有任务都完成。 使得所有的并行任务在栅栏处列队，一致向前移动 一场场连续的比赛，当所有人到达终点后，才重置，开始下一场比赛 特性：CyclicBarrier可以多次重用 Semaphore是什么Semaphore类似于操作系统中的信号量，可以控制对互斥资源的访问线程数，允许n个任务同时访问一个资源。 信号量中管理着一组数量有限的许可，当要使用许可时可以签出他们，当用户使用完毕时，可以将他们签回。 应用 可以控制对互斥资源的访问线程数，允许n个任务同时访问一个资源。 实现某种资源池。例如数据库连接池 对容器施加边界。即将容器变为有界阻塞容器 以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。 1234567891011121314151617181920212223public class SemaphoreExample &#123; public static void main(String[] args) &#123; final int clientCount = 3; final int totalRequestCount = 10; Semaphore semaphore = new Semaphore(clientCount); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalRequestCount; i++) &#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); System.out.print(semaphore.availablePermits() + " "); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125;); &#125; executorService.shutdown(); &#125;&#125;2 1 2 2 2 2 2 1 2 2 原理 acquire()：请求一个许可。如果没有许可，将阻塞直到有许可，或者被中断或操作超时 realease()：返回一个许可给信号量。 相似性Semaphore与ReentranLock都可以用作一个阀门，即每次只允许一定数量的线程通过，并当线程到达阀门时，可以通过也可以等待 ，还可以取消 DelayQueue 无界的BlockingQueue，用于放置实现了Delayed接口的对象 其中的对象只能再其到期时才能从队列中取走。 队列是有序的，队头对象的延迟到期时间最长 即优先级队列的一种变体。 PriorityBlockingQueue 基础的优先级队列，具有可阻塞的读取操作。 在优先级队列中的对象是按照优先级顺序从队列中出现的任务 ScheduledExecutor的温室控制器 ScheduledThreadPoolExecutor 使用schedule运行一次任务 scheduleAtFixedRate每隔规则的时间重复执行任务 可以将runnable设置为在将来的某个时刻执行 ExchangerExchanger类可用于两个线程之间交换信息。 可简单地将Exchanger对象理解为一个包含两个格子的容器，通过exchanger方法可以向两个格子中填充信息。 当两个格子中的均被填充时，该对象会自动将两个格子的信息交换，然后返回给线程，从而实现两个线程的信息交换。 应用 用于两个线程之间交换信息。 例如一个是读取线程，一个是写入线程，则可以通过Exchanger交换缓冲区 J.U.C - 其它组件ForkJoin主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。 12345678910111213141516171819202122232425262728293031323334353637public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; &#123; private final int threshold = 5; private int first; private int last; public ForkJoinExample(int first, int last) &#123; this.first = first; this.last = last; &#125; @Override protected Integer compute() &#123; int result = 0; if (last - first &lt;= threshold) &#123; // 任务足够小则直接计算 for (int i = first; i &lt;= last; i++) &#123; result += i; &#125; &#125; else &#123; // 拆分成小任务 int middle = first + (last - first) / 2; ForkJoinExample leftTask = new ForkJoinExample(first, middle); ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last); leftTask.fork(); rightTask.fork(); result = leftTask.join() + rightTask.join(); &#125; return result; &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinExample example = new ForkJoinExample(1, 10000); ForkJoinPool forkJoinPool = new ForkJoinPool(); Future result = forkJoinPool.submit(example); System.out.println(result.get());&#125; ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。 1public class ForkJoinPool extends AbstractExecutorService ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统（二）：物理内存]]></title>
    <url>%2F2019%2F02%2F28%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[物理内存管理计算机体系结构和内存层次计算机体系结构计算机系统32位，即地址总线是32位的。 CPU寄存器（32位、64位等）、内存、外存 CPU： 内存层次CPU：两级缓存，由硬件MMU控制，3.6GHZ(CPU的频率) 内存（高速缓存未命中），由OS控制，1.3GHZ 外存（缺页）5ms OS的内存管理方式OS内存管理需要实现的目标 抽象，将物料地址空间转换为逻辑地址空间 保护，对地址空间进行保护，独立地址空间 共享，访问相同内存 虚拟化，更大的地址空间 对于内存的访问，以字节进行访问，每个字节有一个物理地址 对于外存的访问， 内存管理方式 重定位，将每一个地址用一个段地址与一个偏移，可以使得程序可移植 分段，使得地址空间不必连续，但是一段必须连续 分页，将内存分为最基本的单位， 虚拟内存 地址空间&amp;地址生成地址空间的定义 物理地址空间，硬件支持的地址空间 起始地址到MAX内存 逻辑地址空间，在CPU运行的进程看到的地址 起始地址0，到MAXprog 地址生成逻辑地址的生成 地址生成时机和限制 编译时 假设起始地址已知，如果起始地址改变，必须重新编译 加载时（加载之后，地址就无法改变了） 编译时起始地址未知，进行重定位生成绝对地址 执行时（不要求地址空间移动） 执行时代码可移动 需地址转换（虚拟内存）硬件支持 地址生成过程 地址检测 连续内存分配在没有其他技术支持的情况下，分配的内存必须是连续的。为提高利用内存的利用效率，从如何找需要的内存分区与如何处理不能用的内存分区来考虑。 连续内存分配：给进程分配一块不小于指定大小的连续的物理内存区域 内存碎片内存碎片：空闲内存不能被利用 外部碎片：分配单元之间未被使用内存 内部碎片：分配单元内部的未被使用内存（需要511字节，但是只能以512字节分配），取决于分配单元大小是否取整 动态分配当程序被加载进行时，分配一个进程指定大小可变的分区 分区的地址是连续的 操作系统需要维护的数据结构 所有进程的已分配分区 空闲分区 分配策略 最先匹配 最佳匹配，将所有的空闲分区查找一遍 最差匹配，使用最大的 碎片整理通过碎片整理获得更大的内存空间。通过调整进程占用的分区位置来减少或避免分区碎片 紧凑 通过移动分配给进程的内存分区，以合并外部碎片 条件：所有应用程序可动态重定位 通常在进程等待时刻进行紧凑 存在开销 分区对换 通过抢占并回收处于等待状态进程的分区，以增大可用内存空间。 开销相对较大，因为在外存的读取较慢 伙伴系统连续内存分配的实例 整个可分配分区大小为2^n 将分区切半直到大于所需的内存空间 非连续内存分配需求背景如果用户不存在需要的连续的内存空间，分配就会失败 段式分配较大， 页式分配较小，分的太小，则逻辑地址到物理地址的对应关系就会有些复杂（处理方式：页表） 连续分配的缺点： 分配给程序的物理内存必须连续 存在外碎片与内碎片 内存分配的动态修改困难 内存利用率较低 非连续分配 设计目标：提高内存利用效率与管理灵活性 允许一个程序的使用非连续的物理地址空间 允许共享代码和数据 支持动态加载与动态链接 需解决的问题 如何实现虚拟地址和物理地址的转换 硬件实现（够用，开销小） 软件实现（灵活，开销大，类似于外排序） 非连续分配的硬件辅助机制，如何选择非连续分配中的内存分块大小 段式 页式 段式存储管理段地址空间 目的：更精细力度和灵活的分离与共享 进程的段地址空间由多个段组成 段的概念 段表示访问方式和存储数据等属性相同的一段地址空间 对应一个连续的内存块 若干个段组成进程逻辑地址空间 段访问机制 逻辑地址由二元组（s,addr）标识 s:段号（查询段表，由OS控制），addr:段内偏移 页式存储管理概念 页帧（帧，描述物理页面） 把物理地址空间划分为大小相同的基本分配单位 2^N 内存物理地址表示：二元组（f,o）帧号，帧内偏移（值为s，表示每帧的字节为2^s） 页面（页，逻辑页面） 把逻辑地址空间划分为大小相同的基本分配单位 帧与页的大小相同 地址转换 页面到页帧 页表 保存了逻辑地址-物理地址间的映射关系 MMU/TLB（存储管理单元/快表，保证转换的高速进行） 逻辑地址的页号是连续的，但是物理地址中的帧号是不连续的 不是所有的页都有对应的帧 页表概述 页表结构： 每个进程都有一个页表 每个页面对应一个页表项 页表项组成： 帧号 页表项标志：存在位（如果逻辑页号有一个物理帧对应，则值为1）、修改位（内容是否修改）、引用位（是否在过去一段时间访问过） 页表内容会随着进程运行状态而动态变化 存放在页表基址寄存器PTBR 性能问题 访问一个内存单元需要两次内存访问 第一次：读页表项 第二次：访问数据 页表大小问题 页表可能非常大 在32K的物理内存中，1K占一个页表项，则一共32项，一个页表项4字节，则128字节 64位机器，1K占一个页表项，64位地址可以表现的地址范围为2^64，页的大小是2^10（1024），即2^54个页面，一个页表项占64位，即8个字节 64位机器里，页表大小非常大。因为地址总线一共有64位，即想获得一个地址需要64位，地址总线当中，前a位为页表项，后面的64-a位为偏移量 解决办法 缓存（快表，时间与空间的相邻性） 间接访问（即多级页表） 快表 概念 缓存近期访问的页表项 在CPU里面，TLB使用关联存储实现，具备快速访问性能（但是CPU里面区域较小） 如果TLB命中，则物理页号可以很快被获取 未命中，对应表项更新到TLB当中 多级页表 概念 通过间接引用将页号分为k级 建立页表树，整个访问次数为k+1 减少每级页表长度 在大地址空间中很繁琐，逻辑地址空间（随着进程增多而增多）增长速度很快 反置页表 反置页表与页寄存器的解决办法 不让页表与逻辑地址空间的大小相对应（因此随着进程增多而不会增大） 让页表与物理地址空间的大小相对应 页寄存器 每个帧与一个页寄存器关联，寄存器内容 使用位：是否被进程占用 占用页号：对应页号p 保护位 优点： 页表大小相对于物理内存很小 页表大小与逻辑地址空间大小无关 缺点 页表信息对调后，需要依靠帧号可找页号 在页寄存器中搜索逻辑地址中的页号（较困难） 地址转换 CPU生产的逻辑地址如何找到对应物理地址 对逻辑地址进行hash，减少搜索 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行hash查找 在块表中查找对应页表项 查找失败时，产生异常 快表功耗等 反置页表 基于hash映射值查找对应页表项中的帧号（将进程标识加入一起进行hash，因为逻辑地址是与进程有关的，所以效率会高一点） hash结束的结果以页帧号进行排序 段页式存储管理段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势 实现 在段式存储管理基础上，给每个段加一个一级页表 内存共享 通过指向相同的页表基址，实现进程间的段共享 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统（1）：基本概念]]></title>
    <url>%2F2019%2F02%2F28%2FOS%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[操作系统概述操作系统定义 没有公认的精确定义 是一个控制程序 一个系统软件 控制程序执行结果、防止错误和计算机的不当使用 执行用户程序，给用户程序提供各种服务 方便使用 是一个资源管理器 应用程序与硬件间的中间层 管理各种软硬件资源，提供访问资源的高效手段 解决资源的访问冲突，确保资源公平使用 操作系统下接CPU、磁盘、内存；上接进程、文件、地址空间。 操作系统内核特征并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。 操作系统通过引入进程和线程，使得程序能够并发运行。 共享 共享是指系统中的资源可以被多个并发进程共同使用。 同时访问（宏观） 互斥共享（微观），互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。 虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时分复用技术和空分复用技术。 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。 异步 程序的执行不是一贯到底，而是走走停停，以不可预知的速度推进 只要运行环境相同，OS要保证程序运行的结果也相同 基本功能进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 为什么学习操作系统学习操作系统的设计与实现 windows：封闭式系统 linux：开放式系统 操作系统演变单用户系统 问题：昂贵组件的低利用率 批处理系统 多程序系统 保持多个工作在内存中，并且在各工作间复用CPU 分时 定时中断用于工作时对CPU的复用 个人计算机： 效率已不是关注点，易用性为重点 分布式计算： 高可用性与可靠性 操作系统结构大内核结构大内核是将操作系统功能作为一个紧密结合的整体放到内核。 由于各模块共享信息，因此有很高的性能。 微内核结构因为分层结构里面层次过多，效率低下。 尽可能将内核功能迁移到用户空间 用户模块间通信使用消息传递 好处：灵活、安全 缺点：性能。需要频繁在用户态与核心态之间切换 外核结构 让内核分配机器的物理资源给多个应用程序，并让每个程序控制如何使用资源。类似于虚拟机的结构 书籍推荐 操作系统概念（第7版 Abraham Silberschatz） 操作系统精髓与设计原理（第7版 William Stallings） 启动、中断、异常、系统调用中断分类外中断由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。 此外还有时钟中断、控制台中断等。 异常由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 陷入在用户程序中使用系统调用。 BIOS计算机系统的启动过程： CPU加电之后如何启动，在内存当中有一段ROM，有一些数据。 BIOS功能： 为系统启动提供服务 基本输入输出程序：以中断调用的方式提供基本的IO功能 系统设置信息（硬盘启动、光盘启动等） 开机自检 系统自启动程序 BIOS将加载程序加载进来，将操作系统的代码和数据加载到内存。 系统启动流程BIOS：固化在主板上的程序，包括系统设置、自检、系统自启动程序 CPU加电稳定后，在ROM中读第一条指令 CPU初始状态为16位实模式 BIOS初始化 硬件自检POST，检测内存、显卡等工作状态，进行设备初始化 执行系统BIOS，进行系统自检，检测即插即用设备 更新CMOS中的扩展系统配置数据ESCD 主引导记录记录MBR格式 启动代码 硬盘分区表 结束标志 分区引导扇区 跳转指令，跳转到启动代码，与平台相关 文件卷头 启动代码，跳转到加载程序 结束代码 加载程序 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发：并发基础概述]]></title>
    <url>%2F2019%2F02%2F26%2FJava%2Fbase%2FJava%E5%B9%B6%E5%8F%91%EF%BC%9A%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[并发为什么要用从OS的角度讲，多线程处理在OS当中几乎已经时一项必备的功能了，让计算机同时去做几件事情 因为计算机的运算能力强大。而且还因为计算机的运算速度与它的存储、通信子系统速度差距太大，大量时间花费在磁盘IO、网络通信或数据库访问上。而我们不希望将CPU大部分时间都处于等待其他资源的时间上。 一个服务端同时对多个客户端提供服务是另一个更具体地并发应用场景。 从开发的角度讲，线程使得复杂的异步代码变得简单，极大地简化了复杂系统地开发。 并发、高并发相关概念并发：同时拥有两个或多个线程，如果程序在单核处理器上运行，多个线程将交替地还如或者换出内存，线程同时存在， 每个线程都处于执行过程中的某个状态，如果运行在多核处理器上，程序的每个线程都将分配到一个处理器核上，因此可以同时运行。 高并发：通过设计保证系统能够同时并行处理很多请求 多线程线程将复杂、异步的代码转换为更直接、直观的代码，线程是控制和利用多CPU系统计算能力的最简单方式 异步：当烧水的时候，水还在烧，这个时候水是否烧开了引起关注，在任务结束的时候发出信号，一边做其他的事情 多线程将异步操作转换为了顺序，同步的代码 多线程的特点 优势： 发挥多处理的强大能力：同时处理多个请求，响应快，复杂操作可以分为多个线程程同时执行。 充分利用多个CPU的计算资源。在如果设计正确，多线程程序可以通过提高CPU资源的利用率来提升系统吞吐率。 即使单CPU下，提高处理器的资源利用率来提升系统吞吐率。CPU在等待IO时可以做其他的事情。在IO时候，进程在读取文件，CPU在等待文件，因此CPU的资源浪费了，而利用多线程，可以使得在读取第二个文件的时候，处理第一个文件 建模的简单性：在某些情况更简单，将异步的代码转换为顺序的代码，容易维护，更好地模拟人类的工作方式 在单线程上进行文件读取与处理，则必须跟踪每个文件的读取与处理状态。多线程下，可以启动两个线程，每个线程只读取和处理单个文件。 如果在程序中只包含一种类型的任务，比包含多种不同类型任务的程序要更易于编写。使用线程可以讲复杂且异步的工作流进一步分解为一组简单且同步的工作流，每个工作流在一个单独的线程中运行，并在特定的同步位置交互 例如Servlet的开发人员不需要了解有多少请求在同一时刻要被处理，也不需要理解套接字的输入流或输出流是否被阻塞，当调用Servlet的service方法响应请求时，可以用同步方式来处理这给请求，就好像它是应该单线程程序。 异步事件的简化处理 服务器应用程序在接受多个远程客户端的套接字连接请求时，如果为每个连接都分配各自的线程并且使用同步IO，就会降低这类程序的开发难度 对于单线程，如果套接字没有数据到来，读操作将一直堵塞，为了避免该问题，单线程需要使用非阻塞IO(java.nio)，而这种IO复杂性远高于同步IO，并且容易出错。而使用多线程则该请求的阻塞不会影响其他请求的处理 响应更灵敏的用户界面 成本： 安全性问题 访问共享数据的多个线程执行的代码需要特别注意，没有充分同步情况下，多线程的操作执行顺序时不可预测的。线程交互远非简单。错误的线程同步引起的错误很难检测，重现和修复。 上下文切换开销 当CPU从执行一个线程切换到执行另一个线程时，CPU需要保存当前线程的本地数据，程序指针等，并加载下一个线程的本地数据，程序指针等来执行。 上下文切换过程中丢失局部性，并将CPU时间更多的花在线程调度而不是运行上。并且同步机制往往抑制某些编译器优化，使得内存缓冲区中数据无效，增加共享内存总线的同步流量。 资源消耗增加 线程需要来自计算机的一些资源才能运行。除了CPU时间，线程需要一些内存来保持其本地堆栈。它还可能占用管理线程所需的操作系统内部的一些资源。 如何选择正确的线程数 风险： 安全性：多个线程共享数据可能会产生与预期不相符的结果 一个简单的next++分为三步：读取，++，写入新值。由于线程之间可能交替占有运行时，因此可能报错。它取决于运行时如何交替进行这些操作。 同步机制：将方法声明为synchronized可以修正该问题 活跃性：某个操作无法继续执行下去，线程会导致一些在单线程程序中不会出现的问题，例如死锁、饥饿、活锁等。它们依赖于不同线程的事件发生时序，在开发或测试中并不总是能够重现。 性能：线程过多使得CPU频繁切换（上下文切换），调度时间增多；同步机制；消耗过多内存 实际场景对于RMI调用。RMI使得代码能够调用在其他JVM中运行的对象， 但是当RMI调用远程对象时，这个调用将在哪个线程中执行，但一定不是我们创建的线程，而RMI会创建多少个线程，同应该远程对象上的同一个远程方法会不会在多个RMI线程中被同时调用。 远程 对象必须注意两个线程安全性问题：正确地协同在多个对象中共享的状态，以及对远程对象本身状态的访问，RMI对象需要做好被多个线程同时调用的准备。 线程状态 新建（New） 创建后尚未启动。 可运行（Runnable） 可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 阻塞（Blocking） 等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待（Waiting） 等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) 限期等待（Timed Waiting） 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 死亡（Terminated） 可以是线程结束任务之后自己结束，或者产生了异常而结束。 如何设计解决并发问题具体思想编写线程安全的代码，核心在于对状态访问操作进行管理，特别时对共享的和可边的状态的访问。而对象的状态包含了任何可能影响其外部可见行为的数据，其是指存储在实例或者静态域当中的数据，并且可能包括其他依赖对象的域，例如Map中的Entity。 一个对象是否线程安全取决于它是否被多个线程访问。并且至少有一个线程是执行写入操作的。 手段 不在线程间共享该状态变量 将状态变量修改为不可变的变量 在访问状态变量时使用同步。 使用同步 设计线程相对安全的类 在调用线程相对安全的类时，额外进行相关的安全访问。或者防止在调用方进行线程不安全的操作 尽可能使用现有的线程安全对象(Atomic)来管理类的状态，相比于非线程安全的对象，判断线程安全对象的可能状态及其状态转换情况更为容易，也更容易维护和验证线程安全性。 并发及并发的线程安全处理： 多线程并发编程 线程安全性 原子性、可见性、有序性 atomic包 CAS算法 synchronize与Lock、volatile、happes-before 安全发布对象 安全发布方法 不可变对象、final关键字的使用、不可变方法 线程不安全类与写法 线程封闭、同步容器、并发容器 堆栈封闭 ThreadLocal线程封闭、JDBC的线程封闭 同步容器、并发容器 J.U.C AQS等J.U.C组件- 线程调度 线程池好处 new Thread弊端 ThreadPoolExecutor、Executor框架接口 线程安全补充内容 死锁产生于预防 多线程并发的最佳实践 spring的线程安全 hashmap与concurrentHashMap 硬件知识硬件的效率与一致性让计算机并发执行若干个运算任务与更充分地利用计算机处理器地效能间地因果关系，看似顺理成章，其实关系比较复杂 其中一个原因是绝大多数地运算任务都不可能只靠处CPU计算就能完成，CPU至少需要与内存交互，读取运算数据、存储运算结果。而这个IO操作很难消除。 由于计算机地存储设备与CPU运算速度有几个数量级地差距，很多现代OS不得不加入一层速度尽可能接近处理器运算速度的高速缓存。 高速缓存很好地解决了速度矛盾，但带来了另外一个问题。即缓存一致性。每个CPU都有自己地高速缓存，而它们又共享同一主内存。则当多个CPU都涉及同一块主内存区域时，将可能导致各自地缓存数据不一致。因此出现了缓存一致性协议，包括有MESI、MSI、Synapse等。 除了针对内存等，为了使得CPU内部的运算单元能够被充分利用，CPU可能会对输入代码进行乱序执行优化，CPU会在计算后将乱序执行的结果重组，保证该结果与顺序执行的结果一致，但不保证程序中每个语句的计算的先后顺序与代码中一致。 CPU多级缓存高速缓存的配置：数据的读取与存储都经过高速缓存，CPU核心与高速缓存有一条快速通道。主存与高速缓存都连接在系统总线上，并且该主线还用于与其他通信 多级缓存：一级缓存的速度与主存速度拉大。加入二级缓存、三级缓存，速度慢于1级，但是更大 多级缓存的意义： CPU的频率太快，主存无法跟上，在处理器时钟周期内，CPU常常需要等待主存，浪费资源。缓存是为了缓解CPU与内存间速度不匹配的问题 缓存无法存放CPU需要的全部数据，但是由于： 时间局部性：如果某个数据被访问，那么在不久的将来可能再次被访问 空间局部性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问 缓存一致性(MESI协议)利用CPU的嗅探总线实现。 用于保证多个CPU 缓存之间共享数据的一致，定义了cache的四种状态 M：被修改，该缓存只缓存在CPU的缓存中，并且被修改过，与主存数据不一致，需要在某个时间写回主存（这个时间其他CPU不能读取该数据），被写会主存当中后转换为E。 E：独享，只缓存在CPU缓存中，但是没有被修改，与主存数据一致，当其他CPU读取该数据，转换为S，当修改该数据则转换为M S：共享，该缓存可能被多个CPU共享，并与主存一致，如果有一个CPU修改该缓存，则转换为M。其他CPU的缓存转换为I I：无效， 操作： local read：读本地缓存数据 local write：将数据写入本地缓存 remote read：将主存数据读取过来 remote write：将数据写入主存 乱序执行优化 处理器为提高运算速度而做出违背代码原有顺序的优化。在不影响结果的情况下，代码的执行次序可能会发生变化 在多核CPU中，后写入缓存的数据未必真的写入缓存。 多线程并发最佳实践 尽量使用本地变量 使用不可变类 最小化锁的作用域范围 使用线程池的executor，而不是newThread 宁可使用同步也不要使用现场的wait和notify 使用blockingQueue实现生产-消费模式 使用并发集合而不是加了锁的同步集合 使用semaphore创建有界的访问 宁可使用同步代码块，也不使用同步的方法 避免使用静态变量 并发模拟 postman：http请求模拟 Apache bench：测试网站性能 JMeter：压力测试工具 代码：semaphore信号量、CountDownLatch计数器。通常与线程池共同使用 并发模型并发模型与分布式系统相似性在并发系统中，不同的线程彼此通信。在分布式系统中，不同的进程彼此通信（可能在不同的计算机上） 模型一个顺序处理相同类型问题的程序更加简单，更少出错，容易测试。如果处理多种类型的问题， 则需要考虑优先级，时间截止等，较为复杂。 因此，为每一个相同类型任务的程序提供一个线程，提供理想上的顺序，并且将域逻辑与时序调度的细节分割开，进行相互交替的操作，只有在特定的同步点进行彼此间的交互。 并行工人​ 传入的工作分配给不同的工作人员。这是一个说明并行工作者并发模型的图表： ​ 在并行工作者并发模型中，委托者将传入的作业分发给不同的工作者。每个工人完成整个工作。这些工作程序并行工作，在不同的线程中运行，并且可能在不同的CPU上运行。是Java应用程序中最常用的并发模型（虽然这种情况正在发生变化）。 优劣 易于理解。要增加应用程序的并行化，您只需添加更多工作程序。 共享可能变得复杂 参考 java并发编程入门与高并发解决方案 慕课网《Java并发编程入门与高并发面试 》课程学习]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：HTTP协议]]></title>
    <url>%2F2019%2F02%2F26%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9AHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[了解Web及网络基础web是建立在何种技术上，HTTP协议是如何诞生并发展的。 使用HTTP协议访问web。 HTTP超文本传输协议（HYperText Transfer Protocol） 支持CS模式，简单快速、灵活、无连接、无状态。 概述 由两个程序实现：一个客户程序和一个服务器程序。运行在不同的端系统当中，通过交换HTTP报文进行会话。 HTTP定义了这些报文的结构以及客户和服务器进行报文交换的方式。 HTTP定义了web客户向web服务器请求web页面的方式，以及服务器向客户传送web页面的方式。 HTTP使用TCP作为支撑运输协议。一旦连接建立，即可以通过套接字接口访问TCP。 HTTP是无状态协议。不会存储任何关于客户的状态信息。 即使一个客户在短时间内两次请求同一个对象，服务器不会因为刚为该客户提供了对象而不再做出反应，而是重新发送该对象。 简化了服务器设计，允许工程师开发可以同时处理数千TCP连接的高性能web服务器。 web术语 web页面是由对象组成的。 一个对象只是一个文件。如HTML文件、JPEG图形、Java小程序、一个视频片段这样的文件。且它们可通过一个URL地址寻址。 多数web页面含有一个HTML基本文件，以及几个引用对象。 如一个Web页面包含HTML文本和5个JPEG图形，则拥有6个对象。HTML基本文件通过对象的URL地址引用页面的其他对象。 URL组成：存放对象的服务器主机名和对象的路径名。http://www.someSchool.edu(主机名)/someDepartment/picture.gif（路径名）。 web浏览器实现了HTTP的客户端。 web服务器实现了HTTP的服务器端，用于存储web对象，每个对象由URL寻址。流行的服务器由Apache和IIS。 非持续连接与持续连接非持续连接：每个请求\响应对是经一个单独的TCP连接发送，即传输一个请求报文和一个响应报文。 持续连接：所有的请求及响应经相同的TCP连接发送。 采用非持续连接的HTTP 当服务器向客户传送一个web页面（包含1个HTML与10个JPEG，并存储在一台服务器上）。 HTTP客户进程在端口80（HTTP的默认端口，在客户和服务器上分别有一个套接字与该连接相关联）发起一个到服务器www,someSchool.edu的TCP连接。 HTTP客户经它的套接字向该服务器发送一个HTTP请求报文。报文包含路径名/someDepartment/home.index。 HTTP服务器进程经套接字接受该请求报文，从存储器中检索出该对象home.index，在一个HTTP相应报文中封装对象，并通过其套接字发送响应报文。 HTTP服务器进程通知TCP断开该TCP连接。 HTTP客户接受响应报文，TCP连接关闭。报文指出封装的是一个HTML文件，客户从响应报文中提取出文件，检查文件，得到10个JPEG的图形引用。 对每个引用的JPEG重复前步骤（可能串行，可能并行）。 缺陷： 每一个新的请求都要建立和维护一个全新的连接，针对每个链接，在客户和服务器中都要分配TCP的缓冲区和保持TCP变量。 每一个对象经受2倍的RTT交付时延。 持续连接的HTTP 服务器在发送响应后，保持该TCP连接打开，在相同的客户与服务器之间的后续请求和响应报文能够通过相同的连接进行传送。 带流水线的持续连接：一个接一个地发出对对象的请求，而不必等待对未决请求的回答。 不带流水线的。 HTTP报文格式以HTTP1.1为例子： 请求报文 响应报文 cookie用户与服务器的交互：cookie 作用 允许站点对用户进行跟踪，将内容与用户身份联系起来，标识一个用户。 在无状态的HTTP上建立了一个用户会话层。但是对用户隐私的一种侵害 概述 cookie技术的4个组件： 在HTTP响应报文中的一个cookie首部行 在HTTP请求报文中的一个cookie首部行 在用户端系统中保留有一个cookie文件，并由用户的浏览器进行管理 位于web站点的一个后端数据库 cookie实现了站点对用户的跟踪。它可以确切的知道，cookie值为x的用户，按什么顺序、在什么时间访问了哪些页面。因此可以在之后向其推荐相关内容。 web缓存web缓存器也叫代理服务器 作用 web缓存器可以大大减少对客户请求的响应时间，特别是当客户与初始服务器之间的瓶颈带宽远低于客户与web缓存器间的瓶颈带宽 web缓存器可以大大减少一个机构的接入链路到因特网的通信量。因此，该机构不必急于增加带宽，因此降低了费用 整体上大大降低了因特网上的Web流量，改善所有应用性能 概述 能够代表初始web服务器来满足HTTP请求的网络实体。有自己的磁盘存储，在存储空间保存最近请求过的对象的副本。 可以配置用户的浏览器，使得用户的所有HTTP请求首先指向web缓存器 web缓存器通常由ISP购买并安装 CDN内容分发网络（Content Distribution Network）,Web缓存器正在因特网中发挥着越来越重要的作用。 HTTP报文如何创建报文、如何理解报文。 报文是如何流动的 HTTP报文的三个组成部分（起始行、首部和实体的主体部分） 请求和响应报文间的区别 请求报文支持的各种功能（方法） 和响应报文一起返回的各种状态码 各种各样的HTTP首部都是用来干什么的 报文流HTTP报文是在HTTP应用程序间发送的数据块。报文在客户端、服务器和代理间流动。“流出”、“流入”、“上游”、“下游”都是描述报文方向的。 数据块以一些文本形式的元信息开头，描述了报文的内容和含义。 后面跟着可选的数据部分。 报文流入源端服务器HTTP使用术语流入、流出描述事务处理的方向。 报文流入源端服务器，工作完成后，会流回用户的Agent代理中。 报文向下游流动无论是请求报文还是响应报文，所有报文都会向下游流动。 所有报文的发送者都在接收者的上游。 方法服务器并不需要实现所有的方法，如果兼容HTTP1.1，只要为资源实现GET方法和HEAD方法。 即使服务器实现了所有的方法，方法的使用可能也是受限的。如DELETE方法或PUT方法的服务器，可能并不希望任何人都能够删除或存储资源。这些限制通常在服务器的配置当中进行设置的，因此会随着站点和服务器的不同而不同 安全方法HTTP定义了安全方法包括GET、HEAD方法。 目的是允许HTTP应用程序开发者通知用户，什么时候会使用某个可能引发动作的不安全方法。 安全方法意味着使用GET或HEAD方法的HTTP请求都不会产生什么动作。 不产生动作：HTTP请求不会再服务器上产生什么结果。 并不一定什么动作都不执行，实际上是由WEB开发者决定的。 Get通常用于请求服务器发送某个资源。HTTP1.1要求服务器实现该方法。 HEAD与GET类似，服务器在响应中只返回首部，不会反悔实体的主体部分。HTTP1.1要求实现该方法 允许客户端在未获取实际资源的情况下，对资源的首部进行检查。判断其类型 通过查看响应中的状态码，查看某个对象是否存在 通过查看首部，测试资源是否被修改了。 服务器开发者必须确保HEAD方法返回的首部与GET请求返回的首部完全相同。 PUT向服务器写入文档。 PUT：让服务器用请求的主体部分来创建一个由所请求的URL命名的新文档。如果该URL已经存在，则用这个主体替代它。 由于PUT允许用户对内容进行修改，因此很多web服务器要求在执行PUT前用密码登录 POST起初是用来向服务器输入数据的。 通常用于支持表单。 使用post请求的情况 无法使用缓存文件（更新服务器上的文件或数据库） 向服务器发送大量数据 发送包含未知字符的用户输入时，post比Get更稳定可靠 Post比Get安全性更高 Get与Post区别 HTTP报文层面：Get将请求放在URL当中，POST将请求放在保文体中。 数据库层面：GET符合幂等性和安全性。POST不符合。 幂等：对数据库一次操作与多次操作结果一致。 安全性：对数据库不会改变。 其他层面：GET可以被缓存、被存储，POST不可以。 TRACETRACE方法允许客户端在最终将请求发送给服务器时，看看它变成了什么样子 客户端发起一个请求，这个请求可能要穿过防火墙、代理、网关或其他一些应用程序。每个中间节点都可能会修改原始的HTTP请求 OPTIONS请求WEB服务器告知其支持的各种功能。 DELETE请服务器删除请求URL所指定的资源。 但是客户端应用程序无法保证删除操作一定会执行，HTTP规范允许服务在不通知客户端的情况下撤销请求。 综述Get和Post的区别 get被服务器强制支持 浏览器对URL长度有限制，因此get请求不能代替post发送大量数据 get请求发送数据量更小 get请求是幂等的 Post请求不能被缓存 post请求相对于Get是安全的 状态Cookie 是由服务发送给客户端的特殊信息，以文本的形式存放在客户端。 客户端再次请求时，会将Cokkie回发。 服务器接收后，会解析Cookie生成与客户端相对应的内容。 Session 服务器端的机制，在服务器上保存的信息。 解析客户端请求并操作session id，按需保存状态信息。 实现方式： Cookie来实现。 URL回写实现，返回给浏览器的地址都带着Session。 Session与Cookie区别 Session更安全。 Cookie在浏览器，Session在服务器，并对服务器有一定压力。 状态码1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：服务器受到请求，但是请求被拒绝。 404 Not Found：找不到资源。 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误，可能是代码抛出异常。 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 HTTPSHTTP协议中有可能存在信息窃听或身份伪装等安全问题。 HTTPS通信机制可以有效地防止这些问题。 HTTP的缺点 通信使用明文（不加密），内容可能被窃听 不验证通信方的身份，因此有可能遭遇伪装 无法证明报文的完整性，所以有可能已遭篡改 等 通信使用明文可能被窃听 HTTP本身不具备加密的功能，因此也无法做到对通信整体进行加密。 TCP/IP是可能被窃听的网络 以TCP/IP的工作机制，通信内容在所有的通信线路上都有可能遭到窥视。 即使已经过加密处理的通信，也会被窥视到通信内容，只是可能让人无法破译密文的含义 窃听方式：收集在互联网上流动的数据包（帧） 对于收集来的数据包的解析工作，可通过抓包或者嗅探工具 加密处理可防止被窃听 加密对象： 通信的加密。 通过和SSL或TLS组合使用，加密HTTP的通信内容。 内容的加密 将报文中包含的内容进行加密处理，客户端需要对HTTP报文进行加密处理后再发送请求 要求客户端和服务端具备加密和解密机制。 内容具有被篡改的风险 不验证通信方的身份，因此有可能遭遇伪装 即存在服务器是否就是发送请求中URI真正指定的主机？ 返回的响应是否真的返回实际提出请求的客户端等问题。 任何人都可发起请求。不存在确认通信方的处理步骤，服务器只要接受到请求，就会返回一个响应 无法确认请求发送至目标的web服务器是否按真实意图返回响应的那台服务器，可能是已伪装的web服务器 无法确认响应返回到的客户端是否按真实意图接受响应的那个客户端，可能是已伪装的客户端 无法确定正在通信的双方是否具备访问权限。因为某些web服务器上保存着重要信息，只想发送给特定用户通信的权限 无法判定请求是来自何方、出自谁手 即使是无意义的请求也会照单全收。无法阻止海量请求下的DOS攻击 查明对手的证书 SSL使用了证书的手段，用于确认方 伪造证书从技术角度讲异常困难。通过确认通信方持有的证书，即可判断通信方的真实意图 服务器持有证书，即意料中的服务器 客户端持有证书，即完成个人信息的确认，页可以用于对web网站的认证环节 无法证明报文完整性、可能已经被篡改 没有办法确认，发出的请求/响应和接受到的请求/响应是前后相同的。 文件可能在传输途中被更改（中间人攻击MITM） 防止篡改： MD5与SHA-1等散列值校验的方法 用来确认文件的数字签名方法 都需要客户端的用户本人亲自检查验证是否是原来服务器上的文件，浏览器无法自动帮助用户检查 如果数字前面与MD5本身被改写，用户是没有办法意识到的。 HTTPS定义HTTP+加密+认证+完整性保护=HTTPS HTTPS是身披SSL外壳的HTTP。 当使用SSL，HTTP先和SSL通信，SSL再和TCP通信。 数据传输流程 浏览器将支持的加密算法信息发送给服务器。 服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器。 浏览器验证证书合法性，并结合证书公钥加密信息发送给服务器。 服务器使用私钥解密信息，验证哈希，加密响应消息回发浏览器。 浏览器解密响应消息，并对消息进行验证，之后进行加密交互数据。 与HTTP区别 HTTPS需要到CA申请证书 HTTPS密文传输 HTTPS默认443端口，HTTP是80端口 HTTP+加密+认证+完整性保护=HTTPS，安全一些 HTTPS真正安全吗浏览器默认填充http://，请求需要进行跳转时有被劫持的风险。 SSL 为网络通信提供安全及数据完整性的一种安全协议。 是OS对外的API，SSL3.0后更名为TLS。 采用身份验证和数据加密保证网络通信的安全和数据的完整性。 加密方式 对称加密。 非对称加密。 哈希算法。 数字签名。 SSL采用混合加密机制 参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[计算机网络：面试准备]]></title>
    <url>%2F2019%2F02%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[计算机网络与因特网因特网具体构成描述： 端系统（或称主机）通过通信链路和分组交换机连接到一起。链路的传输速率为bit/s，当主机间发送数据，发送端将数据分段，并为每段数据加上首部字节，形成的信息包为分组。分组交换机（包含路由器与链路层交换机）从它的一条入通信链路接受到达的分组，从它的一条出通信链路转发分组。一个分组所经历的一系列通信链路和分组交换机称为通过该网络的路径。 端系统通过因特网服务提供商（ISP）接入网络，每个ISP是一个由多个分组交换机和多段通信链路组成的网络。 协议 一个协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及报文发送和/或接受一条报文或其他事件所采取的行动 网络核心分组交换 存储转发交换：多数的分组交换机在链路的输入端使用存储转发交换机制。即在交换机能够开始向输出链路传输该分组的第一个比特前，必须接受到整个分组。 排队时延和分组丢失：对于每条相连的链路，该分组交换机具有一个输出缓存，用于存储路由器准备发往那条链路的分组。当缓存已满，则到达的分组或者排队之一的分组将被丢弃。 转发表和路由选择协议： 电路交换 电路交换、分组交换：通过网络链路和交换机移动数据的两种基本方法。 电路交换中，在会话期间预留了端系统间通信沿路径所需要的资源。（电话） 频分复用 要传送的信号带宽是有限的，而线路可使用的带宽则远远大于要传送的信号带宽，通过对多路信号采用不同频率进行调制的方法，使调制后的各路信号在频率位置上错开，以达到多路信号同时在一个信道内传输的目的。因此，频分复用的各路信号是在时间上重叠而在频谱上不重叠的信号 时分复用 时延、丢包、吞吐量 时延： 结点处理时延（检验分组首部和决定将该分组导向何处） 排队时延（在输出队列中的等待时间） 传输时延（将分组推向链路） 传播时延（在链路向路由器传播） 吞吐量：服务器到客户端的传输速率是min{链宽} 面对攻击的网络 自我复制：感染一台主机后，从该主机寻求进入其他主机的方式 病毒：需要某种形式的用户交互来感染设备 蠕虫：无需明显交互的 DOS攻击： 弱点攻击：向容易受到攻击的程序制作精细的报文 带宽泛洪：向主机发送大量分组，使得接入链路拥堵 连路洪泛：创建大量TCP连接，停止接受合法TCP连接 嗅探分组： 检测网络上的分组，并保存副本 冒充： 生成精细的分组，发送的网络中，进行IP哄骗。 应用层域名系统DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传来保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 文件传送协议FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。 动态主机配置协议DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 DHCP 工作过程如下： 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 远程登录协议TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTPSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 2. POP3POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 3. IMAPIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 参考]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刷题小结]]></title>
    <url>%2F2019%2F02%2F17%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[思路问题类型 解决 双指针 遍历数组 寻找链表的环 节约遍历时间 反转，回文 位运算异或运算 利用 x ^ 1s = ~x 的特点，可以将位级表示翻转；利用 x ^ x = 0 的特点，可以将三个数中重复的两个数去除，只留下另一个数。 利用 x &amp; 0s = 0 和 x &amp; 1s = x 的特点，可以实现掩码操作。一个数 num 与 mask：00111100 进行位与操作，只保留 num 中与 mask 的 1 部分相对应的位。 利用 x | 0s = x 和 x | 1s = 1s 的特点，可以实现设值操作。一个数 num 与 mask：00111100 进行位或操作，将 num 中与 mask 的 1 部分相对应的位都设置为 1。 位与运算 n&amp;(n-1) 去除 n 的位级表示中最低的那一位。例如对于二进制表示 10110100，减去 1 得到 10110011，这两个数相与得到 10110000。 n&amp;(-n) 得到 n 的位级表示中最低的那一位。-n 得到 n 的反码加 1，对于二进制表示 10110100，-n 得到 01001100，相与得到 00000100。 n-n&amp;(~n+1) 去除 n 的位级表示中最高的那一位。 排序 快速排序 Kth Element 问题，使用快速排序的 partition() 进行实现。 堆排序 求解 TopK Elements 问题，通过维护一个大小为 K 的堆，堆中的元素就是 TopK Elements。 Kth Element 问题，堆顶元素就是 Kth Element。 桶排序 出现频率最多的 k 个数 分治法 从问题的最小解开始，左右问题相互独立 利用递归（树是一种经典问题） 字符串 使用长度为 256 的整型数组来统计每个字符出现的个数，每个字符有偶数个可以用来构成回文字符串。 搜索广度优先BFS 可以求解最短路径等 最优解 问题：第一次遍历到目的节点，其所经过的路径为最短路径。应该注意的是，使用 BFS 只能求解无权图的最短路径。 队列：用来存储每一轮遍历得到的节点； 标记：对于遍历过的节点，应该将它标记，防止重复遍历。 java pair,配对，用于返回两个值 深度优先DFS 用来求解 可达性 问题。 栈：用栈来保存当前节点信息，当遍历新节点返回时能够继续遍历当前节点。可以使用递归栈。 标记：和 BFS 一样同样需要对已经遍历过的节点进行标记。 回溯法Backtracking Backtracking 主要用于求解 排列组合 问题 例如有 { ‘a’,’b’,’c’ } 三个字符，求解所有由这三个字符排列得到的字符串，这种问题在执行到特定的位置返回之后还会继续执行求解过程。 因为 Backtracking 不是立即就返回，而要继续求解，因此在程序实现时，需要注意对元素的标记问题： 在访问一个新元素进入新的递归调用时，需要将新元素标记为已经访问，这样才能在继续递归调用时不用重复访问该元素； 但是在递归返回时，需要将元素标记为未访问，因为只需要保证在一个递归链中不同时访问一个元素，可以访问已经访问过但是不在当前递归链中的元素。 动态规划​ 后面的状态依赖于前面已知的状态，根据前面已知，以及最新的数字，可以对后面状态进行推导 0-1背包问题​ 题目描述：有一个容量为 N 的背包，要用这个背包装下物品的价值最大，这些物品有两个属性：体积 w 和价值 v。 将容量N，价值MaxV的问题，分解到了求在容量1-N下，价值MaxV的问题 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。设第 i 件物品体积为 w，价值为 v，根据第 i 件物品是否添加到背包中，可以分两种情况讨论： 第 i 件物品没添加到背包，总体积不超过 j 的前 i 件物品的最大价值就是总体积不超过 j 的前 i-1 件物品的最大价值，dpij = dp(i-1)j。 第 i 件物品添加到背包中，dpij= dp(i-1)(j-w) + v。 ​ 在程序实现时可以对 0-1 背包做优化。观察状态转移方程可以知道，前 i 件物品的状态仅与前 i-1 件物品的状态有关，因此可以将 dp 定义为一维数组，其中 dp[j] 既可以表示 dp(i-1)j 也可以表示 dpij。此时， ​ 因为 dp[j-w] 表示 dp[i-1][j-w]，因此不能先求 dp[i][j-w]，以防将 dp[i-1][j-w] 覆盖。也就是说要先计算 dp[i][j] 再计算 dp[i][j-w]，在程序实现时需要按倒序来循环求解。 123456789101112public int knapsack(int W, int N, int[] weights, int[] values) &#123; int[] dp = new int[W + 1]; for (int i = 1; i &lt;= N; i++) &#123; int w = weights[i - 1], v = values[i - 1]; for (int j = W; j &gt;= 1; j--) &#123; if (j &gt;= w) &#123; dp[j] = Math.max(dp[j], dp[j - w] + v); &#125; &#125; &#125; return dp[W];&#125; 完全背包问题​ 0-1 背包和完全背包在实现上的不同之处是，0-1 背包对物品的迭代是在最外层，而完全背包对物品的迭代是在最里层。 数据结构相关链表 如果是两个链表找交点，找环，一般都是走两个指针 总结算法是对数据的加工技巧。 参考 CyC2018]]></content>
  </entry>
  <entry>
    <title><![CDATA[操作系统概念总览]]></title>
    <url>%2F2019%2F02%2F14%2FOS%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%E6%80%BB%E8%A7%88%2F</url>
    <content type="text"><![CDATA[进程之间的资源不共享，是系统分配资源的基本单位，因此不能够创建多个进程去进行并行处理一个文件。共享内存是另一种 线程无法利用时钟强制中断线程让出cpu，需要使用线程调用therd_yield，通过编程解决 二、进程管理进程与线程1. 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 2. 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 3. 区别Ⅰ 拥有资源 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 Ⅱ 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 Ⅲ 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 Ⅳ 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度​ 当多个进程或线程处于就绪状态，对CPU的资源进行竞争，选择下一个要运行的进程，即调度 进程切换代价 用户态必须切换到内核态，保存当前进程的状态，内存映像也需要保存 将新进程的内存映像装入MMU，新进程开始运行 整个内存的高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核、离开内核） 进程行为 ​ 计算密集型进程：具有较长时间的CPU集中使用与较短的IO等待 ​ IO密集型进程：具有较短时间的CPU集中使用与频繁的IO等待，（IO调度更为重要） ​ 在IO开始后无论处理数据是多还是少，必须花费同样的时间提出硬件请求读取磁盘块。更多的进程开始倾向为IO密集型，因为CPU的改进比磁盘更快。如果需要运行IO密集型进程，就应该让它尽早得到机会，以便使得磁盘始终忙碌。 调度算法 ​ 不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。 1. 批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。 1.1 先来先服务 first-come first-serverd（FCFS） 按照请求的顺序进行调度。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 按估计运行时间最短的顺序进行调度。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 按估计剩余时间最短的顺序进行调度。 2. 交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。 2.1 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 为每个进程分配一个优先级，按优先级进行调度。 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 2.3 多级反馈队列 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 3. 实时系统实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步1. 临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 123// entry section// critical section;// exit section 2. 同步与互斥 同步：多个进程按一定顺序执行； 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE) &#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); consume_item(item); up(&amp;mutex); up(&amp;empty); &#125;&#125; 4. 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。 1234567891011121314monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end;end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 使用管程实现生产者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142// 管程monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end;end monitor;// 生产者客户端procedure producerbegin while true do begin item = produce_item; ProducerConsumer.insert(item); endend;// 消费者客户端procedure consumerbegin while true do begin item = ProducerConsumer.remove; consume_item(item); endend; 经典同步问题生产者和消费者问题前面已经讨论过了。 1. 读者-写者问题允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。 一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1;semaphore data_mutex = 1;int count = 0;void reader() &#123; while(TRUE) &#123; down(&amp;count_mutex); count++; if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(&amp;count_mutex); read(); down(&amp;count_mutex); count--; if(count == 0) up(&amp;data_mutex); up(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; down(&amp;data_mutex); write(); up(&amp;data_mutex); &#125;&#125; 以下内容由 @Bandi Yugandhar 提供。 The first case may result Writer to starve. This case favous Writers i.e no writer, once added to the queue, shall be kept waiting longer than absolutely necessary(only when there are readers that entered the queue before the writer). 12345678910111213141516171819202122232425262728293031323334353637383940414243444546int readcount, writecount; //(initial value = 0)semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)//READERvoid reader() &#123;&lt;ENTRY Section&gt; down(&amp;readLock); // reader is trying to enter down(&amp;rmutex); // lock to increase readcount readcount++; if (readcount == 1) down(&amp;resource); //if you are the first reader then lock the resource up(&amp;rmutex); //release for other readers up(&amp;readLock); //Done with trying to access the resource&lt;CRITICAL Section&gt;//reading is performed&lt;EXIT Section&gt; down(&amp;rmutex); //reserve exit section - avoids race condition with readers readcount--; //indicate you&apos;re leaving if (readcount == 0) //checks if you are last reader leaving up(&amp;resource); //if last, you must release the locked resource up(&amp;rmutex); //release exit section for other readers&#125;//WRITERvoid writer() &#123; &lt;ENTRY Section&gt; down(&amp;wmutex); //reserve entry section for writers - avoids race conditions writecount++; //report yourself as a writer entering if (writecount == 1) //checks if you&apos;re first writer down(&amp;readLock); //if you&apos;re first, then you must lock the readers out. Prevent them from trying to enter CS up(&amp;wmutex); //release entry section&lt;CRITICAL Section&gt; down(&amp;resource); //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource //writing is performed up(&amp;resource); //release file&lt;EXIT Section&gt; down(&amp;wmutex); //reserve exit section writecount--; //indicate you&apos;re leaving if (writecount == 0) //checks if you&apos;re the last writer up(&amp;readLock); //if you&apos;re last writer, you must unlock the readers. Allows them to try enter CS for reading up(&amp;wmutex); //release exit section&#125; We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue. From the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int readCount; // init to 0; number of readers currently accessing resource// all semaphores initialised to 1Semaphore resourceAccess; // controls access (read/write) to the resourceSemaphore readCountAccess; // for syncing changes to shared variable readCountSemaphore serviceQueue; // FAIRNESS: preserves ordering of requests (signaling must be FIFO)void writer()&#123; down(&amp;serviceQueue); // wait in line to be servicexs // &lt;ENTER&gt; down(&amp;resourceAccess); // request exclusive access to resource // &lt;/ENTER&gt; up(&amp;serviceQueue); // let next in line be serviced // &lt;WRITE&gt; writeResource(); // writing is performed // &lt;/WRITE&gt; // &lt;EXIT&gt; up(&amp;resourceAccess); // release resource access for next reader/writer // &lt;/EXIT&gt;&#125;void reader()&#123; down(&amp;serviceQueue); // wait in line to be serviced down(&amp;readCountAccess); // request exclusive access to readCount // &lt;ENTER&gt; if (readCount == 0) // if there are no readers already reading: down(&amp;resourceAccess); // request resource access for readers (writers blocked) readCount++; // update count of active readers // &lt;/ENTER&gt; up(&amp;serviceQueue); // let next in line be serviced up(&amp;readCountAccess); // release access to readCount // &lt;READ&gt; readResource(); // reading is performed // &lt;/READ&gt; down(&amp;readCountAccess); // request exclusive access to readCount // &lt;EXIT&gt; readCount--; // update count of active readers if (readCount == 0) // if there are no readers left: up(&amp;resourceAccess); // release resource access for all // &lt;/EXIT&gt; up(&amp;readCountAccess); // release access to readCount&#125; 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(TRUE) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，可以设置两个条件： 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N // 右邻居#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // 跟踪每个哲学家的状态semaphore mutex = 1; // 临界区的互斥semaphore s[N]; // 每个哲学家一个信号量void philosopher(int i) &#123; while(TRUE) &#123; think(); take_two(i); eat(); put_two(i); &#125;&#125;void take_two(int i) &#123; down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);&#125;void put_two(i) &#123; down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);&#125;void test(i) &#123; // 尝试拿起两把筷子 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123; state[i] = EATING; up(&amp;s[i]); &#125;&#125; 进程通信进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 管道管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 12#include &lt;unistd.h&gt;int pipe(int fd[2]); 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程中使用。 2. FIFO也称为命名管道，去除了管道只能在父子进程中使用的限制。 123#include &lt;sys/stat.h&gt;int mkfifo(const char *path, mode_t mode);int mkfifoat(int fd, const char *path, mode_t mode); FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3. 消息队列相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 4. 信号量它是一个计数器，用于为多个进程提供对共享数据对象的访问。down与up操作 5.共享存储允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用使用内存的匿名段。 6. 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 竞争条件​ 协作的进程可能共享一些彼此公用的存储区，最后的结果取决于进程运行的精确时序（涉及到时钟中断等原因） 临界区​ 用于阻止多个进程同时读写共享数据，方法便是实现互斥访问 屏蔽中断，当访问临界区，则屏蔽对进程的中断，该方案对于OS并不明智 锁变量，但是依然存在竞争条件的问题 严格轮换，设置值去记录轮转到可以进入临界区的进程。 等等 内存管理分层存储器体系： ​ 若干M快速、昂贵、易失的高速缓存cache,数G的速度与价格适中，易失的内存，数TB的低俗、廉价、非易失的磁盘+USB等 ​ 任务：有效管理内存、记录哪些内存正在使用、哪些空闲、在进程需要时分配内存，使用完释放内存。 存储器抽象 ​ 如果将物理地址暴露给进程会带来危险 如果用户进程可以寻址内存的每个字节，就可以很容易破坏OS 运行多个程序将十分困难 要保证多个程序同时处于内存并不相互影响，则需要解决两个问题：保护、重定位 ​ 创造一个新的内存抽象：地址空间，地址空间是一个进程可用于寻址内存的一套地址集合。每个进程有其独立的一个地址空间。 交换技术 ​ 由于内存无法保存所有的进程，因此需要对进程进行处理。有两种处理内存超载的通用方法：交换与虚拟内存。 ​ 交换：将一个进程完整地调入内存，使该进程运行一段时间，然后存入磁盘。 虚拟内存需要运行的程序往往大到内存无法容纳，且系统必须同时支持多个程序同时运行 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。 从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。 分页 虚拟地址空间按照固定大小划分成称为页面的若干单元，在物理内存中对应的单元称为页框（一般与页面大小一致）。RAM与磁盘间的交换通常以整个页面为单元进行。 缺页中断：由于虚拟内存大于物理内存，因此如果访问到了没有映射的页面，则发生缺页中断，OS找到一个很少使用的页框将其写入磁盘，随后将缺失的页面写入内存，重新执行上次的指令。 页表 虚拟内存到物理地址的映射：虚拟地址被分成虚拟页号（页表索引，由页表找到页框号）与偏移量（地址字节偏量,与页框号组合形成物理地址） 加速分页过程 两个主要问题 虚拟内存到物理地址的映射必须非常快 如果虚拟地址空间很大，页表也会很大 每个进程都有自己的页表，因为它有自己的虚拟地址空间 ​ 转换检测缓冲区TLB 基于：大多数程序总是对少量的页面进行多次访问 加快虚拟地址到物理地址的转换 针对大内存的页表 多级页表，针对32位系统，在64位系统当中，页表过于庞大 倒排页表，在实际内存中，每一个页框有一个表项，而不是每一个虚拟内存有一个表项。 虚拟地址到物理地址的转换较困难，无法通过索引，而必须对整个页表进行查找才能找到对应的页 使用TLB解决，全局搜索使用散列表 分页系统地址映射内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。 页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 1. 最佳 OPT, Optimal replacement algorithm 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列： 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。 2. 最近最久未使用 LRU, Least Recently Used 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 3. 最近未使用 NRU, Not Recently Used 每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 4. 先进先出 FIFO, First In First Out 选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 5. 第二次机会算法FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改： 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 6. 时钟 Clock 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 分页系统的设计局部分配策略与全局分配策略 怎么样在相互竞争的可运行进程间分配内存 局部：淘汰进程中最差的页面 全局：淘汰整个内存当中最差的页面 分段虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。 下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。 段页式程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。 分页与分段的比较 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。 地址空间的维度：分页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变。 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 参考]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用算法：查找算法]]></title>
    <url>%2F2019%2F02%2F12%2F%E7%AE%97%E6%B3%95%2F%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%EF%BC%9A%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概述 顺序查找 二分查找 基于二分的优化： 斐波那契查找 插值查找 树表查找 二叉树查找 平衡查找树之2-3查找树 平衡查找树之2-3红黑树 B树 B+树 分块查找 哈希查找 分类静态查找与动态查找 静态或者动态都是针对查找表而言的。动态表指查找表中有删除和插入操作的表。 无序查找与有序查找 无序查找：被查找数列有序无序均可； 有序查找：被查找数列必须为有序数列。 查找算法插值查找概述​ 二分查找对于middle的划分属于傻瓜式。打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。 ​ 改进法：mid=low+(key-a[low])/(a[high]-a[low])*(high-low)，即将1/2改为自适应的参数 斐波那契查找​ 基于黄金分割比例，斐波那契数列中，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618 ​ 他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1; 树查找二叉查找树概念​ 基本思想：二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。 二叉查找树（BinarySearch Tree，也叫二叉搜索树，或称二叉排序树Binary Sort Tree）或者是一棵空树，或者是具有下列性质的二叉树： 1. 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 2. 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 3. 任意节点的左、右子树也分别为二叉查找树。 二叉查找树性质：对二叉查找树进行中序遍历，即可得到有序的数列。 平衡查找树之2-3查找树概念​ 2-3查找树定义：和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node)，他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key，2-3查找树的定义如下： 要么为空，要么： 对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。 对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。 性质 如果中序遍历2-3查找树，就可以得到排好序的序列； 在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。） 平衡查找树之红黑树​ 2-3查找树能保证在插入元素之后能保持树的平衡状态，最坏情况下即所有的子节点都是2-node，树的高度为lgn，从而保证了最坏情况下的时间复杂度。但是2-3树实现起来比较复杂，于是就有了一种简单实现2-3树的数据结构，即红黑树（Red-Black Tree）。 概念 基本思想：红黑树的思想就是对2-3查找树进行编码，尤其是对2-3查找树中的3-nodes节点添加额外的信息。红黑树中将节点之间的链接分为两种不同类型，红色链接，他用来链接两个2-nodes节点来表示一个3-nodes节点。黑色链接用来链接普通的2-3节点。特别的，使用红色链接的两个2-nodes来表示一个3-nodes节点，并且向左倾斜，即一个2-node是另一个2-node的左子节点。这种做法的好处是查找的时候不用做任何修改，和普通的二叉查找树相同。 ​ 定义:红黑树是一种具有红色和黑色链接的平衡查找树，同时满足： 红色节点向左倾斜 一个节点不可能有两个红色链接 整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同。 如果我们将红色的连线水平绘制，那么他链接的两个2-node节点就是2-3树中的一个3-node节点了。 性质​ 整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同（2-3树的第2）性质，从根节点到叶子节点的距离都相等）。 ​ 红黑树的平均高度大约为logn。 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。 ​ 复杂度分析：最坏的情况就是，红黑树中除了最左侧路径全部是由3-node节点组成，即红黑相间的路径长度是全黑路径长度的2倍。 平衡性的修正​ 在红-黑树中插入的节点都是红色的，这不是偶然的，因为插入一个红色节点比插入一个黑色节点违背红-黑规则的可能性更小。原因是：插入黑色节点总会改变黑色高度（违背规则4），但是插入红色节点只有一半的机会会违背规则3。另外违背规则3比违背规则4要更容易修正。 ​ 红-黑树主要通过三种方式对平衡进行修正： 改变节点颜色​ 改变节点颜色比较容易理解，因为它违背了规则3。假设现在有个节点E，然后插入节点A和节点S，节点A在左子节点，S在右子节点，目前是平衡的。如果此时再插一个节点，那么就出现了不平衡了，因为红色节点的子节点必须为黑色，但是新插的节点是红色的。所以这时候就必须改变节点颜色了。所以我们将根的两个子节点从红色变为黑色（至于为什么都要变，下面插入的时候会详细介绍），将父节点会从黑色变成红色。可以用如下示意图表示一下： 左旋​ 通常左旋操作用于将一个向右倾斜的红色链接旋转为向左链接 右旋 B树​ 在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统 概念定义： B树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。 根节点至少有两个子节点 每个节点有M-1个key，并且以升序排列 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间 其它节点至少有M/2个子节点 B+树参考 [[Data Structure &amp; Algorithm] 七大查找算法 数据结构和算法05 红-黑树（看完包懂~]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常用算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库]]></title>
    <url>%2F2019%2F02%2F12%2F%E9%9D%A2%E8%AF%95%2F%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[查询什么是 内连接、外连接、交叉连接、笛卡尔积等？内连接内连接查询操作列出与连接条件匹配的数据行，它使用比较运算符比较被连接列的 列值。 内连接分三种： 等值连接：在连接条件中使用等于号(=)运算符比较被连接列的列值，其查询结 果中列出被连接表中的所有列，包括其中的重复列。 例，下面使用等值连接列出authors和publishers表中位于同一城市的作者和出版社： 12SELECT * FROM authors AS a INNER JOIN publishers AS p ON a.city=p.city 复制代码 不等连接： 在连接条件使用除等于运算符以外的其它比较运算符比较被连接的 列的列值。这些运算符包括&gt;、&gt;=、&lt;=、&lt;、!&gt;、!&lt;和&lt;&gt;。 自然连接：在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选 择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。 例，在选择列表中删除authors 和publishers 表中重复列(city和state)： 12SELECT a.*,p.pub_id,p.pub_name,p.country FROM authors AS a INNER JOIN publishers AS p ON a.city=p.city复制代码 外连接​ 外连接，返回到查询结果集合中的不仅包含符合连接条件的行，而且还包括左表(左外连接或左连接)、右表(右外连接或右连接)或两个边接表(全外连接)中的所有数据行。 left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录。 right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录。 例如1： 12SELECT a.*,b.* FROM luntan LEFT JOIN usertable as b ON a.username=b.username复制代码 例如2： 12SELECT a.*,b.* FROM city as a FULL OUTER JOIN user as b ON a.username=b.username复制代码 交叉连接​ 交叉连接不带 WHERE 子句，它返回被连接的两个表所有数据行的“笛卡尔积”，返回到结果集合中的数据行数等于第一个表中符合查询条件的数据行数乘以第二个表中符合查询条件的数据行数。 例，titles表中有6类图书，而publishers表中有8家出版社，则下 列交叉连接检索到的记录数将等于6*8=48行。 12SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type复制代码 笛卡尔积​ 笛卡尔积是两个表每一个字段相互匹配，去掉where 或者inner join的等值 得出的结果就是笛卡尔积。笛卡尔积也等同于交叉连接。 总结 内连接: 只连接匹配的行。 左外连接: 包含左边表的全部行（不管右边的表中是否存在与它们匹配的行），以及右边表中全部匹配的行。 右外连接: 包含右边表的全部行（不管左边的表中是否存在与它们匹配的行），以及左边表中全部匹配的行。 全外连接: 包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行。 交叉连接 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配。 范式 第一范式（1NF）：符合1NF的关系中的每个属性都不可再分。是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。 第二范式（2NF）：2NF在1NF的基础之上，消除了非主属性对于码的部分函数依赖，应当是完全依赖。 第三范式（3NF）：3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖。 索引​ 索引是一种数据结构 。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 B树和B+树的区别 在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。 B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。 使用B树的好处​ B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。 使用B+树的好处​ 由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间 数据库为什么使用B+树而不是B树 B树只适合随机检索，而B+树同时支持随机检索和顺序检索； B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素； B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。 B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。 增删文件（节点）时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。 数据库索引为什么要用 B+ 树而不用红黑树呢？​ AVL 数和红黑树基本都是存储在内存中才会使用的数据结构，那磁盘中会有什么不同呢？ ​ 这就要牵扯到磁盘的存储原理了,操作系统读写磁盘的基本单位是扇区，而文件系统的基本单位是簇(Cluster)。,也就是说，磁盘读写有一个最少内容的限制，即使我们只需要这个簇上的一个字节的内容，我们也要含着泪把一整个簇上的内容读完。 ​ 那么，现在问题就来了,一个父节点只有 2 个子节点，并不能填满一个簇上的所有内容啊？那多余的内容岂不是要浪费了？我们怎么才能把浪费的这部分内容利用起来呢？哈哈，答案就是 B+ 树。由于 B+ 树分支比二叉树更多，所以相同数量的内容，B+ 树的深度更浅，深度代表什么？代表磁盘 io 次数啊！数据库设计的时候 B+ 树有多少个分支都是按照磁盘一个簇上最多能放多少节点设计的啊！ MySQL B+Tree索引和Hash索引的区别？ Hash索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位; B+树索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问; 那为什么大家不都用Hash索引而还要使用B+树索引呢？ Hash索引 Hash索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询,因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样； Hash索引无法被用来避免数据的排序操作，因为Hash值的大小关系并不一定和Hash运算前的键值完全一样； Hash索引不能利用部分索引键查询，对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用； Hash索引在任何时候都不能避免表扫描，由于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要回表查询数据； Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B+树索引高。 B+Tree索引​ MySQL中，只有HEAP/MEMORY引擎才显示支持Hash索引。 ​ 常用的InnoDB引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况，如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引），通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。 B+树索引和哈希索引的明显区别是： 如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据； 如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索； 同理，哈希索引没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）； 哈希索引也不支持多列联合索引的最左匹配规则； B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。 在大多数场景下，都会有范围查询、排序、分组等查询特征，用B+树索引就可以了。 索引类型 主键索引: 数据列不允许重复，不允许为NULL.一个表只能有一个主键。 唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。 普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。 聚集索引(Clustered)：表中各行的物理顺序与键值的逻辑（索引）顺序相同，每个表只能有一个 含有大量非重复值的列。 使用BETWEEN,&gt;,&gt;=,&lt;或&lt;=返回一个范围值的列 被连续访问的列 返回大型结果集的查询 经常被使用连接或GROUP BY子句的查询访问的列 非聚集索引(Non-clustered)：非聚集索引指定表的逻辑顺序。数据存储在一个位置，索引存储在另一个位置，索引中包含指向数据存储位置的指针。可以有多个，小于249个 索引的缺点 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度； 空间方面：索引需要占物理空间。 优点 索引加快数据库的检索速度 索引降低了插入、删除、修改等维护任务的速度 唯一索引可以确保每一行数据的唯一性 通过使用索引，可以在查询的过程中使用优化隐藏器，提高系统的性能 索引需要占物理和数据空间 使用索引查询一定能提高查询的性能吗？为什么​ 通常,通过索引查询数据比全表扫描要快.但是我们也必须注意到它的代价. ​ 索引需要空间来存储,也需要定期维护, 每当有记录在表中增减或索引列被修改时,索引本身也会被修改. 这意味着每条记录的INSERT,DELETE,UPDATE将为此多付出4,5 次的磁盘I/O. 因为索引需要额外的存储空间和处理,那些不必要的索引反而会使查询反应时间变慢.使用索引查询不一定能提高查询性能,索引范围查询(INDEX RANGE SCAN)适用于两种情况: 基于一个范围的检索,一般查询返回结果集小于表中记录数的30% 基于非唯一性索引的检索 创建索引时需要注意什么？ 非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值； 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高； 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。 最左匹配原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 事务​ 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。 四大特性(简称ACID)数据库如果支持事务的操作，那么就具备以下四个特性： 原子性(Atomicity) 事务是数据库的逻辑工作单位，事务中包括的诸操作要么全做，要么全不做。 一致性(Consistency) 事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性(Isolation) 一个事务的执行不能被其他事务干扰。 持续性/永久性(Durability) 一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。 事务的隔离性​ 数据库事务的隔离级别有4个，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 隔离级别Read Uncommitted（读取未提交内容）​ 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 Read Committed（读取提交内容）​ 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 Repeatable Read（可重读）​ 这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 Serializable（可串行化）​ 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 隔离级别与锁的关系​ 在Read Uncommitted级别下，读操作不加S锁； 在Read Committed级别下，读操作需要加S锁，但是在语句执行完以后释放S锁； 在Repeatable Read级别下，读操作需要加S锁，但是在事务提交之前并不释放S锁，也就是必须等待事务执行完毕以后才释放S锁。 在Serialize级别下，会在Repeatable Read级别的基础上，添加一个范围锁。保证一个事务内的两次查询结果完全一样，而不会出现第一次查询结果是第二次查询结果的子集。 事物隔离是怎么实现的？​ 是基于锁实现的. 锁​ 数据库的乐观锁和悲观锁是什么？ ​ 数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。 ​ 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 悲观锁： 悲观锁指对数据被意外修改持保守态度，依赖数据库原生支持的锁机制来保证当前事务处理的安全性，防止其他并发事务对目标数据的破坏或破坏其他并发事务数据，将在事务开始执行前或执行中申请锁定，执行完后再释放锁定。这对于长事务来讲，可能会严重影响系统的并发处理能力。 自带的数据库事务就是典型的悲观锁。 乐观锁： 乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。 一般是加一个版本号字段 每次更新时候比较版本号。 响应速度：如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁。 冲突频率：如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大。 重试代价：如果重试代价大，建议采用悲观锁。 有哪些锁？分别介绍下​ 在DBMS中，可以按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。 ​ 行级锁 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。​ 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 ​ 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。​ 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 ​ 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 存储过程​ 存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。 优点 存储过程是预编译过的，执行效率高。 存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。 安全性搞，执行存储过程需要有一定权限的用户。 存储过程可以重复使用，减少数据库开发人员的工作量。 缺点 调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。 移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题。 重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。 如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。 视图​ 视图是从一个或几个基本表（或视图）导出的表。它与基本表不同，是一个虚表。数据库中只存放视图的定义，而不存放视图对应的数据，这些数据仍存放在原来的基本表中。所以一旦基本表中的数据发生变化，从视图中查询出的数据也就随之改变了。从这个意义上讲，视图就像一个窗口，透过它可以看到数据库中自己感兴趣的数据及其变化。 视图一经定义，就可以和基本表一样被查询、被删除。也可以在一个视图上再定义新的视图，但对视图的更新（增、删、改）操作则有一定的限制。 视图的优点 查询简单化。视图能简化用户的操作 数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性 视图的缺点 性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。 修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的，这些视图有如下特征： a.有UNIQUE等集合操作符的视图。 b.有GROUP BY子句的视图。 c.有诸如AVG\SUM\MAX等聚合函数的视图。 d.使用DISTINCT关键字的视图。 e.连接表的视图（其中有些例外） 主从复制​ 将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。 主从复制的作用 主数据库出现问题，可以切换到从数据库。 可以进行数据库层面的读写分离。 可以在从数据库上进行日常备份。 复制过程 ​ Binary log：主数据库的二进制日志 Relay log：从服务器的中继日志 第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。 第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。 第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。 大表数据查询，怎么优化 优化shema、sql语句+索引； 第二加缓存，memcached, redis； 主从复制，读写分离； 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统； 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表； 参考 面试/笔试第三弹 —— 数据库面试问题集锦 常见面试题整理–数据库篇（每位开发者必备） 互联网校招面试必备——数据库 | 掘金技术征文 互联网公司面试必问的mysql题目(上) 互联网公司面试必问的mysql题目(下） 20个数据库常见面试题讲解 数据库面试题(开发者必看)]]></content>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F02%2F12%2F%E9%9D%A2%E8%AF%95%2F%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%EF%BC%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[进程进程有哪几种状态，状态转换圈，导致转换的事件 ​ 包含三种状态：就绪状态，运行状态和阻塞状态。阻塞和就绪区别：阻塞是等待CPU以外的资源，就绪等待的是CPU资源。 执行状态：进程正在处理器上运行。 就绪状态：进程已经处于准备运行的状态，即进程已经获得了除了处理器以外的所有资源，一旦的到处理器即可运行。 阻塞状态：进程正在等待某一事件的发生，如果等待某一资源为可用或等待输入输出完成。即使处理器空闲当前进程也不能执行。 转换事件： 就绪——执行：对就绪状态的进程，当进程调度程序按一种选定的策略从中选中一个就绪进程，为之分配了处理机后，该进程便由就绪状态变为执行状态； 执行——阻塞：正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源（主存空间或外部设备）得不到满足时变成等待资源状态，进程运行中出现了故障（程序出错或主存储器读写错等）变成等待干预状态等等； 阻塞——就绪：处于阻塞状态的进程，在其等待的事件已经发生，如输入/输出完成，资源得到满足或错误处理完毕时，处于等待状态的进程并不马上转入执行状态，而是先转入就绪状态，然后再由系统进程调度程序在适当的时候将该进程转为执行状态； 执行——就绪：正在执行的进程，因时间片用完而被暂停执行，或在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行而被迫让出处理机时，该进程便由执行状态转变为就绪状态。 进程间通信方式 管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 ​ 进程通信是指进程之间的信息交换。PV操作是低级通信方式，髙级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三个类。 共享存储 ​ 在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换。在对共享空间进行写/读操作时，需要使用同步互斥工具（如 P操作、V操作），对共享空间的写/读进行控制。共享存储又分为两种：低级方式的共享是基于数据结构的共享；高级方式则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。 ​ 需要注意的是，用户进程空间一般都是独立的，要想让两个用户进程共享空间必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。 消息传递 ​ 在消息传递系统中，进程间的数据交换是以格式化的消息(Message)为单位的。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的发送消息和接收消息两个原语进行数据交换。 直接通信方式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。 间接通信方式：发送进程把消息发送到某个中间实体中，接收进程从中间实体中取得消息。这种中间实体一般称为信箱，这种通信方式又称为信箱通信方式。该通信方式广泛应用于计算机网络中，相应的通信系统称为电子邮件系统。 管道通信 ​ 管道通信是消息传递的一种特殊方式。所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。向管道（共享文件）提供输入的发送进程（即写进程），以字符流形式将大量的数据送入（写）管道；而接收管道输出的接收进程（即读进程），则从管道中接收（读）数据。为了协调双方的通信，管道机制必须提供以下三方面的协调能力：互斥、同步和确定对方的存在。 进程同步方式​ 多进程虽然提高了系统资源利用率和吞吐量，但是由于进程的异步性可能造成系统的混乱。进程同步的任务就是对多个相关进程在执行顺序上进行协调，使并发执行的多个进程之间可以有效的共享资源和相互合作，保证程序执行的可再现性 原则： 空闲让进：当没有进程处于临界区的时候，应该许可其他进程进入临界区的申请 忙则等待：当前如果有进程处于临界区，如果有其他进程申请进入，则必须等待，保证对临界区的互斥访问 有限等待：对要求访问临界资源的进程，需要在有限时间内进入临界区，防止出现死等 让权等待：当进程无法进入临界区的时候，需要释放处理机，边陷入忙等 ​ 原子操作、信号量机制、自旋锁管程、会合、分布式系统 调度算法​ 先来先服务调度算法FCFS：既可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度；因此对于长作业比较有利； ​ 短作业优先调度算法SJF：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱 ； ​ 高相应比算法HRN：响应比=(等待时间+要求服务时间)/要求服务时间； ​ 时间片轮转调度RR：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环 ; ​ 多级反馈队列调度算法：目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。 线程状态​ 在 Java虚拟机 中，线程从最初的创建到最终的消亡，要经历若干个状态：创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态， 线程同步方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 进程与线程的区别定义​ 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。 ​ 线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 区别​ 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。 ​ 进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 简而言之,一个程序至少有一个进程,一个进程至少有一个线程. 线程的划分尺度小于进程，使得多线程程序的并发性高。 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发； 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的 实时性，实现进程内部的并发； 一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在； 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。 优缺点​ 线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP（双CPU机器）机器上运行，而进程则可以跨机器迁移。 什么是缓冲区溢出？有什么危害？其原因是什么？​ 缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害有以下两点： 程序崩溃，导致拒绝额服务 跳转并且执行一段恶意代码 造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。 生产者消费者问题死锁概念​ 多个进程因竞争资源而造成的一种僵局（互相等待），若无外力则这些进程都将无法向前推进。实例：线程1持有资源a，线程2持有资源b，但是线程1必须也同时持有资源b才能进行下去，所以线程1等待线程2释放资源b，而线程2也必须持有资源a才能进行下去，所以线程2等待线程1释放资源a，这样就形成了循环等待的条件，都无法进行下去，这就是死锁现象。 原因 系统资源不足； 进程推进顺序非法。 导致死锁的四个必要条件 互斥：至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止； 占有并等待：一个 进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有； 非抢占：进程不能被抢占，即资源只能被进程在完成任务后自愿释放 循环等待：若干进程之间形成一种头尾相接的环形等待资源关系 死锁的处理基本策略和常用方法基本方法主要有 预防死锁、避免死锁、检测死锁、解除死锁 预防死锁死锁预防的基本思想是 只要确保死锁发生的四个必要条件中至少有一个不成立，就能预防死锁的发生，具体方法包括： 打破互斥条件：允许进程同时访问某些资源。但是，有些资源是不能被多个进程所共享的，这是由资源本身属性所决定的，因此，这种办法通常并无实用价值。 打破占有并等待条件：可以实行资源预先分配策略(进程在运行前一次性向系统申请它所需要的全部资源，若所需全部资源得不到满足，则不分配任何资源，此进程暂不运行；只有当系统能满足当前进程所需的全部资源时，才一次性将所申请资源全部分配给该线程)或者只允许进程在没有占用资源时才可以申请资源（一个进程可申请一些资源并使用它们，但是在当前进程申请更多资源之前，它必须全部释放当前所占有的资源）。但是这种策略也存在一些缺点：在很多情况下，无法预知一个进程执行前所需的全部资源，因为进程是动态执行的，不可预知的；同时，会降低资源利用率，导致降低了进程的并发性。 打破非抢占条件：允许进程强行从占有者哪里夺取某些资源。也就是说，但一个进程占有了一部分资源，在其申请新的资源且得不到满足时，它必须释放所有占有的资源以便让其它线程使用。这种预防死锁的方式实现起来困难，会降低系统性能。 打破循环等待条件：实行资源有序分配策略。对所有资源排序编号，所有进程对资源的请求必须严格按资源序号递增的顺序提出，即只有占用了小号资源才能申请大号资源，这样就不回产生环路，预防死锁的发生。 避免死锁​ 死锁避免的基本思想是动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。资源分配图算法和银行家算法是两种经典的死锁避免的算法，其可以确保系统始终处于安全状态。其中，资源分配图算法应用场景为每种资源类型只有一个实例(申请边，分配边，需求边，不形成环才允许分配)，而银行家算法应用于每种资源类型可以有多个实例的场景。 检测死锁解除死锁策略:鸵鸟策略（发生死锁的情况很少，不设计解除策略以提高整体性能）、预防策略、避免策略、检测与解除死锁 ​ 死锁解除的常用两种方法为进程终止和资源抢占。所谓进程终止是指简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占是指从一个或多个死锁进程那里抢占一个或多个资源，此时必须考虑三个问题： 1. 选择一个牺牲品 2. 回滚：回滚到安全状态 3. 饥饿（在代价因素中加上回滚次数，回滚的越多则越不可能继续被作为牺牲品，避免一个进程总是被回滚） 4. 剥夺资源 5. 撤销进程 进程调度算法缓存算法（页面置换算法）​ 最佳置换算法：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。 ​ 先进先出置换算法：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。 ​ 最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。 ​ 时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。 ​ 改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。 ​ 最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。 池化技术​ 程序中创建一个线程或者在堆上申请一块内存时，都涉及到很多系统调用，也非常耗CPU，如果程序中有很多类似的工作线程或者需要频繁的申请释放小的内存，如果没有进行优化，那么此处代码可能成为程序的瓶颈。 线程池​ 线程池采用预创建的技术，在应用程序启动之后，将立即创建一定数量的线程(N1)，放入空闲队列中。这些线程都是处于阻塞（Suspended）状态，不消耗CPU，但占用较小的内存空间。当任务到来后，缓冲池选择一个空闲线程，把任务传入此线程中运行。当N1个线程都在处理任务后，缓冲池自动创建一定数量的新线程，用于处理更多的任务。在任务执行完毕后线程也不退出，而是继续保持在池中等待下一次的任务。当系统比较空闲时，大部分线程都一直处于暂停状态，线程池自动销毁一部分线程，回收系统资源。 实现线程池管理器：用于创建并管理线程池，包括创建线程、销毁线程池、添加新任务。 工作线程：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务。 任务接口：每个任务必须实现的接口，以供工作线程调度任务的执行。主要规定了任务的入口任务完成后的收尾工作，任务执行状态等。 任务队列（请求）：用于存放没有处理的任务，提供一种缓冲机制。 结果队列：用于存储请求执行后返回的结果 用途 需要大量的线程来完成任务，且完成任务的时间比较短。 WEB服务器完成网页请求这样的任务，使用线程池技术是非常合适的。因为单个任务小，而任务数量巨大，你可以想象一个热门网站的点击次数。但对于长时间的任务，比如一个Telnet连接请求，线程池的优点就不明显了。因为Telnet会话时间比线程的创建时间大多了。 对性能要求苛刻的应用，比如要求服务器迅速响应客户请求。 接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。突发性大量客户请求，在没有线程池情况下，将产生大量线程，虽然理论上大部分操作系统线程数目最大值不是问题，短时间内产生大量线程可能使内存到达极限，并出现”OutOfMemory”的错误。 内存池​ 目的:提出解决方案管理程序中内存的使用，提高内存的使用效率。 ​ 原理:预先分配足够大的内存，形成一个初步的“内存池”。分配内存，就是用户请求内存时，会返回内存池中一块空闲的内存，并将其标识为已经使用。释放内存时，不是真正的delete或者free而是把内存放回内存池的过程，同时把标志位设置空闲。最后应用程序结束时，把内存池销毁。 ​ 优缺点: 减少了内存碎片的产生，因为创建内存池时，分配的都是一块一块比较完整的内存块。 提高了内存的使用效率。这个可以从分配和释放内存看出，因为每次释放没有调用系统函数，而是复用内存池中的内存。 连接池​ 数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，由应用程序动态地对池中的连接进行申请、使用和释放。对于多于连接池中连接数的并发请求，应该在请求队列中排队等待。并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。 ​ 最小连接数是连接池一直保持的数据库连接，所以如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费； ​ 最大连接数是连接池能申请的最大连接数，如果数据库连接请求超过此数，后面的数据库连接请求将被加入到等待队列中，这会影响之后的数据库操作。 对象池​ 避免在程序的生命周期中创建和删除大量的对象。如果知道程序需要同一类型的对象，而且对象的生命周期都很短，就可以为这些对象创建一个池进行缓存。 内存管理​ Windows提供了3种方法来进行内存管理：虚拟内存，最适合用来管理大型对象或者结构数组；内存映射文件，最适合用来管理大型数据流（通常来自文件）以及在单个计算机上运行多个进程之间共享数据；内存堆栈，最适合用来管理大量的小对象。 Windows操纵内存可以分两个层面：物理内存和虚拟内存。 分页和分段有什么区别​ 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。 两者的不同点： 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息； 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定； 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制； 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定 段向用户提供二维地址空间；页向用户提供的是一维地址空间 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。 内存分配算法​ 首次适应(First Fit)算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。 ​ 最佳适应(Best Fit)算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。 ​ 最坏适应(Worst Fit)算法：又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。 虚拟内存内存发展历史​ 没有内存抽象(单进程，除去操作系统所用的内存之外，全部给用户程序使用) —&gt; 有内存抽象（多进程，进程独立的地址空间，交换技术(内存大小不可能容纳下所有并发执行的进程)）—&gt; 连续内存分配(固定大小分区(多道程序的程度受限)，可变分区(首次适应，最佳适应，最差适应)，碎片) —&gt; 不连续内存分配（分段，分页，段页式，虚拟内存） 定义 虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上，如图5所示。 ​ 注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 由图5可以看出，虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2）。如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。 优缺点​ 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处： 在内存中可以保留多个进程，系统并发度提高 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大 参考 互联网操作系统面试===常考点 面试/笔试第二弹 —— 操作系统面试问题集锦 常见面试题整理–操作系统篇（每位开发者必备） 操作系统常见面试题总结 操作系统面试重难点总结]]></content>
  </entry>
  <entry>
    <title><![CDATA[面试准备：计算机网络]]></title>
    <url>%2F2019%2F02%2F12%2F%E9%9D%A2%E8%AF%95%2F%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[计算机网络体系结构 TCP/IP体系 TCP即 传输控制协议 属于 传输层通信协议 基于TCP的应用层协议有HTTP、SMTP、FTP、Telnet 和 POP3 特点 TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）； TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达； TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 UDP即 用户数据报协议 属于 传输层通信协议 基于UDP的应用层协议有 TFTP、SNMP 与 DNS 特点 UDP 是无连接的； UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）； UDP 是面向报文的； UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）； UDP 支持一对一、一对多、多对一和多对多的交互通信； UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 TCP\UDP请简述TCP\UDP的区别TCP和UDP是OSI模型中的运输层中的协议。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。 两者的区别大致如下： TCP是面向连接的，UDP是无连接的 TCP是可靠的，UDP是不可靠的； TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多的通信模式； TCP是面向字节流的，UDP是面向报文的； TCP有拥塞控制机制;UDP没有拥塞控制，适合媒体通信； TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大； TCP三次\二次握手、四次挥手三次握手三次握手(我要和你建立链接，你真的要和我建立链接么，我真的要和你建立链接，成功)： 第一次握手：Client客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server服务端，Client进入SYN_SENT状态，等待Server确认。 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手四次挥手(我要和你断开链接；好的，断吧。我也要和你断开链接；好的，断吧)： 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。此时TCP链接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍要接收。 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 为什么TCP链接需要三次握手？​ 为了防止 已失效的链接请求报文突然又传送到了服务端，因而产生错误。 客户端发出的连接请求报文并未丢失，而是在某个网络节点长时间滞留了，以致延误到链接释放以后的某个时间才到达Server。这是，Server误以为这是Client发出的一个新的链接请求，于是就向客户端发送确认数据包，同意建立链接。若不采用“三次握手”，那么只要Server发出确认数据包，新的链接就建立了。由于client此时并未发出建立链接的请求，所以其不会理睬Server的确认，也不与Server通信；而这时Server一直在等待Client的请求，这样Server就白白浪费了一定的资源。若采用“三次握手”，在这种情况下，由于Server端没有收到来自客户端的确认，则就会知道Client并没有要求建立请求，就不会建立链接。 为什么要四次挥手​ 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。 为什么要传回 SYN​ 接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。 传了 SYN,为啥还要传 ACK​ 双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。 TCP的拥塞处理​ 计算机网络中的带宽、交换结点中的缓存及处理机等都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就会变坏，这种情况就叫做拥塞。拥塞控制就是 防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载。注意，拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。拥塞控制的方法主要有以下四种： 拥塞窗口 ​ 拥塞窗口:TCP包首部有一个字段是16位的窗口大小,窗口分为滑动窗口和拥塞窗口。滑动窗口是接受数据端使用的窗口大小，用来告知发送端接收端的缓存大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的。那么对于数据的发送端就是拥塞窗口了，拥塞窗口不代表缓存，拥塞窗口指某一源端数据流在一个RTT（RTT=传播时延（往返哒）+排队时延（路由器和交换机的）+数据处理时延（应用程序的）。）内可以最多发送的数据包数. ​ 迄今为止，在本章所有的例子中，发送方一开始便向网络发送多个报文段，直至达到接收方通告的窗口大小为止。当发送方和接收方处 于同一个局域网时，这种方式是可以的。但是如果在发送方和接收方之间存在多个路由器和速率较慢的链路时，就有可能出现一些问题。一些中间路由器必须缓存分 组，并有可能耗尽缓存，[Jacobson 1988]证明了这种连接方式是如何严重降低了TCP连接的吞吐量的。现在，TCP需要支持一种被称为“慢启动(slow start)”的算法。该算法通过观察到新分组进入网络的速率应该与另一端返回确认的速率相同而进行工作。 ​ 慢启动为发送方的TCP增加了另一个窗口：拥塞窗口(congestion window)，记为cwnd。当与另一个网络的主机建立TCP连接时，拥塞窗口被初始化为1个报文段（即另一端通告的报文段大小）。每收到一个ACK， 拥塞窗口就增加一个报文段（cwnd以字节为单位，但是慢启动以报文段大小为单位进行增加）。发送方取拥塞窗口与通告窗口中的最小值作为发送上限。拥塞窗 口是发送方使用的流量控制，而通告窗口则是接收方使用的流量控制。 ​ 发送方开始时发送一个报文段，然后等待ACK。当收到该ACK时，拥塞窗口从1增加为2，即可以发送两个报文段。当收到这两个报文段的ACK时，拥塞窗口就增加为4。这是一种指数增加的关系。 ​ 拥塞避免是发送方使用 的流量控制，而通告窗口则是接收方进行的流量控制。前者是发送方感受到的网络拥塞的估 计，而后者则与接收方在该连接上的可用缓存大小有关。 ​ 拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。 ​ 拥塞发生有超时和收到重复确认两种情况， 滑动窗口 ​ 滑动窗口：滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。ACK包含两个非常重要的信息： ​ 一是期望接收到的下一字节的序号n，该n代表接收方已经接收到了前n-1字节数据，此时如果接收方收到第n+1字节数据而不是第n字节数据，接 收方是不会发送序号为n+2的ACK的。举个例子，假如接收端收到1-1024字节，它会发送一个确认号为1025的ACK,但是接下来收到的是 2049-3072，它是不会发送确认号为3072的ACK,而依旧发送1025的ACK。 ​ 二是当前的窗口大小m，如此发送方在接收到ACK包含的这两个数据后就可以计算出还可以发送多少字节的数据给对方，假定当前发送方已发送到第x字节，则可以发送的字节数就是y=m-(x-n).这就是滑动窗口控制流量的基本原理. 慢启动：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小; 拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍，这样拥塞窗口按线性规律缓慢增长。 快重传：快重传要求接收方在收到一个 失序的报文段 后就立即发出 重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。 快恢复：快重传配合使用的还有快恢复算法，当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半，但是接下去并不执行慢开始算法：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。 TCP协议如何来保证传输的可靠性​ TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。 对于可靠性，TCP通过以下方式进行保证： 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据； 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层； 丢弃重复数据：对于重复数据，能够丢弃重复数据； 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒； 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段； 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。 客户端不断进行请求链接会怎样？DDos(Distributed Denial of Service)攻击？ 服务器端会为每个请求创建一个链接，并向其发送确认报文，然后等待客户端进行确认 DDos 攻击 客户端向服务端发送请求链接数据包 服务端向客户端发送确认数据包 客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认 DDos 预防 ( 没有彻底根治的办法，除非不使用TCP ) 限制同时打开SYN半链接的数目 缩短SYN半链接的Time out 时间 关闭不必要的服务 HTTP！！！！！！HTTP简介，设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。 HTTP是不保存状态的协议： ​ HTTP是一种不保存状态的协议，即无状态的协议。HTTP协议自身不对请求和响应之间的通信状态进行保存。每当有新的请求，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应信息，所以在购物网站中一般使用Cookie技术。 报文 通用首部字段（请求报文与响应报文都会使用的首部字段） Date：创建报文时间 Connection：连接的管理 Cache-Control：缓存的控制 Transfer-Encoding：报文主体的传输编码方式 请求首部字段（请求报文会使用的首部字段） Host：请求资源所在服务器 Accept：可处理的媒体类型 Accept-Charset：可接收的字符集 Accept-Encoding：可接受的内容编码 Accept-Language：可接受的自然语言 响应首部字段（响应报文会使用的首部字段） Accept-Ranges：可接受的字节范围 Location：令客户端重新定向到的URI Server：HTTP服务器的安装信息 实体首部字段（请求报文与响应报文的的实体部分使用的首部字段） Allow：资源可支持的HTTP方法 Content-Type：实体主类的类型 Content-Encoding：实体主体适用的编码方式 Content-Language：实体主体的自然语言 Content-Length：实体主体的的字节数 Content-Range：实体主体的位置范围，一般用于发出部分请求时使用 Http和Https的区别​ Http协议运行在TCP之上，明文传输，客户端与服务器端都无法验证对方的身份； ​ Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同： ​ 端口不同：Http与Http使用不同的连接方式，用的端口也不一样，前者是80，后者是443； ​ 资源消耗：和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源； ​ 开销：Https通信需要证书，而证书一般需要向认证机构购买； Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。 SSL协议​ SSL协议，这个协议提供网络连接的加密，如果我们访问一个https的网站，我们的电脑会先和服务器建立一个安全的连接通道，然后服务器会先发送一份网址的安全信息证书到我们的电脑，告诉我们的电脑，访问的服务器没有问题，确认了信息后，服务器就会生成一个加锁的箱子，但是这把锁有两把不一样的钥匙，一把时给我们的电脑的，一把是给服务器自己，然后服务器会把没有上锁的箱子和钥匙发给我们的电脑，我们把信息放在箱子里面然后用钥匙锁上，然后发给服务器，服务器用自己的钥匙打开箱子来保证信息的安全。 对称加密与非对称加密 对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方； ​ 而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。 长连接与短连接​ 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 ​ 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive ​ 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 ​ HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 HTTP2解决的问题 相对于使用 TCP 的HTTP1.1,用户在大多数情况下的感知延迟要有实质上、可度量的改进； 解决 HTTP 中的“队首阻塞”问题； 队首阻塞会在下面的HTTP Pipelining解释 并行操作无需与服务器建立多个连接，从而改进TCP的利用率，特别是拥塞控制方面； 保持 HTTP 1.1 的语义，利用现有文档，包括（但不限于）HTTP 方法、状态码、URI，以及首部字段(既向下兼容) 解决突破HTTP1.0 &amp; HTTP1.1 的性能限制,改进传输性能，实现低延迟和高吞吐量 主要改变 通过支持首部字段压缩和在同一连接上发送多个并发消息，让应用更有效地利用网络资源，减少感知的延迟时间。而且，它还支持服务器到客户端的主动推送机制 二进制分帧数据层 作用:封装HTTP消息,并在客户端与服务器之间传输,将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码 组成:帧 &amp; 消息 &amp; 流 组成:流既通道,通道内双向传输消息,消息由帧组成 流:连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…n) 消息：是指逻辑上的HTTP消息，比如请求、响应等，由一或多个帧组成 帧：HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流，承载着特定类型的数据,如HTTP的header 负荷等等,所有首部数据都会被压缩 二进制分帧层实现了多项请求和响应,可以把消息分级为互不依赖的帧,乱序发送 123451. 可以并行交错地发送请求，请求之间互不影响；2. 可以并行交错地发送响应，响应之间互不干扰；3. 只使用一个连接即可并行发送多个请求和响应；4. 消除不必要的延迟，从而减少页面加载的时间；5. 不必再为绕过 HTTP 1.x 限制而多做很多工作 作用 HTTP 2.0 的二进制分帧机制解决了HTTP1.x中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。 有了新的分帧机制后，HTTP 2.0不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多帧,而这些帧可以交错，还可以分别优先级。HTTP2.0连接都是持久化的，而且客户端与服务器之间也只需要一个连接即可。 大多数HTTP 连接的时间都很短，而且是突发性的，但TCP 只在长时间连接传输大块数据时效率才最高。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用TCP 连接。 服务器推送 HTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求 HTTP Pipelining HTTP Pipelining:其实是把多个HTTP请求放到一个TCP连接中一一发送，而在发送过程中不需要等待服务器对前一个请求的响应；只不过，客户端还是要按照发送请求的顺序来接收响应。 GET与POST PUT： 传输文件，报文主体中包含文件内容，保存到对应URI位置。 HEAD： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。 DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。 OPTIONS：查询相应URI支持的HTTP方法。 GET与POST是我们常用的两种HTTP Method，二者之间的区别主要包括如下五个方面： 从功能上讲，GET一般用来从服务器上获取资源，POST一般用来更新服务器上的资源； 从REST服务角度上说，GET是幂等的，即读取同一个资源，总是得到相同的数据，而POST不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET不会改变服务器上的资源，而POST会对服务器资源进行改变； 从请求参数形式上看，GET请求的数据会附在URL之后，即将请求数据放置在HTTP报文的 请求头 中，以?分割URL和传输数据，参数之间以&amp;相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如：%E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII)；而POST请求会把提交的数据则放置在是HTTP请求报文的 请求体 中。 就安全性而言，POST的安全性要比GET的安全性高，因为GET请求提交的数据将明文出现在URL上，而且POST请求参数则被包装到请求体中，相对更安全。 从请求的大小看，GET请求的长度受限于浏览器或服务器对URL长度的限制，允许发送的数据量比较小，而POST请求则是没有大小限制的。 GET请求中URL编码的意义 我们知道，在GET请求中会对URL中非西文字符进行编码，这样做的目的就是为了 避免歧义。看下面的例子， 针对“name1=value1&amp;name2=value2”的例子，我们来谈一下数据从客户端到服务端的解析过程。首先，上述字符串在计算机中用ASCII吗表示为： 123456786E616D6531 3D 76616C756531 26 6E616D6532 3D 76616C7565326E616D6531：name1 3D：= 76616C756531：value1 26：&amp;6E616D6532：name2 3D：= 76616C756532：value2 ​ 服务端在接收到该数据后就可以遍历该字节流，一个字节一个字节的吃，当吃到3D这字节后，服务端就知道前面吃得字节表示一个key，再往后吃，如果遇到26，说明从刚才吃的3D到26子节之间的是上一个key的value，以此类推就可以解析出客户端传过来的参数。 现在考虑这样一个问题，如果我们的参数值中就包含=或&amp;这种特殊字符的时候该怎么办？比如，“name1=value1”，其中value1的值是“va&amp;lu=e1”字符串，那么实际在传输过程中就会变成这样“name1=va&amp;lu=e1”。这样，我们的本意是只有一个键值对，但是服务端却会解析成两个键值对，这样就产生了歧义。 那么，如何解决上述问题带来的歧义呢？解决的办法就是对参数进行URL编码：例如，我们对上述会产生歧义的字符进行URL编码后结果：“name1=va%26lu%3D”，这样服务端会把紧跟在“%”后的字节当成普通的字节，就是不会把它当成各个参数或键值对的分隔符。 Session、Cookie 与 Application​ Cookie和Session都是客户端与服务器之间保持状态的解决方案，具体来说，cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。 Cookie​ Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie，而客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器，服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。 Session​ 同样地，会话状态也可以保存在服务器端。客户端请求服务器，如果服务器记录该用户状态，就获取Session来保存状态，这时，如果服务器已经为此客户端创建过session，服务器就按照sessionid把这个session检索出来使用；如果客户端请求不包含sessionid，则为此客户端创建一个session并且生成一个与此session相关联的sessionid，并将这个sessionid在本次响应中返回给客户端保存。保存这个sessionid的方式可以采用 cookie机制 ，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器；若浏览器禁用Cookie的话，可以通过 URL重写机制 将sessionid传回服务器。 Session 与 Cookie 的对比 实现机制：Session的实现常常依赖于Cookie机制，通过Cookie机制回传SessionID； 大小限制：Cookie有大小限制并且浏览器对每个站点也有cookie的个数限制，Session没有大小限制，理论上只与服务器的内存大小有关； 安全性：Cookie存在安全隐患，通过拦截或本地文件找得到cookie后可以进行攻击，而Session由于保存在服务器端，相对更加安全； 服务器资源消耗：Session是保存在服务器端上会存在一段时间才会消失，如果session过多会增加服务器的压力。 Application（ServletContext）：与一个Web应用程序相对应，为应用程序提供了一个全局的状态，所有客户都可以使用该状态。 Application​ Application（Java Web中的ServletContext）：与一个Web应用程序相对应，为应用程序提供了一个全局的状态，所有客户都可以使用该状态。 从输入网址到获得页面的过程 浏览器分析链接指向页面的URL 浏览器向DNS请求解析百度服务器的IP地址 域名系统DNS解析出百度服务器的IP地址 浏览器与服务器建立TCP连接 浏览器发出取文件命令（一般是发送HTTP请求） 服务器给出响应，把文件发送给浏览器（服务器通过HTTP响应把页面发送给浏览器） 释放TCP连接 浏览器显示 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询； 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手； TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求； 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器； 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源； 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。 一次完整的HTTP请求所经历的7个步骤​ 建立TCP连接-&gt;发送请求行-&gt;发送请求头-&gt;（到达服务器）发送状态行-&gt;发送响应头-&gt;发送响应数据-&gt;断TCP连接 建立TCP连接 在HTTP工作开始之前，Web浏览器首先要通过网络与Web服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建 Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则， 只有低层协议建立之后才能，才能进行更层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80。 Web浏览器向Web服务器发送请求行 一旦建立了TCP连接，Web浏览器就会向Web服务器发送请求命令。例如：GET /sample/hello.jsp HTTP/1.1。 Web浏览器发送请求头 浏览器发送其请求命令之后，还要以头信息的形式向Web服务器发送一些别的信息，之后浏览器发送了一空白行来通知服务器，它已经结束了该头信息的发送。 Web服务器应答 客户机向服务器发出请求后，服务器会客户机回送应答， HTTP/1.1 200 OK ，应答的第一部分是协议的版本号和应答状态码。 Web服务器发送应答头 正如客户端会随同请求发送关于自身的信息一样，服务器也会随同应答向用户发送关于它自己的数据及被请求的文档。 Web服务器向浏览器发送数据 Web服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据。 Web服务器关闭TCP连接 一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码keep-alive： 常见状态码及原因短语​ HTTP请求结构： 请求方式 + 请求URI + 协议及其版本 HTTP响应结构： 状态码 + 原因短语 + 协议及其版本 1×× : 请求处理中，请求已被接受，正在处理 2×× : 请求成功，请求被成功处理 200 OK 3×× : 重定向，要完成请求必须进行进一步处理 301 : 永久性转移 302 ：暂时性转移 304 ： 已缓存 4×× : 客户端错误，请求不合法 400：Bad Request,请求有语法问题403：拒绝请求404：客户端所访问的页面不存在 5×× : 服务器端错误，服务器不能处理合法请求 500 ：服务器内部错误 503 ： 服务不可用，稍等 IP​ IP地址是指互联网协议地址，是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP地址编址方案将IP地址空间划分为A、B、C、D、E五类，其中A、B、C是基本类，D、E类作为多播和保留使用，为特殊地址。 每个IP地址包括两个标识码（ID），即网络ID和主机ID。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。A~E类地址的特点如下： A类地址：以0开头，第一个字节范围：0~127； B类地址：以10开头，第一个字节范围：128~191； C类地址：以110开头，第一个字节范围：192~223； D类地址：以1110开头，第一个字节范围为224~239； E类地址：以1111开头，保留地址 网络层的ARP协议工作原理​ 网络层的ARP协议完成了IP地址与物理地址的映射。 首先，每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己ARP列表中是否存在该IP地址对应的MAC地址：如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。 此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖 然后给源主机发送一个ARP响应数据包，告诉对方自己是它需要查找的MAC地址； 源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。 如果源主机一直没有收到ARP响应数据包，表示ARP查询失败. IP地址与物理地址 物理地址是数据链路层和物理层使用的地址，IP地址是网络层和以上各层使用的地址，是一种逻辑地址，其中ARP协议用于IP地址与物理地址的对应。 路由器与交换机 TOKEN socket 即套接字，是应用层 与 TCP/IP 协议族通信的中间软件抽象层，表现为一个封装了 TCP / IP协议族 的编程接口（API） Socket不是一种协议，而是一个编程调用接口（API），属于传输层（主要解决数据如何在网络中传输） 即：通过Socket，我们才能在Andorid平台上通过 TCP/IP协议进行开发 对用户来说，只需调用Socket去组织数据，以符合指定的协议，即可通信 成对出现，一对套接字： 1Socket =&#123;(IP地址1:PORT端口号)，(IP地址2:PORT端口号)&#125; 一个 Socket 实例 唯一代表一个主机上的一个应用程序的通信链路 参考 常见面试题整理–计算机网络篇(每位开发者必备) 面试/笔试第一弹 —— 计算机网络面试问题集锦 互联网公司计算机网络热门面试题整理 搞定计算机网络面试，看这篇就够了（补充版） 面试带你飞：这是一份全面的 计算机网络基础 总结攻略 Android：这是一份很详细的Socket使用攻略]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法：面试准备]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[海量数据排序外部排序 传统的排序算法一般指内排序算法，针对的是数据可以一次全部载入内存中的情况。但是面对海量数据，即数据不可能一次全部载入内存，需要用到外排序的方法。外排序采用分块的方法（分而治之），首先将数据分块，对块内数据按选择一种高效的内排序策略进行排序。然后采用归并排序的思想对于所有的块进行排序，得到所有数据的一个有序序列。 例如，考虑一个1G文件，可用内存100M的排序方法。 首先将文件分成10个100M，并依次载入内存中进行排序，最后结果存入硬盘。得到的是10个分别排序的文件。 接着从每个文件载入9M的数据到输入缓存区，输出缓存区大小为10M。对输入缓存区的数据进行归并排序，输出缓存区写满之后写在硬盘上，缓存区清空继续写接下来的数据。 对于输入缓存区，当一个块的9M数据全部使用完，载入该块接下来的9M数据，一直到所有的9个块的所有数据都已经被载入到内存中被处理过。最后我们得到的是一个1G的排序好的存在硬盘上的文件。 继续优化 磁盘I/O通常是越少越好（最好完全没有），那么如何降低磁盘I/O操作呢？关键就在第5和第6步中的40路输入缓冲区，我们可以先做8路merge sort，把每8个块合并为1路，然后再做5-to-1的合并操作。 再深入思考一下，如果有多余的硬件，如何继续优化呢？有三个方向可以考虑： 使用并发：如多磁盘（并发I/O提高）、多线程、使用异步I/O、使用多台主机集群计算。 提升硬件性能：如更大内存、更高RPM的磁盘、升级为SSD、Flash、使用更多核的CPU。 提高软件性能：比如采用radix sort、压缩文件（提高I/O效率）等。 在1000000个元素中选出前100名。在N个元素选出前M个元素。在1000000个元素选出前100名。 优先队列，维护当前看到的前M个元素。 TOP K问题描述： TopK Elements 问题用于找出一组数中最大的 K 个的数。 此外还有一种叫 Kth Element 问题，用于找出一组数中第 K 大的数。 如果要找的 TopK Elements 是最小的 K 个数，那么可以将问题转换成求解 TopK Elements，因为找到 Kth Element 之后，再遍历一遍，小于等于 Kth Element 的数都是 TopK Elements。 堆排序 可针对海量数据 为了查找Top k大的数，我们可以使用大根堆来存储最大的K个元素。大根堆的堆顶元素就是最大K个数中最小的一个。每次考虑下一个数x时，如果x比堆顶元素小，则不需要改变原来的堆。如果想x比堆顶元素大，那么用x替换堆顶元素， 同时，在替换之后，x可能破坏最小堆的结构，需要调整堆来维持堆的性质。算法实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public static int[] findTopK(int[] array, int k) &#123; int heapArray[] = new int[k]; for (int i = 0; i &lt; k; i++) &#123; heapArray[i] = array[i]; &#125; buildMaxHeap(heapArray); for (int i = k; i &lt; array.length; i++) &#123; if (array[i] &lt; heapArray[0]) &#123; heapArray[0] = array[i];//更新堆顶 adjustMaxHeap(heapArray, 0, heapArray.length); &#125; &#125; return heapArray;&#125;/** * 构建大根堆 * * @param array */public static void buildMaxHeap(int[] array) &#123; for (int i = array.length / 2 - 1; i &gt;= 0; i--) &#123; adjustMaxHeap(array, i, array.length); &#125;&#125;/** * 调整堆结构 * * @param array * @param root 根节点 * @param length */public static void adjustMaxHeap(int[] array, int root, int length) &#123; int left = root * 2 + 1; //左节点下标，数组下标从0开始，所以加1 int right = left + 1; //右节点下标 int largest = root;// 存放三个节点中最大节点的下标 if (left &lt; length &amp;&amp; array[left] &gt; array[root]) &#123; //左节点大于根节点，更新最大节点的下标 largest = left; &#125; if (right &lt; length &amp;&amp; array[right] &gt; array[largest]) &#123;//右节点大于根节点，最大节点的下标 largest = right; &#125; if (root != largest) &#123; swap(array, largest, root); adjustMaxHeap(array, largest, length); &#125;&#125;/** * 交换 * * @param arr * @param i * @param j */public static void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125; 快排 虽然我们不会采用快速排序的算法来实现TOP-K问题，但我们可以利用快速排序的思想，在数组中随机找一个元素key，将数组分成两部分Sa和Sb，其中Sa的元素&gt;=key，Sb的元素&lt;key，然后分析两种情况： 若Sa中元素的个数大于或等于k，则在Sa中查找最大的k个数 若Sa中元素的个数小于k，其个数为len，则在Sb中查找k-len个数字 如此递归下去，不断把问题分解为更小的问题，直到求出结果。 该算法的平均时间复杂度为O(N * logk)。以求K大的数为例，算法实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public static int findTopK(int[] array, int left, int right, int k) &#123; int index = -1; if (left &lt; right) &#123; int pos = partition(array, left, right); int len = pos - left + 1; if (len == k) &#123; index = pos; &#125; else if (len &lt; k) &#123;//Sa中元素个数小于K，到Sb中查找k-len个数字 index = findTopK(array, pos + 1, right, k - len); &#125; else &#123;//Sa中元素的个数大于或等于k index = findTopK(array, left, pos - 1, k); &#125; &#125; return index;&#125;/** * 按基准点划分数组，左边的元素大于基准点，右边的元素小于基准点 * * @param array * @param left * @param right * @return */public static int partition(int[] array, int left, int right) &#123; int x = array[left];//基准点，随机选择 do &#123; while (array[right] &lt; x &amp;&amp; left &lt; right)//从后向前扫描，找到第一个比基准点大的元素 right--; if (left &lt; right) &#123; array[left] = array[right];//大元素前移 left++; &#125; while (array[left] &gt;= x &amp;&amp; left &lt; right) //从前向后扫描，找到第一个比基准点小的元素 left++; if (left &lt; right) &#123; array[right] = array[left];//小元素后移 right--; &#125; &#125; while (left &lt; right); array[left] = x; return left;&#125; 空间换时间 如果所有N个数都是正整数，且他们的取值范围并不大，可以考虑申请空间，记录每个整数出现的次数，然后再从大到小取最大的K个。实际就是利用计数排序的思想。 假设所有整数都在（0，maxN）区间，利用一个数组count[maxN]来记录每个整数出现的次数。count[i]表示整数i在N个数中出现的次数。只需要扫描一遍就可以得到count数组，然后寻找第K大的元素。算法实现如下： 123456789101112131415161718192021222324252627public static List&lt;Integer&gt; findTopK(int[] array, int k) &#123; int max = array[0]; for (int i = 0; i &lt; array.length; i++) &#123; if (max &lt; array[i]) &#123; max = array[i]; &#125; &#125; int count[] = new int[max + 1]; for (int i = 0; i &lt; array.length; i++) &#123; count[array[i]] += 1; &#125; List&lt;Integer&gt; topKList = new ArrayList&lt;&gt;(); for (int sumCount = 0, j = count.length - 1; j &gt;= 0; j--) &#123; int c = count[j]; sumCount += c; if (c &gt; 0) &#123; for (int i = 0; i &lt; c; i++) &#123; topKList.add(j); &#125; &#125; if (sumCount &gt;= k) &#123; break; &#125; &#125; return topKList;&#125; 这是一个典型的以空间换取时间的做法。当数组中取值范围比较大时，是及其浪费空间的。如[3,1…9999]，为了求出最大的K个元素，需要额外申请一个长度为10000的数组。 Rand7问题描述： 已知rand5能等概率产生1, 2, 3, 4, 5， 现要用rand5来实现rand7（rand7的意思是要等概率产生1, 2, 3, 4, 5, 6, 7） 用rand5产生等概率的0, 1, 2, 3, 4，准备插入到下一步的等间距数组中, 使得插入后， 刚好合适。 用rand5产生等概率的0, 1, 2, 3, 4, 然后为了被插入， 将其散开成0, 5, 10, 15, 20. 将第一步插入 到第二步中， 于是， 就形成了0， 1， 2， 3， 4， 5， 6， 7， 8， …， 20， 21， 22， 23， 24. 然后就很容易等概率地生成1, 2, 3, 4, 5, 6, 7了。 只出现一次的数字给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 123456789101112class Solution &#123; public int singleNumber(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return -1; &#125; int result = 0; for (int i : nums) &#123; result ^= i; &#125; return result; &#125;&#125; 给定一个整数数组 nums，其中恰好有两个元素只出现一次，其余所有元素均出现两次。 找出只出现一次的那两个元素。 123456789101112131415161718192021222324252627class Solution &#123; public int[] singleNumber(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return null; &#125; int result = 0; for (int i : nums) &#123; result ^= i; &#125; //找到result的不为0的第一个字节 //如何找呢 int pos = 1; while ((result &amp; 1) == 0) &#123; result = result &gt;&gt; 1; pos = pos &lt;&lt; 1; &#125; int[] res = new int[2]; for (int i : nums) &#123; if ((i &amp; pos) == 0) &#123; res[0] ^= i; &#125; else &#123; res[1] ^= i; &#125; &#125; return res; &#125;&#125; 求众数给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 12345678910111213141516//从第一个数开始count=1，遇到相同的就加1，遇到不同的就减1，减到0就重新换个数开始计数，总能找到最多的那个 public int majorityElement(int[] nums) &#123; int count = 1; int maj = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; if (maj == nums[i]) count++; else &#123; count--; if (count == 0) &#123; maj = nums[i + 1]; &#125; &#125; &#125; return maj; &#125; 鸡蛋掉落标准版有2个鸡蛋，从100层楼上往下扔，以此来测试鸡蛋的硬度。比如鸡蛋在第9层没有摔碎，在第10层摔碎了，那么鸡蛋不会摔碎的临界点就是9层。问：如何用最少的尝试次数，测试出鸡蛋不会摔碎的临界点？ 二分法 平方根法 进阶版你知道存在楼层 F ，满足 0 &lt;= F &lt;= N 任何从高于 F 的楼层落下的鸡蛋都会碎，从 F 楼层或比它低的楼层落下的鸡蛋都不会破。 每次移动，你可以取一个鸡蛋（如果你有完整的鸡蛋）并把它从任一楼层 X 扔下（满足 1 &lt;= X &lt;= N）。 你的目标是确切地知道 F 的值是多少。 无论 F 的初始值如何，你确定 F 的值的最小移动次数是多少？ 动态规划 参考 互联网公司最常见的面试算法题有哪些？ 海量数据排序——如果有1TB的数据需要排序，但只有32GB的内存如何排序处理？]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常用算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法思想：分支限界法]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%9A%E5%88%86%E6%94%AF%E9%99%90%E7%95%8C%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本描述​ 类似于回溯法，也是一种在问题的解空间树T上搜索问题解的算法。但在一般情况下，分支限界法与回溯法的求解目标不同。回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。 分支搜索算法​ 所谓“分支”就是采用广度优先的策略，依次搜索E-结点的所有分支，也就是所有相邻结点，抛弃不满足约束条件的结点，其余结点加入活结点表。然后从表中选择一个结点作为下一个E-结点，继续搜索。 ​ 选择下一个E-结点的方式不同，则会有几种不同的分支搜索方式。 FIFO搜索 LIFO搜索 优先队列式搜索 分支限界搜索算法分支限界法的一般过程​ 由于求解目标不同，导致分支限界法与回溯法在解空间树T上的搜索方式也不相同。回溯法以深度优先的方式搜索解空间树T，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树T。 ​ 分支限界法的搜索策略是：在扩展结点处，先生成其所有的儿子结点（分支），然后再从当前的活结点表中选择下一个扩展对点。为了有效地选择下一扩展结点，以加速搜索的进程，在每一活结点处，计算一个函数值（限界），并根据这些已计算出的函数值，从当前活结点表中选择一个最有利的结点作为扩展结点，使搜索朝着解空间树上有最优解的分支推进，以便尽快地找出一个最优解。 ​ 分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。问题的解空间树是表示问题解空间的一棵有序树，常见的有子集树和排列树。在搜索问题的解空间树时，分支限界法与回溯法对当前扩展结点所使用的扩展方式不同。在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，那些导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被子加入活结点表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所求的解或活结点表为空时为止。 回溯法和分支限界法的一些区别​ 有一些问题其实无论用回溯法还是分支限界法都可以得到很好的解决，但是另外一些则不然。也许我们需要具体一些的分析——到底何时使用分支限界而何时使用回溯呢？ ​ 回溯法和分支限界法的一些区别： ​ 方法对解空间树的搜索方式 存储结点的常用数据结构 结点存储特性常用应用 ​ 回溯法深度优先搜索堆栈活结点的所有可行子结点被遍历后才被从栈中弹出找出满足约束条件的所有解 ​ 分支限界法广度优先或最小消耗优先搜索队列、优先队列每个结点只有一次成为活结点的机会找出满足约束条件的一个解或特定意义下的最优解 参考 五大常用算法之五：分支限界法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法思想：回溯法]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%9A%E5%9B%9E%E6%BA%AF%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概念​ 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 ​ 回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。 ​ 许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 基本思想​ 在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯。（其实回溯法就是对隐式图的深度优先搜索算法）。 ​ 若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。 ​ 而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。 一般步骤 针对所给问题，确定问题的解空间：首先应明确定义问题的解空间，问题的解空间应至少包含问题的一个（最优）解。 确定结点的扩展搜索规则 以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。 算法框架 问题框架 设问题的解是一个n维向量(a1,a2,………,an),约束条件是ai(i=1,2,3,…..,n)之间满足某种条件，记为f(ai)。 非递归回溯框架 1234567891011121314151617181920212223242526 int a[n],i; 初始化数组a[]; i = 1; while (i&gt;0(有路可走) and (未达到目标)) // 还未回溯到头 if(i &gt; n) // 搜索到叶结点 &#123; 搜索到一个解，输出； &#125; else // 处理第i个元素 &#123; a[i]第一个可能的值； while(a[i]在不满足约束条件且在搜索空间内) &#123; a[i]下一个可能的值； &#125; if(a[i]在搜索空间内) &#123; 标识占用的资源； i = i+1; // 扩展下一个结点 &#125; else &#123; 清理所占的状态空间； // 回溯 i = i –1; &#125;&#125; 递归的算法框架 回溯法是对解空间的深度优先搜索，在一般情况下使用递归函数来实现回溯法比较简单，其中i为搜索的深度，框架如下： 12345678910111213141516171819 int a[n]; try(int i) &#123; if(i&gt;n) 输出结果; else &#123; for(j = 下界; j &lt;= 上界; j=j+1) // 枚举i所有可能的路径 &#123; if(fun(j)) // 满足限界函数和约束条件 &#123; a[i] = j; ... // 其他操作 try(i+1); 回溯前的清理工作（如a[i]置空值等）; &#125; &#125; &#125;&#125; 参考 五大常用算法之四：回溯法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法思想：贪心算法]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%9A%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念​ 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 ​ 贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。 ​ 所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 基本思路1. 建立数学模型来描述问题。 2. 把求解的问题分成若干个子问题。 3. 对每一子问题求解，得到子问题的局部最优解。 4. 把子问题的解局部最优解合成原来解问题的一个解。适用问题​ 贪心策略适用的前提是：局部最优策略能导致产生全局最优解。 ​ 实际上，贪心算法适用的情况很少。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。 实现框架​ 从问题的某一初始解出发； 12345while （能朝给定总目标前进一步）&#123; 利用可行的决策，求出可行解的一个解元素；&#125;由所有解元素组合成问题的一个可行解； 贪心策略的选择​ 因为用贪心算法只能通过解局部最优解的策略来达到全局最优解，因此，一定要注意判断问题是否适合采用贪心算法策略，找到的解是否一定是问题的最优解。 ​ 贪心算法的证明围绕着：整个问题的最优解一定由在贪心策略中存在的子问题的最优解得来的。 参考 五大常用算法之三：贪心算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法思想：动态规划算法]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%9A%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念​ 动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。 基本思想与策略​ 基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 ​ 由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 ​ 与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用的情况能采用动态规划求解的问题的一般要具有3个性质： 1. 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 2. 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。 3. 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）求解的基本步骤​ 动态规划所处理的问题是一个多阶段决策问题，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如图所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。 初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解。 确定状态和状态变量：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。 确定决策并写出状态转移方程：因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程。 寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。 ​ 一般，只要解决问题的阶段、状态和状态转移决策确定了，就可以写出状态转移方程（包括边界条件）。实际应用中可以按以下几个简化的步骤进行设计： 分析最优解的性质，并刻画其结构特征。 递归的定义最优解。 以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值 根据计算最优值时得到的信息，构造问题的最优解 算法实现的说明​ 动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。 ​ 使用动态规划求解问题，最重要的就是确定动态规划三要素： 问题的阶段 每个阶段的状态 从前一个阶段转化到后一个阶段之间的递推关系。 ​ 递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处。 ​ 确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。 ​ f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)} 经典问题举例参考 五大常用算法之二：动态规划算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法思想：分治算法]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%AE%97%E6%B3%95%2F%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%9A%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)…… 任何一个可以用计算机求解的问题所需的计算时间都与其规模有关。问题的规模越小，越容易直接求解，解题所需的计算时间也越少。例如，对于n个元素的排序问题，当n=1时，不需任何计算。n=2时，只要作一次比较即可排好序。n=3时只要作3次比较即可，…。而当n较大时，问题就不那么容易处理了。要想直接解决一个规模较大的问题，有时是相当困难的。 基本思想及策略分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。 分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。 如果原问题可分割成k个子问题，1&lt;k≤n，且这些子问题都可解并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这就为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题与原问题类型一致而其规模却不断缩小，最终使子问题缩小到很容易直接求出其解。这自然导致递归过程的产生。分治与递归像一对孪生兄弟，经常同时应用在算法设计之中，并由此产生许多高效算法。 适用情况分治法所能解决的问题一般具有以下几个特征： 该问题的规模缩小到一定的程度就可以容易地解决 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。 利用该问题分解出的子问题的解可以合并为该问题的解； 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。 第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加； 第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用；、 第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。 第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。 复杂性分析递归本质上是将原来的问题转换为更小的同一问题。 设计递归问题： 考虑递归的抽象语义。 递归函数就是一个函数，完成一个功能。 即以sum()为例，就是说我只我自己+左子树的和+右子树的和即为整个树的和。从抽象的角度讲，这就是正确的计算方式。 至于如何去计算左子树的值，再去想起来递归这个概念。 基本步骤所有递归算法都可以分为两部分： 定义递归的抽象语义，将原问题转化为更小的问题。 以二叉树和为例：即对于root而言，root的值+左右子树的值为二叉树的和。 求解最基本的问题，这个最基本的问题是不能自动求解的，而是需要我们编写逻辑的。 即考虑最底层的问题，即一个叶子节点只要返回它本身的值即可。 考虑边界条件，以及到达底层的条件判断。 1234567//对树求和public static int sum(Node root)&#123; if(root == null)&#123; return 0; &#125; return root.val + sum(root.left) + sum(root.right);&#125; 分治法在每一层递归上都有三个步骤： 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题； 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题 合并：将各个子问题的解合并为原问题的解。 应用依据分治法设计程序时的思维过程实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。 一定是先找到最小问题规模时的求解方法 然后考虑随着问题规模增大时的求解方法 找到求解的递归函数式后（各种规模或因子），设计递归程序即可。 可求解的经典问题 二分搜索 大整数乘法 Strassen矩阵乘法 棋盘覆盖 合并排序 快速排序 线性时间选择 最接近点对问题 循环赛日程表 汉诺塔 实例递归问题获得数组最大值 1234567891011121314public static int getMax(int[] arr, int L, int R)&#123; if(L == R)&#123; return arr[L]; &#125; int mid = (L + R)/2; int maxLeft = getMax(arr, L, mid); int maxRight = getMax(arr, mid+1, R); return Math.max(maxLeft, maxRight);&#125;public static void main(String[] args)&#123; int[] arr = &#123;4,3,2,1&#125;; sout(getMax(arr, 0, arr.length-1));&#125; 参考 五大常用算法之一：分治算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：集合框架]]></title>
    <url>%2F2019%2F01%2F26%2FJava%2Fbase%2FJava%E5%AE%B9%E5%99%A8%EF%BC%9A%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[基本概念 使用原因编程时候面临一种问题，即在运行时才知道拥有多少对象，需要根据运行时的状态去创建对象，如此，依靠命名创建对象，以获得对对象的引用便不现实。 数组的长度受到限制，不能快速变更，也不是一个很好地选择 java为该问题提供了一套较完整的容器类：List ,Set,Queue,Map 分类 Collection,一个独立元素序列,包含List,Set,Queue 包含了序列的概念(这是什么意思鸭),一种存放一组对象的方式 Map,一组成对的键值对对象,允许使用键查找值, 共性 对于Colletcion，遍历的方法可以是foreach，也可以使用迭代器 Collection接口在接口当中有一个Iterator的方法，即迭代器，使用迭代器访问集合当中的元素 1234567891011public interface Collection&lt;E&gt;&#123; boolean add(E element); Iterator&lt;E&gt; iterator(); ...&#125;public interface Iterator&lt;E&gt;&#123; E next(); boolean hasNext(); void remove(); default void forEachRemaining(Consumer&lt;? super E&gt;);&#125; 数据结构散列集 可以快速查找元素的一种数据结构，但无法控制元素出现的次序 通过为每个对象计算一个整数（散列码）来实现，散列码由对象的实例域产生。不同的对象应当产生不同的散列码并与equals方法兼容 java实现 java采用链表数组实现，每个列表称为桶。计算对象的位置方法：根据对象的散列码m，与桶的数量n，则m%n便是桶的编号，将对象插入桶中。如果桶满了，则为散列冲突，用对象与桶中对象进行比较，判断是否存在 java SE8，桶满后会从链表转为平衡二叉树 集合框架List特性 以特定的顺序保存一组元素 ArrayList针对随机访问元素 LinkedList 针对经常插入或删除中间元素所设计的高效率集合 添加了可以使之用作栈、队列、双端队列的方法 linkedList.add方法将对象添加到末尾，而如果想将对象添加到中间，则需要使用迭代器 Set特性 对于每个值,只保存一个对象 通常使用set，只关心某事物是否是set的成员 TreeSet 以有序状态保持并防止重复，因为有序，所以对象必须能够相互比较，它们必须实现Comparable接口，或者提供一个Comporable 数据存储在红-黑树当中 TreeSet 实现了NavigableSet的接口，增加了几个便于定位元素以及反向遍历的方法 HashSet 防止重复的集合，可以快速寻找到相符合的元素 散列存储 contain方法快速查看是否某个元素已存在，只在某个桶当中查找元素，不必查看集合所有元素 LinkedHashSet 按照被添加的顺序保存对象 散列存储 EnumSetQueue特性 只允许在容器的一端插入，另一端移除 Stack，Queue等都是由linkedList支持的 分类 Deque Queue ArrayQueue PriorityQueue优先级队列，基于堆（可以自我调整的二叉树）实现，元素可以按照任意顺序插入，却总是按照排序的顺序进行检索。即不论何时调用remove方法，总会获得当前优先级队列中最小的元素。（没有进行排序），可以提供comparator对象 StackMap特性 允许将某些对象与其他一些对象关联起来的关联数组，产生对象之间的一种映射 可以用成对的name/Value进行保存与取出，想要检索一个对象，必须使用一个键 通过Map，可以扩展到多维度，例如Map《Map,Map》,Map 《Person,List》等等 操作 更新映射项 存在一个map：count，用于统计一个单词在文件中出现的频度。则使用counts.put(word,counts.get(word)+1); 存在异常，即当第一次发现该单词，counts.get便会返回null的异常 解决方案： merge方法，counts.merge(word,1,Integer::sum);将word与1关联，否则使用Integer::sum函数组合求值 counts.getOrDefault(word,0)， counts.putIfAbsent(word,0);couts.put(word,counts.get(word)+1)，该方法只有当键原先存在时才会放入一个值 HashMap 只对键进行散列，散列或者比较函数只能作用于键，与键关联的值不能进行散列或者比较 LinkedHashMap类似HashMap，但可以记住元素插入的顺序，也可以设定成依照元素上次存取的先后来排序 TreeMap 用键的整体顺序对整体元素进行排序，并将其组织成搜索树 WeakHashMapIdentityHashMap 键的散列值不依靠hashCode，而是System.identityHashCode()，是根据内存地址计算散列码，并且比较使用==而不是equals 参考 《java编程思想 第4版》 第11章 持有对象 《java编程思想 第4版》 第17章 容器深入研究]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：断言]]></title>
    <url>%2F2018%2F11%2F02%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E6%96%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[断言提出问题假设确信某个属性符合要求，并且代码的执行依赖于这个属性，例如需要计算double y = Math.sqrt(x);即确信x是一个非负数。 而我们依然希望对它进行检查，避免一些非法的参数进来，或者说抛出一个异常。但是这些做法都会使得代码一直保留在程序当中，测试完毕后也不会自动删除，如果在程序中含有大量这种检查，则持续运行起来会非常慢。 概述是什么断言允许在测试期间向程序中向代码中插入一些检查语句，当代码发布时，这些检测语句会自动移走。Java引入了关键字assert。 分类，各个分类是什么 assert 条件。对条件进行检查，如果结果为false，则抛出一个AssertionError异常 assert 条件：表达式。表达式将被传入AssertionError构造器并转换成一个消息字符串。 启用和禁用断言默认情况下会禁用断言，可以在运行程序时-enableassertions或-ea启用。 当重启断言时，不需要重新编译程序，启用或禁用断言是类加载器的功能，当断言被禁用则编译器会跳过断言代码。 使用断言完成参数检查在Java中给出了3种处理系统错误的机制 抛出异常 日志 断言。那么合适使用断言呢 断言的失败是致命的，不可恢复的错误 断言检查只用于开发和测试阶段。 123if [ -f ~/.dircolors ]; then eval `dircolors ~/.dircolors`fi 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象引用的初始化方法]]></title>
    <url>%2F2018%2F10%2F19%2FJava%2F%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[对象引用的初始化方法遇到的问题在定义一个复杂的模块类，这个模块由一些其他模块组成，比如说，一辆车的信息，包含着电池、车轮、车锁、车主等等的信息，我又想把它们联系到一起，所以这个类就含有着对其他对象的引用。 那么如果说，我从数据库当中去查找这个类，我最终得到的结果，它的对象引用是什么样子的呢？ 首先我去找了对象引用初始化的方式，如下： 方式: 在定义对象的位置; 在类的构造器中; 在使用对象之前, 即惰性初始化; 实例初始化. 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 四种初始化方式 * &lt;p/&gt; * Created by wang on 15/8/5. */class Soap &#123; public Soap() &#123; System.out.println("Soap"); &#125; @Override public String toString() &#123; return "Constructed"; &#125;&#125;public class TestInit &#123; private String s1 = "Happy"; // 定义初始化 private Soap s2; private String s3, s4; // 实例初始化 &#123; s2 = new Soap(); &#125; public TestInit() &#123; s3 = "Good"; // 构造器初始化 &#125; @Override public String toString() &#123; s4 = "Girl"; // 惰性初始化 return "TestInit&#123;" + "s1='" + s1 + ", s2=" + s2 + ", s3='" + s3 + ", s4='" + s4 + '&#125;'; &#125; public static void main(String[] args) &#123; TestInit ti = new TestInit(); System.out.println(ti); &#125;&#125;/* Output: Soap TestInit&#123;s1='Happy, s2=Constructed, s3='Good, s4='Girl&#125; */ 参考 Java - 对象引用的初始化方式]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：内部类]]></title>
    <url>%2F2018%2F10%2F18%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[内部类内部类是定义在另一个类当中的类，并且，它与组合是完全不同的概念。 分类内部类有动态与静态之分,动态内部类基于外部类而存在,因此,动态的内部类的创建必须要先创建它的外围类,因为一个动态内部类包含着一个隐含属性,即对其外围类的引用. 而静态内部类并不需要 使用原因 每个内部类都能独立地继承自一个(接口的)实现,所以无论外部类是否已经继承这个接口的实现,对于内部类没有影响 内部类可以实现多重继承 内部类方法可以访问该类定义所在的作用域中的数据，包括私有的数据。(其在创建时候,便与外部类,即创造它的对象建立了一种联系,因此可以访问数据) 内部类了解外围类，并能够与其通信 利用内部类可以极好的实现private,对外隐藏实现细节.并且内部类可以对同一个包中的其他类隐藏起来。 当想要定义一个回调函数且不想编写大量代码时，使用匿名内部类比较便捷。 使用内部类可以由外部类的方法进行创建 内部类的对象总会有一个隐式的引用，它指向了创建它的外部对象，因此，内部类是可以直接调用外部类的实例变量 12345678910111213141516171819202122232425public class InnerClassTest &#123; /** * 类的方法构造内部类的实例 */ public void start() &#123; //构造内部类 ActionListener listener = new TimePrinter(); Timer t = new Timer(interval, listener); t.start(); &#125; /** * 内部类 * 内部类可以访问外部类的变量 */ public class TimePrinter implements ActionListener &#123; @Override public void actionPerformed(ActionEvent event) &#123; System.out.println("At the tone, the time is " + new Date()); //这个beep是外部类的变量 if (beep) &#123; Toolkit.getDefaultToolkit().beep(); &#125; &#125; &#125;&#125; 获得内部类的引用内部类不能在另一个类当中进行创建，若在某些时候想要获取这个引用，需要通过外部类的方法来获得,或者使用.new语法。当然我个人觉得，还不如新建一个类 1234567891011121314151617181920212223242526272829package ten.innerClass;/** * 在外部获得内部类的引用 * @Author : Heper * @Time : 2019/1/26 16:31 */public class InnerClassReference &#123; /** * 创建内部类 * 这个内部类必须是一个public的 */ public class Content&#123; private int i; Content()&#123; this.i=1; &#125; &#125; public Content getContent()&#123; return new Content(); &#125; public static void main(String args[])&#123; InnerClassReference innerClassReference=new InnerClassReference(); //与一般的类创建不同,这个类的创建需要添加它的外围类 InnerClassReference.Content content=innerClassReference.getContent(); //也可以采用另一种方式,与平时看到的new语法不同的是,需要在前面加一个外围类的对象 InnerClassReference.Content content2=innerClassReference.new Content(); &#125;&#125; 与外部类进行交互操作外部类的元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package ten.innerClass;/** * 与外部类的链接交互 * 通过这个内部类,可以实现对数组访问操作的统一,亦或者是对类内部对象、数据等对象的统一操作接口 * @Author : Heper * @Time : 2019/1/26 16:53 */public class Sequence &#123; private Object[] items; private int next = 0; public Sequence(int size) &#123; items = new Object[size]; &#125; public void add(Object x) &#123; if(next &lt; items.length) &#123; items[next++] = x; &#125; &#125; /** * 这个是内部类,也是一个迭代器 */ private class SequenceSelector implements Selector &#123; private int i = 0; //在该方法当中,直接使用到了外围类的items,不需要任何的中介 @Override public boolean end() &#123; return i == items.length; &#125; @Override public Object current() &#123; return items[i]; &#125; @Override public void next() &#123; if(i &lt; items.length) i++; &#125; &#125; /** * 返回一个内部类的引用 */ public Selector selector() &#123; return new SequenceSelector(); &#125; public static void main(String[] args) &#123; Sequence sequence = new Sequence(10); for(int i = 0; i &lt; 10; i++) &#123; sequence.add(Integer.toString(i)); &#125; //设计模式的思想,只要是继承了selector接口的,都可以使用这个迭代器 //想要创建一个内部类的对象,必须通过它的外部类来实现 Selector selector = sequence.selector(); while(!selector.end()) &#123; System.out.print(selector.current() + " "); selector.next(); &#125; &#125;&#125;/** * 一个通用的接口 */interface Selector &#123; boolean end(); Object current(); void next();&#125; 在内部类获得外部类的引用局部内部类在之前,内部类都是在外部定义的,而事实上可以在一个方法当中或任意的作用域当中定义内部类,这样的内部类称为局部内部类,需要如此的理由是: 实现了某类型的接口,于是可以创建并返回对其的引用 要解决一个复杂的问题,想创建一个类来辅助解决方案,但并不希望这个类是公共可用的. 在上面，只有start方法使用了内部类，则可以在方法中定义局部类 123456789101112131415161718192021222324public class InnerClassTest &#123; /** * 类的方法构造内部类的实例 */ public void start() &#123; /** * 局部内部类,属于方法,而不属于类,在方法外无法访问 */ class TimePrinter implements ActionListener &#123; @Override public void actionPerformed(ActionEvent event) &#123; System.out.println("At the tone, the time is " + new Date()); //这个beep是外部类的变量 if (beep) &#123; Toolkit.getDefaultToolkit().beep(); &#125; &#125; &#125; //构造内部类 ActionListener listener = new TimePrinter(); Timer t = new Timer(interval, listener); t.start(); &#125;&#125; 不能使用public或者private进行修饰，作用范围只在这个方法当中，对外部完全隐藏。 局部方法可以访问局部变量，即在方法当中定义的变量，但是他们必须是不会在方法中改变的，最好是方法的参数 匿名内部类对局部内部类的一个深入，如果只创建这个类的一个对象，则不必命名了。 123456789101112131415161718192021public class InnerClassTest &#123; /** * 类的方法构造内部类的实例 */ public void start() &#123; /** * 匿名内部类 */ ActionListener listener = new TimePrinter()&#123; public void actionPerformed(ActionEvent event) &#123; System.out.println("At the tone, the time is " + new Date()); //这个beep是外部类的变量 if (beep) &#123; Toolkit.getDefaultToolkit().beep(); &#125; &#125; &#125; Timer t = new Timer(interval, listener); t.start(); &#125;&#125; 静态内部类如果使用内部类只是为了把一个类隐藏在另外一个类的内部，并不需要内部类引用外围类对象。为此，可以将内部类声明为static,以便取消产生的引用。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lambda表达式]]></title>
    <url>%2F2018%2F10%2F18%2FJava%2Fbase%2FJavaBase%EF%BC%9Alambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[lambda表达式lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。 为什么要用Java是面向对象语言，想要传递一个代码段则需要创建一个对象，这个对象的类需要有一个方法能够包含所需的代码。 在某些情况中，需要把一段代码传递给某个对象，但是，由于java是面向对象的，所以，这段代码需要包装在一个类当中举例： 1234/** * 需要一个数组参数与一个实现了Comparator接口的类 */public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) 因此，如果我们想要去使用这个sort，那么就需要去构造一个实现了该接口的类，然后去重写方法，将这个类传递给sort才行。 12345678/** * 构造一个实现Comparator接口的类 */class LengthComparator implements Comparator&lt;String&gt;&#123; public int compareTo(String f,String s)&#123; return f.length()-s.length(); &#125;&#125; 如此,我们才能够实现按照字符串长度来排序。可以看到的是，在这个类当中内容并不是很多，只是一个代码块而已。sort()需要的也只是那个compareTo方法。 适用范围 对于只有一个抽象方法的接口，需要这种接口的对象时就可以提供一个lambda表达。 使用lambda其具体语法为： (类型 参数,类型 参数)-&gt;{表达式} 那么最终我们需要的代码块是： 12345678f.length()-s.length();//java作为强类型,则需要指明类型:(String f,String s) -&gt;f.length()-s.length()//以上便是一个完整的lambda表达式//完整的调用一次Arrays.sort(planets, (String first,String second) -&gt; first.length() - second.length()); lambda既然是代码块，当然也就不只一行 1234(String f,String s)-&gt;&#123; //随便写,就像一个方法一样 return f.length()-s.length();&#125; 一些特殊写法经常会看到一些和上面的示例并不相同的写法 没有写类型参数 1234567/** * planets是一个String数组 * 因此编译器可以推导出其后面的应当是一个String类型的参数 * 所以省略了参数 */Arrays.sort(planets, (first,second) -&gt; first.length() - second.length()); 没有写() 12345/** * 方法只有一个参数,并且参数类型可以推导出来 */ActionListener listener = event - &gt;System.out.println ( " The time is " + new Date ( ) " ) ; 处理lambda表达式lambda表达式的重点是“延时执行”，之所以如此是因为 在一个单独的线程运行代码 多次运行代码 在算法的适当位置运行代码（例如排序） 发生某种情况时运行代码 只在必要时候运行 注意即便这个lambda不需要任何的方法参数，依然要写() 1234()-&gt;&#123; int i=0; System.out.println(i);&#125; lambda表达式可以访问外围方法或类当中的变量，但是这些变量必须是最终变量，不能随意改变，也不可以在表达式内改变 函数式接口定义对于只有一个抽象方法的接口，需要这种接口的对象时就可以提供一个lambda表达式，这种接口为函数式接口。 方法引用对于已经存在的方法，可以完成想传递给其他代码的某个动作，代替了代码块，则可以使用方法引用 1234Timer t = new Timer ( 1000 , System.out:: println );//等价于:Timer t = new Timer ( 1000 ,x-&gt; System.out.println(x) ); 使用: object :: instanceMethod Class :: staticMethod Class :: instanceMethod 构造器引用与方法引用类似，不过方法名为new，例如Person :: new是Person构造器的一个引用，具体是那个引用取决于上下文 变量作用域可能希望在lambda表达式中访问外围方法或类中的变量。 1234567public static void repeadMsg(String text,int deploy)&#123; ActionListener listener = event -&gt;&#123; System.out.println(text); Toolkit.getDefaultToolkit.beep(); &#125;; new Timer(deploy,listener).start();&#125; 这个代码当中，lambda用到了外围的变量text，而这么使用可能会存在问题，即lambda代码可能会在repeatMessage调用返回很久后才运行，此时参数变量已经不存在了，那如何保留text呢 lambda表达式有3个部分 一个代码块 参数 自由变量的值 指非参数而且不在lambda中定义的变量。例如上述的text变量。在该示例当中，text变量被lambda捕获。即这个变量的值被复制到这个对象的实例变量中 要明确所捕获的值是明确定义的，即只能引用值不会改变的变量，当在lambda中进行text++，则是不允许的。如果这个值在lambda外部改变，也是不合法的 即lambda捕获的变量必须实际上是最终变量，即初始化后就不会再为它赋新值。 lambda表达式的函数体拥有与嵌套块相同的作用域，适用命名冲突和遮蔽的有关规则，即lambda内部声明的变量与一个局部变量不可重名等。 this在lambda中指创建这个lambda表达式的方法的this参数，即该对象。 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：泛型]]></title>
    <url>%2F2018%2F10%2F17%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本概念作用 保证类的可重用性 指定容器要持有什么类型的对象，并由编译器保证类型的正确性 应用泛型类使用泛型编写一个更通用的类 当处理一个问题，这个问题需要解决一个对应类，便需要在类当中进行组合。但如果是一组类，我们可能就需要些一组类，无疑是很麻烦的一件事情。这种时候，可以使用泛型 个例问题123456789101112131415161718192021222324252627282930313233343536373839404142package fifteen.generics;import eleven.collection.Pet;/** * 编写一个通用类的尝试 * * @Author : Heper * @Time : 2019/1/28 19:05 */public class Holder &#123; /** * 持有一个Object的类,对它进行处理 * 但是,如此一来,并不能持有一个其他的类,必须要进行向上转型 * 如果说,想要持有一个新的类,就又要写一个新的类 * 使用泛型可以帮助解决这种问题 */ private Object a; public Holder(Object a) &#123; this.a = a; &#125; public void set(Object a) &#123; this.a = a; &#125; public Object get() &#123; return a; &#125; public static void main(String[] args) &#123; Holder h2 = new Holder(new Pet()); Pet a = (Pet) h2.get(); h2.set("Not an Automobile"); String s = (String) h2.get(); h2.set(1); Integer x = (Integer) h2.get(); &#125;&#125; 通用的解决方案123456789101112131415161718192021222324252627282930313233343536373839package fifteen.generics;import eleven.collection.Pet;/** * 基于泛型对类的复用性进行扩展 * * @Author : Heper * @Time : 2019/1/28 19:59 *///public class Holder3&lt;T, E&gt; &#123;public class Holder2&lt;T&gt; &#123; /** * 可以看到,这个类从Object变成了T * 即一个可以在编译时更改的类,则在创建对象时候,只需要指明类型即可 */ private T a; public Holder2(T a) &#123; this.a = a; &#125; public void set(T a) &#123; this.a = a; &#125; public T get() &#123; return a; &#125; public static void main(String[] args) &#123; //创建对象时候,要指明T的类型 Holder2&lt;Pet&gt; h3 = new Holder2&lt;&gt;(new Pet()); Pet a = h3.get(); // No cast needed // h3.set("Not an Automobile"); // Error // h3.set(1); // Error &#125;&#125; 泛型接口泛型方法使用泛型方法需要在返回类型前加 12345678910111213141516171819202122232425/** * 泛型方法 * * @Author : Heper * @Time : 2019/2/2 17:10 */public class GenericMethods &#123; public &lt;T&gt; void f(T x) &#123; System.out.println(x.getClass().getName()); &#125; public static void main(String[] args) &#123; /** * 对f方法的重载 * 编译器自动根据参数的类型进行重载 */ GenericMethods gm = new GenericMethods(); gm.f(""); gm.f(1); gm.f(1.0); gm.f(1.0F); gm.f('c'); gm.f(gm); &#125;&#125; 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>javaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown使用技巧]]></title>
    <url>%2F2018%2F10%2F16%2F%E5%B0%8F%E6%8A%80%E5%B7%A7%2Fmarkdown%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[markdown使用如何添加代码块使用格式: 123\``` 某语言 (java,c,c++) 代码块 \ 1## 列表嵌套 一级列表 二级列表（前面三个空格） 二级列表12345表现为：1. 一级列表 1. 二级列表（前面三个空格） - 二级列表## 表格 表头 表头 表头 内容 内容 内容 内容 内容 内容 1234567891011121314151617表现为：表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容 第二行分割表头和内容。- 文字默认居左- 两边加：表示文字居中- 右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略## 添加超链接 [浏览器上显示的内容](超链接 “鼠标悬停显示的文字”) 1234表现为：## 图片 语法：![图片alt](图片地址 ‘’图片title’’) - 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 - 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 # 参考 # 1.]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode使用技巧]]></title>
    <url>%2F2018%2F10%2F16%2F%E5%B0%8F%E6%8A%80%E5%B7%A7%2Fvscode%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[vscode技巧 在当前目录打开命令行：Ctrl+shift+c 参考 vscode 在当前文件位置打开控制]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：面向对象]]></title>
    <url>%2F2018%2F10%2F16%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[面向对象概述关于面向对象OOP的程序设计模式对象:对象具有状态,行为,标识.意味着每一个对象都可以拥有内部数据（对象的状态）和方法（对象的行为），每一个对象在内存当中都有一个地址 万物皆为对象. 对象可以存储数据,可以在自身上执行操作. 是指可以抽取问题当中的任何概念化的构件(一个生物,一个建筑零件,一项服务),将其表示为程序当中的对象. 程序是对象的集合,通过发送消息来告知彼此所要做的 要请求一个对象,就要对对象发送一条信息 消息是对象或对象的方法调用的请求 每个对象度有自己的由全体对象所构成的存储 每个对象都拥有其类型 每个对象都有一个类,对象是类的实例 类区别于其他类的最重要的特性就是可以发送什么信息给它 某一特定类型的缩影对象度可以接受相同的消息 圆形是几何形,那么可以接受几何形的消息 对象的特性： 对象的行为 （ behavior ) — 可以对对象施加哪些操作 ， 或可以对对象施加哪些方法 ？ 对象的状态 （ state ) — 当施加那些方法时 ， 对象如何响应 ？ 对象标识 （ identity ) — 如何辨别具有相同行为与状态的不同对象 ？ 四个基本特性抽象：将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面，抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么 三大特性 三大特性封装将数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。可以说，封装就是隐藏一切可隐藏的东西，只向外界提供最简单的编程接口 优点： 减少耦合：可以独立地开发、测试、优化、使用、理解和修改 减轻维护的负担：可以更容易被程序员理解，并且在调试的时候可以不影响其他模块 有效地调节性能：可以通过剖析确定哪些模块影响了系统的性能 提高软件的可重用性 降低了构建大型系统的风险：即使整个系统不可用，但是这些独立的模块却有可能是可用的 以下 Person 类封装 name、gender、age 等属性，外界只能通过 get() 方法获取一个 Person 对象的 name 属性和 gender 属性，而无法获取 age 属性，但是 age 属性可以供 work() 方法使用。 注意到 gender 属性使用 int 数据类型进行存储，封装使得用户注意不到这种实现细节。并且在需要修改 gender 属性使用的数据类型时，也可以在不影响客户端代码的情况下进行。 12345678910111213141516171819202122public class Person &#123; private String name; private int gender; private int age; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender == 0 ? "man" : "woman"; &#125; public void work() &#123; if (18 &lt;= age &amp;&amp; age &lt;= 50) &#123; System.out.println(name + " is working very hard!"); &#125; else &#123; System.out.println(name + " can't work any more!"); &#125; &#125;&#125; 继承继承是从已有类得到继承信息创建心累的过程。提供继承信息的称为父类（超类、基类）；得到继承信息的称为子类（派生类） 继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为 向上转型。 1Animal animal = new Cat(); 多态允许不同子类型的对象对同一消息作出不同的响应 多态分为编译时多态和运行时多态： 编译时多态主要指方法的重载（前绑定） 运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定。指方法重写（后绑定） 运行时多态有三个条件： 继承 覆盖（重写） 向上转型 下面的代码中，乐器类（Instrument）有两个子类：Wind 和 Percussion，它们都覆盖了父类的 play() 方法，并且在 main() 方法中使用父类 Instrument 来引用 Wind 和 Percussion 对象。在 Instrument 引用调用 play() 方法时，会执行实际引用对象所在类的 play() 方法，而不是 Instrument 类的方法。 1234567891011121314151617181920212223242526272829303132public class Instrument &#123; public void play() &#123; System.out.println("Instument is playing..."); &#125;&#125;public class Wind extends Instrument &#123; public void play() &#123; System.out.println("Wind is playing..."); &#125;&#125;public class Percussion extends Instrument &#123; public void play() &#123; System.out.println("Percussion is playing..."); &#125;&#125;public class Music &#123; public static void main(String[] args) &#123; List&lt;Instrument&gt; instruments = new ArrayList&lt;&gt;(); instruments.add(new Wind()); instruments.add(new Percussion()); for(Instrument instrument : instruments) &#123; instrument.play(); &#125; &#125;&#125; 程序设计对象是服务的提供者程序本身向用户提供服务，它将调用其他对象提供的服务来实现这一目的。 抽象类Java中可以定义没有方法体的方法，该方法由其子类来具体的实现。该没有方法体的方法我们称之为抽象方法，含有抽象方法的类我们称之为抽象类。 特点抽象方法的特点 只有方法头没有方法体的方法称之为抽象方法。（即只有方法的声明，没有方法的实现） 抽象方法用abstract关键字来修饰。 抽象方法代表一种不确定的操作或行为。（由子类去具体实现） 抽象方法不能被调用。 抽象类的特点 定义中含有抽象方法的类叫做抽象类。 抽象类用abstract关键字来修饰。 抽象类代表一种抽象的对象类型。 抽象类不能实例化。 抽象类中可以有具体方法，可以没有抽象方法。（也就是说一个类中只要有一个方法是抽象方法那么这个类一定是抽象类，反过来，一个抽象类中可以没有抽象方法，可以带有具体实现的方法） 一旦一个类中有抽象方法，那么这个类必须也要用abstract来修饰，代表这个类是抽象类，它是不能被实例化的。 意义抽象类往往用来表征对问题领域进行分析、设计中得出的抽象概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。 为子类提供一个公共的类型； 封装子类中重复内容（成员变量和方法）； 定义有抽象方法，子类虽然有不同的实现，但该方法的定义是一致的。 当我看到类是抽象的，我会很关心它的抽象方法。我知道它的子类一定会重写它，而且，我会去找到抽象类的引用。它一定会有多态性的体现。 static静态静态域与常量如果将域或者常量定义为static，每个类将只有一个这样的域，所有的对象将对静态的域进行共享。因为静态域是属于类的，而不是对象 静态方法静态的东西皆是属于类的，而并不属于对象，因此对静态方法的调用时，应使用类去调用。 当然对象可以去调用静态方法，因为对象都具有一个共享的静态空间，所以它也可以去调用这个静态空间，但是如果使用对象的话，容易造成混淆。因为该方法与这个对象并无关系。 使用静态方法的情况 方法不需要访问对象状态 ， 其所需参数都是通过显式参数提供 一个方法只需要访问类的静态域 静态工厂 工厂方法的功能是类似于构造器的 工厂方法生成不同风格的格式化对象 使用静态工厂的原因： 无法命名构造器，构造器的名字必须与类名相同，但是通过工厂方法可以获得采用不用的名字的实例 当使用构造器时， 无法改变所构造的对象类型 。 main方法方法参数关于按值调用与按引用调用 按值调用：方法接收的是调用者提供的值，方法得到的是所有参数值的一个拷贝 按引用调用：方法接收的是调用者提供的变量地址 java的参数为按值调用 解释为什么参数为对象的时候，改变了真正对象的值 因为创建对象的时候，使用语句 Object o = new Object()，所得到的对象为o，而o是一个对象的引用，当将它传递给方法，方法得到的是o的拷贝，即一个引用的拷贝，即依然是一个队对象的引用，所以对它修改，实际上是通过了这个引用，改变了实际对象的值。 方法重载如何区分重载方法问题：多个方法具有相同的名字，那么Java是如何知道我想使用的是哪一个方法呢。 解决：区分指标为类名于方法的形参，为每一个重载的方法建立一个独一无二的参数类型列表 注：不能只改变方法的返回类型,而不改变方法的参数,当然如果改变了参数,改变返回类型也是可以的 涉及基本类型的重载基本类型能从一个“较小”的类型，自动提升到一个较大的类型，该过程的重载又是如何？ 假设传入一个5，分以下的情况： 存在接受int类型的方法，则调用该方法 传入的数据类型小于声明的参数类型，例如double,则提升原数据类型的数据类型 其中char类型会直接提升到int类型 传入的数据类型大于声明的参数类型，则会报错，需要进行类型转换进行窄化处理 参考 面向对象思想]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2018%2F10%2F09%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[策略模式提出问题 在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。即代码中要根据客户不同的选项进行不同的行为 问题案例问题案例1 电影票打折方案。Sunny软件公司为某电影院开发了一套影院售票系统，在该系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下： 学生凭学生证可享受票价8折优惠； 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元）； 影院VIP用户除享受票价半价优惠外还可进行积分，积分累计到一定额度可换取电影院赠送的奖品。 该系统在将来可能还要根据需要引入新的打折方式。为了实现上述电影票打折功能，Sunny软件公司开发人员设计了一个电影票类MovieTicket，其核心代码片段如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940//电影票类 class MovieTicket &#123; private double price; //电影票价格 private String type; //电影票类型 public void setPrice(double price) &#123; this.price = price; &#125; public void setType(String type) &#123; this.type = type; &#125; public double getPrice() &#123; return this.calculate(); &#125; //计算打折之后的票价 public double calculate() &#123; //学生票折后票价计算 if(this.type.equalsIgnoreCase("student")) &#123; System.out.println("学生票："); return this.price * 0.8; &#125; //儿童票折后票价计算 else if(this.type.equalsIgnoreCase("children") &amp;&amp; this.price &gt;= 20 ) &#123; System.out.println("儿童票："); return this.price - 10; &#125; //VIP票折后票价计算 else if(this.type.equalsIgnoreCase("vip")) &#123; System.out.println("VIP票："); System.out.println("增加积分！"); return this.price * 0.5; &#125; else &#123; return this.price; //如果不满足任何打折要求，则返回原始票价 &#125; &#125; &#125; 测试代码 1234567891011121314151617181920class Client &#123; public static void main(String args[]) &#123; MovieTicket mt = new MovieTicket(); double originalPrice = 60.0; //原始票价 double currentPrice; //折后价 mt.setPrice(originalPrice); System.out.println("原始价为：" + originalPrice); System.out.println("---------------------------------"); mt.setType("student"); //学生票 currentPrice = mt.getPrice(); System.out.println("折后价为：" + currentPrice); System.out.println("---------------------------------"); mt.setType("children"); //儿童票 currentPrice = mt.getPrice(); System.out.println("折后价为：" + currentPrice); &#125; &#125; 问题 MovieTicket类的calculate()方法非常庞大，它包含各种打折算法的实现代码，在代码中出现了较长的if…else…语句，不利于测试和维护。 增加新的打折算法或者对原有打折算法进行修改时必须修改MovieTicket类的源代码，违反了“开闭原则”，系统的灵活性和可扩展性较差。 算法的复用性差，如果在另一个系统（如商场销售管理系统）中需要重用某些打折算法，只能通过对源代码进行复制粘贴来重用，无法单独重用其中的某个或某些算法（重用较为麻烦）。 应用适用性 许多相关的类仅仅是行为有异。策略提供了一种用多个行为中的一个行为来配置一个类的方法 需要使用一个算法的不同变体 算法使用客户不应该知道的数据。策略模式避免暴露复杂、与算法相关的数据结构 一个类定义了多种行为，并且这些行为在这个类的操作中以多个条件语句的形式出现，将相关的条件分支移入它们各自的Strategy中 案例案例1 存在一个种群：鸭子 有些鸭子会飞、有些不会、有些快、有些慢，但都是在飞，那么考虑两种实现方法。 使用继承，在每一个子类进行重写。 创建一个飞行接口，然后交由一组类进行实现该接口。这样就可以使得鸭子实现复用 案例2 有许多的算法可以对一个正文流进行分析，将这些算法硬编码进使用它们的类是不可取的 需要换行功能的客户程序如果直接包含换行算法代码的话会变得很复杂，使得客户程序难以维护，尤其是当需要支持多种换行算法时 不同的时候需要不同的算法 当换行功能是客户程序一个难以分割的成分时，增加新的换行算法或改变现有算法十分困难 案例3 电影票打折方案。Sunny软件公司为某电影院开发了一套影院售票系统，在该系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下： 学生凭学生证可享受票价8折优惠； 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元）； 影院VIP用户除享受票价半价优惠外还可进行积分，积分累计到一定额度可换取电影院赠送的奖品。 具体应用 Java SE 中的每个容器都存在多种布局供用户选择，就用到了策略模式 基础概述是什么 策略模式：定义了算法族，分别分装起来，让他们可以互相替换，此模式使得算法的变化独立于使用算法的客户。使得算法可以在不影响客户端的情况下发生变化，从而改变不同的功能。 策略模式定义了算法族，分别分装起来，让他们可以互相替换，此模式使得算法的变化独立于使用算法的客户 策略模式体现了两个原则 封装变化的概念。（将飞行动作的变化抽离出） 编程中使用接口，而不是使用的是具体的实现类(面向接口编程)。 分类协作结构 参与者 Strategy：策略 定义所有支持的算法的公共接口，Context使用这个接口来调用某ConcreteStrategy定义的算法 ConcreteStrategy：具体策略 以Startegy接口实现某具体算法 Context：上下文 是使用算法的角色，它在解决某个问题（即实现某个方法）时可以采用多种策略。 维护一个对Strategy对象的引用，用一个ConcreteStrategy对象来配置 可以定义一个接口来让Stategy访问它的数据 协作 类关系 Strategy定义一个公共接口，表示策略的意图 ConcreteStrategy继承自Strategy，是实现具体的策略 Context持有一个Strategy的引用，环境角色使用这个接口调用不同的算法，最终给客户端使用 逻辑关系 Strategy与Context相互作用以实现选定的算法，当算法被调用时，Context可以将该算法所需要的所有数据都传递给该Strategy。或者Context将自身作为一个参数传递给Strategy，让Strategy在需要时可以毁掉Context Context将它的客户请求转发给它的Strategy。客户通常创建并传递一个ConcreteStrategy对象给该Context，这样客户仅仅与Context交互。通常有一系列的ConcreteStrategy可供客户选择。 权衡分类结构 效果（优缺）优点 简化了单元测试，每个算法都有自己的类，可以通过自己的接口单独测试 相关算法系列。Strategy类层次为Context定义了一系列的可供重用的算法或行为，继承有助于提取出这些算法中的公共功能 一个替代继承的方法。 可以直接生成一个Context类的子类，从而给它以不同的行为，但会将行为硬编码到Context，将算法的实现与Context耦合到一起，使得难以理解、维护、扩展。并且他们还不能动态改变算法。因此得到一堆相关的类，唯一差别仅仅是算法不同 将算法封装在独立的Strategy类中，使得你可以独立于Context改变，并易于切换、理解、扩展 消除了一些条件语句。提供了用条件语句选择所需的行为以外的另一种选择，当不同的行为堆砌在一个类中很难避免使用条件语句选择何时的行为，将行为封装在一个个独立的Strategy中消除了这些语句。 实现的选择。提供相同行为的不同实现，客户可以根据不同时间/空间的权衡从不同策略中进行选择 缺陷 策略模式把每一种具体的策略都封装成一个实现类，如果策略有很多的话，很显然是实现类就会导致过多，显得臃肿 如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 客户必须了解不同的Strategy。因为客户要选择一个合适的Strategy就必须知道他们有什么不同，因此仅仅当这些不同行为变体与客户相关的行为才需要使用 Strategy和Context之间的通信开销。某些ConcreteStrategy可能永不到所有Strategy传递过来的参数。 实现实现步骤 定义Strategy、Context接口，它们必须是的ConcreteStrategy能够有效的访问它所需要的Context中的任何数据，反之亦然 让Context将数据放在参数中传递给Strategy操作，即将数据发送过去，使得解耦。但是可能发送一些Strategy不需要的数据 将Context作为一个参数传递过去，Strategy显式向其请求数据，或存储它的一个引用。 Context接口内部持有一个策略类的引用 编写具体策略角色(实际上就是实现上面定义的公共接口) 考虑使得Strategy对象成为可选的，如果即使在不使用额外的Strategy对象的情况下，Context依然有意义，则可以简化为在访问Strategy前先检查是否存在，如果存在则使用，如果不存在则执行缺省的行为 案例1Context父类Duck 可以看到在父类当中，我们定义了两个策略的接口，但是没有任何的引用对象。同样也定义了一个方法，但是没有具体的内容，在子类中，需要对它进行@Override重写 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Author : Hyper * @Time : 2018/10/8 19:17 */public abstract class Duck &#123; /** * 声明两个行为为接口类型 * 每一个鸭子都会引用实现该接口的对象 */ FlyBehavior flyBehavior; QuackBehavior quackBehavior; /** * 这些行为不是由Duck本身进行实现的,而是转交给了对应的接口引用的对象 */ public void performQuack() &#123; quackBehavior.quack(); &#125; public void performFly() &#123; flyBehavior.fly(); &#125; /** * 动态地设定鸭子的行为 * * @param fb */ public void setFlyBehavior(FlyBehavior fb) &#123; this.flyBehavior = fb; &#125; public void setQuackBehavior(QuackBehavior qb) &#123; this.quackBehavior = qb; &#125; /** * 较差的方法:呱呱叫 * 需要通过继承@Override重写 */ public void quack() &#123; &#125; /** * 游泳 */ public void swim() &#123; &#125;&#125; 定义策略Strategy 首先，为了多态，先定义了一个飞行行为的接口，可以看到，在该接口当中，我们定义了一个fly()的方法。 123456/** * 抽离飞行的动作,制作接口 */public interface FlyBehavior &#123; void fly();&#125; 接下来，对该接口进行实现,即具体的策略实现 123456789101112/** * 实现飞行的动作 * * @Author : Hyper * @Time : 2018/10/8 19:41 */public class FlyWithWings implements FlyBehavior &#123; @Override public void fly() &#123; System.out.println("FlyWithWings.class"); &#125;&#125; 另一个实现 123456789/** * 火箭动力 */public class FlyRocketPowered implements FlyBehavior &#123; @Override public void fly() &#123; System.out.println("FlyRocketPowered.class"); &#125;&#125; 这样一来，我们还可以看到所有的飞行行为，同时如果有需求的变化，我们可以在一个实现里面修改 Context的具体子类 123456789101112131415/** * 整合接口的实例变量到具体的Duck中 */public class MarrardDuck extends Duck &#123; /** * 在实例化的时候更改接口的对象,使得所有的对象都是这样的一个引用对象 * 在该类使用飞行的时候,就会调用FlyWithWings的对象 * 因为它引用的对象是FlyWithWings的实体 */ public MarrardDuck() &#123; flyBehavior = new FlyWithWings(); quackBehavior = new Quack(); &#125;&#125; 在该子类当中，我们将超类的接口，引用到了一个实例。 测试 做一个简单的测试 12345678910public class Main &#123; /** * @param args */ public static void main(String[] args) &#123; Duck duck = new MarrardDuck(); duck.performFly(); duck.performQuack(); &#125;&#125; 输出结果为： 12FlyWithWings.classQuack.class 即接口引用到了该子类真正的飞行方法。 动态更改 在父类当中，设置了一个方法setFlyBehavior(FlyBehavior fb)，该方法实现动态化 应用到子类当中 123456public class ModuleDuck extends Duck &#123; public ModuleDuck() &#123; flyBehavior = new FlyWithWings(); quackBehavior = new Quack(); &#125;&#125; 进行一次测试 1234567891011public class MiniDuckSimulator &#123; public static void main(String[] args) &#123; Duck duck = new ModuleDuck(); duck.performQuack(); duck.performFly(); //升级这鸭子,让他来点花样飞行 duck.setFlyBehavior(new FlyRocketPowered()); //它变强了 duck.performFly(); &#125;&#125; 输出结果为： 123Quack.classFlyWithWings.classFlyRocketPowered.class 即方法动态的更改 案例3设计Context类，持有一个对抽象算法的引用，并且可以在运行期进行改变算法。在执行getPrice时，即将计算方法教给具体的算法去执行 123456789101112131415161718public class MovieTicketContext &#123; private double price; private DiscountStrategy discount; //维持一个对抽象折扣类的引用 public void setPrice(double price) &#123; this.price = price; &#125; //注入一个折扣类对象 public void setDiscount(DiscountStrategy discount) &#123; this.discount = discount; &#125; public double getPrice() &#123; //调用折扣类的折扣价计算方法 return discount.calculate(this.price); &#125;&#125; 设计抽象算法的接口，拥有一个方法即计算价格 123public interface DiscountStrategy &#123; public double calculate(double price);&#125; 设计具体的实现类，通过实现接口，确定该子算法的具体算法实现方式 1234567public class StudentDiscountStrategy implements DiscountStrategy &#123; @Override public double calculate(double price) &#123; System.out.println("学生票："); return price * 0.8; &#125;&#125; 测试得： 12345678910111213public class example_2_test &#123; public static void main(String[] args) &#123; MovieTicketContext context = new MovieTicketContext(); DiscountStrategy strategy = new StudentDiscountStrategy(); context.setDiscount(strategy); context.setPrice(20); System.out.println(context.getPrice()); //运行期切换算法 strategy = new ChildrenDiscountStrategy(); context.setDiscount(strategy); System.out.println(context.getPrice()); &#125;&#125; 相关模式Flyweight:Strategy对象经常是很好的轻量级对象 进阶策略工厂模式在一个使用策略模式的系统中，当存在的策略很多时，客户端管理所有策略算法将变得很复杂，如果在环境类中使用策略工厂模式来管理这些策略类将大大减少客户端的工作复杂度，其结构图如图 5 所示。 图5 策略工厂模式的结构图 Lambda重构模式即将原有的写法：传入一个新的策略类转换为传入一个Lambda表达式。即将策略类的具体实现转由一个Lambda实现 12345//原有写法Context context = new Context(new Strategy1());//改变为：Conext context = new Context((String s) -&gt; s.matches("[a-z]+"));context.validate(); 反省总结参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2018%2F10%2F08%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式提出问题将一个系统分割成一系列相互协作的类有一个常见的副作用，需要维护相关对象间的一致性。不希望为了维持一致性而使各个类紧密耦合，这样降低了它们的可重用性 问题案例应用适用性 当一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将二者封装在独立的对象中以使它们可以格子独立地改变和复用 当对一个对象的改变需要同时改变其他对象，而不知道具体有多少对象有待改变 当一个对象必须通知其他对象，而它又不能假定其他对象是谁，即不希望对象是紧耦合的。 案例1考虑报纸和杂志的订阅 报社的业务就是出版报纸 向某家报社订阅报纸，只要他们有新的报纸出版，就会给你送来，只要你是他们的订户，你就会一直收到报纸 当你不想再看报纸时，取消订阅，他们就不会再送新报纸过来 只要报社还在运营，就会一直有人向他们订阅报纸或取消订阅报纸 在观察者模式当中：出版社为“主题”，订阅者为“观察者” 案例2考虑Excel里面的图表与数据 定义数据的类和负责界面表示的类可以各自独立地复用，也可以一起工作 当数据改变时，柱状图、表格等会立即改变。但是表格对象和柱状图似乎不知道对方的存在，可以根据需要单独复用表格和柱状图 即意味着表格对象和柱状图都依赖于数据对象，因此数据对象的任何状态改变都应立即通知它们。而且对于数据可以有任意数目的不同的用户界面 基础概述是什么 观察者模式:定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新 可观察者（主题）与观察者，一旦主题的状态发生改变，所有的观察者状态都会得到通知，作为对通知的响应，观察者都会将查询目标的状态与自己的状态同步。 帮助对象知晓现状，不会错过该对象感兴趣的事情，对象甚至可以在运行时可决定是否要继续被通知 定义了一种对象之间的一对多依赖，这样一来，当一个对象改变时，它的所有依赖者都会收到通知并自动更新 一对多的依赖关系 主题是真正拥有数据的人 ，观察者是依赖者，只是更新数据，但并不控制数据 主题是具有状态的对象，并可以控制状态，观察者使用状态，依赖主题告诉他们状态何时改变 松耦合 对于观察者的一切，主题只知道观察者实现了某个接口，主题并不需要知道观察者具体是谁。 当出现新的观察者或新的具体类，只需要实现观察者接口，并将其注册到主题上即可 改变主题与观察者，并不会影响另一方，只要还遵循接口，便可以自由地改变 分类协作结构 参与者 Subject：主题对象 主题知道它的观察者，可以有任意多个观察者观察同一个目标 提供注册和删除观察者对象的接口 Observer：观察者对象，订阅（注册）主题，以便在主题数据改变时能受到更新 ConcreteSubject：具体目标 将有关的状态存入各个ConcreteObserver中，当状态改变时通知观察者 ConcreteObserver：具体观察者 维护一个指向ConcreteSubject的引用 存储有关状态，这些状态与Subject的状态一直，并实现Observer的更新接口，以使得一旦数据改变，新的数据便会以某种形式送到观察者手中 协作 类关系 逻辑关系 当ConcreteSubject发生任何可能导致其观察者与其本身状态不一致的改变时，它将通知它的各个观察者 当得到一个具体Subject的改变通知后，ConcreteObserver可以向Subject查询信息，并使用这些信息以使得它的状态与Subject的状态一致 权衡分类结构效果（优缺）实现实现有两种情景 主题进行推送通知 观察者拉取通知 在之后的手动实现中，只考虑推送通知，而拉取通知有Java的内置实现 实现步骤IDE支持 java.util包中包含有最基本的Observer（观察者）接口和Observvable（主题）类，并且可以进行拉取操作 如何获得观察者 实现Observer接口，然后使用主题类进行addObserver（）,删除则remove 主题如何推送通知 案例1相关模式进阶使用Lambda反省总结 观察者模式定义了对象间一对多的关系 主题（可观察者）用一个共同的接口更新观察者 观察者与可观察者之间松耦合，二者并不清楚内部的细节 使用此模式，可以从观察者处推或拉数据 有多个观察者时，不可以依赖特定的观察次序 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式：目录]]></title>
    <url>%2F2018%2F10%2F08%2FJava%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[设计模式介绍 设计模式是构造OO系统的隐含经验，是为了设计出弹性的、可复用的、可维护的系统 建立可维护的系统，在于随时思考系统之后可能需要的变化以及应付变化的原则 当找不到合适的设计模式，则思考一下面向对象的原则，例如：抽象、封装这些很基础的东西 常用设计模式： 单例模式 策略模式 代理模式 观察者模式 装饰模式 适配器模式 命令模式 工厂模式 模板方法模式 建造者模式 模式的重要性 知道OO基础，并不足以设计出良好的OO系统 良好的OO设计必须具备可复用、可维护、可扩充的特性 模式可以让我们建造出具有良好的OO设计质量的系统 模式可以认为是历经验证的OO设计经验 模式不是代码，而是针对设计问题的通用解决方案，可把他们应用到特定的应用中 大多数的模式和原则，都着眼于软件变化的主题 大多数模式都允许系统局部改变独立于其他部分 设计模式类目根据两条准则对模式进行分类： 目的准则，即模式用来完成什么工作 创建型模式与对象创建有关 结构型模式处理类或对象的组合 行为型模式对类或对象怎么样交互和怎样分配职责进行描述 范围准则，指定模式主要是用于类还是用于对象。 类模式处理类和子类间的关系，通过继承建立，是静态的，编译期确定 对象模式处理对象间关系，是动态的。 创建型工厂模式Factory 定义：定义一个创造对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类 当面对算法时常改动时，每次维护与扩展都需要对工厂进行修改。此时使用工厂模式并不合适，应当选用策略模式 适用性 当一个类不知道它所必须创建的对象的类时 当一个类希望由它的子类来指定它所创建的对象时 当类将创建对象的职责委托给多个帮助子类中的一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候 Abstract Factory提供一个创建一系列相关或相互依赖的接口，而无需指定它们具体的类 适用性 一个系统要独立于它的产品的创建、组合和表示时 一个系统要由多个产品系列中的一个类配置 当你要强调一系列相关的产品对象的设计以便进行联合使用 当你提供一个产品类库，而你只想显示他们的接口而不是实现时 单例模式Singleton 定义：确保一个类只有一个实例，并提供全局访问 适用性 当类只能有一个实例而且客户可以从一个众所周知的访问点访问它 当这个唯一实例应该是通过子类化可扩展的，并且客户应该无需更改代码就能使用一个扩展的实例 建造模式Builder 建造模式：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示 适用性 当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时 当构造过程必须允许被构造的对象有不同的表示时 原型模式Prototype 原型模式：用原型实例指定创建对象的种类，并且通过拷贝这个原型来创建新的对象 适用性 当一个系统应该独立于它的产品创建、构成和表示时 当要实例化的类是在运行时刻指定时。如通过动态装载 为了避免创建一个与产品类层次平行的工厂类层次 当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆他们可能比每次用合适的状态手工实例化该类更方便一些 行为型概述行为型模式设计到算法和对象间职责的分配 行为模式不仅描述对象或类的模式，还描述它们间的通信模式，这些模式刻划了在运行时难以跟踪的复杂的控制流，将你的注意力从控制流转移到对象间的联系方式上。 行为类模式使用继承机制在类间分派行为。 template method是一个算法的抽象定义，逐步定义该算法，每一步调用抽象成一个原语操作，子类具体实现抽象以实现该算法 Interpreter将一个文法表示为一个类层次，并实现一个解释器作为这些类的实例上的一个操作 行为对象模式使用对象复合而不是继承。 一些行为对象模式描述了一组对等的对象怎样相互协作以完成其中任一个对象都无法单独完成的任务。其问题是对等的对象如何相互了解对象，对等对象可以保持显式对对方的引用，但会增加耦合度，极端情况下，每个对象都要了解所有其他的对象 Mediator在对等对象间引入一个Mediator对象以避免这种情况，提供了松耦合所需要的间接性 Chain of Responsibility提供更松的耦合，让你通过一条候选对象链隐式的向一个对发送请求，根据运行时刻情况任一候选者都可以响应相应的请求。候选者数目是任意的，你可以在运行时刻决定哪些候选者参与链中 Observer模式定义并保持对象间的依赖关系，典型是MVC模式，一旦模型状态改变，模型中所有视图将得到通知 其他的行为对象模式常将行为封装在一个对象中并将请求指派给它 Strategy模式将算法封装到对象中，可以方便指定和改变一个对象所用的算法 Command模式将请求封装在对象中，这样它就可以作为参数来传递，也可以被存储在历史列表中，或以其他方式使用 State模式封装一个对象的这套，使得当这个对象的状态对象变化时，该对象可以改变它的行为 Visitor封装分布于多个类间的行为 Iterator抽象了访问和遍历一个集合中对象的方式 命令模式Command 定义：将请求封装成对象，这可以让你使用不同的请求、队列、或者日志请求来参数化其他对象。命令模式也支持撤销操作 适用性 抽象出待执行动作以参数化对象。可用过程语言中的回调函数表达该参数化机制 在不同的时刻指定、排列和执行请求。一个Command对象可以有一个与初始请求无关的生存期。如果一个请求的接收者可用一种与地址空间无关的方式表达，那么就可将负责该请求的命令对象传送给另一个不同的进程并在那实现请求。 支持取消操作。Execute操作可在实施操作前将状态存储起来，在取消操作时这个状态用来消除该操作的影响，并可实现重数的取消 支持修改日志 用构建在原语操作上的高层操作构造一个系统。这种结构在支持事务的信息系统中很场景 迭代器模式Iterator 迭代器模式：提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露其内部的表示 适用性 访问一个聚合对象的内容而无需暴露它的内部表示 支持对聚合对象的多种遍历 为遍历不同的聚合结构提供一个统一的接口（多态迭代） 观察者模式Observer 定义：在对象间定义一对多的依赖，这样一来，当一个对象改变状态，依赖它的对象都会收到通知并自动更新 适用性 当一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将二者封装在独立的对象中以使它们可以格子独立地改变和复用 当对一个对象的改变需要同时改变其他对象，而不知道具体有多少对象有待改变 当一个对象必须通知其他对象，而它又不能假定其他对象是谁，即不希望对象是紧耦合的。 策略模式Strategy 定义：定义了算法族，分别分装起来，让他们可以互相替换，此模式使得算法的变化独立于使用算法的客户 为多种算法创建一个统一的接口，客户持有一个接口引用，可以自由地切换算法类。 在实现上，客户端认识的类更少，减少了各种算法类与使用算法类之间的耦合 举例 一个人自由切换它的出行方式（自行车、汽车）。因此就不需要去使用IF判断他的出行方式而在客户类当中书写相应代码。 进阶 策略模式是用来封装算法的，但在实践中，也可以用来封装几乎任何类型的规则，只要在分析过程中听到需要在不同的时间应用不同的业务规则，就可以考虑使用策略模式处理这种变化的可能性。 适用性 许多相关的类仅仅是行为有异。策略提供了一种用多个行为中的一个行为来配置一个类的方法 需要使用一个算法的不同变体 算法使用客户不应该知道的数据。策略模式避免暴露复杂、与算法相关的数据结构 一个类定义了多种行为，并且这些行为在这个类d额操作中以多个条件语句的形式出现，将相关的条件分支移入它们各自的Strategy中 状态模式State 定义：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类 适用性 一个对象的行为取决于它的状态，并且它必须在运行时刻根据状态改变它的行为 一个操作中含有庞大的多分支的条件语句，且这些分支依赖于对象的状态。这个状态通常用一个或多个枚举常量表示。通常有多个操作包含这一相同的条件结构 State将每一个条件分支放入一个独立的类，使你可以根据对象自身的情况将对象的状态作为一个对象，这一对象可不依赖于其他对象而独立变化 模板方法模式Template 定义：在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。 适用性 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现 各子类中的公共的行为应该被提取出来并集中到一个父类中以避免代码重复 控制子类扩展，模板方法只在特定点调用“hook”操作，这样就只允许在这些点进行扩展 访问者模式Visitor 访问者模式：表示一个作用与某对象结构中的各元素操作。使你在不改变各元素的类的前提下定义作用于这些元素的新操作 适用性 一个对象结构包含很多类对象，它们有不同的接口，而你想对这些对象实施一些依赖于其具体类的操作 需要对一个对象结构中的对象进行很多不同且不相关的操作，而你想要避免这些操作污染这些对象的类 visitor使得你可以将相关的操作集中起来定义在一个类中 定义对象结构的类很少改变，但经常需要在此结构上定义新的操作，改变对象结构的类需要重新定义对所有访问者的接口，会付出很大的代价。 备忘录模式Memento 备忘录模式：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可以将该对象恢复到保存的状态 适用性 必须保存一个对象在某一个时刻的（部分）状态，这样以后需要时它才能恢复到先前的状态 如果一个用接口来让其他对象直接得到这些状态，将会暴露对象的实现细节并破坏封装性 责任链模式Chain of Responsibility 责任链模式：为解除请求的发送者和接受者之间的耦合，而使得多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它 适用性 有多个对象可以处理一个请求，哪个对象处理该请求运行时刻自动确定 想在不明确接收者的情况下，向多个对象中的一个提交一个请求 可处理一个请求的对象集合应被动态指定。 中介者模式Mediator 中介者模式：用一个中介对象来封装一系列对象的交互，中介者使各对象不需要显式地相互引用，从而使得其耦合松散，而且可以独立地改变它们之间的交互 适用性 一组对象以定义良好但是复杂的方式进行通信，产生相互依赖关系结构混乱且难以理解 一个对象引用其他很多对象并且直接与这些对象通信，导致难以复用该对象 向定制一个分布在多个类中的行为，而又不想生成太多子类 解释器模式Interpreter 解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子 类行为模式 适用性 当有一个语言需要解释执行，并且你可以将该语言中的句子表示为一个抽象语法树时，可以使用解释器模式 该文法简单对于复杂的文法,文法的类层次变得庞大而无法管理。 比如四则运算会带来非常多的表达式，公式每次不同，但都是四则四个非终极符连接 有一个简单的语法规则，比如一个sql语句，如果我们需要根据sql语句进行rm转换，就可以使用解释器模式来对语句进行解释。 效率不是一个关键问题最高效的解释器通常不是通过直接解释语法分析树实现的,而是首先将它们转换成另一种形式。例如正则表达式通常被转换为状态机，而这种转换器依然可以用解释器实现。 结构型结构型模式设计如何组合类和对象以获得更大的结构。 结构型类模式使用继承进行组合接口或实现； 结构型对象模式描述了如何对一些对象进行组合，从而实现新功能的一些方法，其在运行期改变组合关系，具有更大的灵活性。 适配器模式Adapter 适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本不兼容的类可以合作无间 适用性 你想使用一个已经存在的类，而它的接口不符合你的需求 你想创建一个可以复用的类，该类可以与其他不想关的类或不可预见的类（即那些接口可能不一定兼容的类）协同工作 （仅适用于对象Adapter）你想使用一些已经存在的子类，但是不可能对每一个都进行子类化以匹配他们的接口。对象适配器可以适配它的父类接口 桥接模式Bridge 桥接模式：将抽象部分与它的实现部分分离，使他们都可以独立地变化 适用性 不希望在抽象和它的实现部分间有一个固定的绑定关系。可能是因为在程序运行时刻实现部分应可以被选择或切换 类的抽象以及它的实现都应该可以通过生成子类的方法进行扩充。这时Bridge模式使你可以对不同的抽象接口和实现部分进行组合，并分别对他们进行扩充 对一个抽象的实现部分的修改应该对客户不产生影响，即客户的代码不必重新编译 外观模式Facade 外观模式：提供了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。 适用性 当你要为一个复杂子系统提供一个简单接口时。子系统往往因为不断演化而变得越来越复杂。大多数模式使用时都会产生更多更小的类。这使得子系统更具有可重用性，也更容易对子系统进行定制，但这也给那些不需要定制子系统的用户带来一些使用上的困难。Facade可以提供一个简单的缺省视图，对大部分用户已经足够 客户程序与抽象类的实现部分之间存在很大的依赖性。引入Facade将这个子系统与客户以及其他子系统分离，提高子系统的独立性和可移植性 当需要构建一个层次结构的子系统时，使用Facade模式定义子系统中每层的入口点，如果子系统间相互依赖，可以让他们仅仅通过facade进行通信，减少依赖。 代理模式Proxy 定义：为另一个对象提供一个替身或者占位符或代理以控制访问这个对象。 适用性 需要用比较通用和复杂的对象指针代替简单的指针时使用代理模式。 远程代理。 虚代理 保护代理。控制对原始对象的访问，保护代理用于对象应该有不同的访问权限的时候 智能指引取代了简单的指针，在访问对象时执行一些附加的操作 对指向实际对象的引用计数，当对象没有用时，可以自动释放 在访问一个对象时，对它进行事务、日志等操作 装饰者模式Decorator 定义：动态地将责任附加到对象上，想要扩展功能，装饰者提供有别于继承的另一种选择 适用性 在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责 处理那些可以撤销的职责 当不能采用生成子类的方法进行扩充时 如可能有大量独立的扩展，每一种组合将产生大量的子类，使得子类数目爆炸增长 可能因为类定义被隐藏或类定义不能用来生成子类 享元模式Flyweight 享元模式：运用共享技术有效支持大量细粒度的对象 适用性 一个应用程序使用了大量的对象 完全由于使用大量的对象，造成很大的存储开销 对象的大多数状态都可变为外部状态。 如果删除对象的外部状态，那么可以用相对较少的共享对象取代很多组对象 应用程序不依赖于对象标识。由于Flyweight对象可以被共享，对于概念上很明显有别的对象，标识测试将返回真值 组合模式Composite 组合模式：允许你将对象组成树形结构来表现“整体/部分”的层次结构。组合能让客户以一致的方式处理个别对象和对象组合 适用性 想表示对象的部分-整体层次 希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象 复合模式 定义： ## 设计原则 开闭原则。 依赖倒置原则。 单一职责原则。 接口隔离原则。 迪米特法则（最少知道原则）。 里氏替换原则。 合成/复用原则(组合/复用原则)。 追寻原则不能过度，要根据实际场景取舍。 开放封闭原则 类、模块、函数应该对扩展开放，对修改关闭。 软件实体应当对扩展开放，对修改关闭。 用抽象构建框架，用实现扩展细节。 面向抽象编程。 抽象是关键。如果没有抽象类或接口系统就没有扩展点。 面向抽象尽量不要修改原来的代码，是指不修改抽象，而抽象是稳定的，因此不容易变化。 优点：提高软件系统的可复用性与可维护性。 封装可变性。将系统中的各种可变因素封装到一个继承结构中，如果多个可变因素混杂到一起，系统将变得复杂混乱 继承是一种 IS-A 关系，子类需要能够当成父类来使用，并且需要比父类更特殊。 如果不满足这个原则，那么各个子类的行为上就会有很大差异，增加继承体系的复杂度。 举例 依赖倒置原则 高层模块不应该依赖于低层模块，二者都应该依赖于其抽象；抽象不应该依赖于细节，细节应该依赖于抽象。 高层模块包含一个应用程序中重要的策略选择和业务模块，如果高层模块依赖于低层模块，那么低层模块的改动就会直接影响到高层模块，从而迫使高层模块也需要改动。 依赖于抽象意味着： 针对接口编程，不要针对实现编程。 任何变量都不应该持有一个指向具体类的指针或者引用； 任何类都不应该从具体类派生； 任何方法都不应该覆写它的任何基类中的已经实现的方法。 优点： 可以减少类间的耦合性，提高系统稳定性，提高代码可读性和可维护性，可降低修改程序所造成的风险。 举例 单一责任原则 一个类应该只有一个引起变化的原因。即一个类只做它该做的事情（事情是一个抽象的概念，高内聚） 当我们能够想到多于一个的动机去改变一个类，那么这个类就具有多于一个的职责。就应该考虑类的职责分离 当我们允许一个类不但要完成自己的事情（管理某种聚合），还同时要担负更多的责任（如遍历）时，就给了这个类两个变化的原因 当集合改变时，这个类必须改变，当遍历的方式改变的话，这个类也必须跟着改变。当有两个变化的原因，会使得该类的变化几率上升。 换句话说就是让一个类只负责一件事，当这个类需要做过多事情的时候，就需要分解这个类。 如果一个类承担的职责过多，就等于把这些职责耦合在了一起，一个职责的变化可能会削弱这个类完成其它职责的能力。 一个类、接口、方法只负责一项职责。 举例 解决 将一个责任只指派给一个类。实现高内聚 接口分离原则 针对接口编程,而不是针对实现编程 不应该强迫客户依赖于它们不用的方法。 该设计原则关注于类的扩展性，针对接口编程时，在运行时就可以使用该接口引用不同的子类，运行时动态改变。 面对一个可能存在变化的类,将其变化抽出来制作一个接口,并针对接口进行不同的实现,从而使得类在”运行时”动态地”改变” 这个抽离的接口可以被复用，因为他们的行为已经和原来的类没有了关系 客户无需知道他们使用的对象的特定类型，只需要对象有客户期望的接口 客户无需知道他们使用的对象是用什么类实现的，只需知道定义接口的抽象类 通过如此设计，我们可以新增行为，不会影响到既有的行为类，也不会影响“使用”到该行为的类 关键在于，现在这样的行为是委托给别人处理，而不是使用定义在父类或者子类内的方法 举例 当不得不在系统某个地方实例化具体的类（指定一个特定的实现） 创建型模式可以很好的解决该问题 迪米特法则 迪米特法则又叫作最少知识原则（Least Knowledge Principle，简写 LKP），就是说一个对象应当对其他对象有尽可能少的了解，不和陌生人说话。 一个对象应该对其他的对象保持最少的了解。 强调只和朋友交流，不和陌生人说话。 出现在成员变量、方法的输入、输出参数中的类称为成员朋友类，而出现在方法体内部的类不属于朋友类。 尽量降低类与类间的耦合。 降低类间的耦合。 举例 实现方法： 就任何对象而言，在该对象的方法内，只应该调用属于以下范围的方法 该对象本身 被当做方法的参数而传递进来的对象 此方法所创建或实例化的任何对象 对象的任何组件 123456789101112//调用从另一个调用中返回的对象的方法//不采用该原则，这样相当于向另一个对象的子部分发出请求//因此需要认识该对象的组件，不符合将朋友圈维持在最小状态public float getTemp()&#123; Thermometer thermometer = station.getThermometer();//从气象站取得温度计 return thermometer.getThermometer();//从温度计获取温度&#125;//采用该原则//在station当中加入方法，直接获得温度public float getTemp()&#123; return station.getThermometer();&#125; 缺点 虽然减少了对象间的依赖，减少了软件的维护成本。但是导致更多的“包装”类被制造出来，以处理和其他组件的沟通，可能导致复杂度、开发时间增加，降低运行时性能 里氏替换原则 任何时候都可以用子类型替换掉父类型。子类一定是增加父类的能力而不是减少父类的能力，因为子类的能力更多，把能力多的对象当成能力少的对象当然没有任何问题。 举例 合成复用原则 多用组合，少用继承 尽量使用对象组合，而不是通过继承来达到复用的目的。 举例 封装变化 找出应用中可能需要变化之处,把他们独立出来,不要和那些不需要变化的代码混合在一起 把会变化的部分取出来并”封装”起来,好让其他部分不会受到影响 即,如果每次新的需求到来,都会使得某方面的代码发生变化, 即确定,该部分的代码需要被抽取出来 举例 例如需要为Duck父类增加一个新的需求，fly方法。 错误的做法： 在父类增加方法。这个时候，由于Duck的子类有一些事不需要fly的，例如橡皮鸭。此时就又需要去子类当中重写覆盖。 新增一个fly的接口，但是此时由于接口不包含实现代码，因此需要在所有子类当中复现，更显繁琐 正确的做法： 将动作分离出来成为一个behave的类，然后与Duck做一个组合 模式 策略模式 为了使交互对象之间松耦合而努力 依赖抽象，不依赖具体类 举例 别找我，我会找你 由超类主控一切，当他们需要的时候，自然回去调用子类。 给出一种防止“依赖腐败”的方法。当高层组件依赖底低层组件，低层组件又依赖高层组件，而高层组件又依赖边侧组件，边侧组件又依赖低层组件时，即依赖腐败。没有人可以轻易搞懂系统如何设计的 该原则下，允许低层组件将自己挂钩到系统上，但是高层组件会决定什么时候和怎么样使用这些低层组件。即低层组件不可用直接调用高层组件 举例 实现 在模板方法模式当中，模板类拥有着算法。只有在需要子类实现某个方法时，才调用子类。 客户代码只依赖于模板方法，而不依赖于具体的类，减少了整个系统的依赖。 如果子类没有先被调用，绝对不会直接调用抽象类。（在客户代码中，引用的是抽象类型，因此依赖就大大减少。、） 共同封闭原则 一起修改的类，应该组合在一起（同一个包里）。如果必须修改应用程序里的代码，我们希望所有的修改都发生在一个包里（修改关闭），而不是遍布在很多包里。 举例 稳定抽象原则 最稳定的包应该是最抽象的包，不稳定的包应该是具体的包，即包的抽象程度跟它的稳定性成正比。 举例 稳定依赖原则 包之间的依赖关系都应该是稳定方向依赖的，包要依赖的包要比自己更具有稳定性。 举例 某些有趣的事情 和大佬们交流，使用观察者模式、策略模式等词，表述地更为方便一些 但是书里面有一个趣谈：写一个helloWorld也和模式挂钩，hhhhh代表着模式病 参考 [head first 设计模式]]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：枚举类]]></title>
    <url>%2F2018%2F10%2F08%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E6%9E%9A%E4%B8%BE%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[枚举提出问题概述是什么关键字enum可以将一组具名的值的有限集合创建为一种新的类型，而这些具名的值可以作为常规的程序组件使用。 分类，各个分类是什么为什么要用（作用）应用场景 多路分发 如果一个系统要分析和执行数学表达式可能会声明Number.plus(Number)等，然而当声明a.plus(b)时，并不知道a或者b的确切类型，则如何让他们进行间交互。 枚举特性EnumClassMethod Class.values方法，返回enum实例的数组，并且该数组中的元素的严格保持其在enum中声明时的顺序。 可以用来遍历enum实例 1234enum Shrubbery&#123; GROUND,CRWLING&#125;public static void main(String[] args)&#123; for(Shrubbery s : Shrubbery.values())&#125; Enum.valueOf(EnumClass,name)根据给定的名字返回相应的enum实例 EnumObjMethod Obj.ordinal()返回一个int值，是每个enum实例在声明时的次序，从0开始。 Obj.name()，返回enum实例声明时的明智，与使用toString方法效果相同 在Enum中添加方法Enum除了不能继承自一个enum外，基本上可以将enum看作一个常规的类，即可以向enum添加方法。 若打算在枚举中定义方法，则必须在enum实例序列的最后添加一个分号。 switch中的enum在Java中switch一般只能使用整数，而枚举实例天生具有整数的次序，因此我们可以在switch中使用 123switch(color)&#123; case RED:&#125; 多路分发当要处理多种交互类型时，程序可能会变得相当混乱。 如果一个系统要分析和执行数学表达式可能会声明Number.plus(Number)等，然而当声明a.plus(b)时，并不知道a或者b的确切类型，则如何让他们进行间交互。 Java只支持单路分发，即如果要执行的操作包含了不止一个类型未知的对象，那么Java的动态绑定机制只能处理其中一个的类型。因此我们必须自己去判定其他的类型，从而实现动态绑定。 解决方法就是多路分发，例如两路分发，就必须有两个方法调用：第一个方法调用决定第一个未知类型，第二个方法决定第二个未知类型。 多态实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public enum Outcome &#123; WIN, LOSE, DRAW &#125;interface Item &#123; Outcome compete(Item it); Outcome eval(Paper p); Outcome eval(Scissors s); Outcome eval(Rock r);&#125;class Paper implements Item &#123; public Outcome compete(Item it) &#123; return it.eval(this); &#125; public Outcome eval(Paper p) &#123; return DRAW; &#125; public Outcome eval(Scissors s) &#123; return WIN; &#125; public Outcome eval(Rock r) &#123; return LOSE; &#125; public String toString() &#123; return "Paper"; &#125;&#125; class Scissors implements Item &#123; public Outcome compete(Item it) &#123; return it.eval(this); &#125; public Outcome eval(Paper p) &#123; return LOSE; &#125; public Outcome eval(Scissors s) &#123; return DRAW; &#125; public Outcome eval(Rock r) &#123; return WIN; &#125; public String toString() &#123; return "Scissors"; &#125;&#125;class Rock implements Item &#123; public Outcome compete(Item it) &#123; return it.eval(this); &#125; public Outcome eval(Paper p) &#123; return WIN; &#125; public Outcome eval(Scissors s) &#123; return LOSE; &#125; public Outcome eval(Rock r) &#123; return DRAW; &#125; public String toString() &#123; return "Rock"; &#125;&#125; public class RoShamBo1 &#123; static final int SIZE = 20; private static Random rand = new Random(47); public static Item newItem() &#123; switch(rand.nextInt(3)) &#123; default: case 0: return new Scissors(); case 1: return new Paper(); case 2: return new Rock(); &#125; &#125; public static void match(Item a, Item b) &#123; System.out.println( a + " vs. " + b + ": " + a.compete(b)); &#125; public static void main(String[] args) &#123; for(int i = 0; i &lt; SIZE; i++) match(newItem(), newItem()); &#125;&#125; /* Output: Rock vs. Rock: DRAWPaper vs. Rock: WINPaper vs. Rock: WINPaper vs. Rock: WINScissors vs. Paper: WINScissors vs. Scissors: DRAWScissors vs. Paper: WINRock vs. Paper: LOSEPaper vs. Paper: DRAWRock vs. Paper: LOSEPaper vs. Scissors: LOSEPaper vs. Scissors: LOSERock vs. Scissors: WINRock vs. Paper: LOSEPaper vs. Rock: WINScissors vs. Paper: WINPaper vs. Scissors: LOSEPaper vs. Scissors: LOSEPaper vs. Scissors: LOSEPaper vs. Scissors: LOSE*///:~ 第一次分发是在a的compete方法当中，此时根据多态识别了a的具体类型 第二次分发在调用eval方法，此时多态识别了b的类型 使用enum分发12345678910111213141516171819202122232425262728293031323334353637383940414243public enum RoShamBo2 implements Competitor&lt;RoShamBo2&gt; &#123; PAPER(DRAW, LOSE, WIN), SCISSORS(WIN, DRAW, LOSE), ROCK(LOSE, WIN, DRAW); private Outcome vPAPER, vSCISSORS, vROCK; RoShamBo2(Outcome paper,Outcome scissors,Outcome rock) &#123; this.vPAPER = paper; this.vSCISSORS = scissors; this.vROCK = rock; &#125; public Outcome compete(RoShamBo2 it) &#123; switch(it) &#123; default: case PAPER: return vPAPER; case SCISSORS: return vSCISSORS; case ROCK: return vROCK; &#125; &#125; public static void main(String[] args) &#123; RoShamBo.play(RoShamBo2.class, 20); &#125;&#125; /* Output:ROCK vs. ROCK: DRAWSCISSORS vs. ROCK: LOSESCISSORS vs. ROCK: LOSESCISSORS vs. ROCK: LOSEPAPER vs. SCISSORS: LOSEPAPER vs. PAPER: DRAWPAPER vs. SCISSORS: LOSEROCK vs. SCISSORS: WINSCISSORS vs. SCISSORS: DRAWROCK vs. SCISSORS: WINSCISSORS vs. PAPER: WINSCISSORS vs. PAPER: WINROCK vs. PAPER: LOSEROCK vs. SCISSORS: WINSCISSORS vs. ROCK: LOSEPAPER vs. SCISSORS: LOSESCISSORS vs. PAPER: WINSCISSORS vs. PAPER: WINSCISSORS vs. PAPER: WINSCISSORS vs. PAPER: WIN*///:~ 进阶反省总结基础如何构造一个枚举类 新建一个Enum的类 添加枚举的实例,实例的要求: 名称要大写 多个单词是使用下划线进行分割 实例之间使用逗号分割 最后实例结尾使用分号; 为类添加字段 必须添加构造方法 可选: 为字段添加getter和setter 为实例添加doc注释 代码12345678910111213141516171819public enum SimpleEnum &#123; /** * 为枚举添加注释 */ TEST("1"), ; /** * 枚举类需要字段和构造器两个属性,否则会出错 */ private String code; public String getCode() &#123; return code; &#125; SimpleEnum(String code) &#123; this.code = code; &#125;&#125; 枚举的作用管理code或者一些常量在实际项目当中,会遇到一些状态码的相关东西,这个使用枚举进行维护是相对便捷的 进行switch12345678910111213141516/** * 使用switch和枚举类进行结合 */public void degree()&#123; SimpleEnum simpleEnum=SimpleEnum.TEST; switch (simpleEnum)&#123; case TEST: System.out.println("test"); return; case ORDER: System.out.println("orde"); return; default: System.out.println("ss"); &#125;&#125; 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shiro集成无状态JWT]]></title>
    <url>%2F2018%2F10%2F03%2FJava%2F%E6%A1%86%E6%9E%B6%2F%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6%EF%BC%9Ashiro%E9%9B%86%E6%88%90%E6%97%A0%E7%8A%B6%E6%80%81JWT%2F</url>
    <content type="text"><![CDATA[转 JWT为什么要使用JWT 在前后端分离的项目当中,服务器端无法存储会话(session),而是每次请求带上相应的用户名 因此我们要实现完全的前后端分离，所以不可能使用session，cookie的方式进行鉴权 JWT的鉴权,通过一个加密的秘钥来实现鉴权 JWT的介绍放弃Cookie,Session,使用JWT进行鉴权，完全实现无状态鉴权。 目标效果访问一个URL:http://127.0.0.1:8080/hello?username=admin&amp;params1=love&amp;params2=girl&amp;digest=df7f1595bd5682638556072c8ccde5edadcd807a829373d21af38fb1bc707da7 如果digest是正确的话，那么就会返回Hello,Andy,否则会login,error。 后台过程 访问该URL 首先进入AccessControlFilter，进行访问控制过滤拦截，如果不满足条件的话，那么直接就返回了，否则接着往下处理。 在AccessControlFilter中我们为委托AuthorizingRealm进行身份的认证。在AuthorizingRealm中的身份验证访问进行客户端消息摘要和服务器端消息摘要的匹配。 如果成功的话，那么就会到Shiro进行进一步的处理，最后到我们的Controller，然后进行返回。 对象的需求 ShiroConfiguration：在这个类中主要是注入shiro的filterFactoryBean和securityManager等对象。 StatelessAccessControlFilter：这个类中实现访问控制过滤，当我们访问url的时候，这个类中的两个方法会进行拦截处理。 StatelessAuthorizingRealm：这个类中主要是身份认证，验证信息是否合理，是否有角色和权限信息。 StatelessAuthenticationToken：在shiro中有一个我们常用的UsernamePasswordToken，因为我们需要这里需要自定义一些属性值，比如：消息摘要，参数Map。 StatelessDefaultSubjectFactory：由于我们编写的是无状态的，每人情况是会创建session对象的，那么我们需要修改createSubject关闭session的创建。 HmacSHA256Utils：Java 加密解密之消息摘要算法，对我们的参数信息进行处理。 基础配置pom &lt;!-- spring boot web支持：mvc,aop... --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- shiro spring. --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;/dependency&gt;contrllerRest测试 import javax.servlet.http.HttpSession; import org.apache.shiro.SecurityUtils; import org.apache.shiro.authz.annotation.RequiresRoles; import org.apache.shiro.session.Session; import org.apache.shiro.subject.Subject; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @RequestMapping(&quot;/hello&quot;) public String hello(String params1,String params2){ return &quot;hello,Andy,params1=&quot;+params1+&quot;,params1=&quot;+params2; } }测试访问http://127.0.0.1:8080/hello 浏览器返回:hello,Andy,params1=null,params1=null 至此,基础配置已经完成 集成shiro的基本配置基本配置添加shirospring配置shiro最基本的操作就是注入ShiroFilterFactoryBean和DefaultWebSecurityManager. 因此,新建ShiroConfiguration类 import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * shiro配置类 * @author Angel --守护天使 * @version v.0.1 * @date 2017年2月25日 */ @Configuration public class ShiroConfiguration { @Bean public ShiroFilterFactoryBean shiroFilter(SecurityManager securityManager){ ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean(); factoryBean.setSecurityManager(securityManager); return factoryBean; } /** * shiro安全管理器: * 主要是身份认证的管理，缓存管理，cookie管理， * 所以在实际开发中我们主要是和SecurityManager进行打交道的 * @return */ @Bean public DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); return securityManager; } }无状态首先,restful风格里面,是没有session和cookie等相关东西的,所以在配置当中要关闭这些东西 需要配置以下的几个地方 SubjectContext在创建的时候，需要关闭session的创建，这个主要是由DefaultWebSubjectFactory的createSubject进行管理。 需要禁用使用Sessions 作为存储策略的实现，这个主要由securityManager的subjectDao的sessionStorageEvaluator进行管理的。 需要禁用掉会话调度器，这个主要由sessionManager进行管理。 配置我们需要先定义一个StatelessDefaultSubjectFactory类，此类继承于DefaultWebSubjectFactory，我们重写createSubject的方法，通过SubjectContext关闭session的创建 import org.apache.shiro.subject.Subject; import org.apache.shiro.subject.SubjectContext; import org.apache.shiro.web.mgt.DefaultWebSubjectFactory; /** * 通过调用context.setSessionCreationEnabled(false)表示不创建会话；如果之后调用 Subject.getSession()将抛出DisabledSessionException异常。 * @author Angel --守护天使 * @version v.0.1 * @date 2017年2月25日 */ public class StatelessDefaultSubjectFactory extends DefaultWebSubjectFactory{ @Override public Subject createSubject(SubjectContext context) { //不创建session. context.setSessionCreationEnabled(false); System.out.println(&quot;shiro.config.subjectFactory.createSubject.SessionCreationEnabled.false&quot;); return super.createSubject(context); } } 调整下ShiroConfiguration，首先我们要注入StatelessDefaultSubjectFactory；其次就是将StatelessDefaultSubjectFactory交给DefaultWebSecurityManager进行管理；最后使用securityManager获取到subjectDao禁用session的存储策略 （注意新加的代码为：Add.2.x） import org.apache.shiro.mgt.DefaultSessionStorageEvaluator; import org.apache.shiro.mgt.DefaultSubjectDAO; import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.session.mgt.DefaultSessionManager; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.apache.shiro.web.mgt.DefaultWebSubjectFactory; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** shiro配置类. @author Angel –守护天使 @version v.0.1 @date 2017年2月25日 / @Configurationpublic class ShiroConfiguration { @Bean public ShiroFilterFactoryBean shiroFilter(SecurityManager securityManager){ ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean(); factoryBean.setSecurityManager(securityManager); return factoryBean; } /** shiro安全管理器: 主要是身份认证的管理，缓存管理，cookie管理， 所以在实际开发中我们主要是和SecurityManager进行打交道的 @return /@Beanpublic DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); //Add.2.2 securityManager.setSubjectFactory(subjectFactory()); //Add.2.5 securityManager.setSessionManager(sessionManager()); /* 禁用使用Sessions 作为存储策略的实现，但它没有完全地禁用Sessions 所以需要配合context.setSessionCreationEnabled(false); ///Add.2.3((DefaultSessionStorageEvaluator)((DefaultSubjectDAO)securityManager.getSubjectDAO()).getSessionStorageEvaluator()).setSessionStorageEnabled(false);return securityManager;} /** Add.2.1 subject工厂管理器. @return /@Beanpublic DefaultWebSubjectFactory subjectFactory(){ StatelessDefaultSubjectFactory subjectFactory = new StatelessDefaultSubjectFactory(); return subjectFactory;}/** Add.2.4 session管理器： sessionManager通过sessionValidationSchedulerEnabled禁用掉会话调度器， 因为我们禁用掉了会话，所以没必要再定期过期会话了。 @return /@Beanpublic DefaultSessionManager sessionManager(){ DefaultSessionManager sessionManager = new DefaultSessionManager(); sessionManager.setSessionValidationSchedulerEnabled(false); return sessionManager;} } 成功关闭session等 测试测试原理：如果是无状态的话，那么在调用代码：currentUser.getSession()是会抛出异常的。所以很好测试，直接在HellController中加入如下方法即可测试 /** * 此方法执行的时候，会抛出异常： * Session creation has been disabled for the current subject. * @param session * @return */ @RequestMapping(&quot;/hello3&quot;) public String hello3(){ Subject currentUser = SecurityUtils.getSubject(); Session session = currentUser.getSession(); System.out.println(session); return&quot;hello3,Andy&quot;; }访问:http://127.0.0.1:8080/hello3 报错: Session creation has been disabled for the current subject. 恭喜成功,达成目标,无状态的shiro 请求控制拦截。准备工作工具类:对参数信息处理——加密解密之消息摘要算法package example.shiro.config; import java.util.List; import java.util.Map; import javax.crypto.Mac; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import org.apache.commons.codec.binary.Hex; /** * @Title : * Created by Hyper on 2018/10/3 16:54 */ public class HmacSHA256Utils { public static String digest(String key, String content) { try { Mac mac = Mac.getInstance(&quot;HmacSHA256&quot;); byte[] secretByte = key.getBytes(&quot;utf-8&quot;); byte[] dataBytes = content.getBytes(&quot;utf-8&quot;); SecretKey secret = new SecretKeySpec(secretByte, &quot;HMACSHA256&quot;); mac.init(secret); byte[] doFinal = mac.doFinal(dataBytes); byte[] hexB = new Hex().encode(doFinal); return new String(hexB, &quot;utf-8&quot;); } catch (Exception e) { throw new RuntimeException(e); } } @SuppressWarnings(&quot;unchecked&quot;) public static String digest(String key, Map&lt;String, ?&gt; map) { StringBuilder s = new StringBuilder(); for (Object values : map.values()) { if (values instanceof String[]) { for (String value : (String[]) values) { s.append(value); } } else if (values instanceof List) { for (String value : (List&lt;String&gt;) values) { s.append(value); } } else { s.append(values); } } return digest(key, s.toString()); } }保存我们的身份信息,用户名，客户端传入的消息摘要，还有客户端传入的参数map等import org.apache.shiro.authc.AuthenticationToken; import java.util.Map; /** * 用于授权的Token对象 * 用户身份即用户名； * 凭证即客户端传入的消息摘要。 * * @Time :Created by Hyper on 2018/10/3 16:55 */ public class StatelessAuthenticationToken implements AuthenticationToken { private static final long serialVersionUID = 1L; //用户身份即用户名； private String username; //参数. private Map&lt;String, ?&gt; params; //凭证即客户端传入的消息摘要。 private String clientDigest; public StatelessAuthenticationToken() { } public StatelessAuthenticationToken(String username, Map&lt;String, ?&gt; params, String clientDigest) { super(); this.username = username; this.params = params; this.clientDigest = clientDigest; } public StatelessAuthenticationToken(String username, String clientDigest) { super(); this.username = username; this.clientDigest = clientDigest; } @Override public Object getPrincipal() { return username; } @Override public Object getCredentials() { return clientDigest; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public Map&lt;String, ?&gt; getParams() { return params; } public void setParams(Map&lt;String, ?&gt; params) { this.params = params; } public String getClientDigest() { return clientDigest; } public void setClientDigest(String clientDigest) { this.clientDigest = clientDigest; } }核心实现访问控制过滤器，拦截我们的请求，我们主要是处理onAccessDenied（）方法，接收到请求的参数，组装成StatelessAuthenticationToken，然后委托为Realm进行处理 思路 客户端生成的消息摘要； 客户端传入的用户身份； 客户端请求的参数列表； 生成无状态Token 委托给Realm进行登录 实现访问控制过滤器import org.apache.shiro.web.filter.AccessControlFilter; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.util.HashMap; import java.util.Map; /** * @Time : Created by Hyper on 2018/10/3 16:55 */ public class StatelessAccessControlFilter extends AccessControlFilter { /** * 先执行：isAccessAllowed 再执行onAccessDenied * &lt;p&gt; * isAccessAllowed：表示是否允许访问；mappedValue就是[urls]配置中拦截器参数部分， * 如果允许访问返回true，否则false； * &lt;p&gt; * 如果返回true的话，就直接返回交给下一个filter进行处理。 * 如果返回false的话，回往下执行onAccessDenied */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { System.out.println(&quot;StatelessAuthcFilter.isAccessAllowed()&quot;); return false; } /** * onAccessDenied：表示当访问拒绝时是否已经处理了；如果返回true表示需要继续处理； * 如果返回false表示该拦截器实例已经处理了，将直接返回即可。 */ @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception { System.out.println(&quot;StatelessAuthcFilter.onAccessDenied()&quot;); //1、客户端生成的消息摘要 String clientDigest = request.getParameter(&quot;digest&quot;); //2、客户端传入的用户身份 String username = request.getParameter(&quot;username&quot;); //3、客户端请求的参数列表 Map&lt;String, String[]&gt; params = new HashMap&lt;String, String[]&gt;(request.getParameterMap()); //为什么要移除呢？签名或者消息摘要算法的时候不能包含digest. params.remove(&quot;digest&quot;); //4、生成无状态Token StatelessAuthenticationToken token = new StatelessAuthenticationToken(username, params, clientDigest); // UsernamePasswordToken token = new UsernamePasswordToken(username,clientDigest); try { //5、委托给Realm进行登录 getSubject(request, response).login(token); } catch (Exception e) { e.printStackTrace(); //6、登录失败 onLoginFail(response); //就直接返回给请求者. return false; } return true; } /** * 登录失败时默认返回401 状态码 */ private void onLoginFail(ServletResponse response) throws IOException { HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); httpResponse.getWriter().write(&quot;login error&quot;); } }Realm进行登录请求就到了我们的Realm代码，所以我们需要编写一个Realm来进行身份验证下，这里的核心就是获取到AccessControlFilter传递过来的StatelessAuthenticationToken中的参数进行消息摘要，然后生成对象SimpleAuthenticationInfo交给Shiro进行比对 import org.apache.shiro.authc.AuthenticationException; import org.apache.shiro.authc.AuthenticationInfo; import org.apache.shiro.authc.AuthenticationToken; import org.apache.shiro.authc.SimpleAuthenticationInfo; import org.apache.shiro.authz.AuthorizationInfo; import org.apache.shiro.authz.SimpleAuthorizationInfo; import org.apache.shiro.realm.AuthorizingRealm; import org.apache.shiro.subject.PrincipalCollection; /** * @Time :Created by Hyper on 2018/10/3 16:56 */ public class StatelessAuthorizingRealm extends AuthorizingRealm { /** * 仅支持StatelessToken 类型的Token， * 那么如果在StatelessAuthcFilter类中返回的是UsernamePasswordToken，那么将会报如下错误信息： * Please ensure that the appropriate Realm implementation is configured correctly or * that the realm accepts AuthenticationTokens of this type.StatelessAuthcFilter.isAccessAllowed() */ @Override public boolean supports(AuthenticationToken token) { return token instanceof StatelessAuthenticationToken; } /** * 身份验证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { System.out.println(&quot;StatelessRealm.doGetAuthenticationInfo()&quot;); StatelessAuthenticationToken statelessToken = (StatelessAuthenticationToken) token; //不能为null,否则会报错的. String username = (String) statelessToken.getPrincipal(); //根据用户名获取密钥（和客户端的一样） String key = getKey(username); //在服务器端生成客户端参数消息摘要 String serverDigest = HmacSHA256Utils.digest(key, statelessToken.getParams()); System.out.println(serverDigest + &quot;,&quot; + statelessToken.getCredentials()); //然后进行客户端消息摘要和服务器端消息摘要的匹配 SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo( username, serverDigest, getName()); return authenticationInfo; } /** * 授权 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { System.out.println(&quot;StatelessRealm.doGetAuthorizationInfo()&quot;); //根据用户名查找角色，请根据需求实现 String username = (String) principals.getPrimaryPrincipal(); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); //这里模拟admin账号才有role的权限. if (&quot;admin&quot;.equals(username)) { authorizationInfo.addRole(&quot;admin&quot;); } return authorizationInfo; } /** * 得到密钥，此处硬编码一个. * * @param username * @return */ private String getKey(String username) { return &quot;andy123456&quot;; } }配置到ShiroConfiguration(Add.4.x)测试http://127.0.0.1:8080/hello?username=admin&amp;params1=love&amp;params2=girl&amp;digest=df7f1595bd5682638556072c8ccde5edadcd807a829373d21af38fb1bc707da7 digest是根据参数生成的,更换值则会login error 权限控制篇配置ShiroConfiguration在shiroConfiguration中加入【开启shiro aop注解支持】和【自动代理所有的advisor】 具体代码为:Add.5.x 在方法(controller)中加入注解@RequiresRoles(“admin”) @RequestMapping(&quot;/hello4&quot;) @RequiresRoles(&quot;admin&quot;) // @RequiresPermissions(&quot;userInfo:add&quot;)//权限管理;要求拥有userInfo:add权限才可以执行 public String hello4() { return &quot;hello4,Andy&quot;; }测试正确的地址http://127.0.0.1:8080/hello4?username=admin&amp;params1=love&amp;params2=girl&amp;digest=df7f1595bd5682638556072c8ccde5edadcd807a829373d21af38fb1bc707da7 错误的http://127.0.0.1:8080/hello4?username=zs&amp;params1=love&amp;params2=girl&amp;digest=df7f1595bd5682638556072c8ccde5edadcd807a829373d21af38fb1bc707da7 报错.UnauthorizedException: Subject does not have role [admin] 源码 个人源码实战练习 参考 Spring Boot之Shiro无状态（1）【从零开始学Spring Boot】 Spring Boot之Shiro无状态（2）【从零开始学Spring Boot】 Spring Boot之Shiro无状态（3）【从零开始学Spring Boot】 Spring Boot之Shiro无状态（4）【从零开始学Spring Boot】]]></content>
  </entry>
  <entry>
    <title><![CDATA[消息队列：概述]]></title>
    <url>%2F2018%2F10%2F02%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[消息队列介绍异步解耦 场景 下单 消息队列特性 业务无关，只做消息分发 FIFO先投递先到达 容灾：节点的动态增删和消息的持久化 性能：吞吐量提升，系统内部通信效率会提高 为什么需要消息队列 生产和消费的速度或稳定性等因素不一致 消息队列好处 业务解耦 只关注自己系统的核心流程 最终一致性 两个系统的状态保持一致 利用记录和补偿实现 错峰与流控 应用场景异步处理 场景说明：用户注册后，需要发送注册邮件和发送注册信息，传统的做法有两种：串行方式、并行方式 串行方式将注册信息写入数据库成功后，发送注册邮件，然后发送注册短信，而所有任务执行完成后，返回信息给客户端 ​ 串行方式 并行方式将注册信息写入数据库成功后，同时进行发送注册邮件和发送注册短信的操作。而所有任务执行完成后，返回信息给客户端。同串行方式相比，并行方式可以提高执行效率，减少执行时间。 ​ 并行方式 上面的比较可以发现，假设三个操作均需要50ms的执行时间，排除网络因素，则最终执行完成，串行方式需要150ms，而并行方式需要100ms。 因为cpu在单位时间内处理的请求数量是一致的，假设：CPU每1秒吞吐量是100此，则串行方式1秒内可执行的请求量为1000/150，不到7次；并行方式1秒内可执行的请求量为1000/100，为10次。 由上可以看出，传统串行和并行的方式会受到系统性能的局限，那么如何解决这个问题？ 我们需要引入消息队列，将不是必须的业务逻辑，异步进行处理，由此改造出来的流程为 ​ 引入消息队列，异步处理消息 根据上述的流程，用户的响应时间基本相当于将用户数据写入数据库的时间，发送注册邮件、发送注册短信的消息在写入消息队列后，即可返回执行结果，写入消息队列的时间很快，几乎可以忽略，也有此可以将系统吞吐量提升至20QPS，比串行方式提升近3倍，比并行方式提升2倍。 应用解耦 场景说明：用户下单后，订单系统需要通知库存系统。 传统的做法为：订单系统调用库存系统的接口。如下图所示： ​ 传统方式：调用库存接口 传统方式具有如下缺点： 假设库存系统访问失败，则订单减少库存失败，导致订单创建失败 订单系统同库存系统过度耦合 如何解决上述的缺点呢？需要引入消息队列，引入消息队列后的架构如下图所示： ​ 引入消息队列，实现应用解耦 订单系统：用户下单后，订单系统进行数据持久化处理，然后将消息写入消息队列，返回订单创建成功 库存系统：使用拉/推的方式，获取下单信息，库存系统根据订单信息，进行库存操作。 假如在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其后续操作了。由此实现了订单系统与库存系统的应用解耦。 流量削锋流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。 应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。 可以控制参与活动的人数； 可以缓解短时间内高流量对应用的巨大压力； 流量削锋处理方式系统图如下： ​ 流量削锋方式系统图 服务器在接收到用户请求后，首先写入消息队列。这时如果消息队列中消息数量超过最大数量，则直接拒绝用户请求或返回跳转到错误页面； 秒杀业务根据秒杀规则读取消息队列中的请求信息，进行后续处理。 日志处理日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下： ​ 消息队列应用于日志处理的架构 日志采集客户端：负责日志数据采集，定时写受写入Kafka队列； Kafka消息队列：负责日志数据的接收，存储和转发； 日志处理应用：订阅并消费kafka队列中的日志数据； 这种架构在实际开发中的应用，可以参照案例：新浪技术分享：我们如何扛下32亿条实时日志的分析处理 服务的技术架构设计 Kafka：接收用户日志的消息队列。 Logstash：做日志解析，统一成JSON输出给Elasticsearch。 Elasticsearch：实时日志分析服务的核心技术，一个schemaless，实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能。 Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因。 消息通讯消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列、聊天室等。 点对点通讯 ​ 点对点通讯架构设计在点对点通讯架构设计中，客户端A和客户端B共用一个消息队列，即可实现消息通讯功能。 聊天室通讯 ​ 聊天室通讯架构设计 客户端A、客户端B、直至客户端N订阅同一消息队列，进行消息的发布与接收，即可实现聊天通讯方案架构设计。 消息中间件示例电商系统 ​ 电商系统架构示意图 消息队列采用高可用、可持久化的消息中间件。比如Active MQ，Rabbit MQ，Rocket MQ。 应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性） 扩展流程（发短信、配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。 消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。 日志收集系统 ​ 日志收集系统架构示意图分为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。 Zookeeper注册中心，提出负载均衡和地址查找服务； 日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列； Kafka集群：接收，路由，存储，转发等消息处理； Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据； JMS消息服务讲消息队列就不得不提JMS 。JMS（Java Message Service,Java消息服务）API是一个消息服务的标准/规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 在EJB架构中，有消息bean可以无缝的与JM消息服务集成。在J2EE架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。 消息模型在JMS标准中，有两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)。 P2P模式 ​ P2P模式P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。 P2P的特点 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中) 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功 如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式。 Pub/Sub模式 ​ Pub/Sub模式包含三个角色：主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。 Pub/Sub的特点 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者必须保持运行的状态。 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。 消息消费在JMS中，消息的产生和消费都是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。 同步订阅者或接收者通过receive方法来接收消息，receive方法在接收到消息之前（或超时之前）将一直阻塞； 异步订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。 JNDI：Java命名和目录接口,是一种标准的Java命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。 JNDI在JMS中起到查找和访问发送目标或消息来源的作用。 JMS编程模型1. ConnectionFactory创建Connection对象的工厂，针对两种不同的JMS消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。 2. DestinationDestination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。 所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。 3. ConnectionConnection表示在客户端和JMS系统之间建立的链接（对TCP/IP Socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。 4. SessionSession是操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。 5. 消息的生产者消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。 6. 消息消费者消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。 7. MessageListener消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。 深入学习JMS对掌握JAVA架构、EJB架构有很好的帮助，消息中间件也是大型分布式系统必须的组件。本次分享主要做全局性介绍，具体的深入需要大家学习，实践，总结，领会。 参考 消息队列技术介绍]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列：RabbitMQ]]></title>
    <url>%2F2018%2F10%2F02%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%9ARabbitMQ%2F</url>
    <content type="text"><![CDATA[常用消息队列一般商用的容器，比如WebLogic，JBoss，都支持JMS标准，开发上很方便。但免费的比如Tomcat，Jetty等则需要使用第三方的消息中间件。本部分内容介绍常用的消息中间件（Active MQ，Rabbit MQ，Zero MQ，Kafka）以及他们的特点。 RabbitMQRabbitMQ是一个消息代理。它的核心思想非常简单：接收并转发消息。你可以把它想象成一个邮局：当你把邮件丢进邮箱时，你非常确定邮递员先生会把它送到收件人手中。在这个比喻中，RabbitMQ就是邮箱、邮局和邮递员。 概念RabbitMQ是流行的开源消息队列系统，用erlang语言开发。RabbitMQ是AMQP（高级消息队列协议）的标准实现。支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX，持久化。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 ​ RabbitMQ结构图 通常我们谈到队列服务, 会有三个概念： 发消息者、队列、收消息者，RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和 队列之间, 加入了交换器 (Exchange). 这样发消息者和队列就没有直接联系, 转而变成发消息者把消息给交换器, 交换器根据调度策略再把消息再给队列。 上图中有几个重要概念： Broker：简单来说就是消息队列服务器实体。 Producer：消息生产者，就是投递消息的程序。 Consumer：消息消费者，就是接受消息的程序。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Exchange 用于转发消息，但是它不会做存储 ，如果没有 Queue bind 到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把Exchange和Queue按照路由规则绑定起来。 也就是交换机需要和队列相绑定，这其中如上图所示，是多对多的关系。 Routing Key：路由关键字，Exchange根据这个关键字进行消息投递。 消息到交换机的时候，交互机会转发到对应的队列中，那么究竟转发到哪个队列，就要根据该路由键。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 一个虚拟主机持有一组交换机、队列和绑定。为什么需要多个虚拟主机呢？很简单， RabbitMQ 当中，用户只能在虚拟主机的粒度进行权限控制。 因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创建一个虚拟主机。每一个 RabbitMQ 服务器都有一个默认的虚拟主机“/”。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 消息队列的使用过程，如下： 客户端连接到消息队列服务器，打开一个channel。 客户端声明一个exchange，并设置相关属性。 客户端声明一个queue，并设置相关属性。 客户端使用routing key，在exchange和queue之间建立好绑定关系。 客户端投递消息到exchange。 exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。 交换机交换机的功能主要是接收消息并且转发到绑定的队列，交换机不存储消息，在启用ack模式后，交换机找不到队列会返回错误。交换机有四种类型：Direct, Topic, Headers and Fanout Direct：direct 类型的行为是”先匹配, 再投送”. 即在绑定时设定一个 routing_key, 消息的routing_key 匹配时, 才会被交换器投送到绑定的队列中去. Topic：按规则转发消息（最灵活） Headers：设置 header attribute 参数类型的交换机 Fanout：转发消息到所有绑定队列 Direct Exchange Direct Exchange 是 RabbitMQ 默认的交换机模式，也是最简单的模式，根据key全文匹配去寻找队列。 第一个 X - Q1 就有一个 binding key，名字为 orange； X - Q2 就有 2 个 binding key，名字为 black 和 green。当消息中的 路由键 和 这个 binding key 对应上的时候，那么就知道了该消息去到哪一个队列中。 Ps：为什么 X 到 Q2 要有 black，green，2个 binding key呢，一个不就行了吗？ - 这个主要是因为可能又有 Q3，而Q3只接受 black 的信息，而Q2不仅接受black 的信息，还接受 green 的信息。 Topic Exchange Topic Exchange 转发消息主要是根据通配符。 在这种交换机下，队列和交换机的绑定会定义一种路由模式，那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息。 在这种交换机模式下： 路由键必须是一串字符，用句号（.） 隔开，比如说 agreements.us，或者 agreements.eu.stockholm 等。 路由模式必须包含一个 星号（*），主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词，例如一个匹配模式是 agreements.eu.berlin.#，那么，以agreements.eu.berlin 开头的路由键都是可以的。 具体代码发送的时候还是一样，第一个参数表示交换机，第二个参数表示 routing key，第三个参数即消息。如下： 1rabbitTemplate.convertAndSend("testTopicExchange","key1.a.c.key2", " this is RabbitMQ!"); topic 和 direct 类似, 只是匹配上支持了”模式”, 在”点分”的 routing_key 形式中, 可以使用两个通配符: *表示一个词. #表示零个或多个词. Headers Exchange headers 也是根据规则匹配, 相较于 direct 和 topic 固定地使用 routing_key , headers 则是一个自定义匹配规则的类型， 在队列与交换器绑定时, 会设定一组键值对规则， 消息中也包括一组键值对( headers 属性),，当这些键值对有一对,，或全部匹配时, 消息被投送到对应队列。 Fanout Exchange Fanout Exchange 消息广播的模式，不管路由键或者是路由模式，会把消息发给绑定给它的全部队列，如果配置了 routing_key 会被忽略。 Hello World使用Java进行实现。 会写两个Java程序。一个发送一条消息的producer和一个接收消息并打印出来的consumer。因为只是刚刚起步，我们会忽略一些Java API的细节，只把精力集中在简单的事情上。消息的内容是“Hello World”。 先决条件假定RabbitMQ 已在标准端口（5672）上的localhost上安装并运行。如果您使用不同的主机，端口或凭据，则需要调整连接设置。 下载客户端压缩包，按照描述检查它的signature。解压到你的工作目录下，并从中取出所有JAR文件。 123&gt; $ unzip rabbitmq-java-client-bin-*.zip&gt; $ cp rabbitmq-java-client-bin-*/*.jar ./&gt; RabbitMQ的java客户端可以通过maven下载，它的groupId是com.rabbitmq，artifactId是amqp-client。 发送 我们把发消息的类叫做Send，收消息的类叫做Recv。Send类将会连接（connect）RabbitMQ，发送一条消息然后退出。 在Send.java中，我们需要import一些类： 123import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Channel; 创建类并且为queue起个名字： 12345678public class Send &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] argv) throws java.io.IOException &#123; ... &#125;&#125; 然后我们创建一个到server的connection： 1234ConnectionFactory factory = new ConnectionFactory();factory.setHost("localhost");Connection connection = factory.newConnection();Channel channel = connection.createChannel(); connection是socket连接的抽象，并且为我们管理协议版本协商（protocol version negotiation），认证（authentication ）等等事情。这里我们要连接的消息代理在本地，因此我们将host设为“localhost”。如果我们想连接其他机器上的代理，只需要将这里改为特定的主机名或IP地址。 接下来，我们创建一个channel，绝大部分API方法需要通过调用它来完成。 发送之前，我们必须声明消息要发往哪个队列，然后我们可以向队列发一条消息： 1234channel.queueDeclare(QUEUE_NAME, false, false, false, null);String message = "Hello World!";channel.basicPublish("", QUEUE_NAME, null, message.getBytes());System.out.println(" [x] Sent '" + message + "'"); 队列的声明是幂等的，也就是说只有当队列不存在时才会创建它。消息内容是byte数组，因此你可以使用各种编码方式。 最后，我们把channel和connection关掉： 12channel.close();connection.close(); 消息没发出去！如果这是你第一次使用RabbitMQ，并且你没有看到“Sent”信息被打印出来，那你可能会在抓耳挠腮，搞不清哪里出了错。也许消息代理启动时没有足够的磁盘空间（默认需要1Gb）所以它拒绝了消息。检查一下代理的logfile，假如有必要的话也可以减少磁盘空间的限制。 配置文件文档 将会告诉你如何设置disk_free_limit。 Send.java 1234567891011121314151617181920import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class Send &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = "Hello World!"; channel.basicPublish("", QUEUE_NAME, null, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + message + "'"); &#125; &#125;&#125; 接收 以上就是我们的发送者。RabbitMQ会把消息推送给接收者，所以不同于只发了一条信息的发送者，我们会让接收者一直监听消息并打印出来。 Recv.java的import部分和Send类差不多： 12345import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer; 新增的DefaultConsumer类是Consumer接口的实现,我们使用它来接收server推送来的消息。起始的代码和sender差不多（译注：都是样板代码）：我们创建连接，打开channel，并且声明我们要监听的队列。注意这个队列要与Send类要发送的队列一致。 1234567891011121314151617public class Recv &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] argv) throws java.io.IOException, java.lang.InterruptedException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); ... &#125;&#125; 注意到，我们在这里也声明了队列。因为我们可能在启动发送者之前启动接收者，因此需要保证在接收消息之前，队列已经存在。 接下来我们要告诉server把队列中的消息发送给我们。因为推送消息是异步的，我们需要以对象的形式提供一个回调，它会缓存消息，直到我们准备好使用它。我们通过一个DefaultConsumer的子类来完成这件事： 12345678910 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println(" [x] Received '" + message + "'"); &#125; &#125;; channel.basicConsume(QUEUE_NAME, true, consumer); Recv.java 12345678910111213141516171819202122232425import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;public class Recv &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + message + "'"); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 工作队列 生产者消费者模式，在工人间分配任务 在这个中，我们将创建一个工作队列，用于在多个工作人员之间分配耗时的任务。 工作队列（又称：任务队列）背后的主要思想是避免立即执行资源密集型任务，并且必须等待它完成。相反，我们安排任务稍后完成。我们将任务封装 为消息并将其发送到队列。在后台运行的工作进程将弹出任务并最终执行作业。当您运行许多工作程序时，它们之间将共享任务。 这个概念在Web应用程序中特别有用，在这些应用程序中，在短HTTP请求窗口期间无法处理复杂任务。 准备在本教程的前一部分中，我们发送了一条包含“Hello World！”的消息。现在我们将发送代表复杂任务的字符串。我们没有真实世界的任务，比如要调整大小的图像或要渲染的pdf文件，所以让我们通过假装我们很忙来伪造它 - 使用Thread.sleep（）函数。我们将字符串中的点数作为其复杂性; 每个点都会占据“工作”的一秒钟。例如，Hello ...描述的假任务 将花费三秒钟。 我们将稍微修改前一个示例中的Send.java代码，以允许从命令行发送任意消息。该程序将任务安排到我们的工作队列，所以我们将其命名为 NewTask.java： 1234String message = String.join（“”，argv）;channel.basicPublish（“”，“hello”，null，message.getBytes（））;System.out.println（“[x] Sent'” + message + “'”）; 我们的旧Recv.java程序还需要进行一些更改：它需要伪造消息体中每个点的第二个工作。它将处理传递的消息并执行任务，所以我们称之为Worker.java： 123456789101112DeliverCallback deliverCallback =（consumerTag，delivery） - &gt; &#123; String message = new String（delivery.getBody（），“UTF-8”）; System.out.println（“[x] Received'” + message + “'”）; try &#123; doWork(message); &#125; finally &#123; System.out.println（“[x] Done”）; &#125;&#125;;boolean autoAck = true ; //确认如下channel.basicConsume（TASK_QUEUE_NAME，autoAck，deliverCallback，consumerTag - &gt; &#123;&#125;）; 我们的假任务是模拟执行时间： 12345private static void doWork （String task） throws InterruptedException &#123; for（ char ch：task.toCharArray（））&#123; if（ch == '。'）Thread.sleep（ 1000）; &#125;&#125; 进行编译 1javac -cp $ CP NewTask.java Worker.java 循环调度使用任务队列的一个优点是能够轻松地并行工作。如果我们正在积压工作积压，我们可以添加更多工人，这样就可以轻松扩展。 首先，让我们尝试同时运行两个worker实例。他们都会从队列中获取消息，但究竟如何呢？让我们来看看。 你需要打开三个控制台。两个将运行工作程序。这些游戏机将成为我们的两个消费者 - C1和C2。 12#shell 1 java -cp $ CP Worker ＃=&gt; [*]正在等待消息。要退出按CTRL + C. 12#shell 2 java -cp $ CP Worker ＃=&gt; [*]等待消息。要退出按CTRL + C. 在第三个中，我们将发布新任务。启动消费者后，您可以发布一些消息： 1234567891011#shell 3 java -cp $ CP NewTask First message。＃=&gt; [x]发送“第一条消息”。java -cp $ CP NewTask第二条消息.. ＃=&gt; [x]发送'第二条消息..' java -cp $ CP NewTask第三条消息... ＃=&gt; [x]发送'第三条消息......' java - cp $ CP NewTask第四条消息.... ＃=&gt; [x]发送'第四条消息....' java -cp $ CP NewTask第五条消息..... ＃=&gt; [x]发送'第五条消息.. ......” 让我们看看交给我们工人的是什么： 123456789java -cp $ CP Worker ＃=&gt; [*]正在等待消息。要退出，请按CTRL + C ＃=&gt; [x]收到“第一条消息”。＃=&gt; [x]收到'第三条消息......' ＃=&gt; [x]收到'第五条消息.....'java -cp $ CP Worker ＃=&gt; [*]正在等待消息。要退出按CTRL + C ＃=&gt; [x]收到'第二条消息..' ＃=&gt; [x]收到'第四条消息....' 默认情况下，RabbitMQ将按顺序将每条消息发送给下一个消费者。平均而言，每个消费者将获得相同数量的消息。这种分发消息的方式称为循环法。与三个或更多工人一起尝试。 消息确认执行任务可能需要几秒钟。你可能想知道如果其中一个消费者开始一项长期任务并且只是部分完成而死亡会发生什么。使用我们当前的代码，一旦RabbitMQ向消费者发送消息，它立即将其标记为删除。在这种情况下，如果你杀死一个工人，我们将丢失它刚刚处理的消息。我们还将丢失分发给这个特定工作者但尚未处理的所有消息。 但我们不想失去任何任务。如果工人死亡，我们希望将任务交付给另一名工人。 为了确保消息永不丢失，RabbitMQ支持消息确认。消费者发回ack（nowledgement）告诉RabbitMQ已收到，处理了特定消息，RabbitMQ可以自由删除它。 如果消费者死亡（其通道关闭，连接关闭或TCP连接丢失）而不发送确认，RabbitMQ将理解消息未完全处理并将重新排队。如果同时有其他在线消费者，则会迅速将其重新发送给其他消费者。这样你就可以确保没有消息丢失，即使工人偶尔会死亡。 没有任何消息超时; 当消费者死亡时，RabbitMQ将重新发送消息。即使处理消息需要非常长的时间，也没关系。 默认情况下，手动消息确认已打开。在前面的示例中，我们通过autoAck = true 标志明确地将它们关闭。一旦我们完成任务，就应该将此标志设置为false并从工作人员发送适当的确认。 123456789101112131415channel.basicQos(1); // accept only one unack-ed message at a time (see below)DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + message + "'"); try &#123; doWork(message); &#125; finally &#123; System.out.println(" [x] Done"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;&#125;;boolean autoAck = false;channel.basicConsume(TASK_QUEUE_NAME, autoAck, deliverCallback, consumerTag -&gt; &#123; &#125;); 使用此代码，我们可以确定即使您在处理消息时使用CTRL + C杀死一名工作人员，也不会丢失任何内容。工人死后不久，所有未经确认的消息将被重新传递。 确认必须在收到交付的同一频道上发送。尝试使用不同的通道进行确认将导致通道级协议异常。 被遗忘的确认错过basicAck是一个常见的错误。这是一个简单的错误，但后果是严重的。当您的客户端退出时，消息将被重新传递（这可能看起来像随机重新传递），但RabbitMQ会占用越来越多的内存，因为它无法释放任何未经消息的消息。 为了调试这种错误，您可以使用rabbitmqctl 来打印messages_unacknowledged字段： 12&gt; sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged&gt; 在Windows上，删除sudo： 12&gt; rabbitmqctl.bat list_queues name messages_ready messages_unacknowledged&gt; 消息持久性我们已经学会了如何确保即使消费者死亡，任务也不会丢失。但是如果RabbitMQ服务器停止，我们的任务仍然会丢失。 当RabbitMQ退出或崩溃时，它将忘记队列和消息，除非你告诉它不要。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久。 首先，我们需要确保RabbitMQ永远不会丢失我们的队列。为此，我们需要声明它是持久的： 12boolean durable = true ;channel.queueDeclare（“hello”，durable，false，false，null）; 虽然此命令本身是正确的，但它在我们当前的设置中不起作用。那是因为我们已经定义了一个名为hello的队列 ，这个队列不耐用。RabbitMQ不允许您使用不同的参数重新定义现有队列，并且会向尝试执行此操作的任何程序返回错误。但是有一个快速的解决方法 - 让我们声明一个具有不同名称的队列，例如task_queue： 12boolean durable = true ;channel.queueDeclare（“task_queue”，durable，false，false，null）; 此queueDeclare更改需要应用于生产者和消费者代码。 此时我们确信即使RabbitMQ重新启动，task_queue队列也不会丢失。现在我们需要将消息标记为持久性 - 通过将MessageProperties（实现BasicProperties）设置为值PERSISTENT_TEXT_PLAIN。 12345import com.rabbitmq.client.MessageProperties;channel.basicPublish（“”，“task_queue”， MessageProperties.PERSISTENT_TEXT_PLAIN， message.getBytes（））; 有关消息持久性的注释将消息标记为持久性并不能完全保证消息不会丢失。虽然它告诉RabbitMQ将消息保存到磁盘，但是当RabbitMQ接受消息并且尚未保存消息时，仍然有一个短时间窗口。此外，RabbitMQ不会为每条消息执行fsync（2） - 它可能只是保存到缓存而不是真正写入磁盘。持久性保证不强，但对于我们简单的任务队列来说已经足够了。如果您需要更强的保证，那么您可以使用 生产者确认。 公平派遣您可能已经注意到调度仍然无法完全按照我们的意愿运行。例如，在有两个工人的情况下，当所有奇怪的消息都很重，甚至消息很轻时，一个工人将经常忙，而另一个工作人员几乎不会做任何工作。那么，RabbitMQ对此一无所知，仍然会均匀地发送消息。 发生这种情况是因为RabbitMQ只是在消息进入队列时调度消息。它不会查看消费者未确认消息的数量。它只是盲目地向第n个消费者发送每个第n个消息。 为了打败我们可以使用basicQos方法和 prefetchCount = 1设置。这告诉RabbitMQ一次不向一个worker发送一条消息。或者，换句话说，在处理并确认前一个消息之前，不要向工作人员发送新消息。相反，它会将它发送给下一个仍然很忙的工人。 12int prefetchCount = 1 ;channel.basicQos（prefetchCount）; 关于队列大小的说明如果所有工作人员都很忙，您的队列就会填满。您将需要关注这一点，并可能添加更多工作人员，或者采取其他策略。 源码Final code of our NewTask.java class: 1234567891011121314151617181920212223242526import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.MessageProperties;public class NewTask &#123; private static final String TASK_QUEUE_NAME = "task_queue"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.queueDeclare(TASK_QUEUE_NAME, true, false, false, null); String message = String.join(" ", argv); channel.basicPublish("", TASK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + message + "'"); &#125; &#125;&#125; And our Worker.java: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;public class Worker &#123; private static final String TASK_QUEUE_NAME = "task_queue"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); final Connection connection = factory.newConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(TASK_QUEUE_NAME, true, false, false, null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); channel.basicQos(1); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + message + "'"); try &#123; doWork(message); &#125; finally &#123; System.out.println(" [x] Done"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;; channel.basicConsume(TASK_QUEUE_NAME, false, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125; private static void doWork(String task) &#123; for (char ch : task.toCharArray()) &#123; if (ch == '.') &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException _ignored) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; &#125;&#125; 发布/订阅我们将向多个消费者传递信息。此模式称为“发布/订阅”。 为了说明这种模式，我们将构建一个简单的日志记录系统。它将包含两个程序 - 第一个将发出日志消息，第二个将接收和打印它们。 在我们的日志记录系统中，接收程序的每个运行副本都将获取消息。这样我们就可以运行一个接收器并将日志指向磁盘; 同时我们将能够运行另一个接收器并在屏幕上看到日志。 基本上，发布的日志消息将被广播给所有接收者。 Exchanges让我们快速浏览前面教程中介绍的内容： 甲生产者是发送消息的用户的应用程序。 甲队列是存储消息的缓冲器。 甲消费者是接收消息的用户的应用程序。 RabbitMQ中消息传递模型的核心思想是生产者永远不会将任何消息直接发送到队列。实际上，生产者通常甚至不知道消息是否会被传递到任何队列。 相反，生产者只能向Exchanges发送消息。交换是一件非常简单的事情。一方面，它接收来自生产者的消息，另一方面将它们推送到队列。交易所必须确切知道如何处理它收到的消息。它应该附加到特定队列吗？它应该附加到许多队列吗？或者它应该被丢弃。其规则由Exchange类型定义 。 有几种交换类型可供选择：direct, topic, headers和 fanout.。我们将专注于最后一个 fanout。让我们创建一个这种类型的交换，并将其称为日志： 1channel.exchangeDeclare（“logs”，“fanout”）; fanout交换非常简单。正如您可能从名称中猜到的那样，它只是将收到的所有消息广播到它知道的所有队列中。而这正是我们记录器所需要的。 无名交流在本教程的前几部分中，我们对交换一无所知，但仍然可以向队列发送消息。这是可能的，因为我们使用默认交换，我们通过空字符串（“”）来识别。 回想一下我们之前如何发布消息： 12&gt; channel.basicPublish（“”，“hello”，null，message.getBytes（））;&gt; 第一个参数是交换的名称。空字符串表示默认或无名交换：消息通过routingKey指定的名称路由到队列（如果存在）。 现在，我们可以发布到我们的命名交换： 1channel.basicPublish（“logs”，“”，null，message.getBytes（））; 临时队列您可能还记得以前我们使用过具有特定名称的队列（还记得hello和task_queue吗？）。能够命名队列对我们来说至关重要 - 我们需要将工作人员指向同一个队列。当您想要在生产者和消费者之间共享队列时，为队列命名非常重要。 但我们的记录器并非如此。我们希望了解所有日志消息，而不仅仅是它们的一部分。我们也只对目前流动的消息感兴趣，而不是旧消息。要解决这个问题，我们需要两件事。 首先，每当我们连接到Rabbit时，我们都需要一个新的空队列。为此，我们可以使用随机名称创建队列，或者更好 - 让服务器为我们选择随机队列名称。 其次，一旦我们断开消费者，就应该自动删除队列。 在Java客户端中，当我们没有向queueDeclare（）提供参数时，我们 使用生成的名称创建一个非持久的，独占的自动删除队列： 1String queueName = channel.queueDeclare（）。getQueue（）; 您可以在队列指南中了解有关独占标志和其他队列属性的更多信息。 此时，queueName包含随机队列名称。例如，它可能看起来像amq.gen-JzTY20BRgKO-HjmUJj0wLg。 绑定 我们已经创建了一个fanout交换和一个队列。现在我们需要告诉交换机将消息发送到我们的队列。交换和队列之间的关系称为绑定。 1channel.queueBind（queueName，“logs”，“”）; 从现在开始，日志交换会将消息附加到我们的队列中。 列出绑定你猜对了，你可以列出现有的绑定 12&gt; rabbitmqctl list_bindings&gt; 把它们放在一起 生成日志消息的生产者程序与前一个教程没有太大的不同。最重要的变化是我们现在想要将消息发布到我们的日志交换而不是无名交换。我们需要在发送时提供routingKey，但是对于fanout交换，它的值会被忽略。这里是 EmitLog.java程序的代码 ： 12345678910111213141516171819public class EmitLog &#123; private static final String EXCHANGE_NAME = "logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, "fanout"); String message = argv.length &lt; 1 ? "info: Hello World!" : String.join(" ", argv); channel.basicPublish(EXCHANGE_NAME, "", null, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + message + "'"); &#125; &#125;&#125; 如您所见，在建立连接后，我们宣布了交换。此步骤是必要的，因为禁止发布到不存在的交换。 如果没有队列绑定到交换机，消息将会丢失，但这对我们没有问题; 如果没有消费者在听，我们可以安全地丢弃该消息。 ReceiveLogs.java的代码： 123456789101112131415161718192021222324252627import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;public class ReceiveLogs &#123; private static final String EXCHANGE_NAME = "logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, "fanout"); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, EXCHANGE_NAME, ""); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + message + "'"); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 路由 有选择地接收消息 上一个教程中，我们构建了一个简单的日志系统 我们能够向许多接收者广播日志消息。 在本教程中，我们将为其添加一个功能 - 我们将只能订阅一部分消息。例如，我们只能将关键错误消息定向到日志文件（以节省磁盘空间），同时仍然能够在控制台上打印所有日志消息。 绑定在前面的例子中，我们已经创建了绑定。您可能会记得以下代码： 1channel.queueBind（queueName，EXCHANGE_NAME，“”）; 绑定是交换和队列之间的关系。这可以简单地理解为：队列对来自此交换的消息感兴趣。 绑定可以采用额外的routingKey参数。为了避免与basic_publish参数混淆，我们将其称为 绑定密钥。这就是我们如何使用键创建绑定： 1channel.queueBind（queueName，EXCHANGE_NAME，“black”）; 绑定密钥的含义取决于交换类型。我们之前使用的fanout交换只是忽略了它的价值。 直接交换我们上一个教程中的日志记录系统向所有消费者广播所有消息。我们希望扩展它以允许根据消息的严重性过滤消息。例如，我们可能需要一个程序将日志消息写入磁盘以仅接收严重错误，而不是在警告或信息日志消息上浪费磁盘空间。 我们使用的是fanout交换，它没有给我们太大的灵活性 - 它只能进行无意识的广播。 我们将使用direct交换。direct交换背后的路由算法很简单 消息进入队列，其 绑定密钥与消息的路由密钥完全匹配。 为了说明这一点，请考虑以下设置： 在此设置中，我们可以看到direct交换X与两个绑定到它的队列。第一个队列绑定橙色绑定，第二个绑定有两个绑定，一个绑定密钥为黑色，另一个绑定为绿色。 在这样的设置中，使用路由密钥orange发布到交换机的消息 将被路由到队列Q1。路由键为黑色 或绿色的消息将转到Q2。所有其他消息将被丢弃。 多个绑定 使用相同的绑定密钥绑定多个队列是完全合法的。在我们的示例中，我们可以在X和Q1之间添加绑定键黑色的绑定。在这种情况下，direct交换将表现得像fanout一样，并将消息广播到所有匹配的队列。路由键为黑色的消息将传送到 Q1和Q2。 发送日志我们将此模型用于我们的日志系统。我们会将消息发送给direct交换，而不是fanout。我们将提供日志严重性作为路由密钥。这样接收程序将能够选择它想要接收的严重性。让我们首先关注发送日志。 一如既往，我们需要先创建一个交换： 1channel.exchangeDeclare（EXCHANGE_NAME，“direct”）; 我们已准备好发送消息： 1channel.basicPublish（EXCHANGE_NAME，severity，null，message.getBytes（））; 为简化起见，我们假设“严重性”可以是“信息”，“警告”，“错误”之一。 订阅接收消息将像上一个教程一样工作，但有一个例外 - 我们将为我们感兴趣的每个严重性创建一个新的绑定。 12345String queueName = channel.queueDeclare().getQueue();for(String severity : argv)&#123; channel.queueBind(queueName, EXCHANGE_NAME, severity);&#125; 把它们放在一起 EmitLogDirect.java类的代码： 123456789101112131415161718192021222324import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class EmitLogDirect &#123; private static final String EXCHANGE_NAME = "direct_logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, "direct"); String severity = getSeverity(argv); String message = getMessage(argv); channel.basicPublish(EXCHANGE_NAME, severity, null, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + severity + "':'" + message + "'"); &#125; &#125; //..&#125; ReceiveLogsDirect.java的代码： 123456789101112131415161718192021222324252627282930313233import com.rabbitmq.client.*;public class ReceiveLogsDirect &#123; private static final String EXCHANGE_NAME = "direct_logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, "direct"); String queueName = channel.queueDeclare().getQueue(); if (argv.length &lt; 1) &#123; System.err.println("Usage: ReceiveLogsDirect [info] [warning] [error]"); System.exit(1); &#125; for (String severity : argv) &#123; channel.queueBind(queueName, EXCHANGE_NAME, severity); &#125; System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + delivery.getEnvelope().getRoutingKey() + "':'" + message + "'"); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 主题 根据模式（主题）接收消息 在上一个教程中，我们改进了日志系统。我们使用的是direct的，而不是使用只能进行虚拟广播的fanout交换，并且有可能选择性地接收日志。 虽然使用direct交换改进了我们的系统，但它仍然有局限性 - 它不能基于多个标准进行路由。 在我们的日志记录系统中，我们可能不仅要根据严重性订阅日志，还要根据发出日志的源来订阅日志。您可能从syslog unix工具中了解这个概念，该 工具根据严重性（info / warn / crit …）和facility（auth / cron / kern …）来路由日志。 这会给我们带来很大的灵活性 - 我们可能想要听取来自’cron’的关键错误以及来自’kern’的所有日志。 要在我们的日志记录系统中实现这一点，我们需要了解更复杂的topic交换。 Topic exchange发送到主题交换的消息不能具有任意的 routing_key - 它必须是由点分隔的单词列表。单词可以是任何内容，但通常它们指定与消息相关的一些功能。一些有效的路由键示例：“ stock.usd.nyse ”，“ nyse.vmw”，“ quick.orange.rabbit ”。路由密钥中可以包含任意数量的单词，最多可达255个字节。 绑定密钥也必须采用相同的形式。主题交换背后的逻辑 类似于直接交换- 使用特定路由密钥发送的消息将被传递到与匹配绑定密钥绑定的所有队列。但是绑定键有两个重要的特殊情况： *（星号）可以替代一个单词。 ＃（hash）可以替换零个或多个单词。 在一个例子中解释这个是最容易的： 在这个例子中，我们将发送所有描述动物的消息。消息将与包含三个单词（两个点）的路由键一起发送。路由键中的第一个单词将描述速度，第二个是颜色，第三个是物种：“ &lt;speed&gt;。&lt;color&gt;。&lt;species&gt;”。 我们创建了三个绑定：Q1绑定了绑定键“ * .orange.* ”，Q2 绑定了“ ..rabbit ”和“ lazy.＃ ”。 这些绑定可以概括为： Q1对所有橙色动物感兴趣。 Q2希望听到关于兔子的一切，以及关于懒惰动物的一切。 路由密钥设置为“ quick.orange.rabbit ”的消息将传递到两个队列。消息“ lazy.orange.elephant ”也将同时发送给他们。另一方面，“ quick.orange.fox ”只会转到第一个队列，而“ lazy.brown.fox ”只会转到第二个队列。“ lazy.pink.rabbit ”将仅传递到第二个队列一次，即使它匹配两个绑定。“ quick.brown.fox ”与任何绑定都不匹配，因此它将被丢弃。 如果我们违反合同并发送带有一个或四个单词的消息，例如“ orange ”或“ quick.orange.male.rabbit ”，会发生什么？好吧，这些消息将不匹配任何绑定，并将丢失。 另一方面，“ lazy.orange.male.rabbit ”，即使它有四个单词，也会匹配最后一个绑定，并将被传递到第二个队列。 Topic 交流Topic 交换功能强大，可以像其他交易所一样运行。 当队列绑定“ ＃ ”（哈希）绑定密钥时 - 它将接收所有消息，而不管路由密钥 - 如fanout交换。 当特殊字符“ * ”（星号）和“ ＃ ”（哈希）未在绑定中使用时，topic交换的行为就像dirct交换一样。 把它们放在一起我们将在我们的日志记录系统中使用主题交换。我们将首先假设日志的路由键有两个词：“ &lt;facility&gt;。&lt;severity&gt; ”。 代码与上一个教程中的代码几乎相同 。 EmitLogTopic.java的代码： 12345678910111213141516171819202122232425import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class EmitLogTopic &#123; private static final String EXCHANGE_NAME = "topic_logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, "topic"); String routingKey = getRouting(argv); String message = getMessage(argv); channel.basicPublish(EXCHANGE_NAME, routingKey, null, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + routingKey + "':'" + message + "'"); &#125; &#125; //..&#125; ReceiveLogsTopic.java: 12345678910111213141516171819202122232425262728293031323334353637import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;public class ReceiveLogsTopic &#123; private static final String EXCHANGE_NAME = "topic_logs"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, "topic"); String queueName = channel.queueDeclare().getQueue(); if (argv.length &lt; 1) &#123; System.err.println("Usage: ReceiveLogsTopic [binding_key]..."); System.exit(1); &#125; for (String bindingKey : argv) &#123; channel.queueBind(queueName, EXCHANGE_NAME, bindingKey); &#125; System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + delivery.getEnvelope().getRoutingKey() + "':'" + message + "'"); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; RPC 如何将往返消息作为远程过程调用 请求回复模式当两个应用程序通过Messaging进行通信时，通信是单向的。应用程序可能需要双向对话。 当应用程序发送消息时，它如何从接收方获得响应？ 发送一对请求 - 回复消息，每个消息都在自己的频道上。 Request-Reply有两个参与者： Java实现在第二篇教程中，我们学习了如何使用工作队列在多个工作人员之间分配耗时的任务。 但是如果我们需要在远程计算机上运行一个函数并等待结果呢？嗯，这是一个不同的故事。此模式通常称为远程过程调用或RPC。 在本教程中，我们将使用RabbitMQ构建RPC系统：客户端和可伸缩的RPC服务器。由于我们没有任何值得分发的耗时任务，我们将创建一个返回Fibonacci数字的虚拟RPC服务。 客户端界面为了说明如何使用RPC服务，我们将创建一个简单的客户端类。它将公开一个名为call的方法，该方法发送一个RPC请求并阻塞，直到收到答案为止： 123FibonacciRpcClient fibonacciRpc = new FibonacciRpcClient();String result = fibonacciRpc.call("4");System.out.println( "fib(4) is " + result); 有关RPC的说明尽管RPC在计算中是一种非常常见的模式，但它经常受到批评。当程序员不知道函数调用是本地的还是慢的RPC时，会出现问题。这样的混淆导致系统不可预测，并增加了调试的不必要的复杂性。错误使用RPC可以导致不可维护的意大利面条代码，而不是简化软件。 考虑到这一点，请考虑以下建议： 确保明显哪个函数调用是本地的，哪个是远程的。 记录您的系统。使组件之间的依赖关系变得清晰。 处理错误案例。当RPC服务器长时间停机时，客户端应该如何反应？ 如有疑问，请避免使用RPC。如果可以，您应该使用异步管道 - 而不是类似RPC的阻塞，将结果异步推送到下一个计算阶段。 回调队列一般来说，通过RabbitMQ进行RPC很容易。客户端发送请求消息，服务器回复响应消息。为了接收响应，我们需要发送带有请求的“回调”队列地址。我们可以使用默认队列（在Java客户端中是独占的）。我们来试试吧： 12345678910callbackQueueName = channel.queueDeclare().getQueue();BasicProperties props = new BasicProperties .Builder() .replyTo(callbackQueueName) .build();channel.basicPublish("", "rpc_queue", props, message.getBytes());// ... then code to read a response message from the callback_queue ... 消息属性AMQP 0-9-1协议预定义了一组带有消息的14个属性。大多数属性很少使用，但以下情况除外： deliveryMode：将消息标记为持久性（值为2）或瞬态（任何其他值）。你可能还记得第二篇教程中的这个属性。 contentType：用于描述编码的mime类型。例如，对于经常使用的JSON编码，将此属性设置为：application / json是一种很好的做法。 replyTo：通常用于命名回调队列。 correlationId：用于将RPC响应与请求相关联。 我们需要这个新的导入： 1import com.rabbitmq.client.AMQP.BasicProperties; 相关ID在上面介绍的方法中，我们建议为每个RPC请求创建一个回调队列。这是非常低效的，但幸运的是有更好的方法 - 让我们为每个客户端创建一个回调队列。 这引发了一个新问题，在该队列中收到响应后，不清楚响应属于哪个请求。那是在使用correlationId属性的时候 。我们将为每个请求将其设置为唯一值。稍后，当我们在回调队列中收到消息时，我们将查看此属性，并根据该属性，我们将能够将响应与请求进行匹配。如果我们看到未知的 correlationId值，我们可以安全地丢弃该消息 - 它不属于我们的请求。 您可能会问，为什么我们应该忽略回调队列中的未知消息，而不是因为错误而失败？这是由于服务器端存在竞争条件的可能性。尽管不太可能，但是在向我们发送答案之后，但在发送请求的确认消息之前，RPC服务器可能会死亡。如果发生这种情况，重新启动的RPC服务器将再次处理请求。这就是为什么在客户端上我们必须优雅地处理重复的响应，理想情况下RPC应该是幂等的。 摘要 我们的RPC将这样工作： 对于RPC请求，客户端发送带有两个属性的消息： replyTo（设置为仅为请求创建的匿名独占队列）和correlationId（设置为每个请求的唯一值）。 请求被发送到rpc_queue队列。 RPC worker（aka：server）正在等待该队列上的请求。当出现请求时，它会执行该作业，并使用来自replyTo字段的队列将带有结果的消息发送回客户端。 客户端等待回复队列上的数据。出现消息时，它会检查correlationId属性。如果它与请求中的值匹配，则将响应返回给应用程序。 把它们放在一起The Fibonacci task: 12345private static int fib(int n) &#123; if (n == 0) return 0; if (n == 1) return 1; return fib(n-1) + fib(n-2);&#125; 我们宣布我们的斐波那契函数。它假定只有有效的正整数输入。（不要指望这个适用于大数字，并且它可能是最慢的递归实现）。 我们的RPC服务器的代码可以在这里找到：RPCServer.java。 服务器代码非常简单： 像往常一样，我们首先建立连接，通道和声明队列。 我们可能希望运行多个服务器进程。为了在多个服务器上平均分配负载，我们需要在channel.basicQos中设置 prefetchCount设置。 我们使用basicConsume来访问队列，我们以对象（DeliverCallback）的形式提供回调，它将完成工作并发回响应。 我们的RPC客户端的代码可以在这里找到：RPCClient.java。 客户端代码稍微复杂一些： 我们建立了一个连接和渠道。 我们的调用方法生成实际的RPC请求。 在这里，我们首先生成一个唯一的correlationId 数并保存它 - 我们的消费者回调将使用此值来匹配相应的响应。 然后，我们为回复创建一个专用的独占队列并订阅它。 接下来，我们发布请求消息，其中包含两个属性： replyTo和correlationId。 在这一点上，我们可以坐下来等待正确的响应到来。 由于我们的消费者交付处理是在一个单独的线程中进行的，因此我们需要在响应到达之前暂停主线程。使用BlockingQueue是一种可能的解决方案。这里我们创建了ArrayBlockingQueue ，容量设置为1，因为我们只需要等待一个响应。 消费者正在做一个非常简单的工作，对于每个消费的响应消息，它检查correlationId 是否是我们正在寻找的那个。如果是这样，它会将响应置于BlockingQueue。 同时主线程正在等待响应从BlockingQueue获取它。 最后，我们将响应返回给用户。 发出客户请求： 1234567RPCClient fibonacciRpc = new RPCClient();System.out.println(" [x] Requesting fib(30)");String response = fibonacciRpc.call("30");System.out.println(" [.] Got '" + response + "'");fibonacciRpc.close(); RPCClient.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.util.UUID;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;import java.util.concurrent.TimeoutException;public class RPCClient implements AutoCloseable &#123; private Connection connection; private Channel channel; private String requestQueueName = "rpc_queue"; public RPCClient() throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); connection = factory.newConnection(); channel = connection.createChannel(); &#125; public static void main(String[] argv) &#123; try (RPCClient fibonacciRpc = new RPCClient()) &#123; for (int i = 0; i &lt; 32; i++) &#123; String i_str = Integer.toString(i); System.out.println(" [x] Requesting fib(" + i_str + ")"); String response = fibonacciRpc.call(i_str); System.out.println(" [.] Got '" + response + "'"); &#125; &#125; catch (IOException | TimeoutException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public String call(String message) throws IOException, InterruptedException &#123; final String corrId = UUID.randomUUID().toString(); String replyQueueName = channel.queueDeclare().getQueue(); AMQP.BasicProperties props = new AMQP.BasicProperties .Builder() .correlationId(corrId) .replyTo(replyQueueName) .build(); channel.basicPublish("", requestQueueName, props, message.getBytes("UTF-8")); final BlockingQueue&lt;String&gt; response = new ArrayBlockingQueue&lt;&gt;(1); String ctag = channel.basicConsume(replyQueueName, true, (consumerTag, delivery) -&gt; &#123; if (delivery.getProperties().getCorrelationId().equals(corrId)) &#123; response.offer(new String(delivery.getBody(), "UTF-8")); &#125; &#125;, consumerTag -&gt; &#123; &#125;); String result = response.take(); channel.basicCancel(ctag); return result; &#125; public void close() throws IOException &#123; connection.close(); &#125;&#125; RPCServer.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import com.rabbitmq.client.*;public class RPCServer &#123; private static final String RPC_QUEUE_NAME = "rpc_queue"; private static int fib(int n) &#123; if (n == 0) return 0; if (n == 1) return 1; return fib(n - 1) + fib(n - 2); &#125; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.queueDeclare(RPC_QUEUE_NAME, false, false, false, null); channel.queuePurge(RPC_QUEUE_NAME); channel.basicQos(1); System.out.println(" [x] Awaiting RPC requests"); Object monitor = new Object(); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; AMQP.BasicProperties replyProps = new AMQP.BasicProperties .Builder() .correlationId(delivery.getProperties().getCorrelationId()) .build(); String response = ""; try &#123; String message = new String(delivery.getBody(), "UTF-8"); int n = Integer.parseInt(message); System.out.println(" [.] fib(" + message + ")"); response += fib(n); &#125; catch (RuntimeException e) &#123; System.out.println(" [.] " + e.toString()); &#125; finally &#123; channel.basicPublish("", delivery.getProperties().getReplyTo(), replyProps, response.getBytes("UTF-8")); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); // RabbitMq consumer worker thread notifies the RPC server owner thread synchronized (monitor) &#123; monitor.notify(); &#125; &#125; &#125;; channel.basicConsume(RPC_QUEUE_NAME, false, deliverCallback, (consumerTag -&gt; &#123; &#125;)); // Wait and be prepared to consume the message from RPC client. while (true) &#123; synchronized (monitor) &#123; try &#123; monitor.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 此处介绍的设计并不是RPC服务的唯一可能实现，但它具有一些重要优势： 如果RPC服务器太慢，您可以通过运行另一个服务器来扩展。尝试在新控制台中运行第二个RPCServer。 在客户端，RPC只需要发送和接收一条消息。不需要像queueDeclare这样的同步调用 。因此，对于单个RPC请求，RPC客户端只需要一次网络往返。 我们的代码仍然相当简单，并不试图解决更复杂（但重要）的问题，例如： 如果没有运行服务器，客户应该如何反应？ 客户端是否应该为RPC设置某种超时？ 如果服务器出现故障并引发异常，是否应将其转发给客户端？ 在处理之前防止无效的传入消息（例如检查边界，类型）。 AMQPAMQP解决了什么问题，或者说它的应用场景是什么？ 对于一个大型的软件系统来说，它会有很多的组件或者说模块或者说子系统或者（subsystem or Component or submodule）。那么这些模块的如何通信？这和传统的IPC有很大的区别。传统的IPC很多都是在单一系统上的，模块耦合性很大，不适合扩展（Scalability）；如果使用socket那么不同的模块的确可以部署到不同的机器上，但是还是有很多问题需要解决。比如： 信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据如何方式丢失？ 如何降低发送者和接收者的耦合度？ 如何让Priority高的接收者先接到数据？ 如何做到load balance？有效均衡接收者的负载？ 如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。 如何做到可扩展，甚至将这个通信模块发到cluster上？ 如何保证接收者接收到了完整，正确的数据？ AMDQ协议解决了以上的问题，而RabbitMQ实现了AMQP。 消费者致谢和生产者确认根据定义，使用诸如RabbitMQ之类的消息传递代理的系统是分布式的。由于发送的协议方法（消息）无法保证到达对等方或被其成功处理，因此生产者和消费者都需要一种交付和处理确认的机制。RabbitMQ支持的几种消息传递协议提供了这些功能。本指南涵盖了AMQP 0-9-1中的功能，但其他协议（STOMP，MQTT等）的想法基本相同。 消费者对RabbitMQ的交付处理确认称为AMQP 0-9-1用语中的确认; 经纪人对生产者的确认是一种称为生产者确认的协议扩展。 这两个功能都基于相同的想法，并受到TCP的启发。它们对于从生产者到RabbitMQ节点以及从RabbitMQ节点到消费者的可靠传递至关重要。 消费者交货致谢当RabbitMQ向消费者传递消息时，它需要知道何时考虑成功发送消息。什么样的逻辑是最佳的取决于系统。因此，它主要是一个应用决策。在AMQP 0-9-1当消费者使用注册它是由basic.consume方法或消息是与所述需求取出basic.get方法。 如果您更喜欢更面向示例和逐步的材料，RabbitMQ教程＃2中也涵盖了消费者的认可。 交货标识符：交货标签在我们继续讨论其他主题之前，重要的是解释如何识别交付（并且确认表明它们各自的交付）。 注册使用者（订阅）时，RabbitMQ将使用basic.deliver 方法传递（推送）消息。该方法携带传递标签，其唯一地标识信道上的传递。因此，每个渠道确定交付标签的范围。 传递标签是单调增长的正整数，并由客户端库提供。确认交付的客户端库方法将交付标记作为参数。 由于交付标签的范围是每个渠道，因此必须在收到的相同渠道上确认交货。确认不同的通道将导致“未知的传递标签”协议异常并关闭通道。 消费者确认模式和数据安全注意事项当节点向消费者传递消息时，它必须决定消费者是否应该考虑消息处理（或至少接收）消息。由于多个事物（客户端连接，消费者应用程序等）可能会失败，因此该决定是数据安全问题。消息传递协议通常提供一种确认机制，允许消费者确认交付给他们所连接的节点。是否使用该机制是在消费者订阅时决定的。 根据所使用的确认模式，RabbitMQ可以在发送消息（写入TCP套接字）后立即成功传递消息，或者在收到明确（“手动”）客户端确认时。手动发送的确认可以是正面的也可以是否定的，并使用以下协议方法之一： basic.ack用于肯定确认 basic.nack用于否定确认（注意：这是AMQP 0-9-1的RabbitMQ扩展） basic.reject用于否定确认，但与basic.nack相比有一个限制 下面将讨论如何在客户端库API中公开这些方法。 肯定的确认只是指示RabbitMQ记录一条消息，并且可以丢弃。basic.reject的否定确认具有相同的效果。差异主要在于语义：正面确认假设消息已成功处理，而负面消息表明交付未处理但仍应删除。 在自动确认模式中，消息被认为在发送后立即成功传送。这种模式可以降低吞吐量（只要消费者可以跟上），以降低交付和消费者处理的安全性。这种模式通常被称为“即发即忘”。与手动确认模型不同，如果消费者的TCP连接或通道在成功交付之前关闭，则服务器发送的消息将丢失。因此，自动消息确认应被视为不安全 ，并不适用于所有工作负载。 使用自动确认模式时需要考虑的另一件事是消费者过载。手动确认模式通常与有界信道预取一起使用，该预取限制了信道上未完成（“进行中”）交付的数量。但是，通过自动确认，根据定义没有这种限制。因此，消费者可能会被交付速度所淹没，可能会累积内存积压并耗尽堆或使操作系统终止其进程。某些客户端库将应用TCP反压（停止从套接字读取，直到未处理的交付积压超过某个限制）。因此，仅建议能够以稳定的速度有效处理交付的消费者使用自动交钥匙模式。 积极承认交付用于传递确认的API方法通常作为客户端库中的通道上的操作公开。Java客户端用户将分别使用Channel.basicAck和Channel.basicNack 来执行basic.ack和basic.nack。这是一个Java客户端示例，它表明了一个积极的认可： 123456789101112131415161718// this example assumes an existing channel instanceboolean autoAck = false;channel.basicConsume(queueName, autoAck, "a-consumer-tag", new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); // positively acknowledge a single delivery, the message will // be discarded channel.basicAck(deliveryTag, false); &#125; &#125;); 一次确认多次交付可以对手动确认进行批处理以减少网络流量。这是通过将确认方法的多个字段（见上文）设置为true来完成的。请注意，basic.reject历史上没有该字段，这就是为什么basic.nack被RabbitMQ引入为协议扩展。 当multiple字段设置为true时，RabbitMQ将确认所有未完成的传递标记，包括确认中指定的标记。与确认相关的所有其他内容一样，这是每个频道的范围。例如，假设在信道Ch上未确认传送标签5,6,7和8 ，当确认帧到达该信道时，delivery_tag设置为8 并且multiple设置为true，则将确认从5到8的所有标签。 。如果multiple设置为false，则交付5,6和7仍然是未确认的。 为了确认与RabbitMQ的Java客户端多次交货，通过真正的 多参数通道＃basicAck： 123456789101112131415161718// this example assumes an existing channel instanceboolean autoAck = false;channel.basicConsume(queueName, autoAck, "a-consumer-tag", new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); // positively acknowledge all deliveries up to // this delivery tag channel.basicAck(deliveryTag, true); &#125; &#125;); 交货的否定确认和重新排列有时，消费者无法立即处理交付，但其他实例可能会。在这种情况下，可能希望将其重新排队并让另一个消费者接收并处理它。basic.reject和basic.nack是用于此的两种协议方法。 这些方法通常用于否定确认交付。经纪人可以丢弃此类提供或重新排队。此行为由重新排队字段控制。当该字段设置为true时，代理将使用指定的传递标记重新排列交付（或多次交付，如下所述）。 这两种方法通常作为客户端库中通道的操作公开。Java客户端用户将使用Channel＃basicReject和Channel＃basicNack 分别执行basic.reject和basic.nack： 1234567891011121314151617181920212223242526272829303132333435// this example assumes an existing channel instanceboolean autoAck = false;channel.basicConsume(queueName, autoAck, "a-consumer-tag", new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); // negatively acknowledge, the message will // be discarded channel.basicReject(deliveryTag, false); &#125; &#125;);// this example assumes an existing channel instanceboolean autoAck = false;channel.basicConsume(queueName, autoAck, "a-consumer-tag", new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); // requeue the delivery channel.basicReject(deliveryTag, true); &#125; &#125;); 当消息被重新排队时，如果可能的话，它将被放置在其队列中的原始位置。如果不是（由于当多个消费者共享队列时同时传递和来自其他消费者的确认），该消息将被重新排队到更靠近队列头的位置。 重新排队的消息可以立即准备好重新发送，具体取决于它们在队列中的位置，即具有活动消费者的频道使用的预取值。这意味着如果所有消费者因为由于瞬态条件而无法处理交付而重新排队，则他们将创建重新排队/重新发送循环。就网络带宽和CPU资源而言，这种环路可能是昂贵的。消费者实施可以跟踪重新发送的数量并拒绝好消息（丢弃它们）或在延迟后安排重新排队。 可以使用basic.nack 方法一次拒绝或重新排队多条消息。这就是它与basic.reject的区别。它接受一个额外的参数，倍数。这是一个Java客户端示例： 123456789101112131415161718// this example assumes an existing channel instanceboolean autoAck = false;channel.basicConsume(queueName, autoAck, "a-consumer-tag", new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); // requeue all unacknowledged deliveries up to // this delivery tag channel.basicNack(deliveryTag, true, true); &#125; &#125;); 信道预取设置（QoS）因为消息是异步发送（推送）到客户端的，所以在任何给定时刻通常在通道上“飞行”中有多条消息。此外，客户的手动确认本质上也是异步的。因此，有一个未确认的交付标签的滑动窗口。开发人员通常更愿意限制此窗口的大小以避免消费者端的无限制缓冲区问题。这是通过使用basic.qos方法设置“预取计数”值来完成的 。该值定义通道上允许的最大未确认交货数。一旦数量达到配置的计数，RabbitMQ将停止在通道上传递更多消息，除非至少有一个未完成的消息被确认。 例如，假设在信道Ch上有未确认的传送标签5,6,7和8，并且信道 Ch的预取计数设置为4，则除非至少有一个未完成的传送，否则RabbitMQ将不再推送Ch的传送。得到承认。当确认帧到达该通道且delivery_tag设置为8时，RabbitMQ将注意到并再发送一条消息。 值得重申的是，交付流程和手动客户端确认完全是异步的。因此，如果在飞行中已经有交付的情况下改变了预取值，则会出现自然竞争条件，并且暂时可以在通道上预取未计数的未确认消息。 即使在手动确认模式下， QoS预取设置也不会影响使用basic.get（“pull API”）获取的消息。 可以为频道或消费者配置QoS设置。有关详细信息，请参阅Consumer Prefetch。 消费者确认模式，预取和吞吐量确认模式和QoS预取值对消费者吞吐量具有显着影响。通常，增加预取将提高向消费者传递消息的速率。自动确认模式可以产生最佳的交付率。但是，在这两种情况下，已传送但尚未处理的消息的数量也将增加，从而增加了消费者的RAM消耗。 应谨慎使用具有无限预取功能的自动确认模式或手动确认模式。在没有确认的情况下消耗大量消息的消费者将导致他们所连接的节点上的内存消耗增长。找到合适的预取值是一个试验和错误的问题，并且会因工作负载而异。100到300范围内的值通常可提供最佳吞吐量，并且不会面临压倒性消费者的重大风险。较高的价值往往会影响收益递减规律。 预取值1是最保守的。它将显着降低吞吐量，特别是在消费者连接延迟较高的环境中。对于许多应用来说，更高的值是合适的和最佳的。 当消费者失败或失去连接时：自动重新排队使用手动确认时，任何未执行的传递（消息）将在关闭发生传递的通道（或连接）时自动重新排队。这包括客户端的TCP连接丢失，消费者应用程序（进程）故障和通道级协议异常（如下所述）。 请注意，检测不可用的客户端需要一段时间。 由于这种行为，消费者必须准备好处理重新发送，否则就要考虑到幂等性。Redeliveries将有一个特殊的布尔属性，即redeliver， 由RabbitMQ 设置为true。对于第一次交付，它将被设置为false。请注意，消费者可以接收先前传递给其他消费者的消息。 客户端错误：双重标记和未知标记如果客户多次确认相同的交付标签，RabbitMQ将导致通道错误，例如PRECONDITION_FAILED - 未知交货标签100。如果使用未知的传递标记，则将抛出相同的通道异常。 经纪人将抱怨“未知交付标签”的另一种情况是，在与接收交付的渠道不同的渠道上尝试确认（无论是正面还是负面）。交货必须在同一渠道上确认。 生产者确认网络可能以不太明显的方式失败，并且检测到某些故障需要时间。因此，将协议帧或一组帧（例如，已发布的消息）写入其套接字的客户端不能假定该消息已到达服务器并且已成功处理。它可能在途中丢失或其交付可能会显着延迟。 使用标准AMQP 0-9-1，保证消息不丢失的唯一方法是使用事务 - 使事务事务处理然后为每个消息或消息集发布，提交。在这种情况下，交易不必要地重量级并且将吞吐量减少250倍。为了解决这个问题，引入了确认机制。它模仿协议中已存在的消费者认可机制。 要启用确认，客户端将发送 confirm.select方法。根据是否 设置了无等待，代理可以使用confirm.select-ok进行响应。一旦在 频道上使用confirm.select方法，就会说它处于确认模式。交易渠道不能进入确认模式，一旦渠道处于确认模式，就不能进行交易。 一旦通道处于确认模式，代理和客户端都会计数消息（计数在第一个confirm.select上从1 开始）。然后，代理通过在同一通道上发送basic.ack来确认消息 。所述输送标签字段包含确认消息的序列号。代理还可以在basic.ack中设置多个字段，以指示已经处理了包括具有序列号的消息的所有消息。 发布的否定致谢在特殊情况下，当代理无法成功处理消息而不是basic.ack时，代理将发送basic.nack。在此背景下，该领域basic.nack的含义在对应部分相同basic.ack 和重新排队字段应该被忽略。通过nack一个或多个消息，经纪人表示它无法处理消息并拒绝对它们负责; 此时，客户端可以选择重新发布消息。 将频道置于确认模式后，将确认所有后续发布的消息或仅确认一次。不保证消息的确定时间。没有消息将被确认和nack’d。 只有在负责队列的Erlang进程中发生内部错误时，才会传递basic.nack。 什么时候发布的消息会被经纪人确认？对于不可路由的消息，代理将在交换验证消息不会路由到任何队列（发回一个空的队列列表）后发出确认。如果消息也作为必需消息发布，则basic.return将在basic.ack之前发送给客户端。负面确认（basic.nack）也是如此。 对于可路由消息，当所有队列都接受消息时，将发送basic.ack。对于路由到持久队列的持久性消息，这意味着持久化到磁盘。对于镜像队列，这意味着所有镜像都已接受该消息。 永久消息的Ack延迟在将消息持久保存到磁盘后，将发送路由到持久队列的持久消息的basic.ack。RabbitMQ消息存储在一段时间（几百毫秒）之后批量传递消息到磁盘，以最小化fsync（2）调用的数量，或者当队列空闲时。这意味着在恒定负载下，basic.ack的延迟 可以达到几百毫秒。为了提高吞吐量，强烈建议应用程序异步处理确认（作为流）或发布批量消息并等待未完成的确认。确切的API因客户端库而异。 订购Publisher确认的注意事项在大多数情况下，RabbitMQ将以与发布时相同的顺序向生产者确认消息（这适用于在单个频道上发布的消息）。但是，生产者确认是异步发出的，可以确认单个消息或一组消息。发出确认的确切时刻取决于消息的传递模式（持久性与瞬态）以及消息路由到的队列的属性（参见上文）。也就是说，可以认为不同的消息可以在不同时间进行确认。这意味着与其各自的消息相比，确认可以以不同的顺序到达。应用程序不应该尽可能依赖于确认的顺序。 生产者确认并保证交付如果代理在将所述消息写入磁盘之前崩溃，则代理会丢失持久消息。在某些情况下，这会导致经纪人以令人惊讶的方式行事。 例如，考虑这种情况： 客户端将持久性消息发布到持久队列 客户端使用队列中的消息（注意消息是持久的并且队列持久），但确认不活动， 经纪人去世并重新启动，并且 客户端重新连接并开始使用消息。 此时，客户端可以合理地假设该消息将再次传递。情况并非如此：重启导致代理丢失消息。为了保证持久性，客户应该使用确认。如果生产者的频道处于确认模式，则生产者将不会收到丢失消息的确认（因为该消息尚未写入磁盘）。 限制最大交货标签传递标记是64位长的值，因此其最大值是9223372036854775807.由于传递标记是按通道确定范围的，因此生产者或消费者在实践中不太可能运行此值。 参考 RabbitMQ教程 消费者致谢和生产者确认]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全框架：整合shiro-登录认证和权限管理]]></title>
    <url>%2F2018%2F09%2F30%2FJava%2F%E6%A1%86%E6%9E%B6%2F%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6%EF%BC%9Ashiro-%E7%99%BB%E5%BD%95%E8%AE%A4%E8%AF%81%E5%92%8C%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[解决的问题 shiro的介绍 shiro的权限验证和角色管理 如何在jsp中集成shiro 关于 Apache Shiro目的 想做一个对用户的登录进行权限的管理，保证安全性 Shiro基础知识Shiro需要的基础知识：权限管理 什么是权限管理？只要有用户参与的系统一般都要有权限管理，权限管理实现对用户访问系统的控制，按照安全规则或者安全策略控制用户可以访问而且只能访问自己被授权的资源。 对权限的管理又分为两大类别： 用户认证 用户授权 用户认证用户认证，用户去访问系统，系统要验证用户身份的合法性 最常用的用户身份验证的方法：1、用户名密码方式、2、指纹打卡机、3、基于证书验证方法。。系统验证用户身份合法，用户方可访问系统的资源。 举个例子： 当我们输入了自己的淘宝的账户和密码，才能打开购物车 用户认证的流程： 判断该资源能否不认证就能访问【登陆页面、首页】 如果该资源需要认证后才能访问，那么判断该访问者是否认证了 如果还没有认证，那么需要返回到【登陆页面】进行认证 认证通过后才能访问资源 从用户认证我们可以抽取出这么几个概念 subject主体：理解为用户,可能是程序，都要去访问系统的资源，系统需要对subject进行身份认证 principal身份信息：通常是唯一的，一个主体还有多个身份信息，但是都有一个主身份信息（primary principal）【我们可以选择身份证认证、学生证认证等等都是我们的身份信息】 credential凭证信息：可以是密码 、证书、指纹。 总结：主体在进行身份认证时需要提供身份信息和凭证信息。 用户授权用户授权，简单理解为访问控制，在用户认证通过后，系统对用户访问资源进行控制，用户具有资源的访问权限方可访问。 用户授权的流程 到达了用户授权环节，当然是需要用户认证之后了 用户访问资源，系统判断该用户是否有权限去操作该资源 如果该用户有权限才能够访问，如果没有权限就不能访问了 授权的过程可以简单理解为：主体认证之后，系统进行访问控制 subject必须具备资源的访问权限才可访问该资源.. 权限/许可(permission) ：针对资源的权限或许可，subject具有permission访问资源，如何访问/操作需要定义permission，权限比如：用户添加、用户修改、商品删除 资源可以分为两种 资源类型:系统的用户信息就是资源类型，相当于java类。 资源实例:系统中id为001的用户就是资源实例，相当于new的java对象。 权限管理模型一般地，我们可以抽取出这么几个模型： 主体（账号、密码） 资源（资源名称、访问地址） 权限（权限名称、资源id） 角色（角色名称） 角色和权限关系（角色id、权限id） 主体和角色关系（主体id、角色id） 通常企业开发中将资源和权限表合并为一张权限表，如下： 资源（资源名称、访问地址） 权限（权限名称、资源id） 合并为： 权限（权限名称、资源名称、资源访问地址） 分配权限用户需要分配相应的权限才可访问相应的资源。权限是对于资源的操作许可。 通常给用户分配资源权限需要将权限信息持久化，比如存储在关系数据库中。把用户信息、权限管理、用户分配的权限信息写到数据库（权限数据模型） 基于角色访问控制RBAC(role based access control)，基于角色的访问控制。 12345//如果该user是部门经理则可以访问if中的代码if(user.hasRole('部门经理'))&#123; //系统资源内容 //用户报表查看&#125; 角色针对人划分的，人作为用户在系统中属于活动内容，如果该 角色可以访问的资源出现变更，需要修改你的代码了， 1234if(user.hasRole('部门经理') || user.hasRole('总经理') )&#123; //系统资源内容 //用户报表查看&#125; 基于角色的访问控制是不利于系统维护(可扩展性不强)。 基于资源的访问控制RBAC(Resource based access control)，基于资源的访问控制。 资源在系统中是不变的，比如资源有：类中的方法，页面中的按钮。 123456对资源的访问需要具有permission权限，代码可以写为：if(user.hasPermission (&apos;用户报表查看（权限标识符）&apos;))&#123; //系统资源内容 //用户报表查看&#125; 建议使用基于资源的访问控制实现权限管理。 粗粒度和细粒度权限细粒度权限管理：对资源实例的权限管理。资源实例就资源类型的具体化，比如：用户id为001的修改连接，1110班的用户信息、行政部的员工。细粒度权限管理就是数据级别的权限管理。 粗粒度权限管理比如：超级管理员可以访问户添加页面、用户信息等全部页面。部门管理员可以访问用户信息页面包括 页面中所有按钮。 粗粒度和细粒度例子： 123456789系统有一个用户列表查询页面，对用户列表查询分权限，如果粗颗粒管理，张三和李四都有用户列表查询的权限，张三和李四都可以访问用户列表查询。进一步进行细颗粒管理，张三（行政部）和李四(开发部)只可以查询自己本部门的用户信息。张三只能查看行政部 的用户信息，李四只能查看开发部门的用户信息。细粒度权限管理就是数据级别的权限管理。 如何实现粗粒度权限管理？粗粒度权限管理比较容易将权限管理的代码抽取出来在系统架构级别统一处理。比如：通过springmvc的拦截器实现授权。 对细粒度权限管理在数据级别是没有共性可言，针对细粒度权限管理就是系统业务逻辑的一部分，在业务层去处理相对比较简单 比如：部门经理只查询本部门员工信息，在service接口提供一个部门id的参数，controller中根据当前用户的信息得到该 用户属于哪个部门，调用service时将部门id传入service，实现该用户只查询本部门的员工。 基于URL拦截基于url拦截的方式实现在实际开发中比较常用的一种方式。 对于web系统，通过filter过虑器实现url拦截，也可以springmvc的拦截器实现基于url的拦截。 使用权限管理框架实现对于粗粒度权限管理，建议使用优秀权限管理框架来实现，节省开发成功，提高开发效率。 shiro就是一个优秀权限管理框架。 回顾URL拦截我们在学习的路途上也是使用过几次URL对权限进行拦截的 当时我们做了权限的增删该查的管理系统，但是在权限表中是没有把资源添加进去，我们使用的是Map集合来进行替代的。http://blog.csdn.net/hon_3y/article/details/61926175 随后，我们学习了动态代理和注解，我们也做了一个基于注解的拦截 在Controller得到service对象的时候，service工厂返回的是一个动态代理对象回去 Controller拿着代理对象去调用方法，代理对象就会去解析该方法上是否有注解 如果有注解，那么就需要我们进行判断该主体是否认证了，如果认证了就判断该主体是否有权限 当我们解析出该主体的权限和我们注解的权限是一致的时候，才放行！ http://blog.csdn.net/hon_3y/article/details/70767050 流程: 认证的JavaBean我们之前认证都是放在默认的Javabean对象上的，现在既然我们准备学Shiro了，我们就得专业一点，弄一个专门存储认证信息的JavaBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 用户身份信息，存入session 由于tomcat将session会序列化在本地硬盘上，所以使用Serializable接口 * * @author Thinkpad * */public class ActiveUser implements java.io.Serializable &#123; private String userid;//用户id（主键） private String usercode;// 用户账号 private String username;// 用户名称 private List&lt;SysPermission&gt; menus;// 菜单 private List&lt;SysPermission&gt; permissions;// 权限 public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getUsercode() &#123; return usercode; &#125; public void setUsercode(String usercode) &#123; this.usercode = usercode; &#125; public String getUserid() &#123; return userid; &#125; public void setUserid(String userid) &#123; this.userid = userid; &#125; public List&lt;SysPermission&gt; getMenus() &#123; return menus; &#125; public void setMenus(List&lt;SysPermission&gt; menus) &#123; this.menus = menus; &#125; public List&lt;SysPermission&gt; getPermissions() &#123; return permissions; &#125; public void setPermissions(List&lt;SysPermission&gt; permissions) &#123; this.permissions = permissions; &#125; &#125; 认证的服务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Overridepublic ActiveUser authenticat(String userCode, String password) throws Exception &#123; /** 认证过程： 根据用户身份（账号）查询数据库，如果查询不到用户不存在 对输入的密码 和数据库密码 进行比对，如果一致，认证通过 */ //根据用户账号查询数据库 SysUser sysUser = this.findSysUserByUserCode(userCode); if(sysUser == null)&#123; //抛出异常 throw new CustomException("用户账号不存在"); &#125; //数据库密码 (md5密码 ) String password_db = sysUser.getPassword(); //对输入的密码 和数据库密码 进行比对，如果一致，认证通过 //对页面输入的密码 进行md5加密 String password_input_md5 = new MD5().getMD5ofStr(password); if(!password_input_md5.equalsIgnoreCase(password_db))&#123; //抛出异常 throw new CustomException("用户名或密码 错误"); &#125; //得到用户id String userid = sysUser.getId(); //根据用户id查询菜单 List&lt;SysPermission&gt; menus =this.findMenuListByUserId(userid); //根据用户id查询权限url List&lt;SysPermission&gt; permissions = this.findPermissionListByUserId(userid); //认证通过，返回用户身份信息 ActiveUser activeUser = new ActiveUser(); activeUser.setUserid(sysUser.getId()); activeUser.setUsercode(userCode); activeUser.setUsername(sysUser.getUsername());//用户名称 //放入权限范围的菜单和url activeUser.setMenus(menus); activeUser.setPermissions(permissions); return activeUser;&#125; Controller处理认证，如果身份认证成功，那么把认证信息存储在Session中 1234567891011121314151617181920@RequestMapping("/login")public String login(HttpSession session, String randomcode,String usercode,String password)throws Exception&#123; //校验验证码，防止恶性攻击 //从session获取正确验证码 String validateCode = (String) session.getAttribute("validateCode"); //输入的验证和session中的验证进行对比 if(!randomcode.equals(validateCode))&#123; //抛出异常 throw new CustomException("验证码输入错误"); &#125; //调用service校验用户账号和密码的正确性 ActiveUser activeUser = sysService.authenticat(usercode, password); //如果service校验通过，将用户身份记录到session session.setAttribute("activeUser", activeUser); //重定向到商品查询页面 return "redirect:/first.action";&#125; 身份认证拦截器 1234567891011121314151617181920212223242526272829303132//在执行handler之前来执行的//用于用户认证校验、用户权限校验@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //得到请求的url String url = request.getRequestURI(); //判断是否是公开 地址 //实际开发中需要公开 地址配置在配置文件中 //从配置中取逆名访问url List&lt;String&gt; open_urls = ResourcesUtil.gekeyList("anonymousURL"); //遍历公开 地址，如果是公开 地址则放行 for(String open_url:open_urls)&#123; if(url.indexOf(open_url)&gt;=0)&#123; //如果是公开 地址则放行 return true; &#125; &#125; //判断用户身份在session中是否存在 HttpSession session = request.getSession(); ActiveUser activeUser = (ActiveUser) session.getAttribute("activeUser"); //如果用户身份在session中存在放行 if(activeUser!=null)&#123; return true; &#125; //执行到这里拦截，跳转到登陆页面，用户进行身份认证 request.getRequestDispatcher("/WEB-INF/jsp/login.jsp").forward(request, response); //如果返回false表示拦截不继续执行handler，如果返回true表示放行 return false;&#125; 授权拦截器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//在执行handler之前来执行的//用于用户认证校验、用户权限校验@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //得到请求的url String url = request.getRequestURI(); //判断是否是公开 地址 //实际开发中需要公开 地址配置在配置文件中 //从配置中取逆名访问url List&lt;String&gt; open_urls = ResourcesUtil.gekeyList("anonymousURL"); //遍历公开 地址，如果是公开 地址则放行 for(String open_url:open_urls)&#123; if(url.indexOf(open_url)&gt;=0)&#123; //如果是公开 地址则放行 return true; &#125; &#125; //从配置文件中获取公共访问地址 List&lt;String&gt; common_urls = ResourcesUtil.gekeyList("commonURL"); //遍历公用 地址，如果是公用 地址则放行 for(String common_url:common_urls)&#123; if(url.indexOf(common_url)&gt;=0)&#123; //如果是公开 地址则放行 return true; &#125; &#125; //获取session HttpSession session = request.getSession(); ActiveUser activeUser = (ActiveUser) session.getAttribute("activeUser"); //从session中取权限范围的url List&lt;SysPermission&gt; permissions = activeUser.getPermissions(); for(SysPermission sysPermission:permissions)&#123; //权限的url String permission_url = sysPermission.getUrl(); if(url.indexOf(permission_url)&gt;=0)&#123; //如果是权限的url 地址则放行 return true; &#125; &#125; //执行到这里拦截，跳转到无权访问的提示页面 request.getRequestDispatcher("/WEB-INF/jsp/refuse.jsp").forward(request, response); //如果返回false表示拦截不继续执行handler，如果返回true表示放行 return false;&#125; 拦截器配置： 1234567891011121314&lt;!--拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- 用户认证拦截 --&gt; &lt;mvc:mapping path="/**" /&gt; &lt;bean class="cn.itcast.ssm.controller.interceptor.LoginInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;!-- 授权拦截 --&gt; &lt;mvc:mapping path="/**" /&gt; &lt;bean class="cn.itcast.ssm.controller.interceptor.PermissionInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 什么是Shiroshiro是apache的一个开源框架，是一个权限管理的框架，实现 用户认证、用户授权。 spring中有spring security (原名Acegi)，是一个权限框架，它和spring依赖过于紧密，没有shiro使用简单。shiro不依赖于spring，shiro不仅可以实现 web应用的权限管理，还可以实现c/s系统，分布式系统权限管理，shiro属于轻量框架，越来越多企业项目开始使用shiro。 Shiro架构： subject：主体，可以是用户也可以是程序，主体要访问系统，系统需要对主体进行认证、授权。 securityManager：安全管理器，主体进行认证和授权都 是通过securityManager进行。 authenticator：认证器，主体进行认证最终通过authenticator进行的。 authorizer：授权器，主体进行授权最终通过authorizer进行的。 sessionManager：web应用中一般是用web容器对session进行管理，shiro也提供一套session管理的方式。 SessionDao： 通过SessionDao管理session数据，针对个性化的session数据存储需要使用sessionDao。 cache Manager：缓存管理器，主要对session和授权数据进行缓存，比如将授权数据通过cacheManager进行缓存管理，和ehcache整合对缓存数据进行管理。 realm：域，领域，相当于数据源，通过realm存取认证、授权相关数据。 cryptography：密码管理，提供了一套加密/解密的组件，方便开发。比如提供常用的散列、加/解密等功能。 比如md5散列算法。 为什么使用Shiro我们在使用URL拦截的时候，要将所有的URL都配置起来，繁琐、不易维护 而我们的Shiro实现系统的权限管理，有效提高开发效率，从而降低开发成本。 Shiro认证导入jar包我们使用的是Maven的坐标就行了 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-quartz&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 当然了，我们也可以把Shiro相关的jar包全部导入进去 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-all&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; Shiro认证流程 通过配置文件创建工厂 12345678910111213141516171819202122232425262728293031323334353637383940414243// 用户登陆和退出@Testpublic void testLoginAndLogout() &#123; // 创建securityManager工厂，通过ini配置文件创建securityManager工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory( "classpath:shiro-first.ini"); // 创建SecurityManager SecurityManager securityManager = factory.getInstance(); // 将securityManager设置当前的运行环境中 SecurityUtils.setSecurityManager(securityManager); // 从SecurityUtils里边创建一个subject Subject subject = SecurityUtils.getSubject(); // 在认证提交前准备token（令牌） // 这里的账号和密码 将来是由用户输入进去 UsernamePasswordToken token = new UsernamePasswordToken("zhangsan", "111111"); try &#123; // 执行认证提交 subject.login(token); &#125; catch (AuthenticationException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; // 是否认证通过 boolean isAuthenticated = subject.isAuthenticated(); System.out.println("是否认证通过：" + isAuthenticated); // 退出操作 subject.logout(); // 是否认证通过 isAuthenticated = subject.isAuthenticated(); System.out.println("是否认证通过：" + isAuthenticated);&#125; 小结 ModularRealmAuthenticator作用进行认证，需要调用realm查询用户信息（在数据库中存在用户信息） ModularRealmAuthenticator进行密码对比（认证过程）。 realm：需要根据token中的身份信息去查询数据库（入门程序使用ini配置文件），如果查到用户返回认证信息，如果查询不到返回null。 自定义realm从第一个认证程序我们可以看见，我们所说的流程，是认证器去找realm去查询我们相对应的数据。而默认的realm是直接去与配置文件来比对的，一般地，我们在开发中都是让realm去数据库中比对。因此，我们需要自定义realm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class CustomRealm extends AuthorizingRealm &#123; // 设置realm的名称 @Override public void setName(String name) &#123; super.setName("customRealm"); &#125; // 用于认证 @Override protected AuthenticationInfo doGetAuthenticationInfo( AuthenticationToken token) throws AuthenticationException &#123; // token是用户输入的 // 第一步从token中取出身份信息 String userCode = (String) token.getPrincipal(); // 第二步：根据用户输入的userCode从数据库查询 // .... // 如果查询不到返回null //数据库中用户账号是zhangsansan /*if(!userCode.equals("zhangsansan"))&#123;// return null; &#125;*/ // 模拟从数据库查询到密码 String password = "111112"; // 如果查询到返回认证信息AuthenticationInfo SimpleAuthenticationInfo simpleAuthenticationInfo = new SimpleAuthenticationInfo( userCode, password, this.getName()); return simpleAuthenticationInfo; &#125; // 用于授权 @Override protected AuthorizationInfo doGetAuthorizationInfo( PrincipalCollection principals) &#123; // TODO Auto-generated method stub return null; &#125;&#125; 配置realm需要在shiro-realm.ini配置realm注入到securityManager中。 测试自定义realm同上边的入门程序，需要更改ini配置文件路径： 123同上边的入门程序，需要更改ini配置文件路径：Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory( "classpath:shiro-realm.ini"); 散列算法我们如果知道md5，我们就会知道md5是不可逆的，但是如果设置了一些安全性比较低的密码：111111…即时是不可逆的，但还是可以通过暴力算法来得到md5对应的明文… 建议对md5进行散列时加salt（盐），进行加密相当 于对原始密码+盐进行散列。\ 正常使用时散列方法： 在程序中对原始密码+盐进行散列，将散列值存储到数据库中，并且还要将盐也要存储在数据库中。 测试： 12345678910111213141516171819202122232425262728public class MD5Test &#123; public static void main(String[] args) &#123; //原始 密码 String source = "111111"; //盐 String salt = "qwerty"; //散列次数 int hashIterations = 2; //上边散列1次：f3694f162729b7d0254c6e40260bf15c //上边散列2次：36f2dfa24d0a9fa97276abbe13e596fc //构造方法中： //第一个参数：明文，原始密码 //第二个参数：盐，通过使用随机数 //第三个参数：散列的次数，比如散列两次，相当 于md5(md5('')) Md5Hash md5Hash = new Md5Hash(source, salt, hashIterations); String password_md5 = md5Hash.toString(); System.out.println(password_md5); //第一个参数：散列算法 SimpleHash simpleHash = new SimpleHash("md5", source, salt, hashIterations); System.out.println(simpleHash.toString()); &#125;&#125; 自定义realm支持md5自定义realm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class CustomRealmMd5 extends AuthorizingRealm &#123; // 设置realm的名称 @Override public void setName(String name) &#123; super.setName("customRealmMd5"); &#125; // 用于认证 @Override protected AuthenticationInfo doGetAuthenticationInfo( AuthenticationToken token) throws AuthenticationException &#123; // token是用户输入的 // 第一步从token中取出身份信息 String userCode = (String) token.getPrincipal(); // 第二步：根据用户输入的userCode从数据库查询 // .... // 如果查询不到返回null // 数据库中用户账号是zhangsansan /* * if(!userCode.equals("zhangsansan"))&#123;// return null; &#125; */ // 模拟从数据库查询到密码,散列值 String password = "f3694f162729b7d0254c6e40260bf15c"; // 从数据库获取salt String salt = "qwerty"; //上边散列值和盐对应的明文：111111 // 如果查询到返回认证信息AuthenticationInfo SimpleAuthenticationInfo simpleAuthenticationInfo = new SimpleAuthenticationInfo( userCode, password, ByteSource.Util.bytes(salt), this.getName()); return simpleAuthenticationInfo; &#125; // 用于授权 @Override protected AuthorizationInfo doGetAuthorizationInfo( PrincipalCollection principals) &#123; // TODO Auto-generated method stub return null; &#125;&#125; 配置文件： 测试： 123456789101112131415161718192021222324252627282930313233343536// 自定义realm实现散列值匹配 @Test public void testCustomRealmMd5() &#123; // 创建securityManager工厂，通过ini配置文件创建securityManager工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory( "classpath:shiro-realm-md5.ini"); // 创建SecurityManager SecurityManager securityManager = factory.getInstance(); // 将securityManager设置当前的运行环境中 SecurityUtils.setSecurityManager(securityManager); // 从SecurityUtils里边创建一个subject Subject subject = SecurityUtils.getSubject(); // 在认证提交前准备token（令牌） // 这里的账号和密码 将来是由用户输入进去 UsernamePasswordToken token = new UsernamePasswordToken("zhangsan", "222222"); try &#123; // 执行认证提交 subject.login(token); &#125; catch (AuthenticationException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; // 是否认证通过 boolean isAuthenticated = subject.isAuthenticated(); System.out.println("是否认证通过：" + isAuthenticated); &#125; Shiro介绍Apache Shiro是一个功能强大、灵活的，开源的安全框架。它可以干净利落地处理身份验证、授权、企业会话管理和加密。 功能 验证用户身份 用户访问权限控制，比如： 判断用户是否分配了一定的安全角色。 判断用户是否被授予完成某个操作的权限 在非 web 或 EJB 容器的环境下可以任意使用Session API 可以响应认证、访问控制，或者 Session 生命周期中发生的事件 可将一个或以上用户安全数据源数据组合成一个复合的用户 “view”(视图) 支持单点登录(SSO)功能 支持提供“Remember Me”服务，获取用户关联信息而无需登录··· 等等——都集成到一个有凝聚力的易于使用的API。 Shiro 致力在所有应用环境下实现上述功能，小到命令行应用程序，大到企业应用中，而且不需要借助第三方框架、容器、应用服务器等。当然 Shiro 的目的是尽量的融入到这样的应用环境中去，但也可以在它们之外的任何环境下开箱即用。 shiro的核心管理对象 ShiroFilterFactory：Shiro过滤器工厂类，具体的实现类是：ShiroFilterFactoryBean，此实现类是依赖于SecurityManager安全管理器的。 SecurityManager：Shiro的安全管理器，主要是身份认证的管理，缓存管理，Cookie管理，所以在时机开发中主要是和SecurityManager进行打交道的，ShiroFilterFacotory只要配置好Filter就可以了。 AccessControlFilter：访问控制过滤器，对请求进行拦截处理，在这里我们可以进行一些基本的判断以及数据的基本处理，然后生成一个AuthenticationToken，然后委托给Realm进行身份的验证和权限的验证。 Ream：用于身份信息权限的验证。 Apache Shiro Features 特性Apache Shiro是一个全面的、蕴含丰富功能的安全框架。下图为描述Shiro功能的框架图： Authentication（认证）, Authorization（授权）, Session Management（会话管理）, Cryptography（加密）被 Shiro 框架的开发团队称之为应用安全的四大基石。那么就让我们来看看它们吧： Authentication（认证）：用户身份识别，通常被称为用户“登录” Authorization（授权）：访问控制。比如某个用户是否具有某个操作的使用权限。 Session Management（会话管理）：特定于用户的会话管理,甚至在非web 或 EJB 应用程序。 Cryptography（加密）：在对数据源使用加密算法加密的同时，保证易于使用。 还有其他的功能来支持和加强这些不同应用环境下安全领域的关注点。特别是对以下的功能支持： Web支持：Shiro 提供的 web 支持 api ，可以很轻松的保护 web 应用程序的安全。 缓存：缓存是 Apache Shiro 保证安全操作快速、高效的重要手段。 并发：Apache Shiro 支持多线程应用程序的并发特性。 测试：支持单元测试和集成测试，确保代码和预想的一样安全。 “Run As”：这个功能允许用户假设另一个用户的身份(在许可的前提下)。 “Remember Me”：跨 session 记录用户的身份，只有在强制需要时才需要登录。 注意： Shiro不会去维护用户、维护权限，这些需要我们自己去设计/提供，然后通过相应的接口注入给Shiro High-Level Overview 高级概述在概念层，Shiro 架构包含三个主要的理念：Subject,SecurityManager和 Realm。下面的图展示了这些组件如何相互作用，我们将在下面依次对其进行描述。 Subject：当前用户，Subject 可以是一个人，但也可以是第三方服务、守护进程帐户、时钟守护任务或者其它–当前和软件交互的任何事件。 SecurityManager：管理所有Subject，SecurityManager 是 Shiro 架构的核心，配合内部安全组件共同组成安全伞。 Realms：用于进行权限信息的验证，我们自己实现。Realm 本质上是一个特定的安全 DAO：它封装与数据源连接的细节，得到Shiro 所需的相关的数据。在配置 Shiro 的时候，你必须指定至少一个Realm 来实现认证（authentication）和/或授权（authorization）。 我们需要实现Realms的Authentication 和 Authorization。其中 Authentication 是用来验证用户身份，Authorization 是授权访问控制，用于对用户进行的操作授权，证明该用户是否允许进行当前操作，如访问某个链接，某个资源文件等。 快速上手基础信息pom包依赖1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 重点是 shiro-spring包 配置文件123456789101112131415161718192021spring:datasource: url: jdbc:mysql://localhost:3306/test username: root password: root driver-class-name: com.mysql.jdbc.Driverjpa: database: mysql show-sql: true hibernate: ddl-auto: update naming: strategy: org.hibernate.cfg.DefaultComponentSafeNamingStrategy properties: hibernate: dialect: org.hibernate.dialect.MySQL5Dialectthymeleaf: cache: false mode: LEGACYHTML5 页面我们新建了六个页面用来测试： index.html ：首页 login.html ：登录页 userInfo.html ： 用户信息页面 userInfoAdd.html ：添加用户页面 userInfoDel.html ：删除用户页面 403.html ： 没有权限的页面 除过登录页面其它都很简单，大概如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;index&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; RBACRBAC 是基于角色的访问控制（Role-Based Access Control ）在 RBAC 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。这样管理都是层级相互依赖的，权限赋予给角色，而把角色又赋予用户，这样的权限设计很清楚，管理起来很方便。 采用jpa技术来自动生成基础表格，对应的entity如下： 用户信息1234567891011121314151617@Entitypublic class UserInfo implements Serializable &#123; @Id @GeneratedValue private Integer uid; @Column(unique =true) private String username;//帐号 private String name;//名称（昵称或者真实姓名，不同系统不同定义） private String password; //密码; private String salt;//加密密码的盐 private byte state;//用户状态,0:创建未认证（比如没有激活，没有输入验证码等等）--等待验证的用户 , 1:正常状态,2：用户被锁定. @ManyToMany(fetch= FetchType.EAGER)//立即从数据库中进行加载数据; @JoinTable(name = "SysUserRole", joinColumns = &#123; @JoinColumn(name = "uid") &#125;, inverseJoinColumns =&#123;@JoinColumn(name = "roleId") &#125;) private List&lt;SysRole&gt; roleList;// 一个用户具有多个角色 // 省略 get set 方法&#125; 角色信息1234567891011121314151617181920@Entitypublic class SysRole &#123; @Id@GeneratedValue private Integer id; // 编号 private String role; // 角色标识程序中判断使用,如"admin",这个是唯一的: private String description; // 角色描述,UI界面显示使用 private Boolean available = Boolean.FALSE; // 是否可用,如果不可用将不会添加给用户 //角色 -- 权限关系：多对多关系; @ManyToMany(fetch= FetchType.EAGER) @JoinTable(name="SysRolePermission",joinColumns=&#123;@JoinColumn(name="roleId")&#125;,inverseJoinColumns=&#123;@JoinColumn(name="permissionId")&#125;) private List&lt;SysPermission&gt; permissions; // 用户 - 角色关系定义; @ManyToMany @JoinTable(name="SysUserRole",joinColumns=&#123;@JoinColumn(name="roleId")&#125;,inverseJoinColumns=&#123;@JoinColumn(name="uid")&#125;) private List&lt;UserInfo&gt; userInfos;// 一个角色对应多个用户 // 省略 get set 方法&#125; 权限信息123456789101112131415161718@Entitypublic class SysPermission implements Serializable &#123; @Id@GeneratedValue private Integer id;//主键. private String name;//名称. @Column(columnDefinition="enum('menu','button')") private String resourceType;//资源类型，[menu|button] private String url;//资源路径. private String permission; //权限字符串,menu例子：role:*，button例子：role:create,role:update,role:delete,role:view private Long parentId; //父编号 private String parentIds; //父编号列表 private Boolean available = Boolean.FALSE; @ManyToMany @JoinTable(name="SysRolePermission",joinColumns=&#123;@JoinColumn(name="permissionId")&#125;,inverseJoinColumns=&#123;@JoinColumn(name="roleId")&#125;) private List&lt;SysRole&gt; roles; // 省略 get set 方法&#125; 根据以上的代码会自动生成user_info（用户信息表）、sys_role（角色表）、sys_permission（权限表）、sys_user_role（用户角色表）、sys_role_permission（角色权限表）这五张表，为了方便测试我们给这五张表插入一些初始化数据： 123456789101112INSERT INTO `user_info` (`uid`,`username`,`name`,`password`,`salt`,`state`) VALUES ('1', 'admin', '管理员', 'd3c59d25033dbf980d29554025c23a75', '8d78869f470951332959580424d4bf4f', 0);INSERT INTO `sys_permission` (`id`,`available`,`name`,`parent_id`,`parent_ids`,`permission`,`resource_type`,`url`) VALUES (1,0,'用户管理',0,'0/','userInfo:view','menu','userInfo/userList');INSERT INTO `sys_permission` (`id`,`available`,`name`,`parent_id`,`parent_ids`,`permission`,`resource_type`,`url`) VALUES (2,0,'用户添加',1,'0/1','userInfo:add','button','userInfo/userAdd');INSERT INTO `sys_permission` (`id`,`available`,`name`,`parent_id`,`parent_ids`,`permission`,`resource_type`,`url`) VALUES (3,0,'用户删除',1,'0/1','userInfo:del','button','userInfo/userDel');INSERT INTO `sys_role` (`id`,`available`,`description`,`role`) VALUES (1,0,'管理员','admin');INSERT INTO `sys_role` (`id`,`available`,`description`,`role`) VALUES (2,0,'VIP会员','vip');INSERT INTO `sys_role` (`id`,`available`,`description`,`role`) VALUES (3,1,'test','test');INSERT INTO `sys_role_permission` VALUES ('1', '1');INSERT INTO `sys_role_permission` (`permission_id`,`role_id`) VALUES (1,1);INSERT INTO `sys_role_permission` (`permission_id`,`role_id`) VALUES (2,1);INSERT INTO `sys_role_permission` (`permission_id`,`role_id`) VALUES (3,2);INSERT INTO `sys_user_role` (`role_id`,`uid`) VALUES (1,1); Shiro 配置首先要配置的是ShiroConfig类，Apache Shiro 核心通过 Filter 来实现，就好像SpringMvc 通过DispachServlet 来主控制一样。 既然是使用 Filter 一般也就能猜到，是通过URL规则来进行过滤和权限校验，所以我们需要定义一系列关于URL的规则和访问权限。 ShiroConfig123456789101112131415161718192021222324252627282930313233343536373839404142@Configurationpublic class ShiroConfig &#123; @Bean public ShiroFilterFactoryBean shirFilter(SecurityManager securityManager) &#123; System.out.println("ShiroConfiguration.shirFilter()"); ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); //拦截器. Map&lt;String,String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;String,String&gt;(); // 配置不会被拦截的链接 顺序判断 filterChainDefinitionMap.put("/static/**", "anon"); //配置退出 过滤器,其中的具体的退出代码Shiro已经替我们实现了 filterChainDefinitionMap.put("/logout", "logout"); //&lt;!-- 过滤链定义，从上向下顺序执行，一般将/**放在最为下边 --&gt;:这是一个坑呢，一不小心代码就不好使了; //&lt;!-- authc:所有url都必须认证通过才可以访问; anon:所有url都都可以匿名访问--&gt; filterChainDefinitionMap.put("/**", "authc"); // 如果不设置默认会自动寻找Web工程根目录下的"/login.jsp"页面 shiroFilterFactoryBean.setLoginUrl("/login"); // 登录成功后要跳转的链接 shiroFilterFactoryBean.setSuccessUrl("/index"); //未授权界面; shiroFilterFactoryBean.setUnauthorizedUrl("/403"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean;&#125;@Beanpublic MyShiroRealm myShiroRealm()&#123; MyShiroRealm myShiroRealm = new MyShiroRealm(); return myShiroRealm;&#125;@Beanpublic SecurityManager securityManager()&#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); return securityManager;&#125;&#125; Filter Chain定义说明： 一个URL可以配置多个Filter，使用逗号分隔 当设置多个过滤器时，全部验证通过，才视为通过 部分过滤器可指定参数，如perms，roles Shiro内置的FilterChain Filter Name Class anon org.apache.shiro.web.filter.authc.AnonymousFilter authc org.apache.shiro.web.filter.authc.FormAuthenticationFilter authcBasic org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter perms org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter port org.apache.shiro.web.filter.authz.PortFilter rest org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter roles org.apache.shiro.web.filter.authz.RolesAuthorizationFilter ssl org.apache.shiro.web.filter.authz.SslFilter user org.apache.shiro.web.filter.authc.UserFilter anon:所有url都都可以匿名访问 authc: 需要认证才能进行访问 user:配置记住我或认证通过可以访问 登录认证实现在认证、授权内部实现机制中都有提到，最终处理都将交给Real进行处理。因为在Shiro中，最终是通过Realm来获取应用程序中的用户、角色及权限信息的。通常情况下，在Realm中会直接从我们的数据源中获取Shiro需要的验证信息。可以说，Realm是专用于安全框架的DAO. Shiro的认证过程最终会交由Realm执行，这时会调用Realm的getAuthenticationInfo(token)方法。 该方法主要执行以下操作: 检查提交的进行认证的令牌信息 根据令牌信息从数据源(通常为数据库)中获取用户信息 对用户信息进行匹配验证。 验证通过将返回一个封装了用户信息的AuthenticationInfo实例。 验证失败则抛出AuthenticationException异常信息。 而在我们的应用程序中要做的就是自定义一个Realm类，继承AuthorizingRealm抽象类，重载doGetAuthenticationInfo()，重写获取用户信息的方法。 doGetAuthenticationInfo的重写 12345678910111213141516171819202122@Overrideprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; System.out.println("MyShiroRealm.doGetAuthenticationInfo()"); //获取用户的输入的账号. String username = (String)token.getPrincipal(); System.out.println(token.getCredentials()); //通过username从数据库中查找 User对象，如果找到，没找到. //实际项目中，这里可以根据实际情况做缓存，如果不做，Shiro自己也是有时间间隔机制，2分钟内不会重复执行该方法 UserInfo userInfo = userInfoService.findByUsername(username); System.out.println("-----&gt;&gt;userInfo="+userInfo); if(userInfo == null)&#123; return null; &#125; SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo( userInfo, //用户名 userInfo.getPassword(), //密码 ByteSource.Util.bytes(userInfo.getCredentialsSalt()),//salt=username+salt getName() //realm name ); return authenticationInfo;&#125; 链接权限的实现shiro的权限授权是通过继承AuthorizingRealm抽象类，重载doGetAuthorizationInfo();当访问到页面的时候，链接配置了相应的权限或者shiro标签才会执行此方法否则不会执行，所以如果只是简单的身份认证没有权限的控制的话，那么这个方法可以不进行实现，直接返回null即可。在这个方法中主要是使用类：SimpleAuthorizationInfo进行角色的添加和权限的添加。 12345678910111213@Overrideprotected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; System.out.println("权限配置--&gt;MyShiroRealm.doGetAuthorizationInfo()"); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); UserInfo userInfo = (UserInfo)principals.getPrimaryPrincipal(); for(SysRole role:userInfo.getRoleList())&#123; authorizationInfo.addRole(role.getRole()); for(SysPermission p:role.getPermissions())&#123; authorizationInfo.addStringPermission(p.getPermission()); &#125; &#125; return authorizationInfo;&#125; 当然也可以添加set集合：roles是从数据库查询的当前用户的角色，stringPermissions是从数据库查询的当前用户对应的权限 12authorizationInfo.setRoles(roles);authorizationInfo.setStringPermissions(stringPermissions); 就是说如果在shiro配置文件中添加了filterChainDefinitionMap.put(“/add”, “perms[权限添加]”);就说明访问/add这个链接必须要有“权限添加”这个权限才可以访问，如果在shiro配置文件中添加了filterChainDefinitionMap.put(“/add”, “roles[100002]，perms[权限添加]”);就说明访问/add这个链接必须要有“权限添加”这个权限和具有“100002”这个角色才可以访问。 登录实现登录过程其实只是处理异常的相关信息，具体的登录验证交给shiro来处理 @RequestMapping(&quot;/login&quot;) public String login(HttpServletRequest request, Map&lt;String, Object&gt; map) throws Exception{ System.out.println(&quot;HomeController.login()&quot;); // 登录失败从request中获取shiro处理的异常信息。 // shiroLoginFailure:就是shiro异常类的全类名. String exception = (String) request.getAttribute(&quot;shiroLoginFailure&quot;); System.out.println(&quot;exception=&quot; + exception); String msg = &quot;&quot;; if (exception != null) { if (UnknownAccountException.class.getName().equals(exception)) { System.out.println(&quot;UnknownAccountException -- &gt; 账号不存在：&quot;); msg = &quot;UnknownAccountException -- &gt; 账号不存在：&quot;; } else if (IncorrectCredentialsException.class.getName().equals(exception)) { System.out.println(&quot;IncorrectCredentialsException -- &gt; 密码不正确：&quot;); msg = &quot;IncorrectCredentialsException -- &gt; 密码不正确：&quot;; } else if (&quot;kaptchaValidateFailed&quot;.equals(exception)) { System.out.println(&quot;kaptchaValidateFailed -- &gt; 验证码错误&quot;); msg = &quot;kaptchaValidateFailed -- &gt; 验证码错误&quot;; } else { msg = &quot;else &gt;&gt; &quot;+exception; System.out.println(&quot;else -- &gt;&quot; + exception); } } map.put(&quot;msg&quot;, msg); // 此方法不处理登录成功,由shiro进行处理 return &quot;/login&quot;; }其它dao层和service的代码就不贴出来了大家直接看代码。 测试 编写好后就可以启动程序，访问http://localhost:8080/userInfo/userList页面，由于没有登录就会跳转到http://localhost:8080/login页面。登录之后就会跳转到index页面，登录后，直接在浏览器中输入http://localhost:8080/userInfo/userList访问就会看到用户信息。上面这些操作时候触发MyShiroRealm.doGetAuthenticationInfo()这个方法，也就是登录认证的方法。 登录admin账户，访问：http://127.0.0.1:8080/userInfo/userAdd显示用户添加界面，访问http://127.0.0.1:8080/userInfo/userDel显示403没有权限。上面这些操作时候触发MyShiroRealm.doGetAuthorizationInfo()这个方面，也就是权限校验的方法。 修改admin不同的权限进行测试 shiro很强大，这仅仅是完成了登录认证和权限管理这两个功能，更多内容以后有时间再做探讨。 个人实战踩坑 关于出现Whitelabel Error Page(空指针页面),原因是自己没有考虑到返回值的问题,原先的页面为了api考虑,使用的是@RestController,也就是返回JSON,但是在一个需要跳转页面的情况下是不合适的,此处应该使用@Controller 总结 用户认证和用户授权是Shiro的基础，用户认证其实上就是登陆操作、用户授权实际上就是对资源拦截的操作。 权限管理的模型一般我们都将资源放在权限表中进行管理起来。 我们可以基于角色拦截，也可以基于资源拦截。要是基于角色拦截的话，那么如果角色的权限发生变化了，那就需要修改代码了。推荐使用基于资源进行拦截 这次URL拦截，我们使用一个JavaBean来封装所有的认证信息。当用户登陆了之后，我们就把用户对菜单栏的访问、对资源的访问权限都封装到该JavaBean中 当使用拦截器进行用户认证的时候，我们只要判断Session域有没有JavaBen对象即可了。 当时候拦截器进行用户授权的时候，我们要判断JavaBean中的权限是否能够访问该资源。 以前URL拦截的方式需要把所有的URL都在数据库进行管理。非常麻烦，不易维护。 我们希望Shiro去认证的时候是通过realm去数据库查询数据的。而我们reaml默认是查询配置文件的数据的。 因此，我们需要自定义reaml，使得它是去数据库查询数据。只要继承AuthorizingRealm类就行了。 当然了，自定义后的reaml也需要在配置文件中写上我们的自定义reaml的位置的。 散列算法就是为了让密码不被别人给破解。我们可对原始的密码加盐再进行散列，这就加大了破解的难度了。 自定义的reaml也是支持散列算法的，相同的，还是需要我们在配置文件中配置一下就好了。 参考 springboot(十四)：springboot整合shiro-登录认证和权限管理 作者示例代码 Spring Boot Shiro权限管理【从零开始学Spring Boot】 Shiro入门这篇就够了【Shiro的基础知识、回顾URL拦截】 Shiro权限管理详解【面试+工作】]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOs7初玩]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2FCentOs7%E5%88%9D%E7%8E%A9%2F</url>
    <content type="text"><![CDATA[参考 在CentOS Linux 7.5上安装MySQL 阿里云新手课堂 Linux_window与linux之间文件互传，上传下载 Linux下SSH远程连接断开后让程序继续运行解决办法 Linux基础–Linux Tools Quick Tutorial]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>start</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL：SQL]]></title>
    <url>%2F2018%2F09%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%EF%BC%9ASQL%2F</url>
    <content type="text"><![CDATA[检索对于MySQL可以配置是否区分大小写 123456select [all | distinct] &lt;目标列表达式&gt; [,&lt;目标列表达式||计算字段&gt;]... from &lt;表名或视图名&gt; [,&lt;表名或视图名&gt;]... [where &lt;条件表达式&gt; [AND | OR] [表达式]] [group by &lt;列名&gt; [having &lt;表达式&gt;]] [order by &lt;列名&gt; [ASC | DESC] [,&lt;列名&gt; [ASC |DESC]]] [limit &lt;数量&gt;] select 表示是一个查询操作 [all | distinct] distinct。消除重复行，它会应用于所有的列，而不仅仅时前置它的列。 all，缺省值，保留所有行 &lt;目标列表达式&gt; 查询若干列：则指明列名，也可使用列的全限定名 查询所有列：* 查询经过计算的值 算术表达式 字符串常量 函数等 select name, 1-age, &#39;testString&#39;, count(*) from &lt;表名或视图名&gt; [,&lt;表名或视图名&gt;] 多表查询 where &lt;条件表达式&gt; 条件表达式 条件操作符 IN 详情查看后续 group by 对查询结果分组：按一列或多列取值相等分组，分组过后集函数只作用于一个组而不是整个查询结果 having 对组进行筛选 order by ASC升序、DESC降序 对多列排序时，则会优先按写在前面的列排序 limit。限制返回的行数 limit 1,1则会从第2行开始返回1行（MySQL从第0行开始） limit 4 offset 3意为从行3开始取4行 简单搜索单个列：select prod_name from products 多个列：select prod_id, prod_name from products即利用,分隔列名。 所有列：select * from products 检索不同的列：select distinct vend_id from products返回vend_id不同的列。 限制结果：select prod_name from products limit 5 使用完全限定的列名：select products.prod_name from products 使用完全限定的表名：select products.prod_name from crashcourse.products 创建计算字段存储在数据库表中的数据一般不是应用程序所需要的格式： 如果想在应该字段中既显示公司名，又显示公司地址，但这两个信息一般包含在不同的表列中 城市、州、邮政编码存储在不同的列中，但邮件标签打印程序需要将它们作为应该恰当格式的字段检索出来 列数据是大小写混合的，但是报表程序需要所有数据大写 订单表存储物品的价格与数量，为打印发票，需要总价 需要根据表数据进行总数、平均数计算或其他计算 计算字段用于直接从数据库检索出转换、计算或格式化过的数据； 字段 基本上与列的意思相同，经常互换使用。数据库列一般称为列，而术语字段通常用在计算字段的连接。 拼接字段 拼接：将值联结到一起构成单个值。使用Concat()连接 123select concat(vend_name,'(',vebd_country,')') frim vendors order by vend_name Concat()拼接穿，将多个串连接起来形成一个较长的串。 计算 123select quantity * item_price as expanded_price frim orderitems where order_num = 2005 别名别名是一个字段或值的替换名，用AS赋值。有时候也称为导出列。 123select concat(vend_name,'(',vebd_country,')') AS vend_title frim vendors order by vend_name order by以单列排序：select prod_name from products order by prod_name 以多列排序：select prod_id from products order by prod_price, prod_name 按降序排序：select prod_id from products order by prod_price DESC, prod_name where过滤单个值：select prod_name from products where prod_name= &#39;2.5&#39;即对串使用’’ 范围值检查：select prod_name from products where prod_price between 5 and 10 空值检查：select prod_name from products where prod_price is NULL 操作符条件操作符 =： &lt;&gt;：不等于 !=：不等于 &lt;： &lt;=： &gt;： &gt;=： BETWEEN：指定的两个值之间 IN IN操作符用来指定条件范围，范围内的每个条件都可以匹配， select prod_name from products where vend_id IN (1002,1003) 对于长的合法选项清单，IN操作符更加清楚只管，计算次序更容易管理 IN一般比OR操作符更快，并且可以包含其他的SELECT语句 select prod_name from products where vend_id IN (SELECT id from vend) NOT NOT操作符用于否定它之后所跟的任何条件。并只支持对IN、BETWEEN和EXISTS取反。 select prod_name from products where vend_id NOT IN (1002,1003) 组合过滤即使用多个WHERE子句。以OR或AND的方式使用。 对多列进行过滤：select prod_name from products where prod_orice = 10 AND vend_id = 1003 检索匹配任一条件：``select prod_name from products where prod_orice = 10 OR vend_id = 1003` AND与OR的计算次序： SQL在处理OR之前优先会处理AND操作符。即AND操作符的优先级更高 select prod_name from products where vend_id = 1002 OR vend_id = 1003 AND prod_price&gt;=10 该语句等价于：select prod_name from products where vend_id = 1002 OR (vend_id = 1003 AND prod_price&gt;=10) 即当AND与OR混用时，一定要使用() 通配符过滤通配符用来匹配值的一部分的特殊字符。通配符本身实际上时SQL的WHERE子句中有特殊含义的字符 %百分号 %表示任意字符出现任意次数。但是不匹配NULL 搜索以jet开头的词：select prod_name from products where prod_name like &#39;jet%&#39; _下划线 匹配任意字符出现单次 select prod_name from products where prod_name like &#39;_ ton an&#39; 通配符的技巧 如果其他操作符能够达到相同目的，应该使用其他操作符 搜索时除非必要，否则不要将通配符放在开始处 仔细注意通配符的位置 正则表达式使用REGEXP select prod_name from products where prod_name regexp &#39;1000&#39; order by prod_name group by分组数据，count等函数只会对其对应的分组奏效 123select vend_id, count(*) as num_prods from products group by vend_id group by子句可以包含任意数目的列，这使得能够对分组进行嵌套，为数据分组提供更细致的控制 如果在group by中嵌套了分组，数据将在最后规定的分组上进行汇总，即指定的所有列都一起计算，因此不能从个别的列取回数据 group by子句中列出的每个列都必须时检索列或有效的表达式 如果分组列中具有NULL，则NULL将作为一个分组返回 group必须在where之后，order by之前。 Having过滤分组，规定包括哪些分组，排除哪些分组。即与where不同，where过滤行，having过滤分组。 例如想要列出至少有两个订单的所有顾客，因此需要基于组过滤，而不是行过滤。 123select cust_id from orders group by cust_id having count(*)&gt;=2; 子查询嵌套在其他查询中的查询。在子查询当中，总是由内向外处理。 1234select cust_id from orders where order_num in ( select order_num from orderitems where prod_id = 'TNT2') 列必须匹配：where子句当中使用子查询，则应该保证select语句具有与where子句中相同数目的列，通常子查询将返回单个列并与单个列匹配，但如果需要也可以使用多个列 子查询也可以使用=、&lt;&gt;等 子查询并不总是执行这种类型的数据检索的最有效的方法。 作为计算字段123select cust_name (select count(*) from orders where orders.cust_id = customers.cust_id)as orders from customers order by cust_name; 子查询并不总是执行这种类型的数据检索的最有效的方法。 联结表联结是一种机制，用来在一条select语句中关联表。可以联结多个表返回一组输出，联结在运行时关联表中正确的行。 等值联结 1234select vend_name, prod_name from vendors, products where vendors.vend_id = products.vend_id order by vend_name, prod_name 如果没有where语句，则将返回笛卡儿积，即返回的行数目，是第一个表的行数*第二个表。 联结的表越多，性能越差 内部联结（其效果与等值一样） 123select vend_name, prod_name from vendors inner join products on vendors.vend_id = products.vend_id 即在from处不同，并且使用了ON子句，而不是where where虽然简单，但是innerjoin是首选语法，能够确保不会忘记联结条件，并且性能可能会稍微好一些 高级联结使用别名进行联结 123select vend_name, prod_name from vendors as v inner join products as p on v.vend_id = p.vend_id 自联结 123select p1.prod_id, p1.prod_name from products as p1, products as p2 where p1.vend_id = p2.vend_id and p2.vend_id = 'DTNTR' 等价于：但是自联结的速度要快很多 1234select prod_id, prod_name from products where vend_id = (select vend_id from products where prod_id = 'DTNTR') 自然联结 对表进行联结时，可能有一个列不止一次出现在不止一个表当中，内部联结返回所有数据，自然联结排除多次出现，使得每个列只返回一次。但是MYSQL不自动完成该工作 外部联结 需要包含没有关联行的那些行。例如列出所有产品以及订购数量，包括没有人订购的产品。 123select customers.cust_id, orders.order_num from customers left outer join orders on customers.cust_id = orders.cust_id 使用联结和联结条件 注意所使用的联结类型，一般使用内部联结，但外部联结也是有效的 保证使用正确的联结条件， 在一个联结中可以包含多个表，甚至对于每个联结可以采用不同的联结类型。但在一起测试前，应该分别测试每个联结。 组合查询执行多个查询，并将结果作为单个返回及返回。应用场景： 在单个查询中从不同的表返回类似结构的数据 对单个表执行多个查询，按单个查询返回数据。 利用UNION进行组合。 UNION会自动去除重复行，其作用与单select使用多个where一样。如果需要重复行，则进行UNION ALL 12345select vend_id from products where prod_price &lt;=5UNIONselect vend_id from products where vend_id in (1001,1002) UNION规则 必须由两条或两条以上的select组成，并且每个查询必须包含相同的列、表达式或聚集函数 列数据类型必须兼容，类型可以不完全相同，但是必须是可以隐式转换的类型。 全文本搜索MyISAM引擎支持，使用全文本必须索引被搜索的列，索引后，select可与match()和against()一起使用以实际执行搜索。 1234create table productnotes&#123; note_text text null, FULLTEXT(note_text)#表明进行全文索引&#125;ENGINE=MyISAM 在导入数据时不应该开启FULLTEXT，而应该先导入数据，之后在开启索引，有助于更快地导入数据。 搜索 12select note_text from productnotes where match(note_text) against('rabbit') 查询扩展查询扩展用来设法放款所返回的全文本搜索结果的范围， 布尔搜索以布尔的形式提供如下内容的细节 要匹配的词 要排斥的词 排列提示（指定某些词比其他词更重要） 表达式分组 另外一些内容 Insert、update、delete12insert into customers values(null,'test')insert into customers(cust_name, cust_address) values(null, 'test') 省略列需要满足以下某个条件： 该列定义位允许NULL 在表定义中给出默认值 插入多行 1insert into customers(cust_name, cust_address) values(null, &apos;test&apos;),(&apos;do&apos;,&apos;test2&apos;) 插入检索出的数据 这里并不关心表名，只关心第几列。 1insert into customers(cust_name, cust_address) select cust_id,cust_address from custnew; updateupdate可以更新表中特定行，或表中所有行。 123update customers set cust_email = 'ela@gamil.com'where cust_id =10005 在update语句中可以使用子查询。 IGNORE如果update更新多行，如果在更新其中一行时出错，整个update会被取消。如果希望即使错误也继续执行则可以使用ignore 1update ignore customers delete1delete from customers where cust_id =10006 表操作删除表 1drop table customer2; 重命名表 1rename table customer2 to customer 更新表新增一列 1alter table vendors add vend_phone char(20); 新增外键 123alter table orders add constranint fk_orders_customers foreign key (cust_id) references customers (cust_id) 函数聚集函数用于汇总数据而不用将它们实际检索出来。例如确定表中的行数，找出最大值等。 聚集函数：运行在行组上，计算和返回单个值的函数。 AVG()：堆表中的行数计数并计算特定列值之和，求得该列的平均值。会忽略所有值为NULL的行 12select AVG(prod_price) as avg_price from products COUNT()： count(*)计算所有行，不管是NULL还是非空 count(column)对特定列计数，并忽略NULL 1select count(*) as num_cust from customers MAX()：可以用于返回文本列的数据， 1select MAX(prod_price) from products SUM()：忽略NULL行 1select SUM(prod_price) from products 聚集不同值即Distinct与ALL。ALL为默认值。当使用Distinct时，各个聚集函数只会考虑不同的值。 处理函数文本串处理函数 Trim()：去除串左右的空格 R(L)tim()：删除数据右(左)侧多余的空格 Upper()：将文本转换为大写 Lower()：转换为小写 SubString()：返回子串中的字符 数值计算函数 日期与时间函数 系统函数 视图 重用SQL语句 简化复杂的SQL操作，编写查询后，可以方便地重用而不必知道具体的查询细节 使用表的组成部分而不是整个表 保护数据 更改数据格式和表示 因为视图不包含数据，如果使用了多个联结和过滤创建了复杂的视图，可能性能下降很多。 创建视图： 12345create view productcustomers as select cust_name,cust_contact,prod_id from customers,orders,orderitems where customers.cust_id = orders.cust_id and orderitems.order_num = orders.order_num 查询创建视图的语句： 1show create view viewname 删除视图： 1drop view viewname]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>start</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器部署]]></title>
    <url>%2F2018%2F09%2F28%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[部署 部署要打开防火墙,同时要打开放在阿里云等控制台上面的端口 启动mysqlservice mysqld start nohup java -jar helloworld.jar &amp; 参考]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>start</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub：Start]]></title>
    <url>%2F2018%2F09%2F28%2F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2FGitHub%EF%BC%9AStart%2F</url>
    <content type="text"><![CDATA[Git原理直接记录快照，而非差异比较Git 和其它版本控制系统(包括 Subversion 和近似工具)的主要差别在于 Git 对待数据的方法。 概念上来区分，其它大部分系统以文件变更列表的方式存储信息。 这类系统(CVS、Subversion、Perforce、Bazaar 等等)将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。存储每个文件与初始版本的差异，如下图所示 - Git 不按照以上方式对待或保存数据。 反之，Git 更像是把数据看作是对小型文件系统的一组快照。 每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。如下图所示 - 这是 Git 与几乎所有其它版本控制系统的重要区别。 因此 Git 重新考虑了以前每一代版本控制系统延续下来的诸多方面。 Git 更像是一个小型的文件系统，提供了许多以此为基础构建的超强工具，而不只是一个简单的 VCS。 稍后我们在 Git 分支讨论 Git 分支管理时，将探究这种方式对待数据所能获得的益处。 近乎所有操作都是本地执行在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。 如果你习惯于所有操作都有网络延时开销的集中式版本控制系统，Git 在这方面会让你感到速度之神赐给了 Git 超凡的能量。 因为你在本地磁盘上就有项目的完整历史，所以大部分操作看起来瞬间完成。 举个例子，要浏览项目的历史，Git 不需外连到服务器去获取历史，然后再显示出来——它只需直接从本地数据库中读取。 你能立即看到项目历史。 如果想查看当前版本与一个月前的版本之间引入的修改，Git 会查找到一个月前的文件做一次本地的差异计算，而不是由远程服务器处理或从远程服务器拉回旧版本文件再来本地处理。 这也意味着你离线或者没有 VPN 时，几乎可以进行任何操作。 如你在飞机或火车上想做些工作，你能愉快地提交，直到有网络连接时再上传。 如你回家后 VPN 客户端不正常，你仍能工作。 使用其它系统，做到如此是不可能或很费力的。 比如，用 Perforce，你没有连接服务器时几乎不能做什么事；用 Subversion 和 CVS，你能修改文件，但不能向数据库提交修改(因为你的本地数据库离线了)。 这看起来不是大问题，但是你可能会惊喜地发现它带来的巨大的不同。 Git 保证完整性Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git 用以计算校验和的机制叫做 SHA-1 散列(hash，哈希)。 这是一个由 40 个十六进制字符(0-9 和 a-f)组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样： 124b9da6552252987aa493b52f8696cd6d3b0037 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。 Git三种状态请注意！如果你希望后面的学习更顺利，记住下面这些关于 Git 的概念。 Git 有三种状态，你的文件可能处于其中之一：已提交(committed)、已修改(modified)和已暂存(staged)。 已提交表示数据已经安全的保存在本地数据库中。 已修改表示修改了文件，但还没保存到数据库中。 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录以及暂存区域。工作目录、暂存区域以及 Git 仓库如下图所示 - Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。 工作目录是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区域是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作‘索引’，不过一般说法还是叫暂存区域。 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 术语 workspace：工作区 通过git init创建的代码库的所有文件但是不包括.git文件(版本库) index/stage：暂存区，也叫索引 通过git add ./*/*Xxx/Xxxx* 添加的修改,都是进入到暂存区了,肉眼不可见 通过 git status 可以看到修改的状态。 repository：仓库区（本地仓库），也叫存储库 remote：远程仓库 code review对代码进行评阅 bugfix修复bug pull request提交合并请求 merge合并其他人提出的pull请求，对pull进行审核，若满足则进行冲突解决并合并到项目当中 Git快速入门能够配置并初始化一个仓库(repository)、开始或停止跟踪(track)文件、暂存(stage)或提交(commit)更改。 本章也将演示如何配置 Git 来忽略指定的文件和文件模式、如何迅速而简单地撤销错误操作、如何浏览项目的历史版本以及不同提交(commits)间的差异、如何向远程仓库推送(push)以及如何从远程仓库拉取(pull)文件。 远程仓库是什么？ Repository(仓库)包含的内容 - Git的目标是管理一个工程，或者说是一些文件的集合，以跟踪它们的变化。Git使用Repository来存储这些信息。一个仓库主要包含以下内容(也包括其他内容)： 许多commit objects 到commit objects的指针，叫做heads Git的仓库和工程存储在同一个目录下，在一个叫做.git的子目录中。 创建Repository(略过)获取Git仓库有两种取得 Git 项目仓库的方法。第一种是从一个服务器克隆一个现有的 Git 仓库。第二种是在现有项目或目录下导入所有文件到 Git 中； 更新提交到仓库中记录每次更新到仓库在一个真实的Git仓库当中，对一些文件作出修改，完成一个阶段性目标后，提交本次更新到仓库中。 工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 我们逐步将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。所以使用 Git 时文件的生命周期如下： 检查当前文件状态 Git status要查看哪些文件处于什么状态，可以用 git status 命令。 如果在克隆仓库后立即使用此命令，会看到类似这样的输出： 1$ git status 跟踪新文件 Git add (file)使用命令 git add 开始跟踪一个文件。 所以，要跟踪 mytext.txt 文件，运行： 1$ git add mytext.txt 此时再运行 git status 命令，会看到 mytext.txt 文件已被跟踪，并处于暂存状态： 123456$ git statusOn branch masterChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: mytext.txt 只要在 Changes to be committed 这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。git add 命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 暂存已修改文件 git add现在我们来修改一个已被跟踪的文件。 如果修改了一个名为 README.md 的已被跟踪的文件，打开文件 README.md并编辑其中的内容，在文件的未尾加入一行内容：”这是暂存已修改文件示例”，然后运行 git status 命令，会看到下面内容： 123456789101112$ git statusOn branch masterChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: mytext.txtChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.md 文件 README.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 git add 命令。 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。 现在让我们运行 git add 将”README.md“放到暂存区，然后再看看 git status 的输出： 123456789101112$ git add README.mdAdministrator@MY-PC /F/worksp/git-start (master)$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.md new file: mytext.txt 现在两个文件都已暂存，下次提交时就会一并记录到仓库。 假设此时，想要在 README.md 里再加条注释， 重新编辑存盘后，准备好提交。不过且慢，先向 “README.md” 文件加入一点内容，再运行 git status ，如下所示 - 1234567891011121314$ echo "Add new Line content 1002 " &gt;&gt; README.md$ git statusOn branch masterChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: README modified: mytext.txtChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.md 在上面可以看到，README.md出现在了两个地方 实际上 Git 只不过暂存了运行 git add 命令时的版本， 如果现在提交，README.md 的版本是最后一次运行 git add 命令时的那个版本，而不是运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来： 1234567891011121314$ git add README.mdAdministrator@MY-PC /F/worksp/git-start (master)$ git statuswarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directory.On branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.md new file: mytext.txt 状态简览 git status -sgit status 命令的输出十分详细，但其用语有些繁琐。 如果你使用 git status -s 命令或 git status --short 命令，将得到一种更为紧凑的格式输出。 运行 git status -s，状态报告输出如下： 123456$ git status -s M README.mdMM RakefileA lib/git.rbM lib/simplegit.rb?? LICENSE.txt 新添加的未跟踪文件前面有 ?? 标记 新添加到暂存区中的文件前面有 A 标记 修改过的文件前面有 M 标记。 你可能注意到了 M 有两个可以出现的位置 出现在右边的 M 表示该文件被修改了但是还没放入暂存区 出现在靠左边的 M 表示该文件被修改了并放入了暂存区。 例如，上面的状态报告显示： README 文件在工作区被修改了但是还没有将修改后的文件放入暂存区,lib/simplegit.rb 文件被修改了并将修改后的文件放入了暂存区。 而 Rakefile 在工作区被修改并提交到暂存区后又在工作区中被修改了，所以在暂存区和工作区都有该文件被修改了的记录。 忽略文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。 来看一个实际的例子： 123456$ cat .gitignore*.[oa]*~Shell 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有以波浪符(~)结尾的文件，许多文本编辑软件(比如 Emacs)都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以(/)开头防止递归。 匹配模式可以以(/)结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号(!)取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号(*)匹配零个或多个任意字符；[abc]匹配任何一个列在方括号中的字符(这个例子要么匹配一个字符 a，要么匹配一个字符 b，要么匹配一个字符 c)；问号(?)只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配(比如 [0-9] 表示匹配所有 0 到 9 的数字)。 使用两个星号(*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。 下面再看一个 .gitignore 文件的例子： 1234567891011121314151617# no .a files*.a# but do track lib.a, even though you're ignoring .a files above!lib.a# only ignore the TODO file in the current directory, not subdir/TODO/TODO# ignore all files in the build/ directorybuild/# ignore doc/notes.txt, but not doc/server/arch.txtdoc/*.txt# ignore all .pdf files in the doc/ directorydoc/**/*.pdf 提示：GitHub 有一个十分详细的针对数十种项目及编程语言的 .gitignore 文件列表，你可以在 http://github.com/github/gitignore 找到它。 查看已暂存和未暂存的修改如果 git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。 稍后我们会详细介绍 git diff，可能通常会用它来回答这两个问题： 当前做的哪些更新还没有暂存？ 有哪些更新已经暂存起来准备好了下次提交？ 尽管 git status 已经通过在相应栏下列出文件名的方式回答了这个问题，git diff 将通过文件补丁的格式显示具体哪些行发生了改变。 假如再次修改 README.md 文件后暂存，然后编辑 READ.md 文件并在文件的最后追加一行内容：”this is another line 1003“ 之后先不暂存， 运行 git status 命令将会看到： 12345678910111213141516$ echo "this is another line 1003 " &gt;&gt; README.md$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: README.md new file: mytext.txtChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.md 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： 1234567891011$ git diffdiff --git a/README.md b/README.mdindex ea161e2..6679481 100644--- a/README.md+++ b/README.md@@ -1,2 +1,3 @@ Add new Line content 1001 Add new Line content 1002+this is another line 1003warning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directo(END) 上面输出显示有加一行“+this is another line 1003”，前面带有一个加号：“+”。 请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。 然后用 git diff --cached 查看已经暂存起来的变化：(--staged 和 --cached 是同义词) 1234567891011121314151617181920$ git diff --cacheddiff --git a/README.md b/README.mdindex 2f88ca7..ea161e2 100644--- a/README.md+++ b/README.md@@ -1,2 +1,2 @@-#git-start-这是一个 Git 学习使用的Git仓库。\ No newline at end of file+Add new Line content 1001+Add new Line content 1002diff --git a/mytext.txt b/mytext.txtnew file mode 100644index 0000000..1820ae1--- /dev/null+++ b/mytext.txt@@ -0,0 +1 @@+This is my first Git control filewarning: LF will be replaced by CRLF in mytext.txt.The file will have its original line endings in your working directory. 如上图中所示，分别对比了两个文件：README.md 和 mytext.txt，其中绿色的内容表示添加，红色的内容表示删除。 注意：git diff 的插件版本,在本教程中，我们使用 git diff 来分析文件差异。 但是，如果你喜欢通过图形化的方式或其它格式输出方式的话，可以使用 git difftool 命令来用 Araxis ，emerge 或 vimdiff 等软件输出 diff 分析结果。 使用 git difftool --tool-help 命令来看你的系统支持哪些 Git Diff 插件。 提交更新 git commit现在的暂存区域已经准备妥当可以提交了。 在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了，如果没有暂存起来则要先使用命令：git add .将所有文件暂存起来， 然后再运行提交命令 git commit： 123$ git status$ git add .$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。 (默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。使用 git config --global core.editor 命令设定你喜欢的编辑软件。) 编辑器会显示类似下面的文本信息(本例选用 Vim 的屏显方式展示)： 1234567891011# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.# On branch master# Changes to be committed:# new file: README# modified: CONTRIBUTING.md#this is my commit info note.~~".git/COMMIT_EDITMSG" 9L, 283C 可以看到，默认的提交消息包含最后一次运行 git status 的输出，放在注释行里，另外开头还有一空行，供你输入提交说明。完全可以去掉这些注释行，不过留着也没关系，多少能帮你回想起这次更新的内容有哪些。 (如果想要更详细的对修改了哪些内容的提示，可以用 -v 选项，这会将你所做的改变的 diff 输出放到编辑器中从而使你知道本次提交具体做了哪些修改。) 退出编辑器时，Git 会丢掉注释行，用输入提交附带信息生成一次提交。如上面示例中，提交的备注信息是：“this is my commit info note.”。 另外，也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示： 1234$ git commit -m "this is my commit info note."[master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README.md 现在已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支(master)提交的，本次提交的完整 SHA-1 校验和是什么(463dc4f)，以及在本次提交中，有多少文件修订过，多少行添加和删改过。 请记住，提交时记录的是放在暂存区域的快照。任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤： 123456789101112$ git statusOn branch masterChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")$ git commit -a -m 'added new benchmarks'[master 83e38c7] added new benchmarks 1 file changed, 5 insertions(+), 0 deletions(-) 看到了吗？提交之前不再需要 git add 文件“README.md”了。 移除文件（取消跟踪并删除文件） git rm (file)要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除(确切地说，是从暂存区域移除)，然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分(也就是 未暂存清单)看到： 12345678910111213$ rm mytext.txt$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) deleted: mytext.txtno changes added to commit (use "git add" and/or "git commit -a") 下一次提交时，该文件就不再纳入版本管理了。 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f(注：即 force 的首字母)。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。 另外一种情况是，我们想把文件从 Git 仓库中删除(亦即从暂存区域移除)，但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项： 12345678910$ git rm --cached mytext.txt$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) deleted: mytext.txt git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说： 1$ git rm log/\*.log 注意到星号 * 之前的反斜杠 \， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： 1$ git rm \*~ 该命令为删除以 ~ 结尾的所有文件。 移动文件不像其它的 VCS 系统，Git 并不 显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做： 1$ git mv file_from file_to 它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明： 1234567$ git mv README.md README$ git statusOn branch masterChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README.md -&gt; README 其实，运行 git mv 就相当于运行了下面三条命令： 123$ mv README.md README$ git rm README.md$ git add README 如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而另一种方式需要三条命令，直接用 git mv 轻便得多。 不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。 查看提交历史git log 撤销操作重新提交 Git commit –amend有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交： 1$ git commit --amend 这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改(例如，在上次提交后马上执行了此命令)，那么快照会保持不变，而你所修改的只是提交信息。 文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。 例如，提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： 123$ git commit -m 'initial commit'$ git add forgotten_file$ git commit --amend 最终你只会有一个提交 - 第二次提交将代替第一次提交的结果。 取消暂存的文件 git reset head (file)接下来的两个小节演示如何操作暂存区域与工作目录中已修改的文件。 这些命令在修改文件状态的同时，也会提示如何撤消操作。 例如，你已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 git add * 暂存了它们两个。 如何只取消暂存两个中的一个呢？ git status 命令提示： 1234567891011$ git add *$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README.md -&gt; README deleted: mytext.txt 在 “Changes to be committed” 文字正下方，提示使用 git reset HEAD &lt;file&gt;... 来取消暂存。 所以，我们可以这样来取消暂存 mytext.txt 文件： 12345678910111213141516$ git reset HEAD mytext.txt$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README.md -&gt; READMEChanges not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) deleted: mytext.txt 撤消对文件的修改 git checkout – (file)如果并不想保留对 mytext.txt 文件的修改怎么办？ 该如何方便地撤消修改 - 将它还原成上次提交时的样子(或者刚克隆完的样子，或者刚把它放入工作目录时的样子)？ 幸运的是，git status 也告诉了你应该如何做。 在最后一个例子中，未暂存区域是这样： 123456789101112131415$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README.md -&gt; READMEChanges not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) deleted: mytext.txt 它非常清楚地告诉了如何撤消之前所做的修改。让我们来按照提示执行： 1234567891011121314151617$ git checkout -- mytext.txtAdministrator@MY-PC /F/worksp/git-start (master)$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) renamed: README.md -&gt; READMEAdministrator@MY-PC /F/worksp/git-start (master)$ lsREADME mytext.txt 可以看到，mytext.txt文件又回来了。 如果仍然想保留对那个文件做出的修改，但是现在仍然需要撤消，我们将会在 Git 分支介绍保存进度与分支；这些通常是更好的做法。 记住，在 Git 中任何已提交的东西几乎总是可以恢复的。甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复。然而，任何你未提交的东西丢失后很可能再也找不到了。 远程仓库的使用查看远程仓库 git remote如果想查看你已经配置的远程仓库服务器，可以运行 git remote 命令。 它会列出你指定的每一个远程服务器的简写。 如果已经克隆了自己的仓库，那么至少应该能看到 origin - 这是 Git 给你克隆的仓库服务器的默认名字： 123456789101112$ git clone http://git.oschina.net/yiibai/git-start.gitCloning into 'ticgit'...remote: Reusing existing pack: 1857, done.remote: Total 157 (delta 0), reused 0 (delta 0)Receiving objects: 100% (1857/1857), 74.35 KiB | 168.00 KiB/s, done.Resolving deltas: 100% (772/772), done.Checking connectivity... done.$ cd git-start$ git remoteorigin 也可以指定选项 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。 123$ git remote -vorigin http://git.oschina.net/yiibai/git-start.git (fetch)origin http://git.oschina.net/yiibai/git-start.git (push) 如果远程仓库不止一个，该命令会将它们全部列出。 例如，与几个协作者合作的，拥有多个远程仓库的仓库看起来像下面这样： 12345678910$ cd git-start$ git remote -vmydoor http://git.oschina.net/yiibai/git-start.git (fetch)mydoor http://git.oschina.net/yiibai/git-start.git (push)curry http://git.oschina.net/yiibai/git-start.git (fetch)curry http://git.oschina.net/yiibai/git-start.git (push)deepfun http://git.oschina.net/yiibai/git-start.git (fetch)deepfun http://git.oschina.net/yiibai/git-start.git (push)koke http://git.oschina.net/yiibai/git-start.git (fetch)koke http://git.oschina.net/yiibai/git-start.git (push) 这样可以轻松拉取其中任何一个用户的贡献。 此外，大概还会有某些远程仓库的推送权限，虽然目前还不会在此介绍。 从远程仓库中抓取与拉取 git fetch(pull)就如刚才所见，从远程仓库中获得数据，可以执行： 1$ git fetch [remote-name] 这个命令会访问远程仓库，从中拉取所有还没有的数据。执行完成后，将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。 如果使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆(或上一次抓取)后新推送的所有工作。 必须注意 git fetch 命令会将数据拉取到本地仓库 - 它并不会自动合并或修改当前的工作。 当准备好时必须手动将其合并入你的工作区。 如果你有一个分支设置为跟踪一个远程分支，可以使用 git pull 命令来自动的抓取然后合并远程分支到当前分支。 这对你来说可能是一个更简单或更舒服的工作流程；默认情况下，git clone 命令会自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支(或不管是什么名字的默认分支)。 运行 git pull 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程仓库当想分享你的项目时，必须将其推送到上游。 这个命令很简单：git push [remote-name] [branch-name]。 当你想要将 master 分支推送到 origin 服务器时(再次说明，克隆时通常会自动帮你设置好那两个名字)，那么运行这个命令就可以将所做的备份到服务器： 1$ git push origin master 只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。 GitHub的使用 命令行的难度蛮大的,初入门经常出现各种的问题 推荐使用工具source tree轻松解决问题 source tree需要翻墙注册,自带VPN哦 命令 git pull取回远程主机某个分支的更新，再与本地的指定分支合并 git fetch命令用于从另一个存储库下载对象和引用。 git checkout在取回远程主机的更新以后，可以在它的基础上，使用git checkout命令创建一个新的分支。 git add命令将文件内容添加到索引(将修改添加到暂存区)。也就是将要提交的文件的信息添加到索引库中 git push命令用于将本地分支的更新，推送到远程主机。 git merge命令用于将两个或两个以上的开发历史加入(合并)一起。 私人仓库本来最近挺想弄个私人仓库的,苦于贫穷,一直没有好的解决办法,终于,被我找到了这个学生优惠,造作呀. 今天在 HN 上到一则消息，“Free private Github repos for students and edu people | 学生和教育人士可免费申请 Github 私有仓库”。 如果你是学生，并且已有 Github 账号，那都可以去申请微型方案（Micro Plan）。私有仓库可用来托管你个人的课程项目、论文或和学位相关的研究。当然了，如果学生需要用于团队的私有仓库，同样可以申请。 如果你是教师，或者是学生组织（诸如校园报社和机器人俱乐部）的赞助商，可以申请组织账号（Organization account ）。 参考 申请GitHub学生免费私有仓库 武汉理工大学申请校园邮箱的网址 加快git clone 几十倍速度的小方法 （30KB vs 2M） 易百教程 设置多个SSH KEY]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>Start</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea使用技巧]]></title>
    <url>%2F2018%2F09%2F28%2F%E5%B0%8F%E6%8A%80%E5%B7%A7%2Fide%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[idea快捷键自动代码格式化 Ctrl+alt+L 插入getter和setter alt+insert 插件篇直接修改源码，不需要重新启动 jetbrain插件 不用书写get/set方法 lombok插件 添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; 添加插件lombok 添加类注解@Data 或 @Get 编码规范 save action插件 Alibaba Java Coding Guidelines插件 使用MAVEN创建多模块的SPRINGCLOUD项目具体实现的项目目录如下图所示 创建父模块首先打开IDEA，File -&gt; new -&gt; Project，我们选择Maven创建工程项目 点击next，输入GroupId与ArtifactId，以此点击next-&gt;finished 依次点击next -&gt; finish ，创建项目完成后目录结构如所示 打开项目目录下的pom.xml，发现与Spring Initializr方式创建的项目有所区别 12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;main-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/project&gt; 修改pom.xml，增加一些依赖下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;main-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- packaging: 打包的机制，如pom, jar, maven-plugin, ejb, war, ear, rar, par --&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.build.outputEncoding&gt;UTF-8&lt;/project.build.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--选择最新都Finchley版本--&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;!--增加相应都值给父pom，用于子项目都继承--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;!--relativePath可以不需要，但是用于指明parent的目录，用于快速查询。--&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;!--用于父项目配置共同的依赖关系，主要配置依赖包相同因素 spring-cloud --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--插件需要依赖的包--&gt;&lt;dependencies&gt; &lt;!--Spring Boot的核心启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web服务依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt; 创建子模块修改完pom.xml后 创建2 模块，依次file-&gt;new-&gt;module,选择Spring Initializr方式创建 next-&gt; 输入Group与Artifact内容，注意group需要与工程项目的相同 next-&gt; 选择eureka-server ， next-&gt; finish 创建完成后，打开pom.xm内容如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.RC2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 将上面的pom.xml修改为： 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--修改parent--&gt; &lt;parent&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;main-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 复制spring-cloud-starter-netflix-eureka-server依赖到父pom.xml依赖中，并增加模块配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yetianyue&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- packaging: 打包的机制，如pom, jar, maven-plugin, ejb, war, ear, rar, par --&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--子模块--&gt; &lt;modules&gt; &lt;module&gt;eureka-server&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.build.outputEncoding&gt;UTF-8&lt;/project.build.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--选择最新都Finchley版本--&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;!--增加相应都值给父pom，用于子项目都继承--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;!--relativePath可以不需要，但是用于指明parent的目录，用于快速查询。--&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;!--用于父项目配置共同的依赖关系，主要配置依赖包相同因素 spring-cloud --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--插件需要依赖的包--&gt; &lt;dependencies&gt; &lt;!--eureka server依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Spring Boot的核心启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web服务依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 简单的配置下单机版的eureka-server，配置如下 12345678910111213server: port: 8761spring: application: name: eureka-servereureka: client: service-url: defaultZone: http://localhsot:8761/eureka/ fetch-registry: false register-with-eureka: false instance: hostname: localhost 在启动类中增加@EnableEurekaServer 注解，运行启动项目，访问http://localhost:8761/ ,发现下图所示，表明搭建成功 其他config-server，provider-user两个模块搭建方式相同，以下列出所有的pom.xml配置提供参考 maintest pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;main-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- packaging: 打包的机制，如pom, jar, maven-plugin, ejb, war, ear, rar, par --&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--子模块--&gt; &lt;modules&gt; &lt;module&gt;config-server&lt;/module&gt; &lt;module&gt;eureka-server&lt;/module&gt; &lt;module&gt;provider-user&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.build.outputEncoding&gt;UTF-8&lt;/project.build.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--选择最新都Finchley版本--&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;!--增加相应都值给父pom，用于子项目都继承--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;!--relativePath可以不需要，但是用于指明parent的目录，用于快速查询。--&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;!--用于父项目配置共同的依赖关系，主要配置依赖包相同因素 spring-cloud --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--插件需要依赖的包--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--配置服务依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Spring Boot的核心启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web服务依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; config-server pom.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;config-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;config-server&lt;/name&gt; &lt;description&gt;config-server&lt;/description&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;com.yetianyue&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; eureka-server pom.xml 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;com.yetianyue&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; provider-user pom.xml 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.spring&lt;/groupId&gt; &lt;artifactId&gt;provider-user&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;provider-user&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;com.yetianyue&lt;/groupId&gt; &lt;artifactId&gt;main-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;./pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 最终整体项目目录如下所示，至此完成多模块的搭建 参考 Intellij Idea 代码格式化/保存时自动格式化 idea 离线安装 lombok插件 使用MAVEN创建多模块的SPRINGCLOUD项目 IntelliJ idea 创建Maven多模块项目并运行(创建SpringCloud不太行) IDE官方帮助文档]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端基础]]></title>
    <url>%2F2018%2F09%2F27%2F%E5%89%8D%E7%AB%AF%2F%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[HTML5 前一个版本是HTML4.1,HTML4.1是一个展示,是展示层面 HTML是一个web应用 CSS3&lt;media&gt; &lt;flex-box&gt; web font .google(慢),七牛,阿里 参考]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>start</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：多态]]></title>
    <url>%2F2018%2F09%2F26%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%A4%9A%E6%80%81%2F</url>
    <content type="text"><![CDATA[何为多态举例考虑一种继承关系，Manager继承于Employee Employee e作为父类，e既可以引用Manager也可以引用Employee。因为Manager也是一个Employee，只是在其基础上进行了拓展。 那么考虑e.getSalary()，这个方法是获取薪水的，那么两个类是 都拥有这个方法的，当e引用不同的对象的时候，问题为：它调用的是哪一个类的getSalary()。 如果它引用的是Employee，那么就会调用Employee的方法，如果它引用的是Manager，那么就会调用Manager的方法，如果Manager没有getSalary()，那么它就会调用Employee的方法。 定义一个对象变量（例如，变量e)可以指示多种实际类型的现象被称为多态。在运行时能够自动地选择调用哪个方法的现象称为动态绑定。虚拟机知道e的实际引用类型，因此能够正确的调用相应的方法 多态核心 多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 指向子类的父类引用由于向上转型了，它只能访问父类中拥有的方法和属性，而对于子类中存在而父类中不存在的方法，该引用是不能使用的，尽管是重载该方法。若子类重写了父类中的某些方法，在调用该些方法的时候，必定是使用子类中定义的这些方法（动态连接、动态调用） 在继承链中对象方法的调用存在一个优先级：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。即先查this对象的父类，没有就重头再查参数的父类 定义 面向对象的三大特性：封装、继承、多态 多态的定义：指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用） 实现多态的技术称为：动态绑定（dynamic binding），是指在执行期间判断所引用对象的实际类型，根据其实际的类型调用其相应的方法。 多态的作用：消除类型之间的耦合关系。 实现形式：继承和接口 必要条件多态存在的三个必要条件 要有继承； 要有重写； 向上转型，父类引用指向子类对象。 优点 可替换性（substitutability）。多态对已存在代码具有可替换性。例如，多态对圆Circle类工作，对其他任何圆形几何体，如圆环，也同样工作。 可扩充性（extensibility）。多态对代码具有可扩充性。增加新的子类不影响已存在类的多态性、继承性，以及其他特性的运行和操作。实际上新加子类更容易获得多态功能。例如，在实现了圆锥、半圆锥以及半球体的多态基础上，很容易增添球体类的多态性。 接口性（interface-ability）。多态是超类通过方法签名，向子类提供了一个共同接口，由子类来完善或者覆盖它而实现的。如图8.3所示。图中超类Shape规定了两个实现多态的接口方法，computeArea()以及computeVolume()。子类，如Circle和Sphere为了实现多态，完善或者覆盖这两个接口方法。 灵活性（flexibility）。它在应用中体现了灵活多样的操作，提高了使用效率。 简化性（simplicity）。多态简化对应用软件的代码编写和修改过程，尤其在处理大量对象的运算和操作时，这个特点尤为突出和重要。 12Animal Adog =new Dog()Adog.eat()会调用Dog的eat方法而不是Animal的方法 注意 参数和返回类型同样可以多态 参考]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器缓存]]></title>
    <url>%2F2018%2F09%2F25%2F%E5%89%8D%E7%AB%AF%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[google浏览器设置不缓存的方法方法1 Google浏览器中，F12打开控制台—&gt;Network—Disable cache 打钩 方法2 在浏览器按F12—&gt;在按下F1—&gt;找到network —-&gt; Disable cache（while DevTools is open） 打钩 方法3快捷键 ctrl+shift+delete —-&gt; 清除浏览数据ctrl+shift+R 强制刷新，不适用浏览器缓存！ 参考 https://blog.csdn.net/xinghuo0007/article/details/72637762]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[框架：log]]></title>
    <url>%2F2018%2F09%2F24%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E6%A1%86%E6%9E%B6%EF%BC%9Alog%2F</url>
    <content type="text"><![CDATA[日志框架介绍 能实现日志输出的工具包 日志：能够描述系统运行状态的所有时间 用户下线 接口超时 数据库崩溃 等等 能力 定制输出目标 定制输出格式 携带上下文信息（线程，调用对象） 运行时选择性输出 灵活的配置 优异的性能 日志级别框架种类日志门面 JCL SLF4J 和 logback 是同一个作者，优选 日志实现 log4j2 极度的性能，太先进，不受到支持 logback 使用1. private final Logger logger =LoggerFactory.getLogger(&quot;类名&quot;.class) 2. @Slf4j public class 类名注意 使用类名的原因是，报出错误是属于哪个类 配置需求 区分info和error 每天产生一个日志文件 配置文件 application.yml 简单，只能做基础的配置 logback-spring.xml applicationlogging: path: /a/a/a 配置日志输出路径 file: /a/a/a 配置日志文件输出路径 level: debug日志级别 com.test.dem: debug指定某个类的debug日志logback-spring18min 参考]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaBase异常]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常Java的基本理念是”结构不佳的代码不能运行” 当在编译期无法找出所有的错误时，余下的错误必须在运行期解决 提出问题现实世界中充满了不良的数据和带有问题的代码，由于程序的错误或一些外部环境的影响造成数据的丢失，用户就可能不再使用这个程序了。 概述是什么面对异常： 向用户报告错误 保存所有的工作结果 允许用户以妥善的形式推出程序 Java使用异常处理机制处理获异常 分类，各个分类是什么异常分类 首先是Error类，它代表硬件上的错误，着运行时系统内部错误或者资源耗尽，或者内存不足等问题，在一些低配般服务器上很可能出现。应用程序不应该抛出该异常。 更需要关注的是Exception上的错误，它代表着软件方面的错误，也是我们程序员的领域。可以看到一个是RuntimeException类，另一个是IOException。 IOException，即你在读取U盘，你把U盘拔了，这种搞事情的，或者IO错误等等，一般不可控，属于其他异常。 试图在文件尾部后读取数据、试图打开一个不存在的文件、试图根据给定字符串查找不存在的Class对象 RuntimeException错误，这就是程序错误了 错误的类型转换、数组访问越界、访问null指针 而如果出现RuntimeException。则一定是程序员的问题。 因此派生于Error类与RuntimeException类的异常称为非受查异常。而其他的异常称为受查异常。编译器将检查是否为所有的受查异常提供了异常处理器。 可能的错误原因为了能够在程序中处理异常情况，必须研究程序中可能会出现的错误和问题，以及哪类问题需要关注。 用户输入错误。 设备错误，即硬件可能被关掉了，打印机没有纸了 物理限制，即内存用完 代码错误，程序方法可能无法正确执行，例如数组越界等。 应用适用性（作用）应用场景异常类方法 Throwable() Throwable(String msg)带有特定的详细描述信息的对象 String getMessage()。获得Throwable对象的详细信息 void initCause(Throwable exce)，生成cause，值造成该异常的异常 Throwable getCause()。获得Cause变量，一般指造成该异常的异常 Throwable printStackTrace()可以访问堆栈轨迹的文本描述信息。 StackTraceElement[] getStackTrace()获得构造这个对象时调用堆栈的跟踪。可以在程序中分析这个数组。 void addSuppressed(Throwable t)为异常增加一个抑制异常，这出现在带资源的try语句中 # 处理错误如果由于出现错误而使得某些操作没有完成，程序应该： 返回一种安全状态，并让用户能够执行一些其他命令，或者 允许用户保存所有操作的结果，并以妥善的方式终止程序 而如此并不容易，因为引发错误条件的代码通常离那些能够让数据恢复到安全状态的代码很远。异常处理的任务就是将控制权从错误产生的地方转移给能够处理这种情况的错误处理器。 在Java中，如果某个方法不能采用正确的途径完成它的任务，就可以通过另外一个路径退出方法，该情况下，方法不返回任何值，而是抛出一个封装了错误信息的对象。 这个方法会立即退出，并不返回任何职，此外调用这个方法的代码也将无法继续执行，而异常处理机制将开始搜索能够处理这种异常情况的异常处理器 声明受查异常如果遇到了无法处理的情况，那么Java方法可以抛出一个异常，方法不仅需要告诉编译器将要返回什么值，还要告诉编译器可能发生什么错误。 当抛出异常后，运行时系统就会搜索异常处理器，以便知道如何处理该异常。 当遇到以下情况需要抛出异常 调用一个抛出受查异常的方法 程序运行过程中发现错误，并且利用throw语句抛出一个受查异常 程序出现错误，例如a[-1] Java虚拟机和运行时库出现的内部错误 不应该声明从RuntimeException继承的非受查异常。并且不需要声明从Error继承的错误，它们属于Java内部错误，我们对其没有控制力。 子类继承如果子类覆盖了超类中的一个方法，子类方法中声明的受查异常不能比超类方法中声明的更通用。即子类可以抛出更特定的异常，或者不抛出异常。如果父类方法没有抛出任何受查异常，子类也不能抛出任何受查异常。 如何抛出异常throw new EOFException() 对于一个已经存在的异常类，抛出非常容易，1.找到一个合适的异常类，2.创建这个类的一个对象，3.将对象抛出。 创建异常类当遇到任何标准异常类都没有能够充分描述请求的问题，则需要定义自己的异常类。定义的类需要包含两个构造器：默认构造器、带有详细描述信息的构造器（超类的toString()会打印出这些信息）。 123456class FileFormatException extends IOException&#123; public FileFormatException(); public FileFormatException(String msg)&#123; super(msg); &#125;&#125; 捕获异常捕获异常如果某个异常发生的时候没有在任何地方进行捕获，那程序就会终止执行，并在控制台上打印出异常信息，包括异常的类型和堆栈信息。 要捕获异常，则需要设置try catch语句块。如果在try语句块中的任何代码抛出了一个在catch语句中声明的异常类 程序将跳过try语句块的其余代码 程序将在执行catch语句中的处理器代码 如果没有抛出了没有声明的异常，则会立即退出。 throw or catch编译器严格执行throws说明符，如果调用了一个抛出受查异常的方法就必须对它进行处理，或这继续传递 捕获那些知道如何处理的异常 将那些不知道怎样处理的异常继续传递。 如果传递异常则需要在方法首部增加throws 抛出异常是躲避异常的方法 异常会抛给调用该方法的方法,因此,调用方法的方法也要去抛出或者处理异常 再次抛出异常和异常链在catch子句中可以抛出一个异常，这样的目的是改变异常的类型，如果开发了一个供其他程序员使用的子系统，那么用于表示子系统系统故障的异常类型可能会产生多种解释。 12345try&#123; access database &#125;catch(SQLException)&#123; throw new ServletException("database error:"+e.getMessage());&#125; 用带有异常信息文本的构造器进行构造新异常，有一种更好的处理方法是: 1234567try&#123; access database &#125;catch(SQLException)&#123; Throwable se = new ServletException("database error "); se.initCause(e); throw se;&#125; 当上游捕获到异常，可以使用se.getCause()获得原始异常。 finally当代码抛出一个异常时，就会终止方法中的剩余代码处理，并退出这个方法的执行。如果方法获得了一些本地资源，并且只有该方法知道，且资源在退出方法前必须回收。则产生资源回收问题。 因此使用finally语句进行资源回收操作，以及必须执行的操作， 对于try-catch-finally finally一定会执行,即使遇到了在try或者catch中遇到了return,也会先跳到finally里面执行,然后再跳转回到finally 多catch下,catch是顺序执行的,而且由于异常也是一个对象,因此应该将子类的catch放在最顶部, 分析堆栈轨迹元素堆栈轨迹是一个方法调用过程的列表，包含了程序执行过程中方法调用的特定文字。当Java程序正常终止而没有捕获异常时，这个列表会显示出来 1234java.lang.Exception: 出问题啦！ at TestPrintStackTrace.f(TestPrintStackTrace.java:3) at TestPrintStackTrace.g(TestPrintStackTrace.java:6) at TestPrintStackTrace.main(TestPrintStackTrace.java:10) 最上面的是运行到的最后一个函数。即第三行代码调用了第六行，第六行调用了第10行 使用异常机制的技巧 异常处理不能代替简单测试 不要过分细化异常 利用异常层次结构 不要压制异常 在检测错误时，“苛刻”比放任好 不要羞于传递异常]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBase：生命周期]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[初始化构造器默认构造器 当在类中没有写构造器的时候，编译器会认为你忘记了这件事情，默认为你加上一个无参的构造器。 当自己写了构造器后，编译器认为你知道自己想要什么，于是认为你不需要编译器的帮助，因此，需要自己选择写或不写无参构造器 使用this和super this可以帮助调用同一个类的其他构造器 super可以调用父类的构造器 它们必须是第一条语句 this与super不可兼得,因为他们必须是第一条语句 但是可以曲线救国 使用初始化块123456//该静态块会在构造方法执行前执行//只要构造类的对象，这些方法就会执行&#123; id=nextId; nextId++;&#125; 关键字this 只在必要的地方使用this,可以便于阅读 this在方法中表示操作该方法的对象，并且方法可以返回一个thisreturn this 可以实现一种x.getthis().getthis().print(); 即多次递归调用 superstatic它是静态的，意味着不能加载动态资源，即不能加载对象的属性以及非静态的资源 静态资源的初始化 当没有赋初值，静态资源会获得基本类型的标准初值，例如int为0，引用为null 创建时间：在创建第一个table对象，或第一次加载类，或第一次访问静态资源 初始化顺序： 先静态对象，即类中的static的资源 后非静态对象。 显式的静态初始化使用静态块，将所有的静态语句组织起来 static { i=47; h=50; }数组初始化初始int[] a或 int a[] 为什么不能确定大小? 因为初始化的只是对对象的一个引用,并没有分配内存空间,只是表明这是一个数组对象,引用哪来的大小 初始化的方法 int[] a= new int(5);//方法1 Integer[] a ={ //方法2 new Integer(1), new Integer(2), }; Integer[] b=new Integer[]{ //方法3 new Integer(1), new Integer(2), };可变参数列表实现 public void printArr(Object ... args){ for (Object obj : args) System.out.println(obj + &quot; &quot;); } 终结条件 finalize对象终结条件的验证if() System.gc()强制执行终结动作 清理 牢记 垃圾回收只与内存有关 对象可能不会被垃圾回收 垃圾回收不等于”析构”(C++) 垃圾回收器的工作范围 垃圾回收器只会回收通过new分配的内存 垃圾回收只与内存有关 对象可能不会被垃圾回收 垃圾回收或者终结,不一定发生,如果JVM未面临内存耗尽,不会浪费时间去执行垃圾回收以恢复内存 特殊情况 获得一块非new的特殊内存 例如对象将自己绘制到了屏幕上,需要在对象销毁时候,将自己擦除 由于不是new得到的内存，因此垃圾回收器无法处理 解决方案:定义finalize()方法 finalize必须与内存相关,因为垃圾回收器只与内存有关 垃圾回收期准备释放对象的内存 调用finalize方法 在下一次垃圾回收动作发生时,真正回收对象占用的内存 垃圾回收器的工作方式引用计数法 当有引用连接至对象时,引用计数+1 当引用离开作用域或者被置为null,引用计数-1 缺陷 如果对象间存在循环引用,可能出现对象应该被回收,但引用计数不为0 工作量极大,速度极慢 对任何活的对象,一定能最终追溯到其存活的堆栈或静态存储区之中的引用 实现方法 停止-复制法 暂停程序运行,将所有的活对象复制到一个新的堆内,没有被复制的都是垃圾,在新堆上,对象紧密排列 效率低,内存开销大 当只有少量的垃圾,较为浪费 标记清扫法 每找到一个活的对象,进行标记,没有被标记的被清扫 自适应 JVM监视,如果所有对象很稳定,采用标记清扫,如果出现很多碎片,采用停止复制 分代 内存分配以块为单位 大型对象会单独占用一个块 每个块有相应代数记录是否存活 垃圾回收器对上次回收动作后新分配的块进行整理,对处理大量短命的对象很有效果 定期进行清扫,大型对象不会被清扫(代数增加),内涵小型对象的块会被复制整理 即时编译器JIT 将程序全部或者部分翻译成机器码 当装载某个类 寻找.class文件,将该文件字节码装入内存 ###有两种方案 JIT编译全部代码 缺陷 加载动作散落在整个程序生命周期 增加可执行代码的长度,降低速度 ###方案二 惰性评估 JIT只在必要的时候编译代码 ###成员初始化 #构造器与垃圾收集器 内存区域 堆:对象的生存空间 实例变量–声明在类里面而不是方法里 栈:方法调用和变量的生存的空间 局部变量 在方法里使用Duck d=new Duck();d在栈里,因为他是对象的引用,d所引用的对象在堆里面 方法进入栈的方式 调用一个方法,方法会被放在调用栈的栈顶, 如果该方法要调用另一个方法,则该另一个方法会放在原方法的上面 放在栈上的方法是一个堆栈块,带有方法的状态\执行到哪一段程序及所有的局部变量 对象生命周期 当对象的引用全部消失,以及无法取得对象的引用,那么符合垃圾回收器的条件 对象引用可以是Null,但是对null操作是运行时异常,所有编译器没有问题]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初遇MVC]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E5%88%9D%E9%81%87MVC%2F</url>
    <content type="text"><![CDATA[代码设计DAO层 主要做数据持久层的工作，负责与数据库联络的一些任务 首先设计dao层的接口，定义实现该接口的实现类 使用该接口进行数据业务的处理，并不关心具体实现是哪个类 service层 服务层，负责业务模块的应用逻辑应用设计，封装业务逻辑 所有的逻辑应当放到service中 编写具体的业务处理，更接近于具体的业务功能的要求，应当是一个可以 对外提供的功能，比如核对商品，查询库存等 设计接口，再设计实现类 调用接口进行业务处理 controller层 控制器，负责具体业务流程的控制，这一层应该写一些业务的调度代码 调用service层的接口来控制业务流程 View层关联 Service层是建立在DAO层之上的，建立了DAO层后才可以建立Service层，而Service层又是在Controller层之下的 Service层应该既调用DAO层的接口，又要提供接口给Controller层的类来进行调用，它刚好处于一个中间层的位置 每个模型都有一个Service接口，每个接口分别封装各自的业务处理方法。 DAO层，Service层这两个层次都可以单独开发，互相的耦合度很低，完全可以独立进行，Controller，View层因为耦合度比较高，因而要结合在一起开发 异常 异常的作用是更好地发现问题并解决问题 要在每一层进行try catch，将异常抛出，通知出现什么问题，并进行友好提示给用户 当使用了ExceptionHandle进行异常的统一处理，异常不断往外抛，最后会交给excepHandle进行处理 Spring只会对RuntimeException进行事务回滚 在程序当中定义自己的异常，将系统异常与逻辑异常区分 错误码code和错误信息Msg的统一管理，使用枚举]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springMVC</tag>
        <tag>代码设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaBase：Inherit]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E7%BB%A7%E6%89%BF%E4%B8%8E%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[继承 java虚拟机对待继承时,会在类先寻找该方法,如果找不到,就找它的父类,依次寻找上级直到找到为止 继承关系可以通过is-a关系检验 public成员会被继承,private成员不会被继承 子类与父类的联系 子类不能访问父类的私有变量,但是!!!子类在创建的时候,还是有初始化父类的私有变量的 当初始化的时候,子类会创建子类,父类以及object类的对象,并会把父类和object类包含在内部,(还是一个对象) 阻止继承：final类与方法 使用final可以使得类无法被继承，同时，也会使得方法无法被子类覆盖 final类中的所有的方法自动成为final方法 final类中的域不会自动final 举例String类就是一个final类，如果存在一个String的引用，它引用的一定是一个String，而不可能是其他的，因为它没有子类 为什么要使用确保不会在子类中改变语义 proteced受保护访问希望超类中的某些方法允许被子类访问，或允许子类的方法访问超类的某个域，则将其定义为proteced，则子类可以直接访问 注意 C#中(Java应该一样)虽然private成员不会被继承,但是可以继承public方法,以此去访问成员, 但是子类是没有那个private成员的!!!!,它没法继承那个成员,它所得到的只是通过继承父类的public方法,以该方法去访问那个成员 Object所有类的超类所有类的超类都是object，每个类都是由它扩展而来的 equals方法 检验一个对象是否等于另一个对象 而原生的方法判断的是对象的两个引用是否引用的是同一个对象。所以一般较没有意义 而经常需要的equals方法是判断其属性等方法是否一致，因此这些时候需要对equals进行重写 hashCode方法 hashCode是对象的存储地址，如果两个对象不相同，那么他们的code也不会相同 字符串的code是根据内容导出的 关于继承和组合 组合：使用现有的类合成一个新的类 聚合：动态的进行组合 如何选择继承和组合 组合相对于继承更为灵活，过分地使用继承会导致设计过分地复杂，而且并不清晰 建议在同样可行的情况下，优先使用组合而不是继承。因为组合更安全，更简单，更灵活，更高效。 问一问自己是否需要从新类向基类进行向上转型。如果是必须的，则继承是必要的。反之则应该好好考虑是否需要继承。 只有当子类真正是超类的子类型时，才适合用继承。换句话说，对于两个类A和B，只有当两者之间确实存在is-a关系的时候，类B才应该继续类A。 优缺点组合优点： 不破坏封装，整体类与局部类之间松耦合，彼此相对独立 具有较好的可扩展性 支持动态组合。在运行时，整体对象可以选择不同类型的局部对象 整体类可以对局部类进行包装，封装局部类的接口，提供新的接口 组合缺点： 整体类不能自动获得和局部类同样的接口 创建整体类的对象时，需要创建所有局部类的对象 继承优点： 子类能自动继承父类的接口 创建子类的对象时，无须创建父类的对象 继承缺点： 破坏封装，子类与父类之间紧密耦合，子类依赖于父类的实现，子类缺乏独立性 支持扩展，但是往往以增加系统结构的复杂度为代价 不支持动态继承。在运行时，子类无法选择不同的父类 抽象类abstract类 抽象类可以包含具体的数据与方法，抽象方法起到一个占位的作用 对象包装器与自动装箱将int等基本数据类型转换为对象，有Integer类等 对象包装器类是不可变的类，一旦构造了之后，其值便无法改变，并且，对象包装器是final类 自动装箱与拆箱自动装箱：list.add(3)将转变为list.add(Integer.valueOf(3)) 自动拆箱：int a =list.get(i)，将自动转换为int a=list.get(i).intValue() 参数数量可变的方法使用… 1234567/** *在这里面，value是一个数组，可以传入多个参数 * 可以调用max(-1,2,3) */public double max(double... value)&#123; &#125; 反射反射定义能够分析类能力的程序称为反射 反射的作用 在运行时分析类的能力 在运行时查看对象，例如，编写一个toString供所有方法使用 实现通用的数组操作代码 利用method对象 Class类java运行时系统始终为所有的对象维护一个被称为运行时的类型标识 接口接口用于描述类的功能 接口的实现 使用 Interface关键字 可以定义常量（public static final），但是不能定义实例域 在SE8之后可以定义方法，但是不能使用实例域，因为没有实例 默认方法为接口的方法提供一个默认的实现 1234567/** * 所有继承了该接口的方法，如果没有重写该方法，则会使用默认实现 * 可以将全部方法声明为默认实现，则就只需要去重写真正需要的方法 */default int compareTo(T other)&#123; return 0;&#125; 实现“接口演化” 如果为一个接口新增了一个方法，那么所有实现该接口的类都要去覆盖这个方法，就会导致旧版代码的不兼容性。 使用默认实现，则以前的类并不需要去覆盖该方法，只有有需求的类才会去覆盖 实现了接口就履行了合约1.履行合约的方式是去定义相关的方法2.履行了合约,即可去实现与合约相关的动作,实现类似继承和多态 对象克隆Cloneable接口克隆一个对象并不能简单的让一个引用去等于另一个引用，因为它们将指向同一个对象。 若想让它们在初始状态相同，而在之后会发生独立的改变，则需要对对象进行克隆。 若想对对象进行克隆，则需要使用clone方法，clone方法是Object的一个protected方法，因此，假设有Employee类，则只有Employee类才能clone Employee类。 克隆的困难 如果类本身只有一些基础数据类型，则clone并无问题 如果类里面存在着对其他对象的引用，那么拷贝便会将子类的引用拷贝过去，那么便会是不安全的浅层拷贝，并没有完全的独立 实现深克隆需要实现Cloneable接口 抽象类1.某些类根本无法初始化,比如说animal类,那类似于这种应该作为一个抽象类abstract,或者说是一个接口2.抽象类可以拥有抽象方法和非抽象方法3.抽象方法没有实体 关于引用的一些问题1234ArrayList&lt;Object&gt; myDogArrayLust = new ArrayList&lt;Object&gt;(); Dog aDog =new Dog(); MyDogArrayList.add(aDog); Dog d=myArrayList.get(0);!!!!报错 解析1.不管放进去了什么,出来也只是Object,除非使用了泛型,标明了类型2.传递过程,传递进去一个Dog类型,然后由于参数是Object,父类引用子类,成功add,但是取出的时候, return的参数也是Object3.因此说,里面确实存放的是一个包含Dog属性的类型,但是获取的却是一个Object的引用,那么根据多态,子类是无法引用父类的4.同样,如果调用一个.eat()方法,那么首先这是一个Object类型的引用,编译器会去寻找Object类及其父类(当然是没有了)的eat()方法,很明显的问题,是不存在的5.因为对于编译器来说,当你传递进去的时候,它是它原来的类型,取出来的时候,它确实是一个Object类型,而不是引用了其他类型,编译器只根据引用的类型,而不是对象的类型 强制类型转换使用instanceof可以检验是否可以成功转换类型o instanceof Dog转换成功返回true]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaBase：Base]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2Fbase%2FJavaBase%EF%BC%9A%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[面向对象关于面向对象的程序设计模式对象:对象具有状态,行为,标识.意味着每一个对象都可以拥有内部数据（对象的状态）和方法（对象的行为），每一个对象在内存当中都有一个地址 万物皆为对象. 对象可以存储数据,可以在自身上执行操作. 是指可以抽取问题当中的任何概念化的构件(一个生物,一个建筑零件,一项服务),将其表示为程序当中的对象. 程序是对象的集合,通过发送消息来告知彼此所要做的 要请求一个对象,就要对对象发送一条信息 消息是对象或对象的方法调用的请求 每个对象度有自己的由全体对象所构成的存储 每个对象都拥有其类型 每个对象都有一个类,对象是类的实例 类区别于其他类的最重要的特性就是可以发送什么信息给它 某一特定类型的缩影对象度可以接受相同的消息 圆形是几何形,那么可以接受几何形的消息 程序设计对象是服务的提供者程序本身向用户提供服务，它将调用其他对象提供的服务来实现这一目的。 SE基础对象与类比较对象是否相等引用相等 hashCode()默认的行为会返回每个对象特有的序号,(根据内存位置计算) 比较引用相等,则可以比较hashcode(不能是重写过的) 对象相等 重写equals和hashcode,保证有相同对象有相同的hashcode,进行equals会返回true 对象状态准则 如果两个对象相等,则hashcode必须相等 如果两个对象相等,则equals返回true 如果两个对象有相同的hashcode则它们不一定相等 如果equals被覆盖,则hashcode必须被覆盖 hashcode默认是对heap上对象产生独特的值,如果没有覆盖,两个对象的hashcode不可能相同 equals默认是执行==,判断是否引用heap上同一个对象,若没有覆盖,则两个对象永不相同 断言 assert(height&gt;0); true执行 false抛出assert异常 只有在打开断言时,断言才会成功运行,否则没有影响 断言可以运来进行debug 静态 final修饰 修饰方法:可以防止方法被覆盖 修饰类:可以防止方法被继承 如果不想写System,使用import static java.lang.System.out,那么就可以out.println 泛型T和E集合基础 集合的类型检查只会发生在编译期间 数组的类型检查会发生在运行期间 集合使用泛型参数 对方法的参数设置为一个ArrayList,那么不能传进去一个ArrayList 因为当传入后者,方法可以认为该集合是animal,那么可以传入一个cat,问题是这样破坏了泛型 解决方法 使用万用字符 注意:下面的extends可以表示接口 ArrayList&lt;? extends Animal&gt;(使用了万用字符,你无法在方法内对list添加任何值) ArrayList同理 使用T: public void take(ArrayList one) hashset集合检查重复 检验hashcode true则检验equals true则判断相同,拒绝加入集合 寻值方式 利用hashcode寻找,速度较快,它会通过对象的hashcode来计算找到对象的地址 继承,多态,接口,抽象类 java虚拟机对待继承时,会在类先寻找该方法,如果找不到,就找它的父类,依次寻找上级直到找到为止 继承关系可以通过is-a关系检验 public成员会被继承,private成员不会被继承 方法可变参数列表]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志与异常处理]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2F%E6%A1%86%E6%9E%B6%2F%E6%97%A5%E5%BF%97%E4%B8%8E%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[@Slf4j如果不想每次都写private final Logger logger = LoggerFactory.getLogger(XXX.class); 可以用注解@Slf4j 日志 org.slf4j.Logger private final static Logger logger= LoggerFactory.getLogger(HttpAspect.class); info方法 error方法等 获取URL method IP 类方法 参数 @Before(&quot;log()&quot;) public void dolog(JoinPoint joinPoint){ ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); //url logger.info(&quot;url={}&quot;,request.getRequestURL()); //method logger.info(&quot;method={}&quot;,request.getMethod()); //ip logger.info(&quot;ip={}&quot;,request.getRemoteAddr()); //类方法 logger.info(&quot;classMethod={}&quot;,joinPoint.getSignature().getDeclaringTypeName()+&quot;.&quot;+joinPoint.getSignature().getName()); //参数 logger.info(&quot;args={}&quot;,joinPoint.getArgs()); }统一异常处理 规范JSON格式 新建一个Result的类，建立code,data等数据域 新建工具类ResultUtil，编写静态方法：Error,Success等]]></content>
  </entry>
  <entry>
    <title><![CDATA[初学restful]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F%E5%88%9D%E5%AD%A6restful%2F</url>
    <content type="text"><![CDATA[** Springboot 实现 Restful 服务，基于 HTTP / JSON 传输 ** restful API定义 RESTful（Representational State Transfer）架构风格，是一个Web自身的架构风格，底层主要基于HTTP协议（ps:提出者就是HTTP协议的作者），是分布式应用架构的伟大实践理论。 RESTful架构是无状态的，表现为请求-响应的形式，有别于基于Bower（浏览器）的SessionId不同。 详解资源 资源是指服务器，将服务器看作是由很多离散的资源组成 资源是一个抽象的概念，可以代表服务器上的一个文件，一张表等等等 一个资源可以由1或多个URL表示，URL既是资源的名称，也是资源的地址 资源的表述 是一段对资源在某个特定时刻的状态的描述，可以在客户端-服务器端交换 形式:HTML,XML,JSon,文本，音频等等 状态的转移 在客户端和服务器端之间转移（transfer）代表资源状态的表述。通过转移和操作资源的表述，来间接实现操作资源的目的 统一接口 REST要求必须通过统一的接口对资源进行各种操作 对于资源执行的操作，其操作语义必须由HTTP消息体之前的部分完全表达，为了提高交互的可见性，以便于通信链的中间组件实现缓存、安全审计等等功能。 以HTTP/1.1协议为例 7个HTTP方法：get/post/put/delete/patch/head/options HTTP头信息 HTTP响应状态代码 一套标准的内容协商机制 一套标准的缓存机制 一套标准的客户端身份认证机制 超文本驱动 又名“将超媒体作为应用状态的引擎”（Hypermedia As The Engine Of Application State Rest API 权限控制Rest的权限控制是比较重要的，因为它是无状态的，那么就需要对每次请求进行认证和授权 认证身份认证，即登录验证用户是否拥有相应的身份。简单的说就是一个Web页面点击登录后，服务端进行用户密码的校验。 权限验证（授权）验证该身份具体拥有某种权限。即针对于某种资源的CRUD,不同用户的操作权限是不同的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：单元测试]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2F%E6%A1%86%E6%9E%B6%2FSpringBoot%EF%BC%9A%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[进行模块测试单元测试有责任的开发人员都应该写单元测试 对项目进行打包的时候会自动执行单元测试 mvn clean package测试内容： service API 代码最终效果 模拟mockMvc对API进行测试 对spring-boot的Test进行简单的整理 实现基础环境搭建首先要对类有一个注解 1234//在JUnit中有很多个Runner，他们负责调用你的测试代码，每一个Runner都有各自的特殊功能，@RunWith(SpringRunner.class)@SpringBootTestpublic class BaseControllerTest&#123; 对一些常见的test注释的介绍 1234567891011/** * 注解详解: * * @BeforeClass :所有测试方法前执行一次，一般在其中写上整体初始化的代码 * @AfterClass 在所有测试方法后执行一次，一般在其中写上销毁和释放资源的代码 * @Test(timeout = 1000) 测试方法执行超过1000毫秒后算超时，测试将失败 * @Test(expected = Exception.class) 测试方法期望得到的异常类，如果方法执行没有抛出指定的异常，则测试失败 * @Ignore(“not ready yet”) 执行测试时将忽略掉此方法，如果用于修饰类，则忽略整个类 * @Test 编写一般测试用例 * @Transactional，test对数据库进行操作时，可以在测试过后回滚数据库状态，因此仅仅只是测试 */ 对service进行测试这个是比较简单的，和常规的没有什么差别 有一个需要注意的点是事务方面，需要添加注释@Transactional，这样的话，如果进行了数据库的操作，那么就会进行回滚 对API进行测试想要对API进行测试 首先需要对类加一个新的注释@WebAppConfiguration 1234@RunWith(SpringRunner.class)@SpringBootTest@WebAppConfigurationpublic class BaseControllerTest &#123; 要模拟创建一个mock的环境 123@Autowiredprivate WebApplicationContext context;private MockMvc mockMvc; 同时，有了变量之后，是没有初始化的，这个时候要用到@Before，在测试前进行初始 123456789/** * 构造mockMvc,初始化mock * * @throws Exception */@Beforepublic void setUp() throws Exception &#123; this.mockMvc = MockMvcBuilders.webAppContextSetup(context).build();&#125; 环境搭建好了，那么接下来进行一手mock，注释在里面写好了，这个方法将参数写在了里面 对参数的解析使用了json-path，需要添加pom 12345&lt;!--用于检测JSON格式的响应数据--&gt;&lt;dependency&gt; &lt;groupId&gt;com.jayway.jsonpath&lt;/groupId&gt; &lt;artifactId&gt;json-path&lt;/artifactId&gt;&lt;/dependency&gt; 接下来开始真正的代码 123456789101112131415161718192021222324252627282930/** * 进行参数的请求,模拟mock * * @throws Exception */@Testpublic void getMap() throws Exception &#123; //调用接口 MvcResult result = (MvcResult) mockMvc //使用get方法 .perform(get("/test/get") .contentType(MediaType.APPLICATION_JSON_UTF8) //传入参数 .param("userId", "11"). param("userName", "henry") //接收的类型 .accept(MediaType.APPLICATION_JSON)) //判断接收到的状态是否是200 .andExpect(status().isOk()) //打印内容 .andDo(print()) .andExpect(content().contentType(MediaType.APPLICATION_JSON_UTF8)) //匹配返回值中的内容 .andExpect(content().string(Matchers.containsString("OK"))) //使用jsonPath解析返回值，判断具体的内容 //需要学习jsonpath .andExpect(jsonPath("$.errcode", is(0))); int statusCode = result.getResponse().getStatus(); Assert.assertEquals(statusCode, 200);&#125; 在实际中，有可能参数是一个类 12345678910111213141516171819202122232425262728/** * 测试添加用户接口 * * @throws Exception */@Testpublic void testAddUser() throws Exception &#123; //构造添加的用户信息 UserInfo userInfo = new UserInfo(); userInfo.setName("testuser2"); userInfo.setAge(29); userInfo.setAddress("北京"); ObjectMapper mapper = new ObjectMapper(); //调用接口，传入添加的用户参数 mockMvc.perform(post("/user/adduser") .contentType(MediaType.APPLICATION_JSON_UTF8) //将整个userInfo当做参数传入 .content(mapper.writeValueAsString(userInfo))) .andExpect(status().isOk()) //使用jsonPath解析返回值，判断具体的内容 .andExpect(content().contentType(MediaType.APPLICATION_JSON_UTF8)) //判断返回值，是否达到预期， //测试示例中的返回值的结构如下&#123;"errcode":0,"errmsg":"OK","p2pdata":null&#125; .andExpect(jsonPath("$.errcode", is(0))) .andExpect(jsonPath("$.p2pdata", notNullValue())) .andExpect(jsonPath("$.p2pdata.id", not(0))) .andExpect(jsonPath("$.p2pdata.name", is("testuser2")));&#125; 注解类注解 @RunWith(SpringRunner.class)//底层junit测试工具,在测试环境跑 @SpringBootTest //启动整个Spring的工程 方法注解 @Test @Transactional，test对数据库进行操作时，可以在测试过后回滚数据库状态，因此仅仅只是测试 对service测试自己编写方法测试 test文件夹下，新建用于测试的.java文件 添加注解 右键Run 该test类 或者 指定的方法 进行测试 显示test passed 则测试成功，test failed 则测试失败 使用IDE 选中测试的方法，点击GoTo，点击Test 点击create 默认会写好方法注释@Test,但是没类注释 对API测试 可以测试的内容： URL 返回的内容 示例 添加类注释和方法注释 添加新的类注解@AutoConfigureMockMvc 注入MockMvc类 使用mvc.perform进行URL请求测试 mvc.perform(MockMvcRequestBuilders.get(“/grils”)) 请求的路径 .andExpect(MockMvcResultMathers.status().isOk())对返回的状态码进行判断 .andExpect(MockMvcResultMathers.content().string(“abc”));对返回的内容进行判断，是否等于abc 判断是否成功 使用断言，如查询一个对象是否存在Assert.assertNotNull(result); 参考 springboot项目中使用MockMvc 进行测试 SpringMVC 测试 mockMVC]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[controller心得]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2F%E6%A1%86%E6%9E%B6%2Fcontroller%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[Controller@Controller 处理HTTP请求 需要配合模板使用,类似于JSP等，不常用模板： 导入包 spring-boot-starter-thymeleaf 新建resoucres.templates.index.html 方法当中return “index” @RestControllerSpring4之后新加的注解，返回JSON @RequestMapping 配置URL映射 对应于两个URL，使用集合{“/hello”，”/hi”} 使用method确认提交方式（GET等） 使用GetMapping,PostMapping @PathVariable 获取URL中的数据 URL路径为say/ID 认为设定Mapping路径{ID}/say @RequestParam 获取请求参数的值 /say?id=100 value=”id”,required=false,defaultValue=”100”,不必然传值，默认值为100 可以写一个对象获取请求参数@GetMapping 组合注解 最简单的HelloWorld/** * Spring Boot HelloWorld案例 * * Created by bysocket on 16/4/26. */ @RestController public class HelloWorldController { @RequestMapping(&quot;/&quot;) public String sayHello() { return &quot;Hello,World!&quot;; } } @RestController：提供实现了RESTAPI，可以服务JSON,XML或者其他。这里是以String的形式渲染出结果 @RequestMapping：提供路由信息，”/“路径的HTTP Request都会被映射到sayHello方法进行处理。]]></content>
      <categories>
        <category>Soring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bootDao]]></title>
    <url>%2F2018%2F09%2F23%2FJava%2F%E6%A1%86%E6%9E%B6%2FDao%2F</url>
    <content type="text"><![CDATA[数据库操作 使用Mysql和Spring-Data-Jpa Spring-Data-Jpa是对Hibernate的整合 JPA定义了一系列对象持久化的标准 实现了这一标准的产品有Hibernate等 数据库配置 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/boot username: root password: 123456 jpa: hibernate: ddl-auto: create show-sql: true ddl-auto create：每次删除表，然后创建一个新表 update：如果存在数据，则会保留数据 validate:验证表里面的属性是否与结构一致，不一致则报错 数据库操作 基于JPA进行操作 JpaRepository&lt;Gril,Integer&gt; Gril为类型，Integer为主键ID的类型 查 基于主键查询全部记录findAll方法 grilRepository.findAll()查询单个记录findOne(id)方法 基于其他在JPA接口当中定义方法 findBy’某字段’，例如 public List findByAge(Integer age)调用方法 findByAge(age) 增增加一个记录save方法，返回值为添加的对象 grilRepository.save() 删删除一个记录delete方法，返回空 改更新一个记录save方法 事务@Transactional]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：Start]]></title>
    <url>%2F2018%2F09%2F22%2FJava%2F%E6%A1%86%E6%9E%B6%2FspringBoot%EF%BC%9A%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[基础搭建运行环境- JDK 7 或 8及以上 - Maven 3.0+ - 编译器：IDEA搭建可参考课程 配置自动化配置 spring boot相比较于Spring是做了一些约定，对于Spring所需要的配置，它进行了默认的配置，可以适应大多数的业务场景 多环境配置 文件application-{}.properties对应不同的环境的配置文件。 使用语句调用不同的配置文件 spring.profiles.active=dev 路径配置为所有的URL添加前缀： server: servlet: context-path: /api自定义配置Spring的配置有一个配置的优先级 命令行参数 java:comp/env 里的 JNDI 属性 JVM 系统属性 操作系统环境变量 RandomValuePropertySource 属性类生成random.* 属性 应用以外的 application.properties（或 yml）文件 打包在应用内的 application.properties（或 yml）文件 在应用 @Configuration 配置类中，用@PropertySource 注解声明的属性文件 SpringApplication.setDefaultProperties 声明的默认属性 踩坑 关于中文，properties在配置中文值会出现乱码，因为编码是 iso-8859，可以改用yml进行配置 关于yml其配置方法与properties不太一样，特此说明 home: province: 浙江省 city: 温岭松门 desc: 我家住在${home.province}的${home.city} 运行启动类123456789101112/** * Spring Boot应用启动类 * * Created by bysocket on 16/4/26. */@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args);&#125;&#125; @SpringBootApplication：Spring Boot 应用的标识 Application很简单，一个main函数作为主入口。SpringApplication引导应用，并将Application本身作为参数传递给run方法。具体run方法会启动嵌入式的Tomcat并初始化Spring环境及其各Spring组件。 跑起来 在IDEA当中Spring的运行是有一个专门的SpringBoot运行方法 运行端口默认为8080，修改端口的路径为src/main/resources/application.properties,修改server.port=8888即可 参考 2小时学会Spring Boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Start</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nutz：Start]]></title>
    <url>%2F2018%2F04%2F19%2FJava%2F%E6%A1%86%E6%9E%B6%2Fnutz%2F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[解读nutzbook问题 为什么只能用jetty我想用tomcat,端口只能是8080,,我日 ##模块类每一个声明了入口函数的模块类都是一个子模块,可以在主模块上进行注册 ##IocIoc目前的了解是将所需要的对象在合适的时候通过ioc获取,不许要去导入很多的包 ##URL路径 注解有继承关系,@At在类上声明会继承给子方法 web.xml配置 &lt;filter&gt; &lt;filter-name&gt;nutz&lt;/filter-name&gt; &lt;filter-class&gt;org.nutz.mvc.NutFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;modules&lt;/param-name&gt; &lt;param-value&gt;com.mine.app.MainModule&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;!-- *.XXX 忽略后缀 --&gt; &lt;!-- /XX/* 忽略前缀 --&gt; &lt;!-- /cc 忽略固定路径 --&gt; &lt;!-- 下面的例子忽略了html和ftl后缀, 忽略了/rs/和/druid/前缀,和忽略了固定路径/abc/notaction --&gt; &lt;param-value&gt;*.html,*.ftl,/rs/*,/druid/*,/abc/notaction&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; web.xml的welcome页面不仅可以通过声明welcome里面的html页面,也可以通过入口函数来标注,比如@At(“/index”), filter-name声明了过滤器的名称 class待定 param说明了filter回去哪个module param-value具体的适配模式 数据库建设SetupDao dao = ioc.get(Dao.class); Daos.createTablesInPackage(dao, &quot;net.wendal.nutzbook&quot;, false); 声明了数据库从哪里去获取POJO,在主模块上标注setup(在主模块上标注的主要作用) POJO 一个普通的javabean,有一个简单的运算属性也是可以的,但不允许有业务方法,也不能携带有connection之类的方法 @Table声明成为一个数据库信息,@View的作用不是很清楚 UserModule @Inject注入 @Filter路径过滤,可以重写,可以继承 视图 这个注解很有意思@Filters(@By(type=CheckSession.class, args={“me”, “/“})) // 检查当前Session是否带me这个属性]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Nutz</tag>
        <tag>Strat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%99%2FHexo%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[新博客新建页面 git bash下，定位到 Hexo 站点目录下。 使用 hexo new page 新建一个页面，命名为 tags ：即 hexo new page tags 或者hexo new posts “” 新建一个文章 ，默认为posts,即在post文件夹下面新建 或者hexo new draft 新建一个草稿，hexo publish 可以将草稿移到post当中，{hexo publish [layout] } 在source/_posts/路径下即可见 文章的头部： title: postName #文章页面上的显示名称，一般是中文 date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改 updated: 2017-09-05 20:18:54 #手动添加更新时间 type: &quot;tags&quot; #类型设置为 tags ，主题将自动为这个页面显示标签云 categories: 默认分类 #分类 tags: #文章标签，可空，多标签请用格式，注意:后面有个空格 - tag1 - tag2 - tag3 description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面 comments: false #如果集成了评论，则关闭评论使文章显示部分内容部署 hexo generate 简写hexo g 生成静态页面 hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 hexo deploy 简写hexo d 将内容部署到网站 hexo publish 发布内容，实际上是将内容从drafts（草稿）文件夹移到posts（文章）文件夹。 hexo server 简写hexo s 启动服务器，默认情况下，访问网站为http://localhost:4000/ 步骤： n c s g d n：新建文件，c：清理缓存，g：生成静态，d：部署 内容标签Bootstrap Callout 这些样式出现在http://getbootstrap.com/ 中。 使用方式 Content (md partial supported) class_name 可以是以下列表中的一个值： default primary success info warning danger 文本居中的引用 此标签将生成一个带上下分割线的引用，同时引用内文本将自动居中。 文本居中时，多行文本若长度不等，视觉上会显得不对称，因此建议在引用单行文本的场景下使用。 例如作为文章开篇引用 或者 结束语之前的总结引用。 使用方式 HTML方式：使用这种方式时，给 img 添加属性 class=”blockquote-center” 即可。 标签方式：使用 centerquote 或者 简写 cq。 blah blah blah blah blah blah blah blah blah 突破容器宽度限制的图片 当使用此标签引用图片时，图片将自动扩大 26%，并突破文章容器的宽度。 此标签使用于需要突出显示的图片, 图片的扩大与容器的偏差从视觉上提升图片的吸引力。 使用方式 HTML方式：使用这种方式时，为 img 添加属性 class=”full-image”即可。 标签方式：使用 fullimage 或者 简写 fi， 并传递图片地址、 alt 和 title 属性即可。 属性之间以逗号分隔。 插件Hexo-adminHexo-admin插件允许我们直接在本地页面上修改文章内容。 下载npm i hexo-admin –save 查看，登录http://localhost:4000/admin即可看到我们所有的文章内容，并且在可视化界面中操作文章内容 VuePress参考 为你的Hexo加上评论系统-Valine]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nutz：Log]]></title>
    <url>%2F2018%2F04%2F18%2FJava%2F%E6%A1%86%E6%9E%B6%2Fnutz%2FNutzLog%2F</url>
    <content type="text"><![CDATA[日志相关资源扫描的LOG​ 2015-03-30 10:49:49,383 org.nutz.resource.Scans.(Scans.java:484) DEBUG - Locations for Scans:​ [JarResourceLocation [jarPath=D:\nutzbook\apache-tomcat-8.0.20\bin\bootstrap.jar], JarResourceLocation [jarPath=D:\nutzbook\apache-tomcat-8.0.20\bin\tomcat-juli.jar], JarResourceLocation [jarPath=D:/nutzbook/workspace/.metadata/.plugins/org.eclipse.wst.server.core/tmp0/wtpwebapps/nutzbook/WEB-INF/lib/nutz-1.b.52.jar], FileSystemResourceLocation [root=D:\nutzbook\eclipse], FileSystemResourceLocation [root=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\classes]]​ 2015-03-30 10:49:49,510 org.nutz.resource.Scans.init(Scans.java:75) DEBUG - Locations for Scans:​ [JarResourceLocation [jarPath=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\lib\nutz-1.b.52.jar], JarResourceLocation [jarPath=D:\nutzbook\apache-tomcat-8.0.20\bin\bootstrap.jar], JarResourceLocation [jarPath=D:\nutzbook\apache-tomcat-8.0.20\bin\tomcat-juli.jar], JarResourceLocation [jarPath=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\lib\log4j-1.2.17.jar], JarResourceLocation [jarPath=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\lib\mysql-connector-java-5.1.34.jar], JarResourceLocation [jarPath=D:/nutzbook/workspace/.metadata/.plugins/org.eclipse.wst.server.core/tmp0/wtpwebapps/nutzbook/WEB-INF/lib/nutz-1.b.52.jar], FileSystemResourceLocation [root=D:\nutzbook\eclipse], JarResourceLocation [jarPath=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\lib\druid-1.0.13.jar], FileSystemResourceLocation [root=D:\nutzbook\workspace.metadata.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\nutzbook\WEB-INF\classes]]​ 2015-03-30 10:49:49,618 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 1 resource by src( ioc/ ) , regex( ^(.+[.])(js|json)$ )​ 2015-03-30 10:49:49,625 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 4 resource by src( net/wendal/nutzbook/ ) , regex( ^.+[.]class$ )​ 10:49:50,070 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 4 resource by src( net/wendal/nutzbook/ ) , regex( ^.+[.]class$ ) 解析 第一条是非Mvc环境下的Scans初始化的日志, 因为Scans类在加载时会先进行自我初始化(找到tomcat等包) 第二条,是设置ServletContext后,Scans类重新初始化,可以看到找到了Web环境下的classes目录和相关的jar包(找到nutz\mysql的jar包,一些环境变量的配置) 第三条,是Ioc扫描js配置文件时输出的日志DEBUG - Found 1 resource by src( ioc/ ) , regex( ^(.+[.])(js|json)$ ) 代表在ioc目录下找到1个匹配的文件. 注意,这里的”ioc/“是指classpath下的ioc目录,这点非常重要 第四条,是@Modules注解所配置的scanPackage=true所触发的入口类扫描. 强调再强调, 注解只是配置信息,自身无代码操作.注解的实际作用,是取决与读取注解的代码如何理解这个注解,而跟这个注解具体的名字,属性是没有相关性的. 第五条,是Ioc扫描注解配置的log.(扫描到了配置@Iocbean的类)需要明白的几个点 Modules跟Ioc扫描注解,是2个不同的动作, 因为Nutz中的Mvc与Ioc是分离的, 一个Module类并不强制为一个Ioc对象,反之也是. 注解只是配置信息. 如果没有代码去读取注解中的配置信息,这个注解是不会有意义的. 容器重要信息的LOG​ 2015-03-30 10:49:49,525 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:55) INFO - Nutz Version : 1.r.59​ 2015-03-30 10:49:49,525 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:56) INFO - Nutz.Mvc[nutz] is initializing …​ 2015-03-30 10:49:49,525 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:60) DEBUG - Web Container Information:​ 2015-03-30 10:49:49,526 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:61) DEBUG - - Default Charset : UTF-8​ 2015-03-30 10:49:49,526 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:62) DEBUG - - Current . path : D:\nutzbook\eclipse.​ 2015-03-30 10:49:49,526 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:63) DEBUG - - Java Version: 1.8.0_112​ 2015-03-30 10:49:49,526 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:64) DEBUG - - File separator : ​ 2015-03-30 10:49:49,527 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:65) DEBUG - - Timezone: Asia/Shanghai​ 2015-03-30 10:49:49,527 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:66) DEBUG - - OS : Windows 7 amd64​ 2015-03-30 10:49:49,527 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:67) DEBUG - - ServerInfo : Apache Tomcat/8.0.20​ 2015-03-30 10:49:49,528 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:68) DEBUG - - Servlet API : 3.1​ 2015-03-30 10:49:49,528 org.nutz.mvc.impl.NutLoading.load(NutLoading.java:70) DEBUG - - ContextPath : /nutzbook​ 2015-03-30 10:49:49,529 org.nutz.mvc.impl.NutLoading.createContext(NutLoading.java:217) DEBUG - &gt;&gt; app.root = D:/nutzbook/workspace/.metadata/.plugins/org.eclipse.wst.server.core/tmp0/wtpwebapps/nutzbook ###解析 第一条, Nutz版本信息, 一般来说,默认回答问题都是按最新版来考虑 第二条, 注意中括号里面值,这个值就是web.xml中NutFilter的名字(mvc初始化) 第三条, 就是个抬头 第四条, 默认编码,非常非常非常非常重要,请按之前的准备章节的配置,这里必然是UTF-8,不然,请检查人品,不行就充值一下吧 第五条, 当前.路径,也就是当前工作目录, 通常配错log4j文件输出路径的时候,就可以到这里找了 第六条, Java的版本号, 有时候系统装了N个JDK,这里就能看出来到底用了啥 第七条, 文件路径分隔符,拼路径的时候有用 第八条, 操作系统的信息 第九条, Web容器的信息, Apache Tomcat/8.0.20 多明白的信息,哈哈 第十条, Servelt API的版本号,一般依赖于Web容器的版本 第十一条, ContentPath, 也就是在${base}所指代的值,如果是ROOT应用,这里就是空字符串 第十二条, 该web项目在tomcat中的真实路径,有时候说某某资源找不到,到这个目录下确认之 IOC初始化的LOG​ 2015-03-30 10:49:49,603 org.nutz.mvc.impl.NutLoading.createIoc(NutLoading.java:354) DEBUG - @IocBy(type=org.nutz.mvc.ioc.provider.ComboIocProvider, args=[“js”, “ioc/“, “anno”, “net.wendal.nutzbook”, “*tx”])​ 2015-03-30 10:49:49,618 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 1 resource by src( ioc/ ) , regex( ^(.+[.])(js|json)$ )​ 2015-03-30 10:49:49,618 org.nutz.ioc.loader.json.JsonLoader.(JsonLoader.java:44) DEBUG - loading ioc js config from [dao.js]​ 2015-03-30 10:49:49,622 org.nutz.ioc.loader.json.JsonLoader.(JsonLoader.java:52) DEBUG - Loaded 2 bean define from path=[ioc/] –&gt; [dataSource, dao]​ 2015-03-30 10:49:49,625 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 4 resource by src( net/wendal/nutzbook/ ) , regex( ^.+[.]class$ )​ 2015-03-30 10:49:49,638 org.nutz.ioc.loader.annotation.AnnotationIocLoader.addClass(AnnotationIocLoader.java:83) DEBUG - Found a Class with Ioc-Annotation : class net.wendal.nutzbook.module.UserModule​ 2015-03-30 10:49:49,652 org.nutz.ioc.loader.annotation.AnnotationIocLoader.(AnnotationIocLoader.java:60) INFO - Scan complete ! Found 1 classes in 1 base-packages!​ beans = [“userModule”]​ 2015-03-30 10:49:49,652 org.nutz.ioc.loader.json.JsonLoader.(JsonLoader.java:36) DEBUG - Loaded 5 bean define from reader –​ [txREPEATABLE_READ, txSERIALIZABLE, txNONE, txREAD_UNCOMMITTED, txREAD_COMMITTED] 解析 第一条, 输出IocBy的具体配置,根本就是完全重现实际配置(主模块上的IocBy) 第二条, 是资源扫描的log,但同时也是”*js”,”ioc/“ 所对应的日志. 含义是在classpath下的ioc目录找到1个js/json文件 第三条, JsonLoader读取dao.js的前置输出, 如果js出错了,下一条log就会变成XXX的json报错信息 第四条, JsonLoader读取dao.js的后置输出, 解析完成后的, 读取到了2个ioc bean定义 第五条, 也是资源扫描的log,但同时也是”*anno”, “net.wendal.nutzbook”所对应的日志, 含义是扫描net.wendal.nutzbook及子package的类 第六条, AnnotationIocLoader开始对扫描得到的类进行解析,寻找带@IocBean注解的类,这里就是找到的第一个类UserModule 第七条, AnnotationIocLoader结束处理的总结陈词, 说在N个根package中找到了M个注解ioc的定义. 最后一条, 看上去是JsonLoader的输出,实际上是*tx所对应的TransIocLoader的输出, TransIocLoader类代理了一个JsonLoader实例. 这个配置也把Aop事务的相关配置给加载了. 以前的做法是单独写个trans.js来声明. URL映射LOG​ 2015-03-30 10:49:49,679 org.nutz.mvc.impl.Loadings.scanModules(Loadings.java:98) DEBUG - module class location ‘file:/D:/nutzbook/workspace/.metadata/.plugins/org.eclipse.wst.server.core/tmp0/wtpwebapps/nutzbook/WEB-INF/classes/net/wendal/nutzbook/MainModule.class’​ 2015-03-30 10:49:49,679 org.nutz.mvc.impl.Loadings.scanModuleInPackage(Loadings.java:126) DEBUG - &gt; scan ‘net.wendal.nutzbook’​ 2015-03-30 10:49:49,681 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 4 resource by src( net/wendal/nutzbook/ ) , regex( ^.+[.]class$ )​ 2015-03-30 10:49:49,682 org.nutz.mvc.impl.Loadings.checkModule(Loadings.java:140) DEBUG -&gt;&gt; add ‘net.wendal.nutzbook.module.UserModule’​ 2015-03-30 10:49:49,698 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/‘&gt;&gt; UserModule.index(…) : void | @Ok(jsp:jsp.user.list) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,714 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/add’ &gt;&gt; UserModule.add(…): Object | @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,715 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/count’ &gt;&gt; UserModule.count(…) : int| @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,716 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/update’ &gt;&gt; UserModule.update(…) : Object | @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,720 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/delete’ &gt;&gt; UserModule.delete(…) : Object | @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,724 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/query’ &gt;&gt; UserModule.query(…) : Object | @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,726 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/login’ &gt;&gt; UserModule.login(…) : Object | @Ok(json:{locked:’password|salt’,ignoreNull:true}) @Fail(http:500) | by 0 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,727 org.nutz.mvc.impl.UrlMappingImpl.printActionMapping(UrlMappingImpl.java:130) DEBUG -‘/user/logout’ &gt;&gt; UserModule.logout(…) : void | @Ok(&gt;&gt;:/ ) @Fail(http:500) | by 1 Filters | (I:UTF-8/O:UTF-8)​ 2015-03-30 10:49:49,728 org.nutz.mvc.impl.NutLoading.evalUrlMapping(NutLoading.java:203) INFO - Found 8 module methods 解析 第一条, 显示MainModule所在的实际路径, 这是解决Maven下的扫描出错的bug的日志 第二条, 显示正在扫描的package的路径 第三条, 资源扫描的log, 均为MainModule中@Modules(scanPackage=true)所触发的扫描行为. 这里所得到4个类,但不等于就是4个模块, 带@At入口方法的类,才会成为模块类 第四条开始, 就是各入口方法的信息了, 现在挑第一条进行完整讲解 ‘/user/‘是映射的完整的路径. 类路径+方法路径 void 入口方法的返回值类型. 如果你配置了@Ok(“json”)然后返回值是String,它就是警告你. UserModule.index(…) 映射的类名及方法名 @Ok(jsp:jsp.user.list) @Ok的配置,这里的含义是jsp视图的jsp.user.list路径. @Fail(http:500) @Fail的配置,这是入口方法或适配器抛出异常才会执行的配置 by 1 Filters @Filters的配置,这里并不会给出完整的,不然真的很长很长. 请留意一下login方法时0个Filters. (I:UTF-8/O:UTF-8) 最后是编码设置,影响的是POST时的body编码,注意啊,URL的编码是不会受影响的,那不是Servlet API标准里面可以设置的内容. 入口方法配置优先级 第一原则, 不可叠加的注解, 例如Ok,Fail,Filters, 优先级是 入口方法&gt;类&gt;MainModule 可叠加的注解,其实只有At, 优先级是 入口方法+(类&gt;MainModule) Ioc获取对象的Log前面说了Ioc初始化的log,这里说的是Ioc.get产生的log, 也就是从Ioc容器获取bean的log 2015-03-30 10:49:49,729 org.nutz.mvc.impl.NutLoading.evalSetup(NutLoading.java:253) INFO - Setup application... 2015-03-30 10:49:49,729 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:144) DEBUG - Get &apos;dao&apos;&lt;interface org.nutz.dao.Dao&gt; 2015-03-30 10:49:49,730 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:166) DEBUG - &gt;&gt; Load definition 2015-03-30 10:49:49,732 org.nutz.ioc.loader.map.MapLoader.load(MapLoader.java:67) DEBUG - Loading define for name=dao 2015-03-30 10:49:49,736 org.nutz.ioc.loader.combo.ComboIocLoader.load(ComboIocLoader.java:137) DEBUG - Found IocObject(dao) in IocLoader(JsonLoader@1168025266) 2015-03-30 10:49:49,737 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:193) DEBUG - &gt;&gt; Make...&apos;dao&apos;&lt;interface org.nutz.dao.Dao&gt; 2015-03-30 10:49:49,750 org.nutz.ioc.aop.impl.DefaultMirrorFactory.getMirror(DefaultMirrorFactory.java:82) DEBUG - class org.nutz.dao.impl.NutDao , no config to enable AOP for this type. 2015-03-30 10:49:49,750 org.nutz.ioc.impl.ScopeContext.save(ScopeContext.java:59) DEBUG - Save object &apos;dao&apos; to [app] 2015-03-30 10:49:49,753 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:144) DEBUG - Get &apos;dataSource&apos;&lt;&gt; 2015-03-30 10:49:49,753 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:166) DEBUG - &gt;&gt; Load definition 2015-03-30 10:49:49,753 org.nutz.ioc.loader.map.MapLoader.load(MapLoader.java:67) DEBUG - Loading define for name=dataSource 2015-03-30 10:49:49,758 org.nutz.ioc.loader.combo.ComboIocLoader.load(ComboIocLoader.java:137) DEBUG - Found IocObject(dataSource) in IocLoader(JsonLoader@1168025266) 2015-03-30 10:49:49,758 org.nutz.ioc.impl.NutIoc.get(NutIoc.java:193) DEBUG - &gt;&gt; Make...&apos;dataSource&apos;&lt;&gt; 2015-03-30 10:49:49,777 org.nutz.ioc.aop.impl.DefaultMirrorFactory.getMirror(DefaultMirrorFactory.java:82) DEBUG - class com.alibaba.druid.pool.DruidDataSource , no config to enable AOP for this type. 2015-03-30 10:49:49,777 org.nutz.ioc.impl.ScopeContext.save(ScopeContext.java:59) DEBUG - Save object &apos;dataSource&apos; to [app] 2015-03-30 10:49:49,811 com.alibaba.druid.pool.DruidDataSource.init(DruidDataSource.java:669) INFO - {dataSource-1} inited解析 导致这些log的代码,其实就一句,在MainSetup里面.Dao dao = ioc.get(Dao.class); 第一条, 这其实是@SetupBy的log, 正是我们之前写的MainSetup类里面调用了ioc.get 第二条, 这是ioc.get方法在打印方法参数,不要误会那是对应ioc bean的属性. 另外, NutIoc是认名称,不是认类型的,默认就是首字母小写之后的类名(如果没有@IocBean或@InjectName配置的话) 第三条, 开始载入配置, 前置log,事情还没发生的 第四条, MapLoader(JsonLoader的超类)中找到名为dao的配置 第五条, ComboIocLoader提示在JsonLoader中找到名为dao的配置了 第六条, 再输出一次修正后的参数, 因为没东西需要修正,所以还是原样输出 第七条, 是AOP的拦截点, 因为没有对应的匹配方法,所以不需要对这个类启用AOP,跳过生成子类 第八条, 把当前的dao这bean的对象提前放入NutIoc的上下文, 是为了解决构造方法注入的问题 第九条到最后, dao这个bean的配置中引用了dataSource, 所以,往下的log都是为了生成dataSource对应的对象 Dao Log​ 2015-03-30 10:49:49,836 org.nutz.filepool.NutFilePool.(NutFilePool.java:23) INFO - Init file-pool by: C:\Users\wendal/.nutz/tmp/dao/ [200000]​ 2015-03-30 10:49:49,837 org.nutz.filepool.NutFilePool.(NutFilePool.java:37) DEBUG - file-pool.home: ‘C:\Users\wendal.nutz\tmp\dao’​ 2015-03-30 10:49:49,843 org.nutz.filepool.NutFilePool.(NutFilePool.java:66) INFO - file-pool.cursor: 120​ 2015-03-30 10:49:49,848 org.nutz.dao.jdbc.Jdbcs.(Jdbcs.java:85) DEBUG - Jdbcs init complete​ 2015-03-30 10:49:49,849 org.nutz.dao.jdbc.Jdbcs.getExpert(Jdbcs.java:98) INFO - Get Connection from DataSource for JdbcExpert​ 2015-03-30 10:49:50,062 org.nutz.dao.impl.DaoSupport$1.invoke(DaoSupport.java:165) DEBUG - JDBC Driver –&gt; mysql-connector-java-5.1.34 ( Revision: jess.balint@oracle.com-20141014163213-wqbwpf1ok2kvo1om )​ 2015-03-30 10:49:50,063 org.nutz.dao.impl.DaoSupport$1.invoke(DaoSupport.java:166) DEBUG - JDBC Name –&gt; MySQL Connector Java​ 2015-03-30 10:49:50,063 org.nutz.dao.impl.DaoSupport.setDataSource(DaoSupport.java:174) DEBUG - Database info –&gt; MYSQL:[MySQL - 5.5.5-10.1.2-MariaDB]​ 2015-03-30 10:49:50,070 org.nutz.resource.Scans.scan(Scans.java:228) DEBUG - Found 4 resource by src( net/wendal/nutzbook/ ) , regex( ^.+[.]class$ )​ 2015-03-30 10:49:50,120 org.nutz.dao.impl.sql.run.NutDaoExecutor._runSelect(NutDaoExecutor.java:193) DEBUG - SELECT COUNT(*) FROM t_user 分析 第一条, 初始化文件池,这是操作Blob/Clob时用到的东西,在虚拟主机使用nutz的时候有可能报错,这时候可以通过修改 org/nutz/dao/jdbc/nutz_jdbc_experts.js 修改里面的路径 第二条及第三条,提示路径及当前的偏移量 第四条, Jdbcs类加载nutz_jdbc_experts.js完成的提示,这是各种数据库方言的配置文件 第五条, 第一次从数据库连接池获取连接的前置log, 如果数据库配置出错,网络不通等等问题, 后面就只有报错的log了 第六条, 驱动程序的版本 第七条, 数据库版本. 我现在比较习惯MariaDB, 基本用法与mysql无异. 第八条, 是资源扫描的log,在扫描那些bean带@Table注解, 触发这句log的代码是 Daos.createTablesInPackage(dao, “net.wendal.nutzbook”, false); 第九条, 是查询User表有多少记录, java语句是 dao.count(User.class) 其余​ 2015-03-30 10:49:49,667 org.nutz.mvc.impl.NutLoading.createViewMakers(NutLoading.java:344) DEBUG - @Views(DefaultViewMaker)​ 2015-03-30 10:49:49,675 org.nutz.mvc.impl.NutLoading.createChainMaker(NutLoading.java:245) DEBUG - @ChainBy(org.nutz.mvc.impl.NutActionChainMaker)​ 2015-03-30 10:49:49,728 org.nutz.mvc.impl.NutLoading.evalLocalization(NutLoading.java:309) DEBUG - @Localization not define 解析 第一条, 是@Views配置,当前MainModule并没有配置,所以这是默认配置,将来用到自定义View的时候自然会配置上 第二条, ChainBy是动作链配置, 是Mvc中的核心配置,也是当前很少人用到的强大配置之一, 下一章就会用到 第三条, 是国际化相关, 在稍后的章节中会开始使用. ​]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Nutz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nutz：Jar包]]></title>
    <url>%2F2018%2F04%2F11%2FJava%2F%E6%A1%86%E6%9E%B6%2Fnutz%2FJar%E5%8C%85%E5%BC%95%E5%85%A5%2F</url>
    <content type="text"><![CDATA[jar包包的版本不一致会导致启动失败 先贴一个pom &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--日志log4j配置--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!--jstl jsp引擎--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.taglibs&lt;/groupId&gt; &lt;artifactId&gt;taglibs-standard-impl&lt;/artifactId&gt; &lt;version&gt;1.2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.taglibs&lt;/groupId&gt; &lt;artifactId&gt;taglibs-standard-spec&lt;/artifactId&gt; &lt;version&gt;1.2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.taglibs&lt;/groupId&gt; &lt;artifactId&gt;taglibs-standard-jstlel&lt;/artifactId&gt; &lt;version&gt;1.2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp.jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl-api&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--nutz包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.nutz&lt;/groupId&gt; &lt;artifactId&gt;nutz&lt;/artifactId&gt; &lt;version&gt;1.r.60&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid监控 web端监控--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.26&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jconsole&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;tools&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--mysql链接--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.mail&lt;/groupId&gt; &lt;artifactId&gt;mail&lt;/artifactId&gt; &lt;version&gt;1.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.liferay&lt;/groupId&gt; &lt;artifactId&gt;nl.captcha.simplecaptcha&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--quartz 好像是时间调动--&gt; &lt;dependency&gt; &lt;groupId&gt;org.nutz&lt;/groupId&gt; &lt;artifactId&gt;nutz-integration-quartz&lt;/artifactId&gt; &lt;version&gt;1.r.60.r2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--shiro 身份验证、授权、密码学和会话管理--&gt; &lt;dependency&gt; &lt;groupId&gt;org.nutz&lt;/groupId&gt; &lt;artifactId&gt;nutz-integration-shiro&lt;/artifactId&gt; &lt;version&gt;1.r.60.r2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-all&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-email&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;class_system&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.4.3.v20170317&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 原文链接]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Nutz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nutz：登录注册]]></title>
    <url>%2F2018%2F04%2F06%2FJava%2F%E6%A1%86%E6%9E%B6%2Fnutz%2F%E7%99%BB%E9%99%86%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[公共maven包如果出现版本不一致会产生错误 安全性的权限验证​ @Ok(“json:{locked:’password|salt’,ignoreNull:true}”)​ @Filters(@By(type=CheckSession.class, args={“me”, “/“})) OK:密码和salt不可以发送到浏览器去. Filters:如果当前Session没有带me这个attr,就跳转到/页面,即首页. 重写filter在login WEB-INF一般无法访问，因此需要中转， @Ok(“jsp:jsp.user.list”) // 真实路径是 /WEB-INF/jsp/user/list.jsp IOC配置文件在ioc的配置文件中,dao.js里conf是一个bean而不是一个文件夹,type和field为属性 var ioc = { conf : { type: &quot;org.nutz.ioc.impl.PropertiesProxy&quot;, fields: { paths: [&quot;custom/&quot;] } }}; druid web.xml druid或/rs下的路径,就无条件跳过NutFilter &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;/rs/*,/druid/*&lt;/param-value&gt; &lt;/init-param&gt; 动作链具体什么作用暂时不清楚动作链需要在MainModule配置@ChainBy(args=”mvc/nutzbook-mvc-chain.js”) idea需要在project structure的module里面将语言版本设置为8级，默认为5 quartz]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Nutz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nutz：增删改查]]></title>
    <url>%2F2018%2F04%2F06%2FJava%2F%E6%A1%86%E6%9E%B6%2Fnutz%2F%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[增删改查校验 strings的isblank检验某字符串是否为空或长度为0或由空白符(whitespace) 构成 通用 @Param(“..”)获取一个表单对象 re.setv是什么东西 修改 返回实际被更新的记录条数，一般的情况下，如果是单一Pojo,更新成功，返回 1，否则，返回 0 dao.updateIgnoreNull(user); 查询 查询的Cnd使用三目运算符是个不错的选择 Cnd cnd = Strings.isBlank(name)? null : Cnd.where(&quot;name&quot;, &quot;like&quot;, &quot;%&quot;+name+&quot;%&quot;); 分页查询 public QueryResult getPetList(Dao dao, int pageNumber, int pageSize){ Pager pager = dao.createPager(pageNumber, pageSize); List&lt;Pet&gt; list = dao.query(Pet.class, null, pager); pager.setRecordCount(dao.count(Pet.class)); return new QueryResult(list, pager); } QueryResult是查询的结果集 如果 pager 被传入了 null，则不分页 生成 Pager 对象的时候需要传入 “当前页数” 和 “页大小” Pager 虽然有 getRecordCount() 和 getPageCount() 方法，但是它不会自动被设值 -因为考虑到效率 通过 Pager.setRecordCount() 可以为 Pager 设置结果集的总数，Pager 会通过 getPageCount() 返回总页数 分页页数从1开始算,如果页数是0,代表不分页, list存放查询结果,pager转换结果集为页数]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Nutz</tag>
      </tags>
  </entry>
</search>
